{"/soft/maixpy/en/course/image/basic/vary.html": {"title": "Basic image transformation and common operations", "content": "---\ntitle: Basic image transformation and common operations\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: basic image transformation and common operations\n---\n\n\nHere is a brief introduction to the basic transformation operations of some frequently used images\n\nRotate:\n\n```python\nimg.rotation_corr()\n```\n\nChange the image size:\n\n```python\nimg.resize()\n```\n\nFor more image transformation, please see [image API](./../../../api_reference/machine_vision/image/image.html)\n\n## Introduction to image buffer\n\nMaixPy has designed two buffers for the image,\n* One is the `RGB565` buffer, as the name suggests, is a memory that stores the information of this picture in the format of `RGB565`. Note that the order in the memory is `[pixel 1 RGB, pixel 2 RGB...]`\n* The other is the `RGB888` buffer, as the name implies, a memory that stores the information of this picture in the format of `RGB88`. Note that the order in the memory is `[all pixels R, all pixels G, all pixels B]`, we also call it `AI` memory\n\nThe main reason for using two memory blocks here is that all image operations of the underlying code and `LCD` display are based on `RGB565`, but `KPU` needs the input of `RGB888`.\n\n```\n                   +---------------+\n                   |               |\n          +--------+ camera(sensor)+-------+\n          |        |               |       |\n          |        +---------------+       |\n          |                                |\n+---------v------+                +--------v---------+\n|                | img.pix_to_ai()|                  |\n|      RGB565    +--------------->+      RGB888      |\n|                |                |                  |\n+--------+-------+                +------+-----------+\n         ^                               |\n         |                               |\n         |                               v\n+--------+----------+             +------+-----------+\n|                   |             |                  |\n|     image ops     |             |   KPU            |\n|                   |             |                  |\n+-------------------+             +------------------+\n\n```\n\n\n\nWhen only the camera captures pictures, the hardware will automatically put a copy of the data into the `RGB888` memory area, and the other will not automatically fill the `RGB888` memory block. The software operation will only operate on the `RGB565` memory, and will not automatically update` RGB888`, (because the update takes time) This is worth noting,\nThis means that every time we change the memory block of `RGB565`, for example, execute `img = img.resize((224, 224))`, if you want `KPU` to use the changed image, you need to execute `img. pix_to_ai()` to manually update the image of `RGB565` to the area of ​​`RGB888`, and then you can call `kpu` related functions for model inference!\n\nThe same update in the opposite direction also provides API: `img.ai_to_pix()`, which will update the data in the `RGB888` area to the `RGB565` area\n\n\n## resize modify resolution\n\n```python\nimport image\nimg = image.Image(size=(100, 100))\nimg2 = img.resize(50, 50)\nprint(img)\nprint(img2)\n```\n\n## Get and modify pixel value\n\n```python\nimport image\nimg = image.Image(size=(10, 10))\nprint(\"pixel 0:\", img[0], img.get_pixel(0, 0))\nimg[0] = (255, 0, 0)\nimg = img.set_pixel(1, 0, (255, 255, 10))\nprint(\"after pixel 0 change:\", img[0], img[1])\n```\n\nThe second pixel `B` set here is `10`, and it is actually found to be `8`. This is a normal phenomenon. As mentioned earlier, the storage in the memory uses `RGB565` for storage, so it will Error\n\n\n## Copy image\n\n```python\nimport image\nimg = image.Image(size=(10, 10))\nimg2 = img.copy()\nimg2[0] = (255, 0, 0)\nprint(img[0], img2[0])\n```\n\n\n## Crop image\n\nAlso use the `copy` function\n\n```python\nimport image\nimg = image.Image(size=(10, 10))\nimg2 = img.copy(roi=(0, 0, 5, 5))\nimg2[0] = (255, 0, 0)\nprint(img)\nprint(img2)\nprint(img[0], img2[0])\n```\n\n\n## Convert to bytes object\n\nConvert to `RGB565` string\n\n```python\nimport image\nimg = image.Image(size=(10, 10))\nimg[0] = (255, 0, 0)\nimg_bytes = img.to_bytes()\nprint(\"bytes length: %d bytes[0]: %x%x\" %(len(img_bytes), img_bytes[0], img_bytes[1]))\n```\nThe output value here is in the format of `RGB565`, which means that one pixel is stored in two bytes\n\nIn addition, you can also compress the image to `JPEG` format first, and then convert it to `bytes`\n```python\nimport image\nimg = image.Image(size=(10, 10))\nimg = img.compressed(quality=20)\njpeg_bytes = img.to_bytes()\nprint(\"bytes length: %d bytes[0]: %x%x\" %(len(jpeg_bytes), jpeg_bytes[0], jpeg_bytes[1]))\n```\n\nUsing the `compressed` function here will not modify the original image, using the `compress()` function will modify the original image, but if the compressed size is larger than the original image, it will fail\n\n\n\n## Convert to grayscale image\n\n```python\nimg = img.to_grayscale(copy=False)\n```\n\nHere the `copy` parameter means whether to re-apply for a piece of memory without modifying the original image\n\n## Convert to RGB565 color image\n\nConvert to a color image, note that only the format has become a color image, the picture is not a color image, if you need to convert a gray image to a color image, use `img.to_rainbow()`\n\n```python\nimg = img.to_rgb565(copy=True)\n```\n\nHere the `copy` parameter means whether to re-apply for a piece of memory without modifying the original image\nIf the original image is grayscale, it must be `True`\n\n## Convert to color picture\n\n```python\nimg = img.to_rainbow(copy=True)\n```\n\nHere the `copy` parameter means whether to re-apply for a piece of memory without modifying the original image\nIf the original image is grayscale, it must be `True`\n\n## Save to file system\n\n```python\nimg.save(\"/sd/test.jpg\", quality=95)\nimg.save(\"/sd/test.bmp\")\n```\n\n\n## Rotate\n\n```python\nimg.rotation_corr([x_rotation=0.0[, y_rotation=0.0[, z_rotation=0.0[, x_translation=0.0[, y_translation=0.0[, zoom=1.0]]]]]])\n```\n\nThe brackets are optional parameters, that is, which axis to rotate along a certain angle. If this function is not available in the firmware of the `minimum` version, the full version of the firmware can be used"}, "/soft/maixpy/en/course/image/kernel-filter.html": {"title": "nuclear filtering", "content": "---\ntitle: nuclear filtering\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: nuclear filtering\n---\n\n\n![image-20200812191240724](kernel-filter.assets/image-20200812191240724.png)\n\n\nRoutine\n\n```python\n# Nuclear filtering\n#\n# This example demonstrates nuclear filtering.\nimport sensor, image, time\n\nsensor.reset() # Initialize the sensor\n#Set the image color format, there are RGB565 color map and GRAYSCALE grayscale\nsensor.set_pixformat(sensor.GRAYSCALE) # or sensor.RGB565\n#Set image pixel size\nsensor.set_framesize(sensor.QVGA) # or sensor.QQVGA (or others)\nsensor.skip_frames(time = 2000) # Let the new settings take effect\nclock = time.clock() # Track FPS frame rate\n\nkernel_size = 1 # 3x3==1, 5x5==2, 7x7==3, etc.\n\nkernel = [-2, -1, 0, \\\n          -1, 1, 1, \\\n           0, 1, 2]\n\nwhile(True):\n    clock.tick() # Track the number of milliseconds that have passed between two snapshots().\n    img = sensor.snapshot() # Take a picture and return the image\n\n    # Run the kernel on every pixel of the image.\n    # Run the kernel on each pixel of the image\n    img.morph(kernel_size, kernel)\n\n    print(clock.fps()) # Note: When connected to a computer, the frame rate will become half the speed. When the computer is not connected, the frame rate will increase.\n```"}, "/soft/maixpy/en/course/image/find_color_blob.html": {"title": "MaixPy Find color blocks", "content": "---\ntitle: MaixPy Find color blocks\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy find color blocks\n---\n\n\nFind all color blocks of the specified color in the picture\n\n## Instructions\n\nMaixPy has implemented a method to find color patches in the image module, and a non-minimum firmware version is required.\n\n* Get pictures from the camera\n\n```python\nimport image, sensor\nimg=sensor.snapshot()\n```\n\n* Find a list of all color block objects (image.blob) from the picture, and the incoming color threshold parameters follow the LAB format (l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)\n\n```python\ngreen_threshold = (0, 80, -70, -10, -0, 30)\nblobs = img.find_blobs([green_threshold])\n```\n\n* Manipulate color block objects\n  \nOperate the color block object according to your own needs, for example, mark the color block object with a rectangular frame in the image\n\n```python\ntmp=img.draw_rectangle(b[0:4])\n```\n\nFor detailed API introduction, please refer to [API-Image](../../api_reference/machine_vision/image/image.html).\n\n## Routine\n\nFind the green patch\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\ngreen_threshold = (0, 80, -70, -10, -0, 30)\nwhile True:\n    img=sensor.snapshot()\n    blobs = img.find_blobs([green_threshold])\n    if blobs:\n        for b in blobs:\n            tmp=img.draw_rectangle(b[0:4])\n            tmp=img.draw_cross(b[5], b[6])\n            c=img.get_pixel(b[5], b[6])\n    lcd.display(img)\n```"}, "/soft/maixpy/en/course/image/sensor.html": {"title": "Sensor", "content": "---\ntitle: Sensor\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Sensor\n---\n\n\nThe sensor module is used to set the parameters of the photosensitive element.\n\nUse routine:\n\n-Real-time preview camera\n\n    ```python\n    import sensor #Introduction of the photosensitive element module\n    sensor.reset()#Initialize the photosensitive element\n    sensor.set_pixformat(sensor.RGB565)#Set to color\n    sensor.set_framesize(sensor.QVGA)#Set the size of the image\n    sensor.skip_frames()#Skip n photos, after changing the settings, skip some frames and wait for the photosensitive element to stabilize.\n\n    while(True):\n        img = sensor.snapshot()#take a photo, img is an image object\n    ```\n\n-Initialization\n\n    ```python\n    sensor.reset()# Initialize the photosensitive element\n    #Set color/black and white\n    sensor.set_pixformat()# Set the pixel mode.\n    sensor.GRAYSCALE# Grayscale, 8bit per pixel.\n    sensor.RGB565# Color, 16bit per pixel.\n    ```\n\n-Set image size\n\n\n    sensor.QQCIF# 88x72\n    sensor.QCIF# 176x144\n    sensor.CIF# 352x288\n    sensor.QQSIF# 88x60\n    sensor.QSIF# 176x120\n    sensor.SIF# 352x240\n    sensor.QQQQVGA# 40x30\n    sensor.QQQVGA# 80x60\n    sensor.QQVGA# 160x120\n    sensor.QVGA# 320x240\n    sensor.VGA# 640x480\n\n    ```python\n    sensor.set_framesize()# Set the size of the image\n    ```\n\n-Skip some frames\n\nsensor.skip_frames(n=10) Skip n photos, after changing the settings, skip some frames and wait for the sensor to stabilize.\n\n-Get an image\n\nsensor.snapshot() takes a picture and returns an image object.\n\n-Auto gain / white balance / exposure\n\nsensor.set_auto_gain() Automatic gain is turned on (True) or turned off (False).\n\nWhen using color tracking, you need to turn off automatic gain.\n\nsensor.set_auto_whitebal() Automatic white balance is turned on (True) or turned off (False).\n\nWhen using color tracking, you need to turn off the automatic white balance.\n\nsensor.set_auto_exposure(enable[\\, exposure_us])\n\nenable Turn on (True) or turn off (False) automatic exposure. Open by default.\n\nIf enable is False, you can use exposure_us to set a fixed exposure time (in microseconds).\n\n-Set window ROI\n\n```python\nsensor.set_windowing(roi)\n```\n\nROI: Region Of Interest, the term \"region of interest\" in image processing. It is the area to be processed extracted from the image to be processed.\n\n```python\nsensor.set_framesize(sensor.VGA) # high resolution\nsensor.set_windowing((240, 240)) #Take the 240*240 area in the middle\n```\n\nThe format of roi is (x, y, w, h).\n\n\n-Set flip\n\n```python\n#Horizontal flip\nsensor.set_hmirror(True)\n# Flip vertically\nsensor.set_vflip(True)\n```"}, "/soft/maixpy/en/course/image/adaptive-histogram-equalization.html": {"title": "", "content": "---\ntitle:\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc:\n---\n\n\n\n```python\n# Adaptive histogram equalization example\n#\n# This example shows how to use adaptive histogram equalization to improve the contrast in the image.\n#Adaptive histogram equalization divides the image into regions, and then equalizes the histograms in these regions,\n#To improve image contrast and global histogram equalization.\n#In addition, you can specify clipping limits to prevent the contrast from becoming wild.\n\nimport sensor, image, time\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QQVGA)\nsensor.skip_frames(time = 2000)\nclock = time.clock()\n\nwhile(True):\n    clock.tick()\n\n    # clip_limit <0 provides you with normal adaptive histogram equalization, which may cause a lot of contrast noise...\n\n    # clip_limit=1 Do nothing. For best results, please slightly higher than 1, as shown below.\n    # The higher the value, the closer it is to the standard adaptive histogram equalization, and will produce huge contrast fluctuations.\n\n    img = sensor.snapshot().histeq(adaptive=True, clip_limit=3)\n\n    print(clock.fps())\n```"}, "/soft/maixpy/en/course/image/find_qrcodes.html": {"title": "MaixPy Find QR code", "content": "---\ntitle: MaixPy Find QR code\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy find QR code\n---\n\n\nRecognize the two-dimensional code from the picture. The common two-dimensional code is QR Code. The full name of QR is Quick Response. It can store more information and represent more data types than the traditional bar code (Bar Code).\n\n## Instructions\n\nThe image module has implemented a method to find the QR code, you need to use a non-minimum firmware version, you need to prepare a QR code, you can use [caoliao QR code](https://cli.im/) to generate the content you want .\n\n* Get pictures from the camera, and point the camera at the QR code\n\n```python\nimport image, sensor\nimg=sensor.snapshot()\n```\n\n* Find a list of all QR code objects (image.qrcode) from the picture\n\n```python\nres = img.find_qrcodes()\n```\n\n* Manipulate QR code objects\n\nE.g. print information\n\n```python\nprint(res[0].payload())\n```\n\nFor detailed API introduction, please refer to [API-Image](../../api_reference/machine_vision/image/image.html).\n\n## Routine\n\nRecognize the QR code. If the QR code cannot be recognized, please try to change the `sensor.vflip()` function parameter.\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\n\nclock = time.clock()\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.set_vflip(1)\nsensor.run(1)\nsensor.skip_frames(30)\nwhile True:\n    clock.tick()\n    img = sensor.snapshot()\n    res = img.find_qrcodes()\n    fps =clock.fps()\n    if len(res)> 0:\n        img.draw_string(2, 2, res[0].payload(), color=(0,128,0), scale=2)\n        print(res[0].payload())\n    lcd.display(img)\n```"}, "/soft/maixpy/en/course/image/image_draw_font/image_draw_font.html": {"title": "How to display Chinese", "content": "---\ntitle: How to display Chinese\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: how to display Chinese\n---\n\n\nMaixPy supports loading Unicode fonts. Unicode (Unicode, Universal Code, Single Code) is an industry standard in the field of computer science.\n\nThe following languages ​​are supported:\n\n* A Latin capital letter \"A\" A\n* ß Latin lowercase letter \"Sharp S\" ß\n* þ Lowercase Latin letter \"Thorn\" þ (not supported by small fonts)\n* Δ Uppercase Greek letter \"Delta\" Δ\n* Й Capital Cyrillic \"Short I\" Й\n* ק Hebrew letter \"Qof\" ק\n* م Arabic letter \"Meem\" م\n* ๗ Thai number 7 ๗\n* ቐ Ethiopian syllable \"Qha\" ቐ\n* あ Hiragana in Japanese \"A\" あ\n* ア Japanese Katakana \"A\" ア\n* Ye Simplified Chinese character \"叶\" Ye\n* Turn Traditional Chinese characters \"转\" to turn\n* 엽 Korean syllable text \"Yeob\" 엽\n\nThis functional interface is completed by using the `image.Image()` object. Please use the latest version of MaixPy firmware September 2, 2020.\n\n## Font interface\n\nUse draw_font to print font strings, similar to `img.draw_font(10, 20, 8, 8, b'/x20/xFC/xFC/x2C/xAC/x4C/x4D/xA3')`.\n\n```python\nimport lcd, image\nlcd.init()\nimg = image.Image()\ntmp = b'/x20/xFC/xFC/x2C/xAC/x4C/x4D/xA3'\nimg.draw_font(10, 20, 8, 8, tmp, scale=1, color=(255, 255, 255))\nlcd.display(img)\n```\n\nExample reference [image_draw_font.py](https://gitee.com/Sipeed/maixpy_scripts/tree/master/multimedia/gui/image/demo_draw_font/image_draw_font.py).\n\n## Font library interface\n\nPlease use font_load / font_free to load or release the font first. This will improve the function of draw_string and support loading from the `xx.Dzk` file and Flash address. After that, draw_string will print the string through the font. Currently only `ASCII` / ` UTF-8` encoding.\n\n> Attached font file [0xA00000_font_uincode_16_16_tblr.Dzk](https://gitee.com/Sipeed/maixpy_scripts/tree/master/multimedia/gui/image/demo_draw_font/tools/0xA00000_font_uincode_16_16_tblr.Dzk)\n\n```python\nimport lcd, image\nlcd.init()\nimg = image.Image()\n# image.font_load(image.UTF8, 16, 16, 0xA00000)\nimage.font_load(image.UTF8, 16, 16,'/sd/0xA00000_font_uincode_16_16_tblr.Dzk')\nimg.draw_string(20, 90, b'こんにちは、世界', x_spacing=2, mono_space=1)\nimage.font_free()\nlcd.display(img)\n```\n\nExample reference [image_draw_string.py](https://gitee.com/Sipeed/maixpy_scripts/tree/master/multimedia/gui/image/demo_draw_font/image_draw_string.py).\n\n## display effect\n\n![view_image_font](./view_image_font.jpg)\n\n## Font Tool\n\nWe will use [FontGenerator.zip](https://gitee.com/Sipeed/maixpy_scripts/tree/master/multimedia/gui/image/demo_draw_font/tools/FontGenerator.zip) in the root directory to export the font corresponding to the font, please See the figure below to complete the export operation.\n\n1. Select the font encoding type as Unicode encoding, which will support the languages ​​of most countries.\n\n   ![image-20200902180913322](./image-20200902180913322.png)\n\n2. Select the scanning mode, which is the scanning and printing direction of 5 horizontal, up and down, then left and right fonts.\n\n   ![image-20200902181130459](./image-20200902181130459.png)\n\n3. Create the font library after configuring the required font style as shown in the figure below.\n\n   ![image-20200902181311553](./image-20200902181311553.png)\n\n4. Just save it in DZK format, the font data access method is shown in the text description\n\n   ![image-20200902181442677](./image-20200902181442677.png)\n\n## Font tool\n\n> Warning: It is not recommended to use font tools, and those who do not understand should not use it.\n\nUse [Pc2Lcd2002.zip](https://gitee.com/Sipeed/maixpy_scripts/tree/master/multimedia/gui/image/demo_draw_font/tools/Pc2Lcd2002.zip) in the directory to get the character string of the font.\n\n1. Confirm that the software is in character mode.\n\n![image-20200902175614964](./image-20200902175614964.png)\n\n\n\n2. Set as shown in the figure to export the desired string.\n\n   ​ ![image-20200902180153452](./image-20200902180153452.png)\n\n3. After filling in the text, click to generate the font.\n\n   ![image-20200902175948599](./image-20200902175948599.png)\n\n4. Extract the font string and use it.\n\n   ![image-20200902180505263](./image-20200902180505263.png)\n\n```\n This (0) is (1) test (2) test (3)\n\n/x00/x20/x10/x17/x00/x02/xF1/x10/x10/x10/x11/x12/x14/x28/x47/x00/x80/x40/x40/xFC/x10/x10/x20/xA0/x40 /xA0/x10/x08/x08/x00/xFE/x00 This 0\n/x1F/x10/x10/x1F/x10/x10/x1F/x00/xFF/x01/x11/x11/x11/x29/x45/x83/xF0/x10/x10/xF0/x10/x10/xF0/x00/xFE /x00/x00/xF8/x00/x00/x00/xFE is 1\n/x00/x27/x14/x14/x85/x45/x45/x15/x15/x25/xE5/x21/x22/x22/x24/x08/x04/xC4/x44/x54/x54/x54/x54/x54/x54 /x54/x54/x04/x84/x44/x14/x08 test 2\n/x00/x20/x10/x10/x07/x00/xF0/x17/x11/x11/x11/x15/x19/x17/x02/x00/x28/x24/x24/x20/xFE/x20/x20/xE0/x20 /x10/x10/x10/xCA/x0A/x06/x02 try 3\n```\n\n> You can use the graphics mode to draw your favorite font graphics, supporting 32 * 32 graphics.\n>\n> ![image-20200902181645277](./image-20200902181645277.png)"}, "/soft/maixpy/en/course/image/image_counting-cells.html": {"title": "MaixPy achieves cell counting", "content": "---\ntitle: MaixPy achieves cell counting\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixPy for cell counting\n---\n\n\n> counting-cells\n\nSteps to achieve cell counting:\n\nOriginal image-grayscale image-corrosion expansion-binarization threshold-filtering operation-counting\n\n\n```python\n\n```"}, "/soft/maixpy/en/course/image/basic_operation.html": {"title": "basic operations of the image", "content": "---\ntitle: basic operations of the image\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: basic operations of images\n---\n\n\n## Coordinates\n\n### Get/Set pixels\n\nWe can get the value of a pixel through the image.get_pixel(x, y) method.\n\n-image.get_pixel(x, y)\n\n    For grayscale image: Return the grayscale value of (x,y) coordinates.\n\n    For color images: return the (r, g, b) tuple of (x, y) coordinates.\n\nSimilarly, we can use the image.set_pixel(x, y, pixel) method to set the value of a pixel.\n\n-image.set_pixel(x, y, pixel)\n\n    For grayscale image: Set the grayscale value of (x,y) coordinates.\n\n    For color images: Set the (r, g, b) value of (x, y) coordinates.\n\nFor example:\n```python\nimg = sensor.snapshot()\nimg.get_pixel(10,10)\nimg.set_pixcel(10,10,(255,0,0))#Set the pixel of coordinate (10,10) to red (255,0,0)\n```\n\n### Get the width and height of the image\n\n-image.width()\n\n    Returns the width of the image (pixels)\n\n-image.height()\n\n    Returns the height of the image (pixels)\n\n-image.format()\n\n    The grayscale image will return sensor.GRAYSCALE, and the color image will return sensor.RGB565.\n\n-image.size()\n\n    Returns the size of the image (byte)\n\n### Image operation\n\n-image.invert()\n\n    Inversely, for a binarized image, 0 (black) becomes 1 (white), and 1 (white) becomes 0 (black).\n\n    Note:\n    The image can be another image object, or an image object read in from a (bmp/pgm/ppm) file.\n    Both images must be the same size and type (grayscale image/color image).\n\n-image.nand(image)\n\n    Perform NAND operation with another picture.\n\n-image.nor(image)\n\n    Perform a NOR operation with another picture.\n\n-image.xor(image)\n\n    Perform an exclusive OR (XOR) operation with another picture.\n\n-image.xnor(image)\n\n    Perform XNOR operation with another image.\n\n-image.difference(image)\n\n    Subtract another picture from this picture. For example, for each pixel of each channel, subtract the absolute value operation. This function is often used for motion detection."}, "/soft/maixpy/en/course/ai/basic/dnn_basic.html": {"title": "Basic knowledge of deep neural network (DNN)", "content": "---\ntitle: Basic knowledge of deep neural network (DNN)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: basic knowledge of deep neural network (DNN)\n---\n\n\nHere is the knowledge you need to know to use MaixPy AI related functions, so that you can understand the following content, so I won't introduce it in depth in this article.\n\n## How to solve a problem-lead the machine to solve the problem\n\nA question is usually divided into **input** and **output (result)**\n\nFor example:\nA straight line in the coordinate system is as follows, the value of the above data point is known:\n![y=kx+b](../../../../assets/dnn/ykxb.jpg)\n\nNow ask the question, if the data point law does not change, enter an x ​​coordinate of 20, what is the value of y?\nAccording to everyone’s knowledge, we all know that this is a one-variable linear equation (`y = kx + b` can be solved). Bring in the values ​​of two points and calculate the equation as `y = 3x + 10`, then when `x=20 The value of `, `y` is `70`, so the input is `20` and the output is `70`.\n\nHere is input (`20`) + algorithm (one-variable linear equation) = output (`70`). This is the basic method we use to solve a problem, so the key is to find the one that conforms to the law of data points on this line segment algorithm.\n\nHumans are very powerful, they will summarize and learn from these data, and finally get this algorithm (equation), and then other people can directly use this algorithm to quickly solve similar problems, then, is there a way to let the machine automatically To find this algorithm?\n\n\n## How to let the machine summarize the algorithm\n\nTo let the machine automatically summarize the algorithm, that is, machine learning (ML, Machine Learning), let's take a look at how humans get this algorithm (equation).\n\n* Step 1: First, there are a large number of data points, and then based on these data points, humans found that the straight line conforms to the algorithm `y = kx + b`, which adapts to all straight lines, but found that there are two unknowns `k` and ` b`, this is the parameter that adapts to any straight line\n* Step 2: Then what kind of straight line is the specific, because the equation has two unknowns, namely the parameters, put the actual two data points into this equation, and get `k = 3` and `b = 10`\n* Step 3: Then we use the online data points that are not used in step 2 to try whether the algorithm (equation) is correct, and finally we find that they are all verified correctly\n* Step 4: Then you need to know the value of `y` of other points through the value of `x`, just substitute `y = 3x + 10`\n\n\nSo, can machine learning also use this step?\n\n* We thoughtfully designed an algorithm structure, adding that we happened to design it directly as `y = kx + b`, we left two parameters for the specific straight line, let’s call this structure **model structure** for now, because There are unknown parameters, which we call the untrained model structure. Where `x` is called **input**, and `y` is called **output**\n\n* Now, we substitute a few points of our straight line into this equation, we call this process **training**, to get the algorithm `y = 3x + 10`, there are no unknown parameters, we now call it It is a **model** or a trained model, where `kb` is the parameter in the model, and `y = kx + b` is the structure of the model. The data points brought into training are called **training data**, and their collective name is **training data set**\n\n* Then, we use several data points on the line segment that are not used in the training process as input, substitute this model for calculation, and get the result, such as `x = 10`, get `y = 40`, and then compare the output Whether the value is consistent with expectations, here we find that `x = 10, y = 40` is indeed on the straight line in the figure, and this point is not used during training, indicating that the model we got passed this verification. The process is called **verification**, `x = 10, y = 40` This data is called verification data. If we use multiple sets of data to verify this model, the collective term for these data is called **validation data set**\n\n* Now, we have obtained a **model**, and verified this model with **validation data set**, which seems to be very accurate, then we can assume that this model basically satisfies our future. x`, requires the value of `y` at any point on the line in the figure, you can enter `x` to give the `y` coordinate of the corresponding point on the line. This process is actually **using the model**, this process is called **reasoning**\n\nIn fact, this is regarded as machine learning. What we humans need is to design the structure of `y = kx + b`, and give **training data set** and **validation data set**, after **training** And **verify** to get a model we think is available, and then use `input + model` to get the correct `output (result)`.\n\n\n\n## What is a deep neural network?\n\nDeep neural network (DNN) is a technology in the field of machine learning (ML).\n\nI mentioned a relatively simple example. According to a straight line data to predict any point on the straight line, the structure of `y = kx + b` is artificially designed and very simple. When used for complex data, it is not found Applied, such as \"Is this picture a ball or a toy\"\n\n![小球](../../../../assets/dnn/ball.jpg) ![toy](../../../../assets/dnn/toy.jpg )\n\nIn order to store the information of the next straight line in the model, the structure `y = kx + b` is used, and the features of the straight line are all stored in the model.\nThe features used to store a picture now, the linear structure of `y = kx + b`, and the two parameters of `k and b` obviously cannot be satisfied. A better structure needs to be designed. The network ** appeared, a kind of mesh structure, which can better remember the characteristic information of the picture, and this mesh structure is multi-layered, that is, it has depth, so it is called a deep neural network (DNN). , Deep neural network), so DNN is a network structure and a means to realize machine learning. Each layer is composed of multiple nodes, as shown in the figure below, a DNN contains **input layer**, **hidden layer**, **output layer**, where the hidden layer consists of three layers (`A[1] , A[2], A[3]`layer), but collectively referred to as hidden layers:\n\n![Deep Neural Network](../../../../assets/dnn/dnn.jpg)\n\n**Input layer**:\nThe figure is a deep neural network structure, `x` is the input, for example, `x` here can be a picture, the input has multiple nodes, each node can be a pixel value, here the input layer draws 7 nodes, add We have a picture with a resolution of `10 x 10`, so the input layer requires a total of `100` nodes.\nHere the input layer is a one-dimensional structure, and the actual situation may have a multi-dimensional structure. For example, if the input is a grayscale image with a resolution of `3x3`, this is actually a two-dimensional structure, that is, a matrix with two rows and two columns (about the matrix Please study the concept by yourself, or understand it as a two-dimensional array for the time being), such as:\n```\n[[109 138 110]\n [220 37 166]\n [32 243 67]\n]\n```\nThe value range of each pixel is ∈[0, 255], and then we flatten it into a one-dimensional array of 9 data for the input layer\n```\n[109 138 110 220 37 166 32 243 67]\n```\n\n> In addition, the value of the input layer will generally be normalized to the range `[0, 1]`\n\nIf it is a color picture, it is three-dimensional, that is `height, width, color channel`, color channels such as `RGB` three color channels, that is, the input has a shape (including the dimensions and the number of data in each dimension), For example, the one-dimensional input shape above is `(9)`, and other images usually use `(height, width, number of channels)` to represent the shape, such as `(10, 10, 3)` for resolution of `10 x 10` , And there are three color channels, such as `RGB`.\n\nHere for the sake of getting started, the principle only introduces one-dimensional situation\n\n\n**Output layer**:\n`y` is the output. The output here has two values. You can understand that the achievement is the `list` of MaixPy's two floating-point values. `[Y1, Y2]`, `Y1` is the probability of being a small ball`, value ∈[0, 1], `Y2` is `probability of being a toy`. So in the end, we use this model, which is to give it a picture. The machine calculates according to the structure and algorithm specified by this model to get a `list`, and we know what is in the picture based on the output value.\n\n**Hidden layer**:\nThe hidden layer connecting the input layer and the output layer, as well as the connection in between, are responsible for calculating the input data into a reasonable output value.\n\n\n## Rest in between, summary\n\nSo far, you know what a **model** is: it is a set of data structures that save the shape of a network and the parameters inside. Usually, the data of this model can be saved as a file, such as `.h5. Files such as tflite.kmodel` are used to explain the shape structure and parameters of this model, but they are used by different software.\nPeople only need to design the model structure and parameters to solve a class of problems, such as common object classification, such as the distinction between a ball or a toy in a picture as mentioned above.\nThere are many parameters in this model. Specifically, when an object needs to be identified, a data set of known classification is used to allow the machine to automatically train a set of appropriate model parameters.\nThen we can enter the data and let the model infer the type of the input data.\n\nTherefore, if we don’t need to train the model and directly use the model trained by others, we only need:\n* Confirm the requirements and find a ready-made model, because the model has been trained, and the meaning of the input and output shapes has been determined\n* Confirm the input shape of the model, such as the model input resolution `10x10` color image, you need to pass the required image to an input layer when using it\n* Confirm the meaning of the output layer, such as the aforementioned recognition of balls and toys, and the final output is a list representing the probability of the object, such as `[0.9, 0.1]`, the first value represents the probability of a ball, Then we know that there is a 90% probability of a small ball in this picture, and only a 10% probability of a toy\n* Put the model into the inference program to run. Don’t worry about the specific procedure, it will be introduced in the next chapter\n\nAt this point, you should roughly understand the following things:\n* What is machine learning\n* What is a deep neural network (simple concept)\n* What is the model\n* What is the input layer, the output layer, what are the meanings of the classification applications in the example above, and what is the shape of the layer?\n* So far, I may not know what model training is\n* If I need a model, I know how to confirm the demand\n\nSo, **if you only want to be able to use the model and don’t need training, you can do it here**, and you don’t need to know anything about the model, just use it as a **black box toolbox**. can. If you want a deeper understanding, please continue to read the following content.\n\n\n\n## Continue: Deep Neural Networks (Continued\n\nNow that we have designed a multi-layer design, let's go deeper:\n\n**Data flow**, **weight**, **bias**:\nWhen the model is inferring, the data flows from the input layer to the output layer, which is the direction of these mesh arrows (section 3 mesh diagram). The calculation from the previous layer to the next layer of each arrow can use a familiar formula: `y = wx + b`, call `w` as **weight** (weight), `b` as **bias** (bias), note that each arrow has a separate `w, b `, that is to say, the value of the node of the next layer is equal to the value of the node of the previous layer after the calculation of this formula, the node of the next layer has multiple nodes of the previous layer, it is equal to the value of all the nodes of the previous layer after this The sum of the calculated values ​​of the formula.\nAfter so many calculations, the result finally appeared in the form of a value in the output layer, and the whole reasoning was completed.\n\n**Activation function**:\n\nAlthough the above model can get results through input, it will be found that all layer calculations are linear functions, so no matter how many layers there are, the whole is actually a linear function, that is, `y0 = w1x + b1` + `y = w2y0 + b2 `==> `y = w2(w1x + b1) + b2` ==> `y = w2w1x + w2b1 + b2`, in fact it is still a linear function, then the meaning of multiple layers is gone, so we need to add in the middle Non-linear functions make the network a little more complicated, so I will do tricks on each node. Before each node outputs data, use a non-linear function to calculate it, such as `sigmod` or `relu` function. It’s actually very simple to hear the name. Looking at the picture below, in short, x and y are not linear:\n![sigmod](../../../../assets/dnn/sigmod.jpg) ![relu](../../../../assets/dnn/relu.jpg)\n\nThat is, until now, except for the input layer, the output value of all nodes needs to go through `Sigmod(∑(Wn * x + Bn))`, and output a floating point value\n**softmax**:\n\nWhen the output layer is finally output, because of the previous calculations, the value range is not very uniform. Although we can compare the size, the largest value is considered the answer, but for the sake of uniformity and intuitively know the possibility of each category (In addition, for the accuracy of training, I won’t talk about it here.) As mentioned earlier, the probability of a category we finally output has a value range ∈[0, 1], and the sum of all output values ​​is `1`, so All values ​​of the output layer are processed after the output layer, the formula is\n![softmax](../../../../assets/dnn/softmax.jpg)\n\nAt this point, the inference process from input to output is over\n\n## Deep neural network training\n\nEarlier we briefly introduced the structure and composition of deep neural networks and the forward process from the input layer to the output layer. When we use the model, this is the forward process.\nThen, the model is set, and the parameters (such as `w, b`) in it are all random values. How to make it automatically train to get the values ​​of the parameters in the model? As we mentioned earlier, we use some data input with known results to get the parameters. Similarly, here we also input data with known results to get the first output result\n\n**Judging the output accuracy (accuracy) (or error/loss)** and **loss function**:\n\nThe results are obtained in the output layer. For example, `[0.6, 0.4]` represents the probability of a small ball `0.9`, and the probability of a toy is `0.1`, but because it is data with known answers, the actual correct answer is `[ 1.0, 0.0]`, which obviously does not meet the requirements.\nTherefore, the error between the correct answer and the calculated answer is: `[0.4, -0.4]`, but one problem is that the range of the error value is not very attractive. If the value range of the error is ∈`[0, ∞] `Just fine. In high school mathematics, there is a function `y = log10(x)`, the coordinate diagram is as follows:\n![log10](../../../../assets/dnn/log10x.jpg)\nIt is found that when `x` takes the value ∈`[0, 1]`, the value of `-y` is exactly ∈`[0, ∞]`, and our output result is also exactly ∈`[0, 1]`! Therefore, we directly calculate the error like this: `error = -log10(output)`, that is, the closer the output is to `1`, the closer the error is to `0`. This method is called `CEE, Cross Entropy Error)`, in addition to this method, there are other methods such as Mean Squared Error (MSE, Mean Squared Error), etc.\n\nAt this point, we know the error between the current result and the actual result\n\n**Back propagation of error** and **Parameter optimization (weight update)**:\nBecause the parameters of the model do not meet our expectations, we need to modify the parameters. We use backpropagation.\nEarlier we got the error, because the parameters are not correct enough, we use this error to modify the parameters in the model to achieve the effect of fine-tuning the parameters in the model. It is as if you are turning on a faucet. If the water hits (that is, the error is large), tighten the switch a little bit, loosen it a little bit if it is smaller, and adjust it.\nJust like our forward calculation, this time we changed it to reverse. From back to front, we can get the error value at each node, and then update the parameters in the model according to a certain learning rate. I won't elaborate on it for the time being.\n\nIn short, after a round of reverse adjustment of parameters, a new model is obtained\n\n**Measure the quality of the model: training set error and validation set error**:\n\nWe use the data in the training data set to repeatedly perform forward inference to obtain the error, and then adjust the process in the reverse direction. After using the training data set, we may get a relatively small error, but this only shows that the model is The data is more accurate, and some new data may not be accurate, so we need to use some data that is not in the training set to **verify** the effect of the model:\nWe use **validation data set** to forward inference and get the error, because the validation data set is not involved in training, which means that the parameters of the model and the validation data set have nothing to do with each other. We use the error obtained to constant the model The better or worse, the smaller the error, the better the effect\n\n**Multiple iterations**:\n\nIf you have trained all the data sets and find that the error is still large, you can continue training with multiple training methods, that is, **multiple iterations**. After each iteration, use the verification data set to verify the effect. If the error of the training set and the error of the validation set are small enough, we can temporarily assume that the model has good results.\n\n**Test Set**:\nAt this time, we can use another batch of new data to test the effect of our model, because this is brand-new data, did not participate in the training and did not participate in the verification (that is, determine when to stop training), theoretically more Credibility. If the test error is small, then the training is considered successful\n\n**Optimize training**:\nIf the final effect is not very good, there are many places to adjust, such as\n* The number of training iterations is not the more the better. Too much training on a batch of data sets may cause the model to be effective only for this batch of data, and the generalization ability is not enough, that is, **overfitting**\n* The learning rate of each training can also be adjusted\n* Check the data set, whether there are some data that affect the classification\n* Optimize the network structure, whether it is input or output or internal structure and parameters, according to different data and tasks can have a better design, also called **feature engineering**\n\n\n## Said at the end\n\nAt this point, you should roughly understand the following things:\n* What is machine learning\n* What is a deep neural network\n* What is the model\n* What is the input layer, the output layer, what are the meanings of the classification applications in the example above, and what is the shape of the layer?\n* What is training and what is its function\n* What are the data training set, validation set, and test set, where are they used, and what needs to be paid attention to\n* What is the standard to measure the quality of the model\n\nIf you still don’t understand, you can understand it again carefully, or refer to related materials. If you find a better way to explain it, please follow the document contribution method in the left directory to participate in the contribution.\n\n\n## Modify record\n\n| Date | Author | Remarks |\n| --- | --- | --- |\n| 2020.11.17 | [neucrack](https://neucrack.com) | Initial version, introducing the basic concepts of deep neural networks according to MaixPy needs, first draft |"}, "/soft/maixpy/en/course/ai/basic/maixpy_hardware_ai_basic.html": {"title": "Basic knowledge of MaixPy AI hardware acceleration", "content": "---\ntitle: Basic knowledge of MaixPy AI hardware acceleration\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Basic knowledge of MaixPy AI hardware acceleration\n---\n\n\n## Model usage and hardware acceleration principle\n\nEarlier, we learned that a model is a data organization and many parameters, and finally exists in the form of a file such as a file in the format of `kmodel`.\nAnd for this model to be used in the MaixPy program, the program must first understand the file format of `kmodel` and support the algorithm in the model, so that the input can be output after some split calculation processes according to the description of the model.\n\nTherefore, the key point is to support the algorithms in the model, called **operators**. In theory, we can use software to implement these operators, and then we can successfully run the model. The physical device that executes the software is the CPU. The network model is very computationally intensive. In addition, what we input is a picture. The picture itself has a huge amount of data. Even the main frequency of `K210` and `400MHz` cannot satisfy the smooth calculation model.\n\nTherefore, either upgrade the `CPU`, but the cost is too high, or make a dedicated hardware, let this hardware specialize in a specific algorithm, because it does not do general calculations like the `CPU`, so the speed will be very fast. , We usually use a dedicated graphics accelerator card called `GPU` to accelerate graphics calculations. On the `K210`, this dedicated hardware is called `KPU` (kendryte proccess unit). The first one is the company name, which is actually the same as other chips. The `NPU` does the same thing.\n\nIn MaixPy, the code to derive the model has been integrated, and the `KPU` is used for calculation acceleration. There is no need to write a lot of code when using it. You only need to call a few functions to quickly run the model.\n\n\n## About KPU\n\nAlthough KPU can accelerate model calculations, due to various factors such as cost, time, power consumption, volume, heat generation, application field positioning and other factors, its capabilities are not like the powerful `NPU` in the professional field, including every type Operator, it can only handle part of it.\n\nKPU implements the hardware acceleration of the four basic operations of convolution, batch normalization, activation, and pooling, but they cannot be used separately and are an integrated acceleration module.\n\nTherefore, inference models on KPU, the following requirements (if you do not need to train and design the model, you do not need to understand it carefully):\n\n1. Memory limitations\n\nK210 has 6MB general RAM and 2MB KPU dedicated RAM. The input and output feature maps of the model are stored in 2MB KPU RAM. Weights and other parameters are stored in 6MB general-purpose RAM.\n\n2. Which operators can be fully accelerated by KPU?\n\nThe following constraints need to be met.\n\n* Feature map size: the input feature map is less than or equal to 320x240 (WxH) while the output feature map is greater than or equal to 4x4 (WxH), and the number of channels is from 1 to 1024.\n* Same symmetric paddings (TensorFlow uses asymmetric paddings when stride=2 and the size is even).\n* For ordinary Conv2D and DepthwiseConv2D, the convolution kernel is 1x1 or 3x3, and the stride is 1 or 2.\n* MaxPool(2x2 or 4x4) and AveragePool(2x2 or 4x4).\n* Any element-wise activation function (ReLU, ReLU6, LeakyRelu, Sigmoid...), KPU does not support PReLU.\n\n3. Which operators can be partially accelerated by KPU?\n\n* Asymmetric paddings or valid paddings convolution, nncase will add necessary Pad and Crop before and after it.\n* Ordinary Conv2D and DepthwiseConv2D, the convolution kernel is 1x1 or 3x3, but stride is not 1 or 2. nncase will decompose it into KPUConv2D and a StridedSlice (may also need Pad).\n* MatMul, nncase will replace it with a Pad (to 4x4) + KPUConv2D (1x1 convolution sum) + Crop (to 1x1).\n* TransposeConv2D, nncase will replace it with a SpaceToBatch + KPUConv2D + BatchToSpace.\n\nInstructions are from [here](https://github.com/kendryte/nncase/blob/master/docs/FAQ_ZH.md)\n\n\n## Model conversion\n\nAs mentioned earlier, a model is actually a set of structure and parameter data. Different software can only recognize models in a specific format. KPU only recognizes models in `.kmodel` format. Generally, models trained on computers do not, such as `tensorflow` `.h5` format or `.tflite` format, to be used by `KPU`, it must be changed to `kmodel`, and use [nncase](https://github.com/kendryte/nncase) tool to achieve model conversion the goal of\nIf you need to convert the model, see the introduction in this warehouse for specific usage\n\n## kmodel V3 model and V4 model\n\nDue to the code update, two major versions were produced in the process, `V3` and `V4`, where the `V3` model refers to the use of [nncase v0.1.0 RC5](https://github.com/kendryte/nncase/ releases/tag/v0.1.0-rc5) The converted model; `V4` model refers to [nncase v0.2.0](https://github.com/kendryte/nncase/releases/tag/v0.2.0-beta4) Converted model\n\nThere is a certain difference between the two, so now the two are publicly stored, `V3` has less code, less memory, and higher efficiency, but it supports fewer operators; `V4` supports more operators, but both Realized by software, no hardware acceleration, more memory usage, so each has its own strengths. MaixPy firmware can also choose whether to support `V4`.\n\n## Use model kmodel in MaixPy\n\n1. Load the model in the SD card (TF card)\n\nPut the model on the SD card, then load\n\n\n```python\n   import KPU as kpu\n   m = kpu.load(\"/sd/test.kmodel\")\n```\n\n2. Load the model in Flash\n\nDownload the model to Flash, then load\n\n```python\n   import KPU as kpu\n   model_addr_in_flash = 0x300000\n   m = kpu.load(model_addr_in_flash)\n```\n\nHere `model_addr_in_flash` is the offset address of the model in Flash, and the model can be burned to the corresponding address of Flash through kflash.py or kflash_gui\n\n3. Ready to enter\n\nIn general, we will use images as input:\n* Directly use the data collected by the camera as input:\n```\nimg = sensor.snapshot()\n```\nHere `img` can be directly used as input, here need **note**: After the `snapshot` function collects the image, it will put the image data in two places\n(1) `RGB565` memory block, the image is stored in a memory in the form of `RGB565`, which is convenient for image processing functions. Note that the order in the memory is `[pixel 1 RGB, pixel 2 RGB...]`\n(2) `RGB888` memory block, the image is stored in another memory in the form of `R8G8B8`, note that the order in the memory is `[all pixels R, all pixels G, all pixels B]`, which we also call For `AI` memory\n\n**Among them, the data actually input as KPU is `RGB888` area**, this is explained in detail in the previous document [MaixPy image and common operations](/course/basic/image/vary.html) chapter\n\n* Read from file, or modified camera image\n\nThe image collected directly from the camera will automatically fill the `RGB888` area, but when we use image processing functions such as `image.resize()`, only `RGB565` will be modified, and `RGB888` will not be modified, because it needs to modify two memory at the same time It takes a lot of time, and the input of `KPU` is `RGB888` memory, so when you need to perform `KPU` operations, you need to synchronize (refresh) the `RGB888` memory block, and use `img.pix_to_ai()` to synchronize , Otherwise the modification has no effect on `KPU`.\nsuch as:\n```python\nimg = sensor.snapshot()\nimg = img.resize(240, 240)\nimg.pix_to_ai()\n```\n\n```python\nimg = image.Imag(\"/sd/test.jpg\")\nimg.pix_to_ai()\n```\n\n4. Forward running model\n\nRun the model forward, that is, walk the model calculation in the direction from input to output, and get the output value through input:\n\n```python\n\nfeature_map = kpu.forward(m, img)\n```\nHere we get the `feature_map`, which is a feature map. For example, the classification of `small balls` and `toys` we used earlier, the output feature map is two nodes, each node represents the probability of the corresponding object, we will feature Figure converted to `list` object\n```python\np_list = feature_map[:]\nprint(p_list)\n```\nYou can get a result similar to `[0.9, 0.1]`\n\n\n\n## Common problems in the use of KPU\n\n### How big a model can KPU load?\n\nC language code running model:\n    When k210 runs the c code, it can load the model <6MB, depending on the content of the C code.\nMaixPy running model:\n    * When running MaixPy (minimum version), a model of about 4MB can be loaded. If you don’t use the camera and LCD, you can load up to 5MiB of models (because the buffer of the camera and LCD takes up a lot of memory, but the actual application is not very meaningful)\n    * When running MaixPy (full version), it can load a model of about 2MiB\n    * In addition, it also supports real-time loading of models from `Flash`. In theory, as long as the single-layer memory does not exceed 2MiB, the overall model can be infinitely large, but at the expense of computing speed. For usage, see [here](https://github.com/sipeed/MaixPy_scripts/tree/master/machine_vision/load_big_model). If you are interested in the principle and implementation, you can see [here](https://neucrack.com/p/313)\n\n\n\n### What should I do if I report an error \"memory overflow\"?\n\nWhen this problem occurs, according to the system memory management mentioned earlier, there are generally two possibilities:\n1. The place where the error is reported has nothing to do with the system heap. It may be caused by insufficient memory in `GC`, but increase the total memory size of `GC` appropriately\n2. Caused by the model being too large. You can try the following solutions in turn:\n  1. Change the firmware of maixpy ​​mini version\n  2. Perform model pruning optimization\n  3. Use the `kpu.load_flash` interface to load the model in real time when running, but the execution efficiency is reduced a bit\n  4. If the memory is insufficient and the performance of `kpu.load_flash` cannot be satisfied, then you may need to use [C SDK](https://github.com/kendryte/kendryte-standalone-sdk) for development.\n\n### What should I do if I report an error \"load error, only support kmodel v3/v4\"?\n\nIf this problem occurs, you can try the following solutions:\n\n1. If you are loading the model in the Flash, please make sure that the `flash offset` is filled in correctly and that there is no conflict with the address of the maixpy ​​firmware (the address of the model in the Flash is too high, and then when the firmware is programmed into the Flash, the firmware size Exceeded the starting address of the model, causing the model to be destroyed)\n2. If it is `kmodel V4` converted with `nncase 0.2.0`, please try to convert with `nncase 0.1.0` to generate `kmodel V3`\n\n### I want to select and load different models (for example, press the button to run the target classification, press the button again to run the target detection), how should I write the program?\n\nBecause the internal RAM is limited, when you need to switch between different models for `kpu.load(address)`, please execute `kpu.deinit(k210model)` to release the memory occupied by the previous model, and then load the new model.Time-shared memory"}, "/soft/maixpy/en/course/ai/train/maixhub.html": {"title": "Maixhub model training", "content": "---\ntitle: Maixhub model training\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maixhub model training\n---\n\n\nMaixhub provides model training function and model sharing function. You only need to prepare the data set that needs to be trained. There is no need to build a training environment and code. Upload the training data to quickly train the model.\n\nMaixhub currently supports the training of classification models and target detection models.\n\nWhat you need to do:\n* Determine the target, whether it is classification or detection\n* Make a data set that meets the requirements according to the instructions for use\n* Upload the data set and wait for automatic training in the cloud\n* After the training is completed, the result will be notified by email, whether it is a success or a failure, there will be an email notification with detailed task information and result files\n\n\nMaixhub instruction manual reference [Maixhub training instruction manual](https://www.maixhub.com/index/mtrain/help.html)"}, "/soft/maixpy/en/course/ai/train/local.html": {"title": "Local model training", "content": "---\ntitle: Local model training\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: local model training\n---\n\n\n\nLocal model training is performed using [sipeed/maix_train](https://github.com/sipeed/maix_train) this code, using Tensorflow as the training framework\n\nMain support:\n* Object classification model (using Mobilenet V1): Only identify what is the object in the picture\n* Object detection model (using YOLO V2): Find the figure body recognized in the picture, and find its coordinates and size at the same time\n\n## System environment\n\nFirst, a computer with Linux system is required\nIf your main system is Windows, you can use the following system environment:\n* You can use a virtual machine, `virtual box` or `vmware`, the system recommends installing `Ubuntu20.04`\n* Or install dual systems, please search and learn the installation method yourself, or see [this dual system installation tutorial](https://neucrack.com/p/330)\n\nYou may want to develop under `Windows`, but it is strongly recommended to use `Linux` instead of `Windows`:\n* First of all, most model training frameworks support `Linux` first, and the difficulty of developing under `Linux` will be easier than developing under `Windows`\n* As a developer, learning to use `Linux` is a basic skill. Of course, unless you are a fan of `Windows`, then I believe you must have the ability to port software from other systems to `Windows`\n\n\n## Software Installation\n\nTraining can use CPU for training, but the speed is relatively slow. If you use a dedicated graphics card (GPU) for acceleration, the speed will be much faster. Individuals generally use `Nvidia` graphics cards, such as `RTX 3090`, of course, use ordinary` GTX 1060 6G memory `version can be used happily\n\nFor the first contact, it is recommended to use the CPU for training first, the environment installation will be much easier, the following only talks about the method of CPU training, GPU please learn by yourself\n> For GPU usage, please refer to the official Tensorflow [GPU Usage Tutorial](https://tensorflow.google.cn/install/gpu). If you encounter problems with the graphics card driver, please refer to [here](https://neucrack.com/ p/252), if you encounter problems with [docker installation](https://tensorflow.google.cn/install/docker ), you can also see [here](https://neucrack.com/p/116 )\n\n\nThe following method of use is excerpted from the warehouse’s [README](https://github.com/sipeed/maix_train/blob/master/README.md), if there are discrepancies, please refer to the warehouse’s `README`, pay attention to distinguish\n\n\n* Clone the training code to local\n\n```\ngit clone https://github.com/sipeed/maix_train --recursive\n```\n\n* Installation dependencies\n\n```\ncd maix_train\npip3 install -r requirements.txt\n```\nChinese users can use Alibaba Cloud or Tsinghua's source, the download speed is faster\n```\npip3 install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/\n```\n\n* Download [nncase v0.1.0-rc5](https://github.com/kendryte/nncase/releases/tag/v0.1.0-rc5) and unzip it to `maix_train/tools/ncc/ncc_v0.1`, guaranteed The path of the execution file is `maix_train/tools/ncc/ncc_v0.1/ncc`\n\n* Configuration project\n\nInitialize the project first\n```\npython3 train.py init\n```\nThen edit the `maix_train/instance/config.py` configuration according to your hardware situation\n\n## Prepare the data set\n\nPrepare the data set, the image size is `224x224`, the format can refer to the data set example under `maix_train/datasets`\n\nSee also [Maxhub's data set requirements](https://www.maixhub.com/index/mtrain/help.html)\n\n\n## Train classification model\n\n```\npython3 train.py -t classifier -z datasets/test_classifier_datasets.zip train\n```\n\nOr unzip the data set to a folder, specify the data set folder\n```\npython3 train.py -t classifier -d datasets/test_classifier_datasets train\n```\n\n## Train the target detection model\n\n```\npython3 train.py -t detector -z datasets/test_detector_xml_format.zip train\n```\n\n## Use model\n\nLike the model trained with `Maixhub`, a `zip` file will be generated in the `out` folder, which contains the results, copy **all** files to the root directory of the `SD` card, and then power on the development board Just run"}, "/soft/maixpy/en/course/ai/image/self_learn_classifier.html": {"title": "self learning classifier", "content": "---\ntitle: self learning classifier\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: self learning classifier\n---\n\n\nNo need to train separately, learn the object features directly on the development board, and then use it directly\n\nDemo video: [youtube](https://www.youtube.com/watch?v=aLW1YQrT-2A) or [bilibili](https://www.bilibili.com/video/BV1Ck4y1d7tx)\n\n## Instructions\n\n* [Here](https://dl.sipeed.com/MAIX/MaixPy/release/master/maixpy_v0.5.0_33_gfcd6d8a) Download version >= v0.5.0-33 firmware\n* [Download kmodel](https://maixhub.com/modelInfo?modelId=16)\n* Use [kflash_gui](https://github.com/sipeed/kflash_gui) to download firmware and model\n* Run [Sample script](https://github.com/sipeed/MaixPy_scripts/blob/master/machine_vision/self_learning_classifier/self_learning_classifier.py)\n> If use the lite version kmodel, you should add `fea_len` arg as `512` when create classifier object, when use the bigger kmodel this param is not needed:\n```python\nclassifier = kpu.classifier(model, class_num, sample_num, fea_len=512)\n```\n\nThen start learning objects after running\n\n* Press the `boot button` on the development board to capture 3 categories `mobile`, `car`, `keyboard`, each category only needs to be captured once\n* Then capture 15 pictures, no order is required, such as capturing 5 pictures of `mobile phone`, 5 `cars`, 5 pictures of `keyboard`\n* Then it will automatically learn the features of these 15 pictures\n* The last recognized image category will be displayed in the upper left corner\n\n\n\n## Save/load learned features\n\n* Use `classifier.save(path)` to save the learned features to the `path` file\n* Use `KPU.classifier.load()` to load features, refer to [self_learning_classifier_load.py](https://github.com/sipeed/MaixPy_scripts/blob/master/machine_vision/self_learning_classifier/self_learning_classifier_load.py) file"}, "/soft/maixpy/en/course/ai/image/face_detect.html": {"title": "Face detection", "content": "---\ntitle: Face detection\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: face detection\n---\n\n\nFind the face in a picture, and frame the face, that is, know the position and size of the face\n\nUse the `YOLO V2` model to detect faces\n\n## Instructions:\n\n* Download model: Go to [here](https://dl.sipeed.com/MAIX/MaixPy/model) to download the model file `face_model_at_0x300000.kfpkg`\n* Use kflash_gui to download the model to Flash, or put it in SD card\n* Load model\n```python\ntask = kpu.load(0x300000)\n# task = kpu.load(\"/sd/face.kmodel\")\nanchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025)\nkpu.init_yolo2(task, 0.5, 0.3, 5, anchor)\n```\nBecause the model of `YOLO V2` is used, it has a dedicated function interface, use `init_yolo2` to initialize the model\n\nThe parameters are:\n* `kpu_net`: kpu network object, that is, the loaded model object, the return value of `KPU.load()`\n* `threshold`: Probability threshold, only if the probability of this object is greater than this value will the output result, value range: [0, 1]\n* `nms_value`: box_iou threshold, in order to prevent the same object from being framed in multiple boxes, when two boxes are framed on the same object, the intersection area of ​​the two boxes accounts for the proportion of the total occupied area of ​​the two boxes. When it is less than this value, take the box with the highest probability\n* `anchor_num`: the number of anchor points, fixed here as `len(anchors)//2`\n* `anchor`: The anchor point parameters are consistent with the model parameters. This parameter of the same model is fixed and bound to the model (it is determined when the model is trained) and cannot be changed to other values.\n\nThen enter the image data and run the model\n\n```python\ncode = kpu.run_yolo2(task, img)\n```\n\nTo get the result, see [here](https://github.com/sipeed/MaixPy_scripts/blob/master/machine_vision/face_find/demo_find_face.py) for the complete example\n\nAPI documentation see [Maix.KPU](/api_reference/Maix/kpu.html)"}, "/soft/maixpy/en/course/ai/image/1000_type_classifier.html": {"title": "1000 object classification models", "content": "---\ntitle: 1000 object classification models\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: 1000 object classification models\n---\n\n\nCan recognize 1000 objects\n\n## Instructions\n\n* Use `minimum` version firmware\n* [Download model file](https://dl.sipeed.com/MAIX/MaixPy/model), download `mobilenet_0x300000.kfpkg`\n* Use `kflash_gui` to burn this file to `Flash`, the default address is `0x300000`\n* Save the file [labels.txt](https://github.com/sipeed/MaixPy_scripts/tree/master/machine_vision/mobilenet_1000_class/labels.txt) ([Alternate Link](https://en.bbs.sipeed.com /uploads/default/original/1X/d41ad9dfbe01f228abe726986fbf1baf4e288f2e.zip)) to the file system, see the introductory tutorial (use your ingenuity) for specific methods (reference answer: because there is too much content, if you use the REPL to copy and paste directly, data may be wrong. So use a tool to transfer. The easiest way is to put it on the SD card; if you want to put it in `/flash`, the minimum may not support IDE, you can use `upyloader` to send files)\n* Because this model has `4.2MiB`, which is relatively large, so the firmware of `minimum` is used, and the memory used by `GC` is not too large. You can set a smaller size in the following way and leave the memory for the model\n\n```python\nfrom Maix import utils\nimport machine\n\nutils.gc_heap_size(256*1024)\nmachine.reset()\n```\n\n* Import model\n\n```python\nimport KPU as kpu\ntask = kpu.load(0x300000)\n```\n\n* Read in labels\n\n```python\nf=open('/sd/labels.txt','r')\nlabels=f.readlines()\nf.close()\n```\n\n* Initialize the camera, LCD\n\nYou can set whether the camera is mirrored and whether the LCD is rotated according to your own hardware installation\n\nSlightly, please refer to the previous tutorial\n\n* Identify objects\n\n```python\nfmap = kpu.forward(task, img)\nplist=fmap[:]\npmax=max(plist)\nmax_index=plist.index(pmax)\n```\n\nHere, the result of the operation is converted into a `list` object, and then the subscript of the maximum value is found. Through this subscript, we know what the label name is (`labels[max_index]`)\n\n\n* show result\n\n```python\nimg = img.draw_string(0, 0, \"%.2f: %s\" %(pmax, labels[max_index].strip()), color=(255, 0, 0))\nlcd.display(img, oft=(0,0))\nprint(fps)\n```\n\n\nSee the complete example [maixpy_scripts](https://github.com/sipeed/MaixPy_scripts/tree/master/machine_vision/mobilenet_1000_class)"}, "/soft/maixpy/en/course/ai/image/face_recognization.html": {"title": "Face recognition", "content": "---\ntitle: Face recognition\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: face recognition\n---\n\n\nIn addition to detecting the position of the face, it can also identify who the person is (you need to target the person and press the button to learn)\n\nEffect video: [youtube](https://www.youtube.com/embed/hS_mcGptXeo) or [bilibili](https://www.bilibili.com/video/BV1bJ411Q7L6)\n\n<iframe src=\"https://player.bilibili.com/player.html?aid=77466790&bvid=BV1bJ411Q7L6&cid=132521878&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen =\"true\" width=500 height=400> </iframe>\n\n## Instructions\n\n\n* Download the model from [maixhub](https://www.maixhub.com/index/index/detail/id/235.html) and follow the instructions to obtain the model `smodel`, which is the encrypted version of `kmodel`\n* Download the model to the development board according to the method of the introductory tutorial\n* Run script [script](https://github.com/sipeed/MaixPy_scripts/blob/master/machine_vision/face_recognization/demo_face_recognization.py)\n\n\n## Program understanding\n\nThere are three models in common, namely:\n* Face detection model, which uses the same model as the previous face detection, that is, find the face\n* Face key point detection model, find the position of the eyes, nose and mouth of the face from the face found in the front\n* Face feature extraction model to obtain a feature value from a face picture\n\nProceed as follows:\n* Face detected\n* Cut out the face, find the eyes, nose and mouth of the face, here is a picture of `128x128`\n* Rotate the face in the face image to the standard position\n* Use the feature extraction model to extract the feature value of the face\n\nWith the previous foundation, the program here can be understood, and I will not elaborate on it. It just changed from using one model before to using three models in order, plus one more point. Simple image cropping and rotation processing are all calling `API`, look at the code carefully to know how the specific details are implemented"}, "/soft/maixpy/en/course/index.html": {"title": "MaixPy tutorial instructions", "content": "---\ntitle: MaixPy tutorial instructions\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixPy manual tutorial instructions\n---\n\n\nBefore reading this tutorial, please **be sure to look at the left-hand table of contents [Getting started must see guide]**\n\nThe tutorial is written on the basis that I have fully mastered the content of the previous Getting Started\n\n\nThis tutorial mainly introduces how to use the functions included in MaixPy in modules,\nWhen watching the tutorial, you may need to learn together with API documentation and routine warehouse [MaixPy_scripts](https://github.com/sipeed/maixpy_scripts)"}, "/soft/maixpy/en/course/network/network_config.html": {"title": "How to connect MaixPy to the Internet", "content": "---\ntitle: How to connect MaixPy to the Internet\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to connect MaixPy to the Internet\n---\n\n\n> Big Rat 2020-11-26 Edit\n\nSince it is called AIOT, it can't be without networking. MaixPy now supports W5X00 / EPS32 / ESPAT and other networking methods, as shown below.\n\n- ESP32 needs to be equipped with [dedicated SPI firmware](https://github.com/sipeed/Maixduino_esp32_fimware) to support TCP / UDP client.\n\n- ESPAT works with Espressif[AT firmware (esp-at)](https://github.com/espressif/esp-at), and only supports TCP clients.\n\n- W5X00 can be configured + used by connecting to the Internet cable, and supports TCP/UDP client.\n\nBefore using the Socket, please connect the network first. The wired one needs to resolve the DNS and IP address, gateway, and the wireless one needs to fill in the WIFI account (SSID) and password. Do not ask \"Bug found!!! How to access No problem with Baidu (I don’t have internet access).\n\n## Computer Network Foundation\n\n> If you don't know these basics, you can't use it.\n\nIt is recommended to know the following keywords when applying MaixPy network function:\n\n- What are network and socket?\n- What is TCP \\ UDP? What is HTTP \\ HTTPS \\ MQTT \\ FTP?\n\nFrom the perspective of pragmatism, in maixpy ​​(micropython), the content about the network is divided into the most basic two-layer interface.\n\n### network\n\nResponsible for managing the interface of the network card. The network card is a type of hardware interface that sends the network data protocol from the hardware and belongs to the category of hardware.\n\nFor example: Usually the main function of a WIFI network card is to connect to a wireless router to help users connect to the Internet, while a wired network card helps users connect to the Internet through a network cable. They will complete gateway configuration, DNS resolution, Ping request and other operations at this layer. If it is used as a server, it will also complete functions such as wireless network distribution and domain name resolution.\n\n### socket\n\nThe difference from the network card is that the socket is only responsible for the transmission of the data protocol at the application layer. It is usually encapsulated by the bottom PCB connection block into the common socket socket interface module. It mainly provides the connection transmission method of TCP/IP and UDP. Users can perform network programming based on this interface.\n\n#### What are TCP and UDP?\n\nOn the basis of socket, we are divided into two typical transmission interfaces, TCP and UDP. The main emphasis is on whether the communication between the two applications is connected. If the connection is not maintained, the UDP connection method is used. If a long connection with the server is required, then When using TCP connection, please note that UDP and TCP ports are independent of each other and do not need to be confused.\n\n> TCP has a streaming long connection retransmission mechanism, through several types of internal timers and data congestion windows, it can be ensured that user data will not be lost to a certain extent, but there are cases of overtime waiting.\n\n> UDP does not need to be connected, and the data is directly transmitted in the form of broadcast to the upper switch and router, so UDP packets have a certain degree of penetration, and can penetrate data packets outside without configuration in the upper network (actual situation Will be changed).\n\n#### What is HTTP \\ HTTPS \\ MQTT \\ FTP?\n\nBased on this, communication protocols such as HTTP protocol running on port 80, HTTP and other communication protocols transmitted on port 443, FTP file transfer protocol on port 21, and application transfer protocols such as MQTT and WebSocket based on this can be expanded, but they are all Based on the functions completed by the original socket interface, the only difference is the encapsulated application protocol.\n\n### How to network?\n\nPlease select the corresponding networking script according to your own network situation, you can run it directly, or upload it to the hardware as a class library to facilitate subsequent socket development. You can use a script similar to the following to complete the network configuration, which is in the sample code Can know the specific usage.\n\nGeneral verification usage:\n\n```python\n\nimport network_esp32\nprint(network_esp32)\nprint(dir(network_esp32))\n\nfrom network_esp32 import wifi\nprint(wifi)\n\n'''ouput\n>>> <module'network_esp32' from'network_esp32.py'>\n['__class__','__name__','__file__','GPIO','network','time','board_info','fm','wifi']\n<class'wifi'>\nMicroPython v0.5.1-140-g7bf6445e7-dirty on 2020-11-26; Sipeed_M1 with kendryte-k210\nType \"help()\" for more information.\n>>>\n'''\n\n```\n\nReal environment usage:\n\n```python\n\nSSID = \"Sipeed_2.4G\"\nPASW = \"xxxxxxxx\"\n\ndef enable_esp32():\n    from network_esp32 import wifi\n    if wifi.isconnected() == False:\n        for i in range(5):\n            try:\n                # Running within 3 seconds of power-up can cause an SD load error\n                # wifi.reset(is_hard=False)\n                wifi.reset(is_hard=True)\n                print('try AT connect wifi...')\n                wifi.connect(SSID, PASW)\n                if wifi.isconnected():\n                    break\n            except Exception as e:\n                print(e)\n    print('network state:', wifi.isconnected(), wifi.ifconfig())\n\nenable_esp32()\n\ndef enable_espat():\n    from network_espat import wifi\n    if wifi.isconnected() == False:\n        for i in range(5):\n            try:\n                wifi.reset()\n                print('try AT connect wifi...')\n                wifi.connect(SSID, PASW)\n                if wifi.isconnected():\n                    break\n            except Exception as e:\n                print(e)\n    print('network state:', wifi.isconnected(), wifi.ifconfig())\n\n#enable_espat()\n\n```\n\n#### Maixduino + ESP32\n\nUse Maixduino's esp32 to connect to the network and upload the library [network_esp32.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/network_esp32.py).\n\n```python\n# This file is part of MaixPY\n# Copyright (c) sipeed.com\n#\n# Licensed under the MIT license:\n# http://www.opensource.org/licenses/mit-license.php\n#\n\nimport time, network\nfrom Maix import GPIO\nfrom fpioa_manager import fm\n\nclass wifi():\n\n    nic = None\n\n    def reset(force=False, reply=5, is_hard=True):\n        if force == False and __class__.isconnected():\n            return True\n        try:\n            # IO map for ESP32 on Maixduino\n            fm.register(25,fm.fpioa.GPIOHS10)#cs\n            fm.register(8,fm.fpioa.GPIOHS11)#rst\n            fm.register(9,fm.fpioa.GPIOHS12)#rdy\n\n            if is_hard:\n                print(\"Use Hareware SPI for other maixduino\")\n                fm.register(28,fm.fpioa.SPI1_D0, force=True)#mosi\n                fm.register(26,fm.fpioa.SPI1_D1, force=True)#miso\n                fm.register(27,fm.fpioa.SPI1_SCLK, force=True)#sclk\n                __class__.nic = network.ESP32_SPI(cs=fm.fpioa.GPIOHS10, rst=fm.fpioa.GPIOHS11, rdy=fm.fpioa.GPIOHS12, spi=1)\n                print(\"ESP32_SPI firmware version:\", __class__.nic.version())\n            else:\n                # Running within 3 seconds of power-up can cause an SD load error\n                print(\"Use Software SPI for other hardware\")\n                fm.register(28,fm.fpioa.GPIOHS13, force=True)#mosi\n                fm.register(26,fm.fpioa.GPIOHS14, force=True)#miso\n                fm.register(27,fm.fpioa.GPIOHS15, force=True)#sclk\n                __class__.nic = network.ESP32_SPI(cs=fm.fpioa.GPIOHS10,rst=fm.fpioa.GPIOHS11,rdy=fm.fpioa.GPIOHS12, mosi=fm.fpioa.GPIOHS13,miso=fm.fpioa.GPIOHS14,sclk= fm.fpioa.GPIOHS15)\n                print(\"ESP32_SPI firmware version:\", __class__.nic.version())\n\n            # time.sleep_ms(500) # wait at ready to connect\n        except Exception as e:\n            print(e)\n            return False\n        return True\n\n    def connect(ssid=\"wifi_name\", pasw=\"pass_word\"):\n        if __class__.nic != None:\n            return __class__.nic.connect(ssid, pasw)\n\n    def ifconfig(): # should check ip != 0.0.0.0\n        if __class__.nic != None:\n            return __class__.nic.ifconfig()\n\n    def isconnected():\n        if __class__.nic != None:\n            return __class__.nic.isconnected()\n        return False\n\nif __name__ == \"__main__\":\n    # It is recommended to callas a class library (upload network_espat.py)\n\n    # from network_esp32 import wifi\n    SSID = \"Sipeed_2.4G\"\n    PASW = \"xxxxxxxx\"\n\n    def check_wifi_net(reply=5):\n        if wifi.isconnected() != True:\n            for i in range(reply):\n                try:\n                    wifi.reset(is_hard=True)\n                    print('try AT connect wifi...')\n                    wifi.connect(SSID, PASW)\n                    if wifi.isconnected():\n                        break\n                except Exception as e:\n                    print(e)\n        return wifi.isconnected()\n\n    if wifi.isconnected() == False:\n        check_wifi_net()\n    print('network state:', wifi.isconnected(), wifi.ifconfig())\n\n    # The network is no longer configured repeatedly\n    import socket\n    sock = socket.socket()\n    # your send or recv\n    # see other demo_socket_tcp.py / udp / http / mqtt\n    sock.close()\n\n'''ouput\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n    >>>\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    Use Hareware SPI for other maixduino\n    [esp32_spi] use hard spi(1)\n    hard spi\n    esp32 set hard spi clk:9159090\n    Get version fail\n    try AT connect wifi...\n    Use Hareware SPI for other maixduino\n    [Warning] function is used by unknown(pin:10)\n    [Warning] function is used by unknown(pin:6)\n    [Warning] function is used by unknown(pin:11)\n    [esp32_spi] use hard spi(1)\n    hard spi\n    esp32 set hard spi clk:9159090\n    ESP32_SPI firmware version: 1.4.0\n    try AT connect wifi...\n    network state: True ('192.168.0.180', '255.255.255.0', '192.168.0.1')\n    >\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n    >>>\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    network state: True ('192.168.0.180', '255.255.255.0', '192.168.0.1')\n    >\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n'''\n```\n\n#### AT firmware of ESP82XX\n\nUse the AT firmware of ESP8266/85 to connect to the Internet and upload the library [network_espat.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/network_espat.py)\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../../api_reference/builtin_py/board_info.html) is required before use.\n\n```python\n# This file is part of MaixPY\n# Copyright (c) sipeed.com\n#\n# Licensed under the MIT license:\n# http://www.opensource.org/licenses/mit-license.php\n#\n\nimport time, network\nfrom Maix import GPIO\nfrom machine import UART\nfrom fpioa_manager import fm\nfrom board import board_info\n\nclass wifi():\n\n    __is_m1w__ = True\n    uart = None\n    eb = None\n    nic = None\n\n    def init():\n        if __class__.__is_m1w__:\n            fm.register(0, fm.fpioa.GPIOHS1, force=True)\n            M1wPower=GPIO(GPIO.GPIOHS1, GPIO.OUT)\n            M1wPower.value(0) # b'\\r\\n ets Jan 8 2013,rst cause:1, boot mode:(7,6)\\r\\n\\r\\nwaiting for host\\r\\n'\n\n        fm.register(board_info.WIFI_EN, fm.fpioa.GPIOHS0) # board_info.WIFI_EN == IO 8\n        __class__.en = GPIO(GPIO.GPIOHS0,GPIO.OUT)\n\n        fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) # board_info.WIFI_RX == IO 7\n        fm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX) # board_info.WIFI_TX == IO 6\n        __class__.uart = UART(UART.UART2, 115200, timeout=1000, read_buf_len=8192)\n\n    def enable(en):\n        __class__.en.value(en)\n\n    def _at_cmd(cmd=\"AT\\r\\n\", resp=\"OK\\r\\n\", timeout=20):\n        __class__.uart.write(cmd) # \"AT+GMR\\r\\n\"\n        time.sleep_ms(timeout)\n        tmp = __class__.uart.read()\n        # print(tmp)\n        if tmp and tmp.endswith(resp):\n            return True\n        return False\n\n    def at_cmd(cmd=\"AT\\r\\n\", timeout=20):\n        __class__.uart.write(cmd) # \"AT+GMR\\r\\n\"\n        time.sleep_ms(timeout)\n        tmp = __class__.uart.read()\n        return tmp\n\n    def reset(force=False, reply=5):\n        if force == False and __class__.isconnected():\n            return True\n        __class__.init()\n        for i in range(reply):\n            print('reset...')\n            __class__.enable(False)\n            time.sleep_ms(50)\n            __class__.enable(True)\n            time.sleep_ms(500) # at start> 500ms\n            if __class__._at_cmd(timeout=500):\n                break\n        __class__._at_cmd()\n        __class__._at_cmd('AT+UART_CUR=921600,8,1,0,0\\r\\n', \"OK\\r\\n\")\n        __class__.uart = UART(UART.UART2, 921600, timeout=1000, read_buf_len=10240)\n        # important! baudrate too low or read_buf_len too small will loose data\n        #print(__class__._at_cmd())\n        try:\n            __class__.nic = network.ESP8285(__class__.uart)\n            time.sleep_ms(500) # wait at ready to connect\n        except Exception as e:\n            print(e)\n            return False\n        return True\n\n    def connect(ssid=\"wifi_name\", pasw=\"pass_word\"):\n        if __class__.nic != None:\n            return __class__.nic.connect(ssid, pasw)\n\n    def ifconfig(): # should check ip != 0.0.0.0\n        if __class__.nic != None:\n            return __class__.nic.ifconfig()\n\n    def isconnected():\n        if __class__.nic != None:\n            return __class__.nic.isconnected()\n        return False\n\nif __name__ == \"__main__\":\n    # It is recommended to callas a class library (upload network_espat.py)\n\n    # from network_espat import wifi\n    SSID = \"Sipeed_2.4G\"\n    PASW = \"xxxxxxxx\"\n\n    def check_wifi_net(reply=5):\n        if wifi.isconnected() != True:\n            for i in range(reply):\n                try:\n                    wifi.reset()\n                    print('try AT connect wifi...', wifi._at_cmd())\n                    wifi.connect(SSID, PASW)\n                    if wifi.isconnected():\n                        break\n                except Exception as e:\n                    print(e)\n        return wifi.isconnected()\n\n    if wifi.isconnected() == False:\n        check_wifi_net()\n    print('network state:', wifi.isconnected(), wifi.ifconfig())\n\n    # The network is no longer configured repeatedly\n    import socket\n    sock = socket.socket()\n    # your send or recv\n    # see other demo_socket_tcp.py / udp / http / mqtt\n    sock.close()\n\n'''ouput\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    [Warning] function is used by fm.fpioa.GPIOHS1(pin:17)\n    [Warning] function is used by fm.fpioa.GPIOHS0(pin:16)\n    reset...\n    try AT connect wifi... True\n    could not connect to ssid=Sipeed_2.4G\n    reset...\n    try AT connect wifi... True\n    network state: True ('192.168.0.165', '255.255.255.0', '192.168.0.1', '0', '0','b0:b9:8a:5b:be:7f','Sipeed_2.4G' )\n    >\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n    >>>\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    network state: True ('192.168.0.165', '255.255.255.0', '192.168.0.1', '0', '0','b0:b9:8a:5b:be:7f','Sipeed_2.4G' )\n    >\n'''\n```\n\n#### WIZNET5K by Spmod\n\nUse Spmod's WIZNET5K network card to connect to the Internet and upload the library [network_wiznet5k.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/network_wiznet5k.py)\n\n> vamoosebbf 2020-12-10 edit\n\nWIZNET5K is a wired network card module, you only need to plug in the network cable when using it, using the SPI protocol, this module is enabled by default in the complete firmware, but not in the minimum firmware.\n```python\nspi1 = SPI(4, mode=SPI.MODE_MASTER, baudrate=600 * 1000,\n            polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck=WIZNET5K_SPI_SCK, mosi=WIZNET5K_SPI_MOSI, miso = WIZNET5K_SPI_MISO)\n\nnic = network.WIZNET5K(spi = spi1, cs = WIZNET5K_SPI_CS)\nprint(\"Static IP: \", nic.ifconfig())\n\n#dhcp Obtain IP dynamically, because the static IP has been set above, this step can be skipped. It should be noted that if you use DHCP, you must use an infinite loop like the following code, otherwise the acquisition will be unsuccessful\nwhile True:\n    if(nic.dhclient()):\n        print(\"DHCP IP:\", nic.ifconfig())\n        break;\n\n'''output\n>>> Static IP: ('192.168.0.117', '255.255.255.0', '192.168.0.1', '8.8.8.8')\ninit dhcp\nDHCP IP: ('192.168.0.165', '255.255.255.0', '192.168.0.1', '8.8.8.8')\n'''\n\n```\n\n### Networking performance\n\nPlease start using socket network programming after confirming the network and obtaining the IP address, and you have obtained the IP address as follows.\n\n```shell\nnetwork state: True ('192.168.0.165', '255.255.255.0', '192.168.0.1', '0', '0','b0:b9:8a:5b:be:7f','Sipeed_2.4G' )\n```"}, "/soft/maixpy/en/course/network/socket_usage.html": {"title": "How to use Socket network programming", "content": "---\ntitle: How to use Socket network programming\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to use Socket network programming\n---\n\n\n> Big Rat 2020-11-26 edit, so far MaixPy's socket module has not yet implemented interfaces such as listen / bind / accept.\n\n## How to use TCP and UDP clients to connect to the server\n\nAssuming that the basic content of [How to connect MaixPy to the network](./network_config.html) is known, run the sample code directly.\n\n* Warning: Don’t ask: \"Why can’t you access the network without a network connection!\"\n\nPlease confirm the address and port before using the following client code.\n\n### Prepare client code\n\nThere are the following types of typical client code:\n\n- TCP client [demo_socket_tcp_client.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_tcp_client.py)\n- UDP client [demo_socket_udp_client.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_udp_client.py)\n- TCP video transmission client [demo_socket_pic_client.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_pic_client.py)\n\n### Prepare debugging tools (server code)\n\nCommonly used in network debugging assistants, or running the provided Python3 server script on your computer.\n\n- TCP server [demo_socket_tcp_server.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_tcp_server.py)\n- UDP server [demo_socket_udp_server.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_udp_server.py)\n- TCP image transmission server [demo_socket_pic_server.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_pic_server.py)\n\nFirst start a network service with a known IP address and port, and wait for MaixPy as a client to send data to the server.\n\n### Examples of typical client code\n\n-TCP\n\n```python\nimport socket\nADDR = (\"192.168.0.107\", 60000)\nsock = socket.socket()\nsock.connect(ADDR)\nsock.settimeout(1)\nwhile 1:\n    sock.send(\"hello\\n\")\n    #data = sock.recv(10) # old maxipy have bug (recv timeout no return last data)\n    #print(data) # fix\n    try:\n      data = b\"\"\n      while True:\n        tmp = sock.recv(1)\n        print(tmp)\n        if len(tmp) == 0:\n            raise Exception('timeout or disconnected')\n        data += tmp\n    except Exception as e:\n      print(\"rcv:\", len(data), data)\n    #time.sleep(2)\n\nsock.close()\n```\n\n-UDP\n\n```python\nimport socket\nADDR = (\"192.168.0.107\", 60000)\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nsock.settimeout(1)\nwhile 1:\n    try:\n        sock.sendto(\"hello\\n\", ADDR)\n        data, addr = sock.recvfrom(1024)\n    except Exception as e:\n        print(\"receive error:\", e)\n        continue\n    print(\"addr:\", addr, \"data:\", data)\n    time.sleep(2)\nsock.close()\n'''\n>>>\nraw REPL; CTRL-B to exit\n>OK\nnetwork state: True ('192.168.0.186', '255.255.255.0', '192.168.0.1')\naddr: ('192.168.0.107', 60000) data: b'HELLO\\n'\naddr: ('192.168.0.107', 60000) data: b'HELLO\\n'\naddr: ('192.168.0.107', 60000) data: b'HELLO\\n'\n'''\n```\n\n### Other network functions\n\nThe following are special function codes.\n\n#### esp32's ping\n\n- [demo_esp32_ping.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_esp32_ping.py)\n\n```shell\n    ESP32_SPI firmware version: 1.4.0\n    try AT connect wifi...\n    network state: True ('192.168.0.180', '255.255.255.0', '192.168.0.1')\n    ping baidu.com: 40 ms\n    >\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n```\n\n#### ADC of esp32\n\n- [demo_esp32_read_adc.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_esp32_read_adc.py)\n\n```shell\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    (2370, 3102, 3071)\n    2017 2753 0977 2709 0963 0855: adc\n    0617 0757 0150 0095 0133 0153: adc\n    1319 1478 0955 0939 0698 0619: adc\n    2403 3231 3299 3298 1483 0779: adc\n    1119 1815 1274 1315 0230 0255: adc\n    0951 0951 0295 0283 0319 0399: adc\n    2175 2769 2576 2579 1487 1104: adc\n    1995 2846 2647 2699 0839 0441: adc\n```\n\n> In fact, espAT also obtains ADC in this way, but it can only be used on designated pins.\n\n#### HTTP support\n\n- [demo_http_get_jpg.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_http_get_jpg.py)\n\n#### https support\n\nThis function is not compiled by default, but what is provided is the use of HTTP, and HTTP and HTTPS are only the difference of the path url. Note that the IP resolution of https depends on the firmware of the network card and is not completed on the K210.\n\n- [demo_socket_https.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_https.py)\n\n#### scan WIFI AP hotspot of esp32, 82XX\n\n- [demo_esp32_ap_scan.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_esp32_ap_scan.py)\n\n- [demo_espat_ap_scan.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_espat_ap_scan.py)\n```python\n'''\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    SSID: Sipeed_2.4G, ENC: WPA/WPA2 PSK, RSSI: -57\n    SSID: ChinaNet-Ffdj, ENC: WPA/WPA2 PSK, RSSI: -58\n    SSID: wea_615, ENC:WPA/WPA2 PSK, RSSI: -67\n    SSID: ChinaNet-PnAN, ENC: WPA/WPA2 PSK, RSSI: -70\n    SSID: wea_613, ENC:WPA/WPA2 PSK, RSSI: -73\n    SSID: ChinaNet-TnSG, ENC: WPA/WPA2 PSK, RSSI: -82\n    SSID: chipshine_GUEST, ENC:WPA/WPA2 PSK, RSSI: -83\n    SSID: ASUS, ENC: WPA/WPA2 PSK, RSSI: -86\n    SSID: gta888, ENC: WPA/WPA2 PSK, RSSI: -87\n    SSID: huahua, ENC: WPA/WPA2 PSK, RSSI: -88\n    >\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n'''\n```\n\n#### mqtt support\n\nThis is the code provided by the official repository of micropython. If it is for commercial use, please configure the socket as non-blocking and add the MQTT keep-alive protocol.\n\n- [demo_socket_mqtt.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_socket_mqtt.py)\n\n#### Update the AT firmware of ESP82XX\n\n> This is a function provided for the AT firmware, so you can understand it naturally.\n\n- [demo_espat_ap_test.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_espat_ap_test.py)\n\n- [espat_upgrade.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/espat_upgrade.py)"}, "/soft/maixpy/en/course/others/pye.html": {"title": "pye (Micropython Editor)", "content": "---\ntitle: pye (Micropython Editor)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: pye (Micropython Editor)\n---\n\n\nIn MaixPy, we have built-in an open source editor [Micropython Editor(pye)](https://github.com/robert-hh/Micropython-Editor)\n\n> Note that this function is not included in the `minimum` version of the firmware\n\nUse `os.listdir()` to view the files in the current directory,\n\nUse `pye(\"hello.py\")` to create a file and enter the editing mode, and the instructions for using shortcut keys can be found in [here](https://github.com/robert-hh/Micropython-Editor/blob/master /Pyboard%20Editor.pdf)\n\nFor example, we write code\n\n```python\nprint(\"hello maixpy\")\n```\n\nThen press `Ctrl+S` and press `Enter` to save, press `Ctrl+Q` to exit editing\n\n**Note**: The use of this editor has certain requirements for the serial tool used. The `BackSpace` key must be set to the `DEL` function, otherwise pressing `BackSpace` will call the same function as `Ctrl+H` ( That is character replacement).\n\nIt is recommended to use `minicom` under Linux, you need to use `sudo minicom -s` to set, refer to [previous tutorial](./../../get_started/env_serial_tools.html)\n\nThe same is true under Windows, search the setting method according to the tool you use, such as `xshell` search `xshell How to set backspace to del` to get the result:\n\n`File` -> `Properties` -> `Terminal` -> `Keyboard`,\nChange the sequence of delete and backspace to ASCII 127."}, "/soft/maixpy/en/course/others/mem.html": {"title": "Memory management", "content": "---\ntitle: Memory management\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: memory management\n---\n\n\n\nIn MaixPy, two types of memory management are currently used, one is GC (garbage collection) and the other is system heap memory, both of which exist at the same time.\n\nFor example: the chip has 6MiB of memory, adding the firmware uses the previous 2MiB, and the remaining 4MiB, the default `GC` uses 512KiB, and the rest is used for system heap memory management.\n\n\n* In the code written at the level of `mpy`, variables are stored in the memory block managed by `GC`, such as defining a variable `a = [1,2,3,4]`, if the memory of `GC'` is insufficient, It will automatically trigger the execution of the `gc.collect()` function, and the `GC` will automatically destroy the unused variables, leaving space for new variables.\n> `GC` uses the method of `mark-clear` to reclaim memory. If you are interested, please see [here](https://neucrack.com/p/46)\n* Because `GC` needs to scan the memory, if the rest is given to `GC` except for the memory occupied by the program, each scan will take a lot of time, so it is divided into two memory. Heap memory is controlled by code at the `C` level, mainly used for image memory, AI memory, LCD memory, and loading models into memory, etc.\n\n\nThe total size of `GC` memory can be set. Therefore, the size of `GC` memory can be modified appropriately according to the specific usage, for example:\n* In order to load a larger model, you can set the `GC` memory setting smaller\n* If the allocation of new variables indicates insufficient memory, you can appropriately set the `GC` memory to be larger\n* If it is not enough, consider reducing the firmware size or optimizing the code\n\nExample of setting `GC` memory size:\n\n```python\nfrom Maix import utils\nimport machine\n\nprint(utils.gc_heap_size())\n\nutils.gc_heap_size(1024*1024) # 1MiB\nmachine.reset()\n```\n\nNote that the modification needs to be restarted to take effect\n\nView memory allocation:\n\n```python\nimport gc\n\nprint(gc.mem_free() / 1024) # stack mem\n\nimport Maix\n\nprint(Maix.utils.heap_free() / 1024) # heap mem\n\n'''\n>>>\nraw REPL; CTRL-B to exit\n>OK\n352.0937\n4,640.0\n>\nMicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\nType \"help()\" for more information.\n>>>\n'''\n```"}, "/soft/maixpy/en/course/others/maixui.html": {"title": "MaixUI basic usage guide", "content": "---\ntitle: MaixUI basic usage guide\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixUI basic usage guide\n---\n\n\nHow to consume MaixUI items correctly?\n\n## Why develop it? What is its meaning and existence value?\n\nThere is always a basic requirement for the UI framework under any chip, but because the K210 cannot continue to use the LVGL environment while supporting the Ai function, the UI loses its original meaning.\n\nThat is, when you can't use QT or LVGL, you want to be able to use Python to write UI applications, so the image-based MaixUI UI framework was born.\n\n## Requirements for MaixUI\n\nBased on the latest MaixPy firmware, the following requirements will be met on October 7, 2020.\n\n- Ensure that MicroPython's GC memory is recyclable and controllable at all times.\n\n- Ensure that the UI component code is independent, not included in the firmware, and can be debugged and modified.\n\n- Ensure system stability, ensure that code and hardware resources can be re-entered, and no core dump phenomenon will occur.\n\n- Run reentrant, which means running dynamic code to show UI style, similar to HTML5 / CSS design.\n\n- Python's exception capture is fed back to the screen in real time to quickly locate the error line.\n\n- UI-related drawing functions can be used in multiple decorations or run independently.\n\n- All MicroPython hardware drivers provided by the framework can independently run corresponding unit tests.\n\n- When the framework is running, it allows dynamic loading of external UI applications that conform to the structure, and user-defined applications can be obtained from storage or network.\n\nSo in the most basic example, it will strictly control the memory usage to 512k ~ 1M and keep the drawing performance between 15 ~ 24fps.\n\n## How to eat?\n\nHere, let’s start with the simplest entry code, the complete code is here [app_main.py](https://github.com/sipeed/MaixUI/blob/master/app/app_main.py).\n\n```python\n# This file is part of MaixUI\n# Copyright (c) sipeed.com\n#\n# Licensed under the MIT license:\n# http://www.opensource.org/licenses/mit-license.php\n#\n\nimport time, gc, math, sys\n\ntry:\n  from core import agent, system\n  from dialog import draw_dialog_alpha\n  from ui_canvas import ui, print_mem_free\n  from ui_container import container\n  from wdt import protect\n  from creater import get_time_curve\nexcept ImportError as e:\n  sys.print_exception(e)\n  from lib.core import agent, system\n  from lib.dialog import draw_dialog_alpha\n  from ui.ui_canvas import ui, print_mem_free\n  from ui.ui_container import container\n  from driver.wdt import protect\n  from lib.creater import get_time_curve\n\n```\n\nThey are the dependent code of import required to run it, and the following dependencies are:\n\n- from core import agent, system\n  - Provide an agent soft timer and a global instance system soft timer object.\n- from dialog import draw_dialog_alpha\n  - Provides drawing operations for a rounded border MessageBox control.\n- from ui_canvas import ui, print_mem_free\n  - Provides a basic interface of UI canvas, through which to manage the overall unified drawing operation.\n- from ui_container import container\n  - Provides a container module for running UI applications, which can be used to switch between different UI applications.\n- from wdt import protect\n  - Watchdog, to ensure that the system can restart and recover after a core dump occurs.\n- from creater import get_time_curve\n  - A curve generation function based on time or counter to maintain non-linear animation effects.\n\nThese two pieces of code are used to import the code loaded into different areas (under the root directory or folder of Flash/SD), so you only need to know how to import the code.\n\n- You can use MaixPy IDE to send files, or use [mpfshell-lite](https://github.com/junhuanchen/mpfshell-lite) to put files to the flash or sd of the hardware.\n- You can use an SD card reader, put the entire folder under the maixui warehouse into the SD card and start it.\n\n### Define UI application\n\nThen introduce a typical basic application case, prepare the following code (class launcher static class).\n\n```python\n\nclass launcher:\n\n  def load():\n    __class__.ctrl = agent()\n    __class__.ctrl.event(20, __class__.draw)\n\n  def free():\n    __class__.ctrl = None\n\n  @ui.warp_template(ui.blank_draw)\n  @ui.warp_template(ui.grey_draw)\n  @ui.warp_template(ui.bg_in_draw)\n  @ui.warp_template(ui.anime_in_draw)\n  @ui.warp_template(ui.help_in_draw)\n  #@ui.warp_template(taskbar.time_draw)\n  #@ui.warp_template(taskbar.mem_draw)\n  #@catch # need sipeed_button\n  def draw():\n    height = 100 + int(get_time_curve(3, 250) * 60)\n    pos = draw_dialog_alpha(ui.canvas, 20, height, 200, 20, 10, color=(255, 0, 0), alpha=200)\n    ui.canvas.draw_string(pos[0] + 10, pos[1] + 10, \"Welcome to MaixUI\", scale=2, color=(0,0,0))\n    ui.display()\n\n  def event():\n    __class__.ctrl.cycle()\n\n```\n\nHere, __class__ is similar to the this pointer in the instance class, through which the global variables of the current class can be accessed.\n\nThe static class has three life cycle functions of load / free / event to provide to the UI container to maintain the continuous operation of the UI application.\n\n- load will only be executed once and is used to initialize the UI application.\n- free will only be executed once, for the release of UI applications.\n- The event will be provided to the UI container to perform its operations in a loop.\n  - UI container refers to [ui/ui_container.py](https://github.com/sipeed/MaixUI/tree/master/ui/ui_container.py).\n  - Of course, you can also keep running without the UI container.\n\nYou can see that the UI application defines the agent soft timer and sets the expected execution cycle of the drawing function to 20ms when it is loaded, and the setting will not be lower than the actual running cycle.\n\n```python\n    __class__.ctrl = agent()\n    __class__.ctrl.event(20, __class__.draw)\n```\n\nThen maintain the time-sharing event (non-blocking no-block) owned by the soft timer ctrl in the event function, so based on this design you can make many time-sharing tasks with different timings.\n\n```python\n    __class__.ctrl.cycle()\n```\n\nIt can be executed periodically, or it can be used up and deleted, as shown below.\n\n```python\n    self.ctrl = agent()\n    # loop\n    self.ctrl.event(5, self.draw)\n    # once\n    def into_launcher(self):\n      container.reload(launcher)\n      self.remove(into_launcher)\n    self.ctrl.event(2000, into_launcher)\n```\n\nThen we see specific UI drawing events, which are different from hardware-driven events such as buttons/touches, but no matter what kind of events, we expect it to end as soon as possible and hand over to the core of operation.\n\n```python\n  @ui.warp_template(ui.blank_draw)\n  @ui.warp_template(ui.grey_draw)\n  @ui.warp_template(ui.bg_in_draw)\n  @ui.warp_template(ui.anime_in_draw)\n  @ui.warp_template(ui.help_in_draw)\n  #@ui.warp_template(taskbar.time_draw)\n  #@ui.warp_template(taskbar.mem_draw)\n  #@catch # need sipeed_button\n  def draw():\n    height = 100 + int(get_time_curve(3, 250) * 60)\n    pos = draw_dialog_alpha(ui.canvas, 20, height, 200, 20, 10, color=(255, 0, 0), alpha=200)\n    ui.canvas.draw_string(pos[0] + 10, pos[1] + 10, \"Welcome to MaixUI\", scale=2, color=(0,0,0))\n    ui.display()\n```\n\nHere, we have one of the most basic draw() drawing functions, and five basic functions are decorated for it. In fact, the decoration is just good-looking, it is actually equivalent to the following code, so whether to use it depends on your preference.\n```python\n  def draw():\n    ui.blank_draw() # prepare a blank image canvas object\n    ui.grey_draw() # Draw gray on the canvas\n    ui.bg_in_draw() # Draw a sipeed logo on the canvas with a built-in background image.\n    ui.anime_in_draw() # Load the animation effect of surrounding water waves on the canvas\n    ui.help_in_draw() # Draw the built-in help instructions on the canvas.\n\n    height = 100 + int(get_time_curve(3, 250) * 60) # Get time-based sine curve value\n    # Draw the effect of the MessageBox with a rounded border at the specified position, and get the starting point of the upper left corner of the border.\n    pos = draw_dialog_alpha(ui.canvas, 20, height, 200, 20, 10, color=(255, 0, 0), alpha=200)\n    # Print the string \"Welcome to MaixUI\" at the specified location.\n    ui.canvas.draw_string(pos[0] + 10, pos[1] + 10, \"Welcome to MaixUI\", scale=2, color=(0,0,0))\n    # Display the current canvas on the screen, and multiple executions will not affect it. After execution, the current canvas object will be released.\n    ui.display()\n```\n\nThe same is true for events connected to other buttons/touches/cameras. You can view the specific implementation of UI drawing here [ui/ui_canvas.py](https://github.com/sipeed/MaixUI/tree/master/ui/ui_canvas. py).\n\n### Run UI framework\n\nBefore actually entering the above business logic, we need to run the UI framework, so we need an entry function, such as the code in `if __name__ == \"__main__\":`.\n\n```python\n\nif __name__ == \"__main__\":\n  container.reload(launcher)\n  while True:\n    container.forever()\n\n```\n\nTo explain, we see that the UI container (container.reload(launcher)) is used to load a UI application named launcher to run. You can view the specific implementation of the UI container here [ui/ui_container.py](https:// github.com/sipeed/MaixUI/tree/master/ui/ui_container.py).\n\nBut just writing in this way is not stable enough, so we can use two while True to keep the program never exiting (unless the system core dump crashes).\n\nAnd the current fps value is obtained by the difference between last and the current tick_ms. It is recommended to close the print function in non-debugging situations. It is very time-consuming (ms level).\n\n```python\n  while True:\n    while True:\n      last = time.ticks_ms()-1\n      while True:\n        try:\n          #time.sleep(0.1)\n          print(1000 // (time.ticks_ms()-last),'fps')\n          last = time.ticks_ms()\n        except Exception as e:\n          gc.collect()\n          print(e)\n        finally:\n          try:\n            ui.display()\n          except:\n            pass\n\n```\n\nThen we strengthen the stability of the environment, adding watchdog maintenance (protect.keep()) and GC memory collection (gc.collect()), and maintaining a global soft timer (system.parallel_cycle()) , Used as a global timer thread.\n\n```python\n\nif __name__ == \"__main__\":\n  container.reload(launcher)\n  while True:\n    while True:\n      last = time.ticks_ms()-1\n      while True:\n        try:\n          #time.sleep(0.1)\n          print(1000 // (time.ticks_ms()-last),'fps')\n          last = time.ticks_ms()\n\n          gc.collect()\n          container.forever()\n          system.parallel_cycle()\n\n          protect.keep()\n          #gc.collect()\n          #print_mem_free()\n        except KeyboardInterrupt:\n          protect.stop()\n          raise KeyboardInterrupt\n        #except Exception as e:\n          #gc.collect()\n          #print(e)\n        finally:\n          try:\n            ui.display()\n          except:\n            pass\n\n```\n\n- You can use time.sleep(0.1) to reduce the execution rate of the UI container to observe whether the change state of the UI is in line with expectations. Sometimes changes higher than 15 fps are not perceived by the human eye, which can reduce unnecessary drawing processes. Compress the drawing process to improve performance.\n- You can use except Exception as e: to ensure that any exception will not cause the UI framework to crash, but you can comment this out to catch possible exceptions when debugging.\n\n> By default, if the program does not execute protect.keep() for more than 10 seconds to reset the watchdog, the system will automatically restart. This starts when the wdt driver is imported. For details, please see [driver/wdt.py](https ://github.com/sipeed/MaixUI/tree/master/driver/wdt.py) driver.\n\nFinally, add catching KeyboardInterrupt exception events to ensure that the program can be stopped and re-run after IDE or Ctrl + C input, and stop the watchdog event (protect.stop()), and also try to execute in finally ui.display() prevents the canvas from being released due to an exception in the drawing event and ensures that the image canvas object can always be released at the end of the loop.\n\n```python\n  try:\n    protect.keep()\n  except KeyboardInterrupt:\n    protect.stop()\n    raise KeyboardInterrupt\n  except Exception as e:\n    gc.collect()\n    print(e)\n  finally:\n    try:\n      ui.display()\n    except:\n      pass\n```\n\nThe above is the most basic demonstration of the MaixUI framework. Although MaixUI will only provide Cube and Amigo application cases, it can be used as long as it is based on MaixPy, or in other words, the MicroPython environment that supports image interface objects can be used.\n\nI hope that we will be able to synchronize to CPython in the future, that is, we can synchronize UI-style development on CPython to the MicroPython environment. This will complete the development efficiently, but the performance will not drop.\n\n### At last\n\nThis document describes how to run the most basic examples. If you want to see more examples, you can refer to [app_cube.py](https://github.com/sipeed/MaixUI/tree/master/app/app_cube.py) & [app_amigo .py](https://github.com/sipeed/MaixUI/tree/master/app/app_amigo.py) Two cases.\n\n> As of now on October 7, 2020, the App case for MaixPy's common functions has been completed, but this requires you to personally write and experience XD. The description only has a little simple interaction and animation display.\n\nThe current running effect of app_main.py is as follows:\n\n![](./image/app_main.gif)"}, "/soft/maixpy/en/course/others/lvgl.html": {"title": "lvgl", "content": "---\ntitle: lvgl\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: LittlevGL\n---\n\n\n**It is not recommended to use this module now, please have sufficient development level, and will not accept questions about the sharing of LVGL and AI functions, thank you for your cooperation (December 11, 2020)**\n\nPlease use the bin firmware with LVGL to operate.\n\nRefer to the official document: [lvgl blog page](https://blog.littlevgl.com/2019-02-20/micropython-bindings)\n\n## Routine\n\nReference [MaixPy_Scripts of github](https://github.com/sipeed/MaixPy_scripts/tree/master/multimedia/gui/lvgl)"}, "/soft/maixpy/en/course/others/system.html": {"title": "System Control", "content": "---\ntitle: System Control\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: system control\n---\n\n\n## Reset (reset)\n\n```python\nimport machine\n\nmachine.reset()\n```\n\n\n## Main frequency (cpu)\n\nYou can set the main frequency of CPU and KPU, please refer to [Maix.freq](/api_reference/Maix/freq.html) module\n\n```python\nfrom Maix import freq\nfreq.set(cpu = 400, kpu = 400)\n```"}, "/soft/maixpy/en/course/media/video.html": {"title": "Use of video", "content": "---\ntitle: Use of video\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: video (video) use\n---\n\n\nDetailed API reference: [video API](./../../api_reference/media/video.html)\n\n## Instructions\n\n> MaixAmigo, MaixCube needs [Initialize ES8374 audio decoder chip](https://github.com/sipeed/MaixPy_scripts/blob/master/modules/others/es8374/es8374.py) before using audio \n\n* Create a video object, set the volume\n\n```python\nimport video\n\nv = video.open(\"/sd/badapple.avi\")\nv.volume(50)\n```\n\n* Initialize lcd, used to play the screen\n\n```python\nimport lcd\n\nlcd.init()\n```\n\n* Create I2S to process audio objects\n\n```python\nfrom Maix import GPIO, I2S\n\ni2s = I2S(I2S.DEVICE_0)\ni2s.channel_config(i2s.CHANNEL_1, I2S.TRANSMITTER, resolution=I2S.RESOLUTION_16_BIT,\n                       cycles=I2S.SCLK_CYCLES_32, align_mode=I2S.RIGHT_JUSTIFYING_MODE)\nfm.register(34, fm.fpioa.I2S0_OUT_D1, force=True)\nfm.register(35, fm.fpioa.I2S0_SCLK, force=True)\nfm.register(33, fm.fpioa.I2S0_WS, force=True)\n\n```\n\n* Play video\n\n```python\nwhile True:\n    if v.play() == 0:\n        print(\"play end\")\n        break\n```\n\n* Recycling objects\n\n```python\nv.__del__()\n```\n\n## Routine\n\n> The avi file address in the test case: [badapple.avi](https://api.dl.sipeed.com/shareURL/MAIX/MaixPy/assets)\n\n* Play avi files: [video_play](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/video/demo_video_play.py)\n* Use the camera to record the video as an avi file and save it: [record_video](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/video/demo_video_record.py)\n* Sequentially capture and display each frame of avi video: [video_capture](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/video/demo_video_capture.py)\n* Amigo play avi files: [amigo_play_video](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/video/amigo_play_video.py)"}, "/soft/maixpy/en/course/media/audio.html": {"title": "the use of audio", "content": "---\ntitle: the use of audio\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: audio (audio) use\n---\n\n\nDetailed API reference: [audio API](./../../api_reference/media/audio.html)\n\n## Instructions\n\n> MaixAmigo, MaixCube needs [Initialize ES8374 audio decoder chip](https://github.com/sipeed/MaixPy_scripts/blob/master/modules/others/es8374/es8374.py) before using audio \n\n* Create audio object\n\n```python\nimport audio\n\nplayer = audio.Audio(path = \"/sd/6.wav\")\n```\n\n* Create I2S objects (used to process audio objects)\n\n```python\nfrom Maix import I2S\n\n# init i2s(i2s0)\nwav_dev = I2S(I2S.DEVICE_0)\n# config i2s according to audio info\nwav_dev.channel_config(wav_dev.CHANNEL_1, I2S.TRANSMITTER,resolution = I2S.RESOLUTION_16_BIT ,cycles = I2S.SCLK_CYCLES_32, align_mode = I2S.RIGHT_JUSTIFYING_MODE)\n```\n\n* Get audio object information and associate I2S object\n\n```python\n# read audio info\nwav_info = player.play_process(wav_dev)\nprint(\"wav file head information: \", wav_info)\n```\n\n* Configure I2S objects according to audio information\n\n```python\nsample_rate = wav_info[1]\nwav_dev.set_sample_rate(sample_rate)\n```\n\n* Use the associated I2S object to play audio\n\n```python\n# loop to play audio\nwhile True:\n    ret = player.play()\n    if ret == None:\n        print(\"format error\")\n        break\n    elif ret==0:\n        print(\"end\")\n        break\n```\n\n* End playback\n\n```python\nplayer.finish()\n```\n\n## Routine\n\n> Test audio address: [6.wav](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/audio/6.wav)\n\n* Play wav files: [play_wav](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/audio/play_wav.py)\n* Record audio as a wav file and save: [record_wav](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/audio/record_wav.py)"}, "/soft/maixpy/en/course/advance/add_c_module.html": {"title": "How to add a MaixPy module in C", "content": "---\ntitle: How to add a MaixPy module in C\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to add a MaixPy module in C\n---\n\n\n\n## Preliminary knowledge\n\nEverything is an object in `python`\n\nYou need to know what module, type, function, and class are, what are the relationships and differences\n\n* module (module)\n\nIn `MaixPy`, the functions of each category are put into a module,\nFor example, the built-in `uos`, `usys`, `machine`,\nIn addition, our own new file, such as `test.py`, can also be a module,\nWe use modules like this:\n```python\nimport uos\nimport machine\nimport test\n```\n> In C source code, it is `mp_type_module`\n\n* type (type)\n\nUsed to represent a basic type, it can contain some methods or variables\n\n> In C source code, it is `mp_type_type`\n\n* class (class)\n\nA class is actually a `type`, for example\n```python\nclass A:pass\nprint(type(A))\n```\nWill output\n```\n<class'type'>\n```\n\nWhen `A` is instantiated\n```\nclass A:pass\na = A()\nprint(type(a))\n```\nWill output\n```\n<class'A'>\n```\nIndicates that `a` is an instance (object) of `A`\n\n> Defining a class in C is actually defining a `mp_type_type`\n\n## Add module in C\n\nOur goal is to realize that the following code can be used at the `MaixPy` level:\n```python\nimport my_lib\nprint(my_lib.__name__)\nmy_lib.hello()\n```\n\n\n### Create a new folder in the `components/port/src` directory, for example, name it `my_lib`\n\n### Then create a new `my_lib.c` file under the `my_lib` folder\n\n### Edit `my_lib.c` to add code\n#### Define a module:\n```c\n#include \"obj.h\"\n\nconst mp_obj_module_t my_lib_module = {\n    .base = {&mp_type_module },\n    .globals = (mp_obj_dict_t*)&mp_module_my_lib_globals_dict,\n};\n```\nHere `my_lib_module` is the defined `my_lib` module object,\n`mp_type_module` indicates that it is a module,\n`mp_module_my_lib_globals_dict` is the global variables and functions of the module. It is a `dict` object, which has our own definitions. It has not been defined yet\n\n#### Define module global variables\n\n```c\nSTATIC mp_obj_t hello()\n{\n    mp_printf(&mp_plat_print, \"hello from my_lib\");\n    return mp_const_none;\n}\n\nMP_DEFINE_CONST_FUN_OBJ_0(my_lib_func_hello_obj, my_lib_func_hello);\n\nSTATIC const mp_map_elem_t my_lib_globals_table[] = {\n    {MP_OBJ_NEW_QSTR(MP_QSTR___name__), MP_OBJ_NEW_QSTR(MP_QSTR_my_lib) },\n    {MP_OBJ_NEW_QSTR(MP_QSTR_hello), (mp_obj_t)&my_lib_func_hello_obj },\n    \n};\n\nSTATIC MP_DEFINE_CONST_DICT (\n    mp_module_my_lib_globals_dict,\n    my_lib_globals_table\n);\n```\n\nHere defines a set of key-value pair arrays, key-value pair values, `mp_map_elem_t` is defined as follows:\n```c\ntypedef struct _mp_map_elem_t {\n    mp_obj_t key;\n    mp_obj_t value;\n} mp_map_elem_t;\n```\n\n* The first value is `key`, and the type is `str` object, which is called by `my_lib.key` at the level of `MaixPy`. Here, `MP_OBJ_NEW_QSTR(MP_QSTR___name__)` is used to generate a `str` object with a value of `__name__`. You may have questions about where the `__name__` this `c` variable is defined. This is automatically generated by the tool during the compilation phase `Variables, in short, remember this can be written to generate a constant `str` object and save it in the firmware.\n* The second value is a number, and the type is an object, which can be `str/function/int/float/tuple/list/dict`, etc., in the following way:\n  * `str`: Here is also the definition of a `str` type value `my_lib`, that is, using `my_lib.__name__` at the level of `MaixPy` to get the result `my_lib`.\n  * `Other constant objects`: You can use `mp_obj_new_xxx`, such as `int` variable `mp_obj_new_int(10)`, function search in `obj.h`\n  * `Function`: The corresponding value of `key``hello` here is `(mp_obj_t)&my_lib_func_hello_obj`, which is a function object. Note that it is not a `C` function. As mentioned earlier, everything in `python` is an object. A function object is used, and then the address is cast to `mp_obj_t`. This function object uses the macro definition of `MP_DEFINE_CONST_FUN_OBJ_0` to define the `C` function of `my_lib_func_hello` as the object of `my_lib_func_hello_obj`. Note that the `hello` function needs to return a value `mp_const_none`, and note that it cannot return `NULL` because `NULL` `Not a (`MaixPy`) object, this return value is the return value when the `hello()` function is called at the `MaixPy` level\n  > In addition to `MP_DEFINE_CONST_FUN_OBJ_0`, which has no parameters, there are also `1/2/3/n` parameters, as well as keywords with keywords. Please refer to the source code to learn by analogy\n\n\nThen use the `MP_DEFINE_CONST_DICT` macro definition to turn the key-value pair of `my_lib_globals_table` into a `dict` object that can be understood at the `MaixPy` level (`mp_map_elem_t` is only understandable at the `C` level) `mp_module_my_lib_globals_dict`, this object is also the previous step Used when defining modules in\n\nAt this point, the definition of a module is complete. At the level of `MaixPy`, in theory, the following statement can be used to use\n```python\nimport my_lib\nprint(my_lib.__name__)\nmy_lib.hello()\n```\n\nBut we haven't compiled\n\n#### Add the module to the firmware and compile it\n\n* Add at the end of the `my_lib.c` file:\n\n```c\nMP_REGISTER_MODULE(MP_QSTR_my_lib, my_lib_module, MODULE_MY_LIB_ENABLED);\n\n```\n\nThis line of code registers the module, but whether it is compiled into the firmware depends on whether the macro definition of `MODULE_MY_LIB_ENABLED` is defined as `1` in `mpconfigport.h`\n\n* So we open the `mpconfigport.h` file and add\n\n```c\n#define MODULE_MY_LIB_ENABLED (1)\n```\n\n* Open `components/micropython/CMakeLists.txt` to edit\n\nFind the place where there is `############## Add source files ###############`\nAdd after\n```cmake\nappend_srcs_dir(MPY_PORT_SRCS \"port/src/my_lib\")\n```\nAt this point, the project will compile the folder `my_lib` to the firmware\n\nThen `python project.py rebuild` can compile the firmware, because there are new files, you must use the `rebuild` command instead of `build`, pay attention to the compilation prompt, if there is an error, pay attention to modify\n\n\n## Add a type to the module\n\nA `my_lib` module was previously defined, now we want to define a class in `my_lib`, called `A`, as follows\n\n```python\nimport my_lib\n\na = my_lib.A()\nprint(a.add(1, 2))\n```\n\nI only talk about the general idea here, and then provide a sample, you can understand it if you are smart\n\n* Define a `mp_obj_type_t` object, just like the previous definition of `mp_obj_module_t`\n* Similarly, give this class object a `dict` object, as a member of this class, the member can be a constant or function or even another `type` object\n* Register this class object to the previous `my_lib` module\n\nThe definition of `mp_obj_type_t` object and member definition can refer to the implementation in `port/src/standard_lib/machine/machine_i2c.c`\n> When defining `mp_obj_type_t`, there is a `make_new` member, this function is used to create a new object function will be called, such as `a = my_lib.A(); a.add(1,2)`\n> If you don't create a new object and call the class method or variable directly, this function will not be called `A.var_a`\n\nFor example, we define a `const mp_obj_type_t my_lib_A_type ...`\n\nThen add this object to `my_lib_globals_table` in `my_lib/my_lib.c` and map it to `key` `A`\n```c\n{MP_ROM_QSTR(MP_QSTR_A), MP_ROM_PTR(&my_lib_A_type) },\n```\n\n\n\n## Note when writing firmware in C language\n\n* `mp_printf` vs `printk` vs `printf`:\nBecause `IDE` uses the serial communication protocol, do not directly use the `printk` or `printf` function to print messages at the `C` level, **must** use the `mp_printf` function to print, otherwise it will cause the `IDE` to run When receiving unintelligible data and disconnecting! !\n\nOf course, you can use `printk` for debugging, because this function will not trigger a system interrupt and can be called in the interrupt function, but it is only used for debugging and must be deleted when the code is actually submitted! !"}, "/soft/maixpy/en/course/advance/compile.html": {"title": "How to complie", "content": "---\ntitle: How to complie\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to complie\n---\n\n\nThis article is an open source project development document written to help some users who want to become developers.\n\n## Get maixpy ​​open source project\n\nPlease prepare the linux system environment (WSL on Windows is also possible), hook up the XXX proxy, enter `git clone https://github.com/sipeed/MaixPy` to pull the MaixPy warehouse code and submodules, and make sure to read the catalog after you get it [Build.md](https://github.com/sipeed/MaixPy/blob/master/build.md) document under.\n\n> Students who do not have an agent can use the github mirror station list (`https://github.com/rc1844/fastgithub`) to accelerate the pull of the maixpy ​​repository. Please do not use gitee to pull the maixpy ​​repository, which will drop the submodule repository.\n\n```\njuwan@juwan-N85-N870HL:~$ git clone https://gitclone.com/github.com/sipeed/MaixPy\nCloning to'MaixPy'...\nremote: Object count: 77517, completed.\nremote: Compressed object: 100% (20929/20929), complete.\nremote: Total 77517 (delta 56791), reused 76050 (delta 55761)\nAmong the recipients: 100% (77517/77517), 53.62 MiB | 972.00 KiB/s, completed.\nProcessing delta: 100% (56791/56791), complete.\njuwan@juwan-N85-N870HL:~$ cd MaixPy/\njuwan@juwan-N85-N870HL:~/MaixPy$ git submodule update --recursive --init\nThe submodule'components/kendryte_sdk/kendryte-standalone-sdk' (https://github.com/sipeed/kendryte-standalone-sdk) has been registered to the path'components/kendryte_sdk/kendryte-standalone-sdk'\nThe submodule'components/micropython/core' (https://github.com/micropython/micropython.git) has been registered to the path'components/micropython/core'\nThe submodule'components/micropython/port/src/lvgl/lv_bindings' (https://github.com/littlevgl/lv_binding_micropython.git) has been registered to the path'components/micropython/port/src/lvgl/lv_bindings'\nThe submodule'components/micropython/port/src/ulab/micropython-ulab' (https://github.com/Neutree/micropython-ulab.git) has been updated to the path'components/micropython/port/src/ulab/micropython -ulab' sign up\nThe submodule'components/spiffs/core' (https://github.com/pellepl/spiffs.git) has been registered to the path'components/spiffs/core'\nThe submodule'tools/flash/kflash_py' (https://github.com/sipeed/kflash.py.git) has been registered to the path'tools/flash/kflash_py'\nThe submodule'tools/kconfig/Kconfiglib' (https://github.com/ulfalizer/Kconfiglib.git) has been registered to the path'tools/kconfig/Kconfiglib'\nThe submodule'tools/spiffs/mkspiffs' (https://github.com/igrr/mkspiffs.git) has been registered to the path'tools/spiffs/mkspiffs'\nCloning to'/home/juwan/MaixPy/components/kendryte_sdk/kendryte-standalone-sdk'...\nCloning to'/home/juwan/MaixPy/components/micropython/core'...\n```\n\nNote that there is no acceleration in pulling the sub-repository after this, and you will try to pull it from github. You can also use the same method to pull the sub-module location separately (defined in `.gitmodules`). This document cannot help you Solve network problems.\n\n> If https://gitclone.com is down, try to find other lines by yourself.\n\nHow to confirm whether the final submodule is pulled completely, you can enter `git submodule status`, please do not compile if it is incomplete, there will be errors.\n\n```shell\njuwan@juwan-N85-N870HL:~/Desktop/maixpy$ git submodule status\n 7fdb511fe61026eec5874885de5981c4f60f664d components/kendryte_sdk/kendryte-standalone-sdk (v0.5.2-181-g7fdb511)\n ced340d739e84737dd5c8e6b4ab9af2ea44e29e7 components/micropython/core (v1.11-64-gced340d73)\n ddf09164ee1711a61169030a7ee8bf370ee5743f components/micropython/port/src/lvgl/lv_bindings (remotes/origin/dev-6.0-32-gddf0916)\n c315a571df49a19b843f7dffc300c21ccb7d4edd components/micropython/port/src/ulab/micropython-ulab (0.24-27-gc315a57)\n ec68ba8208d7550860e4e78299d58a529b88bf85 components/spiffs/core (0.2-234-gec68ba8)\n 1ef6f4c0b2cb8b1872b6ffe9337f4e02d5487fa6 tools/flash/kflash_py (v1.0-79-g1ef6f4c)\n 53c72959ac4d71f99913e4b0eea99261a6585430 tools/kconfig/Kconfiglib (v12.12.1-14-g53c7295)\n 983970e40ff381d95d68a9bddff70c4d9921021b tools/spiffs/mkspiffs (0.2.3-6-g983970e)\n```\n\n### Compile maixpy ​​open source project\n\n> This section assumes that you do not have any experience in building cross-compilation chains.\n\nFirst press [build.md](https://github.com/sipeed/MaixPy/blob/master/build.md) to perform various operations in order. If you don’t speak English, you can open a translator.\n\nThe steps are as follows:\n\n- nstall the necessary compilation tools and Python modules for the linux environment, and make sure cmake / make / python3 are available.\n- Set the toolchain toolchain to the directory `/opt/kendryte-toolchain/` in the system to facilitate the SDK to find the compilation tool, and ensure that the /opt/kendryte-toolchain/bin/riscv64-unknown-elf-gcc compilation tool exists.\n- Enter `cd projects/maixpy_k210` under the specific hardware project of MaixPy and enter `python3 project.py build` to start compiling.\n\nThis is the end of the entire compilation step. After successful compilation, you will get a build folder in the `projects/maixpy_k210` directory, which contains the following files:\n\n- maixpy.bin will be burned to the K210 firmware at address 0x000000.\n- maixpy.txt The content of the decompiled code corresponding to the current firmware, to help you check the information of the pointer address of the core dump.\n\nOther files are .a and .o intermediate files generated during the compilation process and can be ignored.\n\n### Burn maixpy ​​firmware to your hardware\n\nNow you get the maixpy.bin firmware, insert the hardware, and then use `python3 project.py -B goE -p /dev/ttyUSB1 -b 1500000 flash` to burn the hardware. Take the `-B` parameter as an example.\n\n```shell\njuwan@juwan-N85-N870HL:~/Desktop/maixpy/projects/maixpy_k210$ python3 project.py -h\n- SDK_PATH:/home/juwan/Desktop/maixpy\nmaixpy\nusage: project.py [-h] [-p PORT] [-b BAUDRATE] [-t] [-n] [-s] [-B {dan,bit,bit_mic,goE,goD,maixduino,kd233,auto }] [-S] [--toolchain PATH] [--toolchain-prefix PREFIX]\n                  [--config_file PATH] [--verbose]\n                  {config,build,rebuild,menuconfig,clean,distclean,clean_conf,flash}\n\nbuild tool, e.g. `python project.py build`\n```\n\nAmong them, `-B goE` is the choice of version, and the optional items are `dan, bit, bit_mic, goE, goD, maixduino, kd233, auto` indicating the burning method, which has a lot to do with the specific hardware.\n\n- Bit usually corresponds to the chip using CH340.\n\n- maixduino usually corresponds to the chip using CH552.\n\nSpecifically, you can try a variety of options, and you can also choose the BAUDRATE option of burning frequency 115200 and 1.500000. Of course, no matter which configuration, as long as it can be burned in, you need to check the help description of -h for more usage methods.\n\nThe common burning process is as follows:\n\n```shell\n➜ maixpy_k210_minimum git:(master) ✗ sudo kflash -b 1500000 -p /dev/ttyUSB0 build/maixpy.bin\n[sudo] fqr password:\n[INFO] COM Port Selected Manually: /dev/ttyUSB0\n[INFO] Default baudrate is 115200, later it may be changed to the value you set.\n[INFO] Trying to Enter the ISP Mode...\n._\n[INFO] Automatically detected goE/kd233\n\n[INFO] Greeting Message Detected, Start Downloading ISP\nDownloading ISP: |============================================ ================================================= ============| 100.0% 10kiB/s\n[INFO] Booting From 0x80000000\n[INFO] Wait For 0.1 second for ISP to Boot\n[INFO] Boot to Flashmode Successfully\n[INFO] Selected Baudrate: 1500000\n[INFO] Baudrate changed, greeting with ISP again ...\n[INFO] Boot to Flashmode Successfully\n[INFO] Selected Flash: On-Board\n[INFO] Initialization flash Successfully\nProgramming BIN: |============================================= ================================================= ============| 100.0% 47kiB/s\n[INFO] Rebooting...\n```\n\n### Command line to connect hardware & run code\n\nYou can basically use it up to this step.\n\nHere is a recommendation for some quick operations of linux or micropython during development. First, you can use minicom or picocom serial tool to enter the MicroPython terminal (add `&& picocom /dev/ttyUSB0 -b 115200` after the burning command), then When entering micropython, you can press Ctrl + E to enter the paste mode, and then paste the code and enter Ctrl + D to end the input of the running code.\n\n```python\n>>>\nhello world!\n>>>\n```\n\nIn this way, you have completed quick verification and development, but if you want to debug a certain piece of functional code, you can upload the code directly through the command line via [mpfshell-lite](https://github.com/junhuanchen/mpfshell-lite) , Reset and run, and then report an error and debug.\n\n> Low-level development of dynamic languages ​​often operate in this way, so we want to thank all developers who do interpreter interfaces for doing a lot of interface verification.\n\n## MaixPy project application description\n\nAssuming that you already know how to use MaixPy project to develop, compile, and burn, then I will introduce the usage of some tools in depth, here only some common usage will be explained, and no detailed explanation will be expanded.\n\n### Introduce cmake's project compilation method\n\ncmake is a tool that compiles and generates Makefile after writing code and rules through CMakeLists.txt. The usage and details are independent of Baidu. Here is a simple structured cmake project [Get_static_library_by_cmake](https://github.com/junhuanchen/Get_static_library_by_cmake.git) for You run and learn by reference.\n\n\nBefore cmake, makefiles were used for project management. Until today, micropython officially still uses a double-layer Makefile + inclue (makefile) project to manage multi-version hardware.\n\nBut MaixPy only adds micropython to its environment as a dependent library package, so in fact the software architecture design of MaixPy is built around the form of K210 software components.\n\nSo you can go to the hello_world project in the maixpy ​​folder to see how it is composed.\n\n- hello_world\n  - build\n  - compile\n  - main\n  - CMakeLists.txt\n  - config_defaults.mk\n  - project.py\n\nThe MaixPy project has prepared a template for you to build the K210 project. Ignore the process of project construction here, and focus on the project configuration part that needs to be compiled and linked, that is, CMakeLists.txt under main. Its content is as follows.\n\n```cmake\n\n############### Add include ##################\n# list(APPEND ADD_INCLUDE \"include\"\n#)\n# list(APPEND ADD_PRIVATE_INCLUDE \"\")\n############################################\n\n############ Add source files #################\nlist(APPEND ADD_SRCS \"src/main.cpp\"\n    )\n# aux_source_directory(src ADD_SRCS)\n# list(REMOVE_ITEM COMPONENT_SRCS \"src/test2.c\")\n############################################\n\n###### Add required/dependent components ######\nlist(APPEND ADD_REQUIREMENTS kendryte_sdk)\n############################################\n\n############ Add static libs ##################\n# list(APPEND ADD_STATIC_LIB \"lib/libtest.a\")\n############################################\n\nregister_component()\n\n```\n\nYou can see that `ADD_SRCS` links a `src/main.cpp` code file as the program entry.\n\nYou can load modules from other places through `ADD_REQUIREMENTS`. For example, `list(APPEND ADD_REQUIREMENTS kendryte_sdk)` requests the SDK package `kendryte_sdk`.\n\nWhat if you want to link your own nncase library? What about other library codes?\n\nIt can be directly changed to the code of `LINK_DIRECTORIES(/home/juwan/maixpy/projects/maixpy_old/main/src/nncase)` under the absolute path. The premise of this is that the library is provided by the cmake project of.\n\n> Here is a demonstration of how to call your own nncase library during compilation, and read the project after combining these key information. It should be easier to use.\n\n### How to package the micropython spiffs file system and share it\n\nIf you use MaixPy for development, you will find that MaixUI provides a file system file (img). When you flash the same img as the UI system, you will directly enter the UI interface after burning.\n\nYou need to know that MicroPython is a program starting from 0x0. In the program, the VFS (virtual file system) will be constructed in the [0xD00000, (0xD00000 + 0x300000)) interval of Flash through spiffs, which is defined in maixpy/projects/maixpy_xxxxx/config_defaults.mk owned.\n\n```makefile\nCONFIG_SPIFFS_SIZE=0x300000\nCONFIG_SPIFFS_START_ADDR=0xD00000\n```\n\n> Only the use of tools is discussed here, without detailed explanation of its implementation.\n\nAnd [spiffs](https://github.com/pellepl/spiffs) does not support directory structure, then we will find that the file name of ui's img in flash will have a name like `lib/core.py`, Under normal circumstances, it is impossible for us to create this file, so we need to package it with tools.\n\nThere is a gen_spiffs_image.py script in the tools/spiffs/mkspiffs directory to complete the function of this packaged image. For usage, please refer to the instructions in tools/spiffs/README.md.\n\n- Prepare an fs folder under the spiffs directory, which contains the code or resource file content you want to package.\n- Execute `python gen_spiffs_image.py ../../projects/maixpy_k210/config_defaults.mk` to get the maixpy_spiffs.img binary file.\n- Burn the img obtained above to 0xD00000 to restore the content in the micropython file system.\n\nIf you make some small systems and publish them in this way, users will get the img file you provided and burn them in and you will immediately get the same environment as you. This is actually the same as publishing a system image based on a Linux system. of.\n\nNow, have you learned it?\n\n### MaixPy's continuous integration service (Travis CI)\n\nTravis CI provides continuous integration services (Continuous Integration, CI for short). It binds the projects on Github, as long as there is new code, it will be automatically crawled. Then, provide a running environment, perform tests, complete the build, and deploy to the server.\n\nMention that MaixPy uses travis + tools/release.sh to compile the project and upload the compilation directory to the release server to complete the daily build. This is common in the automated build and compilation of various packages. You may be interested Try it yourself.\n\n> [Continuous Integration Service Travis CI Tutorial](http://www.ruanyifeng.com/blog/2017/12/travis_ci_tutorial.html)\n\n### How to better read open source project source code\n\nHaving said that, from a personal point of view, in addition to the basic requirement of reading code, if you want to better read the source code, there are different organizational structures for different projects. Any beginner who has just entered the industry , You can use the project you have experienced as an entry point, and gradually establish a complete software engineering awareness from the aspects of project architecture, source code, compilation, testing, and software release. It is also a good method to conduct in-depth knowledge learning around this, I hope you You can build a complete software engineering system through this article.\n\n## Final reference\n\n- bing.com + keyword + yourself"}, "/soft/maixpy/en/course/advance/project_framework.html": {"title": "Code frame structure", "content": "---\ntitle: Code frame structure\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: code frame structure\n---\n\n\n\n\n## Directory Introduction\n\n| Directory | Sub-directory | Sub-directory 2 | Sub-directory 3 | Content summary |\n| --- | --- | --- | --- | --- |\n| assets | | | | Resource files |\n| projects | | | | Project files, one project per folder |\n| tools | | | | Tools |\n| components|┐ | | | components |\n| | └-boards | | | Board code |\n| | └-drivers | | | Drive |\n| | └-micropython |┐ | | micropython related code |\n| | |└-core | | micropython source code |\n| | |└-port|┐ | maixpy ​​custom part source code |\n| | | |└-builtin_py | maixpy ​​default built-in class |\n| | | |└-include | Porting some header files |\n| | | |└-src | Function module source code |\n| | └-spiffs | | | SPIFFS file system |\n| | └-utils | | | Tools (Function) |\n\n\n> The current code is not very well structured in the `components/micropython/port/src` directory due to historical reasons. The future code should follow the current framework as much as possible to achieve a hierarchy\n\n\n## Add code\n\nThe project is organized using `CMake`, and the project supports multiple configurable options (`Kconfig`)\n\n* If you do not add folders and configuration items, you can add files and compile them in the existing folders\n* If you need to add modules, you can modify `CMakeLists.txt` to add content, you can refer to the less content [c_cpp_project_framework](https://github.com/Neutree/c_cpp_project_framework)\n* If you need to add configuration items, you can modify the `Kconfig` file to achieve the goal. All configuration items will generate macro definitions and add them to `global_config.h` (generated files) during compilation, and in `CmakeLists.txt` This macro definition can be used in all files.\n> For example, define `config BOARD_M5STICK` in Kconfig, in CMakeLists.txt, you can determine whether to compile specific code by judging whether CONFIG_BOARD_M5STICK is true. When compiling, you can choose whether to check it through `python3 project.py menuconfig`"}, "/soft/maixpy/en/course/advance/pack_fs.html": {"title": "Packaging file system", "content": "---\ntitle: Packaging file system\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: packaging file system\n---\n\n\nPack several files on the PC into a SPIFFS file system image, use kflash to burn to a specific address in flash, these files can be read directly on the development board (MaixPy)\n\nFor details, please see the instructions: [pack SPIFFS for MaixPy](https://github.com/sipeed/MaixPy/tree/master/tools/spiffs)\n\nOperation example GIF:\n![pack fs](https://cdn.sipeed.com/pack_spiffs_ops.gif)\n\nGIF alternate link: [pack_spiffs_ops.gif](../../../assets/course/advance/pack_spiffs_ops.gif)"}, "/soft/maixpy/en/course/maixpy/demo_find_green_blob.html": {"title": "MaixPy finds color patches", "content": "---\ntitle: MaixPy finds color patches\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixPy finds color patches\n---\n\n## MaixPy finds color patches\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\n\nlcd.init(freq=15000000)\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\ngreen_threshold = (0, 80, -70, -10, -0, 30)\nwhile True:\n    img=sensor.snapshot()\n    blobs = img.find_blobs([green_threshold])\n    if blobs:\n        for b in blobs:\n            tmp=img.draw_rectangle(b[0:4])\n            tmp=img.draw_cross(b[5], b[6])\n            c=img.get_pixel(b[5], b[6])\n    lcd.display(img)\n```"}, "/soft/maixpy/en/course/speech/recognizer_mfcc.html": {"title": "isolated word", "content": "---\ntitle: isolated word\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: isolated word\n---\n\n\n> **This document has passed the MaixPy 0.5.1_128 minimum_speech_with_ide_support firmware test. Please make sure the hardware recording function is available before use.**\n\nThis is an algorithm module for isolated word recognition. The user generates a vocabulary template through recording and loads it into the module, and then recognizes the vocabulary template loaded by the user through it, and returns the possibility of matching. Please refer to [STM32-based isolated word speech recognition ](https://gk969.com/stm32-speech-recognition/).\n\n- Isolated word recognition\n\n    According to the way of pronunciation, there are three types: isolated word recognition, connected word recognition, and continuous speech recognition; the so-called isolated word recognition (Isolated Word Recognition) means that when the sound to be recognized is issued, only one word in the vocabulary is included at a time Article.\n\n- Vocabulary template\n\n    We record a vocabulary spoken by the human voice and use algorithms to make it into a recognizable template, which is called a vocabulary template.\n\n- Template matching\n\n    Assuming that the algorithm module is loaded with a vocabulary template, after we input data to the algorithm module through recording, it will perform internal matching to obtain the most likely recognition result.\n\n> The specific identification process of this module is: pre-filtering, ADC, framing, endpoint detection, pre-emphasis, windowing, feature extraction, feature matching. Endpoint detection (VAD) uses a combination of short-term amplitude and short-term zero-crossing rate. After detecting the effective speech, according to the human hearing perception characteristics, the Mel frequency cepstral coefficient (MFCC) of each frame of speech is calculated. Then the dynamic time warping (DTW) algorithm is used to match the feature template, and the recognition result is finally output.\n\n## how to use?\n\nCurrent hardware support level: Maix BIT / DOCK / DUINO / GO.\n\n> As of 20201123, after the Cube & Amigo has passed ES8374, the microphone's noise floor is too high and it will be judged as a noisy environment, which needs to be repaired.\n\n### Sample code out of the box\n\n-Use the test case of maixduino/maixbit [isolated_word.py](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/speech_recognizer/isolated_word.py), please read the code for the usage method, please pay attention to the microphone of the hardware Configuration and channel configuration.\n-Maix DOCK can directly use the sample code [demo_isolated_word_on_maixdock.py](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/speech_recognizer/demo_isolated_word_on_maixdock.py), just follow the on-screen instructions to speak, see [ Test video](https://www.bilibili.com/video/BV1oz4y1C7yE?from=search&seid=17464946072274851468).\n\n### Module call flow\n\nIn order to better use this module, please understand the usage process.\n\n#### Prepare I2S recording module\n\nConfigure an I2S.DEVICE_0 device and set the CHANNEL_0 channel to the recording input.\n\n```python\nfrom Maix import GPIO, I2S\nfrom fpioa_manager import fm\n\nfm.register(20,fm.fpioa.I2S0_IN_D0, force=True)\nfm.register(18,fm.fpioa.I2S0_SCLK, force=True) # dock 32\nfm.register(19,fm.fpioa.I2S0_WS, force=True) # dock 30\n\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode=I2S.STANDARD_MODE)\nrx.set_sample_rate(16000)\nprint(rx)\n```\n\noperation result:\n\n```shell\n[MAIXPY]i2s0:(sampling rate=16003, sampling points=1024)\n[MAIXPY]channle0:(resolution=2, cycles=2, align_mode=1, mode=1)\n[MAIXPY]channle1:(resolution=0, cycles=0, align_mode=0, mode=0)\n[MAIXPY]channle2:(resolution=0, cycles=0, align_mode=0, mode=0)\n[MAIXPY]channle3:(resolution=0, cycles=0, align_mode=0, mode=0)\n```\n\n#### Create an isolated word module\n\nThe parameters initialized by isolated_word are as follows:\n\n- [dmac] The DMA channel used for recording. [Channel 2] is used by default.\n- [i2s] Recording device, I2S.DEVICE_0 is used by default.\n- [size] The capacity of vocabulary templates, which means the total number of templates that can be loaded. The default is 10.\n- [shift] Channel selection. Maix series hardware recording devices usually use mono input. Set 0 as the left channel, so 1 is the right channel.\n\n```python\nfrom speech_recognizer import isolated_word\n\n# default: maix dock / maix duino set shift=0\nsr = isolated_word(dmac=2, i2s=I2S.DEVICE_0, size=10, shift=0) # maix bit set shift=1\nprint(sr.size())\nprint(sr)\n\n## threshold\nsr.set_threshold(0, 0, 10000)\n```\n\nThe results are as follows:\n\n```shell\n10\n[MAIXPY] isolated_word:(80212a60)\n mfcc_dats=8023a060\n\n size=10\n\n i2s_device_number_t=0\n\n dmac_channel_number_t=2\n```\n\n#### Entry vocabulary template\n\nCall the following code:\n\n- If the surrounding environment is very noisy, it will output 2 (isolated_word.Ready) to 3 (isolated_word.MaybeNoise) repeatedly, and you need to be in a quiet environment to enter the vocabulary template\n- If the status is isolated_word.Speak, it means you can speak\n- If you run sr.record(0) and its status changes to isolated_word.Done, it means the recording is complete and it will be saved to the template number 0.\n- You can check the current module status through sr.state()\n\n```python\n## record and get & set\nwhile True:\n  time.sleep_ms(100)\n  print(sr.state())\n  if sr.Done == sr.record(0):\n    data = sr.get(0)\n    print(data)\n    break\n  if sr.Speak == sr.state():\n    print('speak A')\n#sr.set(1, data)\n```\n\nIn the same way, if you want to enter the second [Vocabulary Template], you only need to change the entry position, such as to sr.record(1) (the computer storage array starts counting from 0).\n\n#### Identify vocabulary templates\n\nAssuming that you have entered [Vocabulary Template], call the following code, it will continue to recognize the current voice and start matching the entered [Vocabulary Template], which is the so-called isolated word speech recognition.\n\n```python\nprint('recognizer')\nwhile True:\n  time.sleep_ms(200)\n  #print(sr.state())\n  #print(sr.dtw(data))\n  if sr.Done == sr.recognize():\n    res = sr.result()\n    print(res)\n```\n\nThe final effect is to print out the best matching [word template] number and related data. For details, please check the result function usage. You can judge whether the recognition is reasonable according to the actual situation, such as whether the matching frame length/matching degree meets expectations , Too large or too small are unreasonable."}, "/soft/maixpy/en/course/speech/fft_waterfall.html": {"title": "FFT waterfall chart (rain chart)", "content": "---\ntitle: FFT waterfall chart (rain chart)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: FFT waterfall chart (rain chart)\n---\n\n\nThe FFT waterfall chart is the frequency distribution chart of the data over time. The following will introduce how to use MaixPy to draw the waterfall chart.\n\n## Drawing method\n\n* Prepare time domain signals (such as audio data)\n\n```python\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE)\nrx.set_sample_rate(sample_rate)\naudio = rx.record(sample_points)\n```\n\n* Perform FFT operation (use FFT operation on the data and get its frequency distribution)\n\n```python\nfft_points = 512\nfft_res = FFT.run(audio.to_bytes(),fft_points)\nfft_amp = FFT.amplitude(fft_res)\n```\n\n* Draw on image (due to the symmetry of the FFT result, only a part of it needs to be drawn)\n\n```python\nhist_x_num = 128\nimg = image.Image(size=(128,128))\nfor i in range(hist_x_num):\n        img[i] = fft_amp[i]\n```\n\n*Detailed API reference [I2S-API](../../api_reference/Maix/i2s.html), [FFT-API](../../api_reference/Maix/fft.html)*\n\n## Routine\n\n> The following example is tested in firmware v0.5.1 MaixDock\n\nAcquire audio data in real time and draw it as an FFT waterfall chart\n\n[demo_fft_waterfall.py](https://github.com/sipeed/MaixPy_scripts/blob/master/hardware/demo_fft_waterfall.py)\n\neffect:\n\n![](../../../assets/course/fft_waterfall.gif)"}, "/soft/maixpy/en/course/speech/fft.html": {"title": "FFT signal processing", "content": "---\ntitle: FFT signal processing\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: FFT signal processing\n---\n\n\nFFT is Fast Fourier Transform (Fast Fourier Transform), which converts time-domain signals into frequency-domain signals, and has a wide range of applications, such as eliminating audio image noise.\n\n## Instructions\n\nk210 is equipped with a hardware FFT module, which supports 64-point, 128-point, 256-point and 512-point FFT.\n\n* Import FFT module\n\n```python\nimport FFT\n```\n\n* Input time domain data (such as audio data) and perform FFT operation\n\n```python\nres = FFT.run(data, points, shift)\n```\n\nFor related API explanation, please refer to [FFT-API](../../api_reference/Maix/fft.html)\n\n## Routine\n\nCollect sound and perform FFT calculation, and display the calculated data as a histogram on the screen: [demo_fft_spectrum](https://github.com/sipeed/MaixPy_scripts/blob/master/hardware/demo_fft_spectrum.py)\n\neffect:\n<iframe width=\"600\" height=\"350\" src=\"//player.bilibili.com/player.html?aid=44617696&cid=78104545&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy/en/course/speech/recognizer_cnn.html": {"title": "maix asr (automatic speech recognition)", "content": "---\ntitle: maix asr (automatic speech recognition)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: maix asr (automatic speech recognition)\n---\n\n\n> **This document has passed the MaixPy 0.5.1_128 minimum_speech_with_ide_support firmware test. Please make sure that the recording function/call model is available before use.**\n\nThis is a speech recognition module based on an acoustic model. When the user sets a vocabulary composed of pinyin and loads it into the module, the user can start recording to recognize the vocabulary input by the user and return a list of possible matching words.\n\n> I recently received some feedback on February 1, 2021, confirming that some students can't get results when running under the IDE. At this time, please switch to Menu>Run in the terminal to see the results.\n\n## Instructions\n\n**Warning** Students who don't know how to use the recording and call the model, please learn the prerequisite skills before using this document.\n\n- Burn acoustic model\n\n> After TODO, it will be stored in a unified link to the download station.\n\nGet the acoustic model [maix_asr_2900k_0x500000](https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/speech_recognizer/maix_asr_2900k_0x500000.kmodel) from here, and burn it to 0x500000 address.\n\n> Load the module without burning the model, it will core dump, don't ask how to report the error.\n\n- Create recording equipment\n\nThis module supports all Maix series hardware. We only need to configure an I2S.DEVICE_0 device and set CHANNEL_0 to the recording input. If it is Cube and amigo, you need to configure the specific audio decoder chip first, and then turn on the I2C recording device.\n\n```python\nfrom Maix import GPIO, I2S\nfrom fpioa_manager import fm\n\nfm.register(20,fm.fpioa.I2S0_IN_D0, force=True)\nfm.register(18,fm.fpioa.I2S0_SCLK, force=True) # dock 32\nfm.register(19,fm.fpioa.I2S0_WS, force=True) # dock 30\n\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode=I2S.STANDARD_MODE)\nrx.set_sample_rate(16000)\nprint(rx)\n```\n\n- Create an auxiliary class for maix_asr, you can skip it.\n```python\n\nfrom speech_recognizer import asr\n\nclass maix_asr(asr):\n\n  asr_vocab = [\"lv\", \"shi\", \"yang\", \"chun\", \"yan\", \"jing\", \"da\", \"kuai\", \"wen\", \"zhang\", \"de\", \"di\" , \"se\", \"si\", \"yue\", \"lin\", \"luan\", \"geng\", \"xian\", \"huo\", \"xiu\", \"mei\", \"yi\", \"ang\", \" ran\", \"ta\", \"jin\", \"ping\", \"yao\", \"bu\", \"li\", \"liang\", \"zai\", \"yong\", \"dao\", \"shang\", \"xia\" , \"fan\", \"teng\", \"dong\", \"she\", \"xing\", \"zhuang\", \"ru\", \"hai\", \"tun\", \"zhi\", \"tou\", \"you\", \" ling\", \"pao\", \"hao\", \"le\", \"zha\", \"zen\", \"me\", \"zheng\", \"cai\", \"ya\", \"shu\", \"tuo\", \"qu\" , \"fu\", \"guang\", \"bang\", \"zi\", \"chong\", \"shui\", \"cuan\", \"ke\", \"shei\", \"wan\", \"hou\", \"zhao\", \" jian\", \"zuo\", \"cu\", \"hei\", \"yu\", \"ce\", \"ming\", \"dui\", \"cheng\", \"men\", \"wo\", \"bei\", \"dai\" , \"zhe\", \"hu\", \"jiao\", \"pang\", \"ji\", \"lao\", \"nong\", \"kang\", \"yuan\", \"chao\", \"hui\", \"xiang\", \" bing\", \"qi\", \"chang\", \"nian\", \"jia\", \"tu\", \"bi\", \"pin\", \"xi\", \"zou\", \"chu\", \"cun\", \"wang\" , \"na\", \"ge\", \"an\", \"ning\", \"tian\", \"xiao\", \"zhong\", \"shen\", \"nan\", \"er\", \"ri\", \"zhu\", \" xin\", \"wai\", \"luo\", \"gang\", \"qing\", \"xun\", \"te\", \"cong\", \"gan\", \"lai\", \"he\", \"dan\", \"wei\" , \"die \", \"kai\", \"ci\", \"gu\", \"neng\", \"ba\", \"bao\", \"xue\", \"shuai\", \"dou\", \"cao\", \"mao\", \"bo\", \"zhou\", \"lie\", \"qie\", \"ju\", \"chuan\", \"guo\", \"lan\", \"ni\", \"tang\", \"ban\", \"su\", \"quan\", \"huan \", \"ying\", \"a\", \"min\", \"meng\", \"wu\", \"tai\", \"hua\", \"xie\", \"pai\", \"huang\", \"gua\", \"jiang\", \"pian\", \"ma\", \"jie\", \"wa\", \"san\", \"ka\", \"zong\", \"nv\", \"gao\", \"ye\", \"biao\", \"bie\", \"zui \", \"ren\", \"jun\", \"duo\", \"ze\", \"tan\", \"mu\", \"gui\", \"qiu\", \"bai\", \"sang\", \"jiu\", \"yin\", \"huai\", \"rang\", \"zan\", \"shuo\", \"sha\", \"ben\", \"yun\", \"la\", \"cuo\", \"hang\", \"ha\", \"tuan\", \"gong \", \"shan\", \"ai\", \"kou\", \"zhen\", \"qiong\", \"ding\", \"dang\", \"que\", \"weng\", \"qian\", \"feng\", \"jue\", \"zhuan\", \"ceng\", \"zu\", \"bian\", \"nei\", \"sheng\", \"chan\", \"zao\", \"fang\", \"qin\", \"e\", \"lian\", \"fa \", \"lu\", \"sun\", \"xu\", \"deng\", \"guan\", \"shou\", \"mo\", \"zhan\", \"po\", \"pi\", \"gun\", \"shuang\", \"qiang\", \"kao\", \"hong\", \"kan\", \"dian\", \"kong\", \"pei\", \"tong\", \"ting\", \"zang\", \"kuang\", \"reng\", \"ti \", \"pan\", \"heng\", \"chi\", \"lun\", \"kun\", \"han\", \"lei\", \"zuan\", \"man\", \"sen\", \"duan\", \"leng\", \"su i\", \"gai\", \"ga\", \"fou\", \"kuo\", \"ou\", \"suo\", \"sou\", \"nu\", \"du\", \"mian\", \"chou\", \"hen\" , \"kua\", \"shao\", \"rou\", \"xuan\", \"can\", \"sai\", \"dun\", \"niao\", \"chui\", \"chen\", \"hun\", \"peng\", \" fen\", \"cang\", \"gen\", \"shua\", \"chuo\", \"shun\", \"cha\", \"gou\", \"mai\", \"liu\", \"diao\", \"tao\", \"niu\" , \"mi\", \"chai\", \"long\", \"guai\", \"xiong\", \"mou\", \"rong\", \"ku\", \"song\", \"che\", \"sao\", \"piao\", \" pu\", \"tui\", \"lang\", \"chuang\", \"keng\", \"liao\", \"miao\", \"zhui\", \"nai\", \"lou\", \"bin\", \"juan\", \"zhua\" , \"run\", \"zeng\", \"ao\", \"re\", \"pa\", \"qun\", \"lia\", \"cou\", \"tie\", \"zhai\", \"kuan\", \"kui\", \" cui\", \"mie\", \"fei\", \"tiao\", \"nuo\", \"gei\", \"ca\", \"zhun\", \"nie\", \"mang\", \"zhuo\", \"pen\", \"zun\" , \"niang\", \"suan\", \"nao\", \"ruan\", \"qiao\", \"fo\", \"rui\", \"rao\", \"ruo\", \"zei\", \"en\", \"za\", \" diu\", \"nve\", \"sa\", \"nin\", \"shai\", \"nen\", \"ken\", \"chuai\", \"shuan\", \"beng\", \"ne\", \"lve\", \"qia\" , \"jiong\", \"pie\", \"seng\", \"nuan\", \"nang\", \"miu\", \"pou\", \"cen\", \"dia\", \"o\", \"zhuai\", \"yo\", \" dei\", \"n\", \"ei\", \"nou\", \"bia\", \"eng\", \"den\", \"_\"]\n\n  def get_asr_list(string='xiao-ai-fas-tong-xue'):\n    return [__class__.asr_vocab.index(t) for t in string.split('-') if t in __class__.asr_vocab]\n\n  def get_asr_string(listobj=[117, 214, 257, 144]):\n    return'-'.join([__class__.asr_vocab[t] for t in listobj if t <len(__class__.asr_vocab)])\n\n  def unit_test():\n    print(__class__.get_asr_list('xiao-ai'))\n    print(__class__.get_asr_string(__class__.get_asr_list('xiao-ai-fas-tong-xue')))\n\n  def config(self, sets):\n    self.set([(sets[key], __class__.get_asr_list(key)) for key in sets])\n\n  def recognize(self):\n    res = self.result()\n    # print(tmp)\n    if res != None:\n      sets = {}\n      for tmp in res:\n        sets[__class__.get_asr_string(tmp[1])] = tmp[0]\n        #print(tmp[0], get_asr_string(tmp[1]))\n      return sets\n    return None\n\nfrom machine import Timer\n\ndef on_timer(timer):\n  #print(\"time up:\",timer)\n  #print(\"param:\",timer.callback_arg())\n  timer.callback_arg().state()\n\ntry:\n  # default: maix dock / maix duino set shift=0\n  t = maix_asr(0x500000, I2S.DEVICE_0, 3, shift=0) # maix bit set shift=1\n  tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=64, callback=on_timer, arg=t)\n  tim.start()\n\n  #for i in range(50):\n    #time.sleep_ms(100)\n  #t.stop()\n  #for i in range(50):\n    #time.sleep_ms(100)\n  #t.run()\n\n  t.config({\n    'xiao-ai-ya': 0.3,\n    'hao-de-ya': 0.2,\n    'ni-hao-ya': 0.3,\n  })\n\n  print(t.get())\n\n  while True:\n    #time.sleep(1)\n    tmp = t.recognize()\n    # print(tmp)\n    if tmp != None:\n      print(tmp)\nexcept Exception as e:\n  print(e)\nfinally:\n  tim.stop()\n  t.__del__()\n  del t\n```\n\n- Speak into the microphone\n\nWe can see that the following words are defined in the code:\n\n```python\n  t.config({\n    'xiao-ai': 0.3,\n    'hao-de': 0.2,\n    'ni-hao': 0.3,\n  })\n\n  print(t.get())\n```\n\nThat is, you can complete the recognition by saying [ni-hao], [hao-de], and [xiao-ai] into the microphone within 6 seconds. The configuration items are two fields, and the length of the first field does not exceed six.Group Pinyin, the second field indicates the lowest threshold of recognition (matching threshold). If it is higher than this value, it will be printed, and if it is lower than this value, it will be discarded.\n\nAt the beginning of the test, you can speak a little louder, see [Demo Video](https://www.bilibili.com/video/BV1C5411L7JC/) for specific effects, complete example: [test_maix_asr.py](https://github.com/sipeed/MaixPy_scripts/blob/d1d95a4d2fbe4c4b87d683c5fb79fda1fe3f9aae/multimedia/speech_recognizer/test_maix_asr.py)"}, "/soft/maixpy/en/maixpy_history.html": {"title": "MaixPy Development History", "content": "---\ntitle: MaixPy Development History\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy development history\n---\n\n\nWrite down the development history of this article, hoping to let future developers know what MaixPy has gone through, what are the reasons for some major changes, and when major progress has been made.\n\n\nThe code submission history can be seen in the [historic](https://github.com/sipeed/MaixPy/commits/historic) and [master](https://github.com/sipeed/MaixPy/commits/master) branches\n\n\n## September 2018\n\nThe MaixPy project was launched, and the opportunity was the completion of the K210 chip tapeout.\n\nSo everyone wanted to make a set of easy-to-use software kits that allow more people to use AI development in embedded applications. Because of the ease of use of Micropython, and the k210 has 6+2MiB memory, the main frequency is 400MHz, and it is fully capable of controlling Micropython. Micropython is selected as the programming syntax\n\nBased on the development board Maix dock, the name is now called Lichee Pill, and the QQ group name is also called Lichee Pill Alchemy Group\n\n[xiaohui](https://github.com/xiaoxiaohuixxh) and [wipping](https://github.com/wipping) started to try to port Micropython\n\n## December 2018\n\nK210 SDK was replaced from freertos to standalone SDK, and the on-chip peripheral driver adaptation was started\n\n[neucrack](https://github.com/neutree), [xel](https://github.com/xelll) and [zepan](https://github.com/Zepan) join the project team\n\n\n## February 2019\n\nRelease the first version of the firmware [v0.1.1 beta](https://github.com/sipeed/MaixPy/releases/tag/v0.1.1), support basic peripherals, inherit the image sensor lcd API of openmv, Equipped with some open source tools such as upyloader, armpy, etc., write documents and publish them on maixpy.sipeed.com\n\nIn addition, there are also two new development boards, Maix bit and Maix Go.\n\nXiaohui left the project team\n\n## March 2019\n\nRelease the second version of the firmware [v0.2.4](https://github.com/sipeed/MaixPy/releases/tag/v0.2.4), adding support for jpeg, wav, kpu, nes, avi, lvgl, etc.\n\n\n## April 2019\n\nAdapted to OpenMV IDE, which is MaixPy IDE, based on the original software, only USB communication is changed to serial communication supported by k210, and other functions remain unchanged\n\nThe pre-compiled firmware began to differentiate the function into multiple firmware, mainly considering the problem of insufficient memory in the running model\n\nwipping left the project team, zepan and xel focused on other project teams\n\n\n## June 2019\n\n\nThe project structure was refactored. Previously, the code was directly added to the directory structure of micropython and the code was added to the port directory. However, there would be a problem, that is, updating the micropython program becomes more troublesome, and you need to separate the code added by micropython and MaixPy , And the old code structure is too messy, the Makefile is not very well written, and the build is slow.\nSo with the current directory structure, cmake + kconfig is used to build the project, and each component is modularized, and you can choose whether to compile into the firmware. The compilation framework is [here](https://github.com/Neutree/ c_cpp_project_framework). But there are still some remaining problems. There are some legacy codes under the directory that are not fully coupled.\n\n\n## July 2019\n\nAdded support for M5Stick-V development board, maintained by [Martin Han](https://github.com/MarsTechHAN)\n\n\n## December 2019\n\n[Maixhub](https://www.maixhub.com) is online, used for online model training, only need to upload data set without writing code\n\nHardware update: online M1N module, golden finger module\n\n## April 2020\n\n[Sugar Lao Duck](https://github.com/QinYUN575) Join the project team\n\n\n## May 2020\n\n[Big Rats](https://github.com/junhuanchen) Join the project team\n\n## June 2020\n\nHardware update: Maix Cube development board is online\n\n## July 2020\n\nAdd board-level configuration files for different boards, put them in the file system, and read them after booting. This is mainly because Cube and Amigo add power chips. In order to use them normally, you must first set the power chip when booting.\n\nHardware update: Maix Amigo development board is online, with a shell added\n\n## November 2020\n\nReorganize the documents, more perfect documents and communities"}, "/soft/maixpy/en/share/open_projects.html": {"title": "Selected MaixPy related open source projects", "content": "---\ntitle: Selected MaixPy related open source projects\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy related open source project selection\n---\n\n\nHere are some good MaixPy related open source projects to share, welcome to star\n\nIf you also have a good MaixPy-related open source project, welcome to submit [issue](https://github.com/sipeed/MaixPy_DOC/issues) for adding,\nClaim:\n* Related to MaixPy\n* The project has a complete and clear `README`, including introduction, effects, code, usage, etc.\n\n\n## Model training\n\n| Project Home | Introduction | Author |\n| --- | --- | --- |\n| [sipeed/maix_train](https://github.com/sipeed/maix_train) | Classification and detection model training project | [Sipeed](https://github.com/sipeed/maix_train/graphs/contributors) |\n| [lemariva/MaixPy_YoloV2](https://github.com/lemariva/MaixPy_YoloV2) | Use Mobilenet+YOLOv2 to perform object detection on the Sipeed Maix Dock development board, see [blog](https://lemariva.com /blog/2020/01/maixpy-object-detector-mobilenet-and-yolov2-sipeed-maix-dock) | [lemariva](https://github.com/lemariva) |\n| [zhen8838/K210_Yolo_framework](https://github.com/zhen8838/K210_Yolo_framework)| yolo v3 model training framework on k210 | [zhen8838](https://github.com/zhen8838) |\n| [TonyZ1Min/yolo-for-k210](https://github.com/TonyZ1Min/yolo-for-k210) | Train YOLO object detection model on windows | [TonyZ1Min](https://github.com/TonyZ1Min) |\n\n\n\n## UI & System\n\n| Project Home | Introduction | Author |\n| --- | --- | --- |\n| [sipeed/MaixUI](https://github.com/sipeed/MaixUI)| An UI written with MaixPy scripts | Sipeed |\n| [eggfly/M5StickVComputer](https://github.com/eggfly/M5StickVComputer) | A pure Python application framework running on `M5StickV` | [eggfly](https://github.com/eggfly) |"}, "/soft/maixpy/en/share/recommend_articles.html": {"title": "MaixPy Featured Article", "content": "---\ntitle: MaixPy Featured Article\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixPy Featured Articles\n---\n\n\n\nFrom the community **selected** articles, collect some good articles here to facilitate everyone to learn and communicate.\n\nIn addition, if you have experience and want to share, you are also welcome to participate. After writing the article, submit [issue](https://github.com/sipeed/MaixPy_DOC/issues) to add\nClaim:\n* Related to MaixPy\n* Clear article directory hierarchy\n* The logic of the article is clear, and the introduction, effect, operation process, and summary of the sharing need to be stated, with pictures and texts\n\nYou can also directly add experience sharing in the document according to [Participation in experience sharing/sharing template](../share/my_share/index.html). If it is well written, it will also be included on this page\n\n-----------\n\nThe article links are all included in the following posts to facilitate updates:\n\n[Selected Article Navigation](https://cn.bbs.sipeed.com/d/481) (Maybe Chienese article, you can use google translation to translate)"}, "/soft/maixpy/en/share/my_share/index.html": {"title": "MaixPy Experience Sharing —— XXX", "content": "---\ntitle: MaixPy Experience Sharing —— XXX\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy experience sharing-XXX\n---\n\n\nThis catalog is mainly used for sharing your own experience or tutorials, and it can also be moved with the author's permission to reprint, and famous sources.\n\n\n## To participate in sharing, you need to master the knowledge in advance\n\n* Use of git and github\n* Use of github PR (pull request)\n\nThere is a brief introduction in the introductory tutorial, please learn by yourself for detailed usage\n\nIf you are not confident to master these skills, you can submit [issue](https://github.com/sipeed/MaixPy_DOC/issues) to explain the problem or contribute experience, etc. We will help you to add\n\n\n## How to add\n\n\n### Clone document to local\n\n```\ngit clone https://github.com/sipeed/MaixPy_DOC\ncd MaixPy_DOC\n```\n\n\n### New directory\n\nNeed to create a new directory dedicated to writing shared articles,\nCreate a folder in the `MaixPy_DOC/docs/maixpy/zh/share/my_share/` directory, the folder name can only be in lowercase English and underscore, you can name it with your English name, such as `tom` or `lihua`,\nThe following uses `MaixPy_DOC/docs/maixpy/zh/share/my_share/tom` as an example\n\nOf course, if you write an English document, you need to put it in the `MaixPy_DOC/docs/maixpy/en/share/my_share/tom` folder\n\nCreate a file in this folder, name it `readme.md`, and use the `markdown` syntax to write and share in it,\nCreate a `MaixPy_DOC/docs/maixpy/zh/share/my_share/tom/assets` directory to store pictures,\nThe relative path is used to reference the pictures in the document. For example, if the path of an image is `MaixPy_DOC/docs/maixpy/zh/share/my_share/tom/assets/cover.jpg`, it will be in `MaixPy_DOC/docs/maixpy/zh/share/my_share/tom/readme.md `Use the following syntax to quote pictures in\n```\n![Cover](./assets/cover.jpg)\n```\n\nNote, don’t enlarge files in the folder, and don’t use too big pictures, otherwise the document warehouse will be huge\n\n\n### Write documentation\n\nTo make the document look well-formed and easier to read,\nTo write a document **must** follow the grammar and format requirements: **See [document specification](../../contribute/doc_convention.html)**\n\n**Document template**, write an article according to the template, you can modify it according to your own situation\n\n```markdown\n\n\n| Author | Contact | Personal Homepage |\n| --- | --- | --- |\n| XXX | XXXX@XXX.com | [github/sipeed](http://github.com/sipeed) |\n\n\n## Introduction:\n\nDescribe the background of this sharing, the final effect display, etc., you can use pictures, GIFs or videos to display, but don’t put too large images in the `assets` folder, otherwise users will not be able to load them for a long time due to internet speed problems. , It loses its meaning\n\n\n\n## Preparation:\n\n### Preliminary knowledge\n\n### Software and hardware environment to be prepared\n\n#### Hardware\n\nGraphic description of the development board, peripheral modules, etc. used\n\n#### Software\n\nGraphic description of the software tools used, MaixPy version\nIf you use third-party software tools, you can attach the relevant name or download link\n\n\n\n## Process, specific title customization\n\n\n\n## Process, specific title customization\n\n\n\n## Results\n\nIt is recommended to add pictures to show the actual running effect\n\n\n\n## to sum up\n\nSummary of this sharing\n\n\n## Questions and feedback\n\nCan provide feedback\n\n\n\n## Reference\n\nIndicate the articles and source code cited in the article in a list here\n\n* Cited article 1: https://www.sipeed.com\n\n```\n\n\n### Add this share to the directory column on the left side of the document\n\n\nOpen `MaixPy_DOC/docs/maixpy/zh/SUMMARY.md`, add your own share at the end, such as\n\n\n\n```\n## Community & Share\n\n-[Featured Tutorial](./share/recommend_articles.html)\n-[Open source project](./share/open_projects.html)\n-Everyone's experience sharing\n  * [Participation in experience sharing/sharing template](./share/my_share/index.html)\n  * [jerry's model training tutorial](./share/my_share/jerry/index.html)\n\n```\n\nThe effect after adding your own card is:\n\n```\n## Community & Share\n\n-[Featured Tutorial](./share/recommend_articles.html)\n-[Open source project](./share/open_projects.html)\n-Everyone's experience sharing\n  * [Participation in experience sharing/sharing template](./share/my_share/index.html)\n  * [Model Training Tutorial-jerry](./share/my_share/jerry/index.html)\n  * [How to design your own model-tom](./share/my_share/tom/index.html)\n```\n\nNote that there are two spaces in front of **\\***, not `tab`\n\n\n### Submit\n\nAfter writing, submit the modification, and then submit the PR on github. After the PR is passed, the official document page will have this article"}, "/soft/maixpy/en/others/open_projects.html": {"title": "Open source projects related to MaixPy", "content": "---\ntitle: Open source projects related to MaixPy\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: open source projects related to MaixPy\n---\n\n\n\nIf you have any open source projects related to MaixPy, please let us know by email (support@sipeed.com) or [issues](https://github.com/sipeed/MaixPy_DOC/issues/new), or directly modify the document and submitPR\n\nLooking forward to your fun, interesting or practical works~~~"}, "/soft/maixpy/en/others/maixhub_faq.html": {"title": "Maixhub FAQ", "content": "---\ntitle: Maixhub FAQ\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maixhub FAQ\n---\n\n\n## How to make a data set\n\nRefer to the help document of the [maixhub](https://www.maixhub.com) training page\n\n## What to do if the training fails\n\nAfter the training fails, please go to the user center or email to check the failure details"}, "/soft/maixpy/en/others/maixpy_faq.html": {"title": "MaixPy FAQ", "content": "---\ntitle: MaixPy FAQ\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy FAQ\n---\n\n\n\n\n## What are the similarities and differences between MaixPy and C development, and how should I choose\n\nMaixPy is a scripting language based on Micropython. It does not need to be compiled and parsed at runtime. It is simpler and more convenient to write, but it is not as real as C language at runtime.\nSo if you are a quick verification, novice, only python, less hair, etc., you can use MaixPy; those who are pursuing extreme performance efficiency or are familiar with C, and those who are not confident about the long-term stability of MaixPy can use C language development\n\n## MaixPy IDE cannot successfully connect to the development board\n\n**phenomenon:**\n\n​ After getting the development board, I have been unable to connect to MaixPy IDE\n\n* Check whether the firmware supports IDE, early firmware and firmware with `minimum` in the name are not supported\n* Check whether the serial port is occupied (other software also opened the serial port)\n* After clicking the connection, do not use it with the terminal tool at the same time, otherwise the serial port will be occupied and cannot be opened\n* If you have been unable to successfully connect successfully, check:\n  * Please check whether the development board model selection is wrong;\n\n  * Observe whether there is any change on the development board screen, if there is no response, it may be the serial port selection error;\n\n  * Try to upgrade to the latest [master branch firmware](http://cn.dl.sipeed.com/MAIX/MaixPy/release/master), and the latest MaixPy IDE software\n\n> MaixPy version number is lower than 0.5.0_v0 does not support connection to MaixPy IDE\n\n\n## The document webpage cannot be opened and the speed is slow\n\nIf you encounter some pages that cannot be accessed, please check whether the URL (path) is correct, and you can return to the home page (`maixpy.sipeed.com`) and re-enter.\n\nFor example, this URL is caused by clicking too quickly:\n\n```shell\nhttp://localhost:4000/zh/zh/get_started/how_to_read.html\n```\n\nThe correct URL should be:\n\n```shell\nhttp://localhost:4000/zh/get_started/how_to_read.html\n```\n\nIn addition, you can try another network line, such as connecting to a proxy, or changing mobile phone data. You can also use `cn.maixpy.sipeed.com` in China.\n\n## The download speed of the download station is slow, and the file cannot be downloaded\n\nIf you encounter slow download speed at the dl.sipeed.com download station, you can use the domestic synchronization server cn.dl.sipeed.com to download, the path is the same, and it is synchronized once a day;\nSome files provide CDN download links, which will be faster, for example, IDE has instructions in readme.txt\n\n## Micro SD card cannot be read\n\n\nMicro SD cannot be read phenomenon and solutions:\n\n* Confirm whether the SD can be used normally on the computer, if not, the SD is damaged,\n\n* The computer can be used normally, read SD, but MaixPy development board cannot be used:\n\n  SD card is not formatted as MBR partition FAT32 format\n\n* The computer can use the SD card normally. It is also confirmed that the disk format of the SD card is FAT32, but the MaixPy development board still cannot be used:\n\n  Possible reasons: When some SDs leave the factory, there is no disk partition table in the sd, or the disk partition table type is not MBR\n\n  Solution: Use a third-party disk management software to convert the sd partition table type to MBR, and format the sd format to FAT32\n\n> Here **Diskgenius** is used to convert the disk partition table format\n\n![Diskgenius](../../assets/other/diskgenius.png)\n\n\n![GPT type to MBR](../../assets/other/diskgenius_sd_gpt_to_mbr.png)\n\n![MBR Type](../../assets/other/diskgenius_sd.png)\n\n* SD card does not support SPI protocol\n\nAt present, the hardware can only support SPI protocol reading, try to buy a regular card\n\nFor example: the two cards on the left side of the picture below are not supported by MaixPy drivers, the middle and right ones are supported, but the class 10 card in the middle has the fastest speed (up to 128GB tested and available)\n> I have also tested several SanDisk, Kingston, and Samsung cards purchased online, and found that one of the Samsung cards cannot be used\n\n![](../../assets/hardware/other/tf_sdcard.png)\n\n\n## How much capacity does the SD card support?\n\nMaximum tested 128GiB can be used\n\n## Use SD to load file, model is unsuccessful\n\nPhenomenon: We may encounter errors when loading the model during use.\n\nPossible cause of the problem: sd is not compatible and the mount is unsuccessful\n\nVerify whether the SD card is mounted:\n\n```python\nimport os\nprint(os.listdir(\"/\"))\n>>['flash'] # SD card is not mounted\n\n>>['flash','sd'] # Successfully mount the SD card\n```\n\n## Why is the frame rate reduced a lot when the IDE is connected\n\nK210 has no USB peripherals, so it can only use the serial port to communicate with the IDE. The speed is not as fast as the USB device, so it will affect the frame rate. You can turn off the IDE camera preview\n\n\n## Why the camera image previewed on the IDE is blurry\n\nK210 has no USB peripherals, so it can only use the serial port to communicate with the IDE. The speed is not as fast as the USB device. Therefore, the picture is compressed. If you need to see a clear picture, please watch it on the screen of the development board, or save it as a picture and upload it to the computer View\n\nTherefore, the image preview function of the IDE is mainly for teaching and demonstration. It is usually recommended to use the screen.\nYou can use the following code to set the preview quality\n```python\nsensor.set_jb_quality(95)\n```\nThis sets the quality of the preview image to 95%, but the frame rate will be significantly reduced\n\n\n## How to increase the camera frame rate\n\n* Change to a better camera. For example, the frame rate of `ov7740` will be higher than that of `ov2640`. But the premise is that the camera circuit must be compatible with the circuit of the development board\n* Increase the camera clock frequency (`sensor.reset(freq=)`), but be careful not to be too high, too high will make the picture worse\n* You can compile the source code yourself, turn on the camera double buffering option (by default), and `sensor.reset(dual_buff=True)`, the frame rate will increase, but the memory consumption will increase accordingly (approximately 384KiB)\n\n\n## IDE frame buffer imaging direction is incorrect, LCD display direction is incorrect\n\nSince MaixPy supports many hardware models, the display direction will be incorrect when using MaixPy IDE or LCD display, then we need to rotate the image at this time;\nBefore correcting the display direction, we need to confirm whether the sensor direction is rotated (the image in the upper right corner of MaixPy IDE is the image directly output by the Sensor) or the LCD direction is rotated\nCorrection method:\n\n- Sensor direction correction:\n\n```python\n# Set camera horizontal mirroring\n# `enable`: 1 means to turn on horizontal mirroring 0 means to turn off horizontal mirroring\nsensor.set_hmirror(enable)\n\n# Set the camera to mirror vertically\n# `enable`: 1 means turn on vertical mirroring 0 means turn off vertical mirroring\nsensor.set_vflip(enable)\n```\n\n- lcd direction correction:\n\n```python\n# Set `LCD` screen orientation\n# Parameters: `dir`: value range [0,3], rotate clockwise from `0` to `3`\n# Return value: current direction, value [0,3]\nlcd.rotation(dir)\n\n# Set whether `LCD` is mirrored\n# Parameters: `invert`: Whether to display in a mirror, `True` or `False`\n# Return value: The current setting, whether it is mirrored or not, returns `True` or `False`\nlcd.mirror(invert)\n```\n\n## After burning MaixPy, MaixPy fails to start\n\nPhenomenon: We may encounter MaixPy cannot be started after burning MaixPy (it appears that the screen cannot be turned on, the screen is white, etc.).\nThe cause of the problem: A large part of this phenomenon is that the configuration file in the internal file system is read incorrectly, or the system configuration value we set (such as the gc heap value is too large) is incorrect and the system cannot be started.\n\nSolution: Erase the file system (erase all flash)\n\nUse kflash_gui to select the `erase` function in the upper right corner, then load the `MaixPy file system` template, the address becomes `0xD00000`, and the length becomes `3MiB`\n\nOr download the erase firmware: erase.fpkg/flash_erase_16MB.bin/[erase_spiffs.kfpkg](https://cn.dl.sipeed.com/MAIX/MaixPy/release)\n\n\n## Using JTAG debugger has been unable to connect to K210\n\nPhenomenon: Using bare metal to develop K210, JTAG debugger has been unable to connect to K210\n\npossible reason:\n  1. There is a problem with the OpenOCD debugging environment (the details are not explained here)\n  2. After burning ken_gen.bin, the JTAG debugging function of K210 will be permanently disabled\n\n## After downloading and saving the script to MaixPy internal flash, the board cannot update the firmware and cannot start the script\n\n-Possible phenomenon: After downloading and saving the script to MaixPy internal flash, the board cannot update the firmware, and the board cannot start\n\n\n> The problem can be located from the hardware and software:\n\nPossible hardware reasons:\n\n​ TODO: To be updated\n\nPossible software reasons:\n\n  1. GPIO16 is pulled up in the program, which causes the automatic download point circuit to fail to pull down GPIO16, making K210 enter ISP mode\n\n## kflash cannot burn/update MaixPy firmware\n\nkflash_gui configuration options\n\n- Development board model\n  - The wrong development board model is selected\n- Burning space (SRAM/Flash)\n  - Wrong selection of burning space\n- Baud rate & download speed mode\n  - Download baud rate is too high"}, "/soft/maixpy/en/thanks.html": {"title": "Thanks", "content": "---\ntitle: Thanks\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: thanks\n---\n\n\n* [MaixPy source code contributor](https://github.com/sipeed/MaixPy/graphs/contributors)\n* [MaixPy_scripts sample code contributor](https://github.com/sipeed/MaixPy_scripts/graphs/contributors)\n* [Maixduino source code contributor](https://github.com/sipeed/Maixduino/graphs/contributors)\n* [MaixPy_DOC document contributor](https://github.com/sipeed/MaixPy_DOC/graphs/contributors)"}, "/soft/maixpy/en/develop_kit_board/module_microphone.html": {"title": "Sipeed Microphone", "content": "---\ntitle: Sipeed Microphone\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Sipeed Microphone\n---\n\n\n<table border=\"2\">\n    <tr>\n        <th colspan=3>Sipeed microphone module</th>\n    </tr>\n    <tr>\n        <td>Description</td>\n        <td>Physical image</td>\n        <td>Description</td>\n    </tr>\n        <td>\n            Single microphone module\n        </td>\n        <td>\n            <img src=\"../../assets/hardware/module/microphone_taobao_400x400.jpg\" height=\"200\">\n            </p>\n            <a href=\"https://sipeed.taobao.com/\">Click to buy microphone module</a>\n        </td>\n        <td>\n        1. Microphone IC: MSM261S4030H0</p>\n        2. Interface: 6P 2.54mm cable interface</p>\n        3. Power supply voltage: 3.3V@5mA</p>\n        4. Module size: 15.2mm*9.1mm</p>\n        4. Working temperature: -30℃~80℃</p>\n    <tr>\n    <tr>\n        <td>\n            Single microphone module\n        </td>\n        <td>\n            <img src=\"../../assets/hardware/module/mic_array_taobao.jpg\" height=\"200\">\n            </p>\n            <a href=\"https://sipeed.taobao.com/\">Click to buy microphone module</a>\n        </td>\n        <td>\n        1. Microphone IC: 6 MSM261S4030H0</p>\n        2. Interface: 10Pfpc / 10 pin 2.54mm cable interface</p>\n        3. Power supply voltage: 5V@mA</p>\n        4. Module size: 15.2mm*9.1mm</p>\n        4. Working temperature: -30℃~80℃</p>\n    </tr>\n</table>\n\n\n## Sipeed Mic-Array\n\nMic-Array microphone array, as of MaixPy version `MicroPython v0.5.0-218-g8053a70`, the pin io on the microphone array hardware supports custom configuration\n\n\n| No. | MaixGo (default configuration IO) | Description |\n| --- | --- | --- |\n| MIC_D0 | 23 | --- |\n| MIC_D1 | 22 | --- |\n| MIC_D2 | 21 | --- |\n| MIC_D3 | 20 | --- |\n| MIC_WS | 19 | --- |\n| MIC_SCLK | 18 | --- |\n| --- | --- | --- |\n| LED_DAT | 24 | SK9822 DAT |\n| LED_CLK | 25 | SK9822 CLK |\n\n### Routine\n\nSound source localization\n\n```python\nfrom Maix import MIC_ARRAY as mic\nimport lcd\n\nlcd.init()\nmic.init()#Default configuration\n# mic.init(i2s_d0=23, i2s_d1=22, i2s_d2=21, i2s_d3=20, i2s_ws=19, i2s_sclk=18, sk9822_dat=24, sk9822_clk=25)#Customizable configuration IO\n\nwhile True:\n    imga = mic.get_map() # Get sound source distribution image\n    b = mic.get_dir(imga) # Calculate and get the sound source direction\n    a = mic.set_led(b,(0,0,255))# Configure RGB LED color value\n    imgb = imga.resize(160,160)\n    imgc = imgb.to_rainbow(1) # Convert image to rainbow image\n    a = lcd.display(imgc)\nmic.deinit()\n```\n\neffect:\n\n<iframe width=\"600\" height=\"350\" src=\"//player.bilibili.com/player.html?aid=37058760&cid=65120313&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy/en/develop_kit_board/maix_dock.html": {"title": "Maix Dock", "content": "---\ntitle: Maix Dock\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Dock\n---\n\n\n## Appearance and function introduction\n\n### Appearance list\n\n- MaixDock(M1W)\n\n![MaixDock(M1W)](../../assets/hardware/maix_dock/sipeed_maix_dock_m1w.jpg)\n\n- MaixDock(M1)\n\n![MaixDock(M1)](../../assets/hardware/maix_dock/sipeed_maix_dock_m1.jpg)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz* (double-precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen (package): | 2.4 inch TFT, screen resolution: 320\\*240 |\n| Camera (package): | 30W pixel GC0328 camera |\n| WIFI: | MaixDock(M1W) uses M1W (integrated ESP8285 WIFI SOC); MaixDock(M1) has no internal WIFI function |\n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n\n### Pin Resources\n\n![](../../assets/hardware/maix_dock/maixdock_pin_maps.svg)\n\n## Download\n\nSipeed-Maix-Dock data download: [Sipeed-Maix-Dock](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maix-Dock)\n\nSipeed-Maix-Dock specification download: [Sipeed-Maix-Dock](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maix-Dock/Specifications)\n\nSipeed-Maix-Dock schematic download: [Sipeed-Maix-Dock][Sipeed-Maix-Dock]\n\n[Sipeed-Maix-Dock]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maix-Dock/Maix-Dock_11.27/Maix-Dock_11.27(Schematic).pdf"}, "/soft/maixpy/en/develop_kit_board/get_hardware.md.deal.html": {"title": "How to choose a development board", "content": "---\ntitle: How to choose a development board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to choose a development board\n---\n\n\nTo start using MaixPy, you must need a K210 development board, you can get your favorite hardware from Sipeed's official Taobao store:\n[Sipeed Official Taobao Store](https://sipeed.taobao.com/)\n\n## Required hardware\n\n### A development board\n\nSince MaixPy has many early product lines, the specific development board and parameter list are as follows, users can choose the corresponding development board according to their own practical ability and needs\n\n> The onboard ROM of MaixPy series development board is 16MB SPI FLASH, RAM: 6MB (general purpose) + 2MB (KPU dedicated)\n\n<table border=\"2\">\n    <tr>\n        <th colspan=3>MaixPy series development board</th>\n    </tr>\n    <tr>\n        <td>Description</td>\n        <td>Physical image</td>\n        <td>Description</td>\n    </tr>\n        <td>Maix Amigo</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_amigo/sipeed_maix_amigo_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Amigo</a>\n        </td>\n        <td>3.5-inch large screen, reserved three Grove ports, three SPMOD ports (one of which is a gamepad port)</td>\n    <tr>\n        <td>Maix Cube</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_cube/sipeed_maix_cube_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Cube</a>\n        </td>\n        <td>Mini development board, leads to Grove/Spmod interface</td>\n    </tr>\n    <tr>\n        <td>Maix Dock(M1W)</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_dock/sipeed_maix_dock_m1w.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Dock(M1W)</a>\n            </td>\n        <td>All pins are led out, using M1W module (integrated ESP8285)</td>\n    </tr>\n    <tr>\n        <td>Maix Dock(M1)</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_dock/sipeed_maix_dock_m1.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Dock(M1)</a>\n        </td>\n        <td>All pins lead out, using M1 module </td>\n    </tr>\n    <tr>\n        <td>Maix Bit</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_bit/sipeed_maix_bit_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Bit</a>\n        </td>\n        <td>All pins lead out, 2x20pin, the smallest system board</td>\n    </tr>\n    <tr>\n        <td>Maix Duino</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_duino/sipeed_maix_duino_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Duino</a>\n        </td>\n        <td>Compatible with Arduino, supports ESP32 WIFI, supports reading of 5 ADC channels of ESP32</td>\n    </tr>\n    <tr>\n        <td>Maix GO</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_go/sipeed_maix_go_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix GO</a>\n        </td>\n        <td>Discontinued</td>\n    </tr>\n    <tr>\n        <td>Maix Nano</td>\n        <td>\n            <img src=\"../../assets/hardware/m1n/sipeed_maix_m1n_400x400.jpg\" height=\"200\"></br>\n            <img src=\"../../assets/hardware/m1n/sipeed_maix_nano_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Nano</a>\n        </td>\n        <td>Core development board</td>\n    </tr>\n</table>\n\n### USB Type-C cable\n\n<img src=\"../../assets/hardware/other/usb_type_c.png\" height=\"300\" alt=\"type_c\">\n\nType-C was chosen because it supports positive and negative insertion, which is very friendly to development\n\nYou can ask if it is included in the official purchase from Taobao. At present, most Android phones are also using Type-C cables\n\n> **USB data cable note: ** Due to the uneven quality of USB cables on the market, the wires used (mainly the core material) are different, and the better data cable uses tinned copper, copper wire, copper foil wire, and bare wire. Copper, etc., the line resistance is small, the voltage drop at both ends of the data line is small, and copper clad steel, copper clad iron, the line resistance is large, the voltage drop at both ends of the data line is large, causing the actual voltage and current supplied to the development board Small, make the development board in an abnormal working state; therefore, it is recommended to use a reliable data cable (generally the quality of the data cable attached to the mobile phone is relatively reliable)\n\n### Screen\n\n**The screen is strongly recommended to buy!**\n\nFrom Taobao official purchase, you can ask whether it is included. It is recommended that users buy a board or package with LCD to facilitate the visual display of the results when running the program later.\n\n| Board type | Screen driver IC | Support resolution | Whether to support touch | Remarks |\n| --- | --- | --- | --- | --- |\n| Maix Cube(IPS) | ST7789 | 240\\*240 | Not supported | --- |\n| Maix Amigo | ILI9486 | 320\\*480 | Support (FT6X36) | --- |\n| Maix Amigo (IPS version) | ILI9486 | 320\\*480 | Support (FT6X36) | --- |\n| Maix Nano (without screen) | --- | --- | --- | --- |\n| Maix Dock | ST7789 | 320\\*240 | Not Supported | --- |\n| Maix Bit | ST7789 | 320\\*240 | Not Supported | --- |\n| Maix Dock | ST7789 | 320\\*240 | Not Supported | --- |\n| Maix Go | ST7789 | 320\\*240 | Support (FT6X36) | --- |\n### camera\n\nOn sale are: OV2640 (conventional, M12), OV7740, GC0328;\n\nSince the resolution supported by the K210 DVP interface is VGA (640*480 30W), you can actually use a camera with 30W pixels.\n\nAs of MaixPy firmware version: `MaixPy 0.5.0_160`, the supported camera models are as follows\n\n| Model | Device id | Pixel | Description | Remarks |\n| --- | --- | --- | --- | --- |\n| OV2640 | 0x2642 | 200W | Better support | |\n| OV7740 | 0x7742 | 30W | Better support | |\n| OV3660 | 0x3660 | 300W | Compatible operation | |\n| GC0328 | 0x9d | 30W | Better support | |\n| GC2145 | 0x2145 | 200W | Compatible operation | |\n| MT9D111 | 0x1519 | 200W | Can run, support is incomplete | |\n| OV5640 | 0x5640 | 500W | Better support | --- |\n\n\nAs of the firmware version `MicroPython v0.5.0-173`, the related camera test conditions are as follows:\n\n| Hardware model | Monocular or binocular camera that passed the test |\n| --- | --- |\n| M1/M1W Module Series (Maixduino, Dock, Go) | OV2640, GC0328, OV7740, GC2145, OV5640 |\n| M1n Module Series (Nano, Cube) | OV2640, GC0328, OV7740, GC2145, OV5640 |\n| MaixBit | OV2640, GC0328, OV7740, GC2145, OV5640 |\n| Maix Amigo | OV7740 (rear shot), GC0328 (front shot) |\n\n-The color mode of the current camera\n\n| YUV422 | RGB565 & YUV422 |\n| --- | --- |\n| OV2640 | OV5640 |\n| OV7740 | GC2145 |\n| GC0328 | --- |\n\n\nYou can ask for the model from Taobao official purchase, OV7740 frame rate is relatively high; OV2640 is relatively old, and the picture quality is slightly inferior to GC0328\n\n> Note: Many users ask which one supports the highest frame rate when they come up. In fact, the frame rate will be different in addition to the hardware, and in the program you use, the frame rate will also be different due to the different processing procedures of the program, so The specific maximum frame rate cannot be marked here (so as not to mislead users).\n\n### Micro SD card (TF card) (optional)\n\nFiles can be manipulated without using a Micro SD card. A part of the internal Flash has been reserved as a file system, but the Flash speed is very slow!\n\nIn order to facilitate the quick operation of picture files, you can choose to buy a `Micro SD` card, 　 MaixPy 　 built-in SPI SD card protocol driver,\n\nWhen buying, try to choose a new Micro SD card with fast speed protocol, such as SD 2nd generation protocol, Class10 memory card\n\nBecause the K210 does not have SDIO hardware peripherals, it uses SPI to communicate with the SD card. Of course, the quality of SD cards on the market is uneven, and the SPI mode may not be compatible. Try to buy a regular card. If you really need it, please customize it yourself. Drive~~\n\nFor example: the two cards on the left side of the picture below are not supported by MaixPy drivers, the middle and right ones are supported, but the class10 card in the middle has the fastest speed (up to 128GB tested available)\n> I have also tested several SanDisk, Kingston, and Samsung cards purchased online, and found that one of the Samsung cards cannot be used\n\n![TF SDCard](../../assets/hardware/other/tf_sdcard.png)\n\n[**Sipeed official store SD card purchase link**](https://item.taobao.com/item.htm?spm=a1z10.5-c.w4002-21231188711.12.5a7f7379ZEhEdC&id=587713418483), the card’s SPI protocol only It supports the V1 version, so the reading rate is low. It is recommended to buy other SD cards that support the SPI V2 protocol. The SD card can be selected in the Taobao store development board package.\n\n### ST-Link (used to update the firmware of STM32 on the development board Maix Go) (optional)\n\nIf you buy a `Maix Go`, a `STM32` chip is integrated on it to simulate the `USB to serial port` tool and to simulate `JTAG`, if you want to update its firmware later, it is recommended to buy a `ST-Link `Spare; if you don't need `JTAG` function, you don't need to buy it\n\n### JTAG debugger (optional)\n\n-**Note:**\n\n**!!! After burning ken_gen.bin, the JTAG debugging function of K210 will be permanently disabled**\n\n`K210` This chip supports `JTAG` debugging. If you need the debugging function, you need to use the `JTAG` debugger. Please consult and purchase at the official Taobao store of `Sipeed`.\n\nIf it is a `Maix Go` development board, you do not need to purchase a separate `JTAG` debugger. The `Maix Go` development board integrates a `STM32` chip, which can simulate `JTAG` (`STM32` uses `CMSIS-DAP` or `open-ec` firmware), `open-ec` firmware is not currently supported, and will be supported in the future, please refer to the description of the `open-ec` github project homepage"}, "/soft/maixpy/en/develop_kit_board/maix_nano.html": {"title": "Maix Nano", "content": "---\ntitle: Maix Nano\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Nano\n---\n\n\n## Appearance and function introduction\n\n### Appearance list\n\n![Maix Nano](../../assets/hardware/m1n/sipeed_maix_nano.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz* (double-precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen: | No screen |\n| Camera (package): | 30W pixel GC0328 camera |\n\n### Hardware onboard expansion interface\n\nMaix Nano reserves a [SP_MOD](../modules/sp_mod/index.html) interface\n\n## Download\n\n* M1n data download: [dl.sipeed.com](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-M1n)\n* M1n schematic download: [Sipeed M1n Datasheet V1.0.pdf](https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-M1n/Sipeed%20M1n%20Datasheet%20V1.0.pdf)"}, "/soft/maixpy/en/develop_kit_board/maix_go.html": {"title": "Maix Go", "content": "---\ntitle: Maix Go\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maix Go\n---\n\n\n## Appearance and function introduction\n\n### Appearance list\n\n![Maix Go](../../assets/hardware/maix_go/Go.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz* (double-precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen: | 2.4 inch TFT, capacitive touch screen resolution: 320\\*240 |\n| Camera (package): | 200W pixels (actual use 30W), 0V2640 model M12 camera |\n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n\n## Download\n\nSipeed-Maix-Go data download: [Sipeed-Maix-Go](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maix-GO)"}, "/soft/maixpy/en/develop_kit_board/grove_ai_hat.html": {"title": "Grove AI HAT", "content": "---\ntitle: Grove AI HAT\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Grove AI HAT\n---\n\n## Appearance and function introduction\n\n### Appearance at a glance\n\n![Grove AI HAT](../../assets/hardware/grove_ai_hat/grove_ai_hat1.png)\n\n### Onboard functions\n\n| Project           | Description                                                                      |\n| ----------------- | -------------------------------------------------------------------------------- |\n| CPU:              | Dual-core 64bit RISC-V / 400MHz (double-precision FPU integration)               |\n| Memory:           | 8MiB 64bit on-chip SRAM                                                          |\n| Storage:          | 16MiB Flash                                                                      |\n| Screen (package): | 2.4 inch TFT, capacitive touch screen resolution: 320\\*240                       |\n| Camera (package): | Equipped with **0V7740** **30W** pixels **Sensor**                               |\n| Buttons:          | Reset button, power button (short press to turn on, long press *8S* to turn off) |\n| USB:              | Type-C interface, positive and negative blind plugging                           |\n| Onboard sensors:  | Three-axis acceleration sensor (ADXL345BCCZ-RL), ADC (ADS1115IDGS)               |\n\n\n### Hardware onboard expansion interface\n\nThe development version opens four [Grove](https://cn.maixpy.sipeed.com/eh/modules/grove/) interfaces to users, and users can easily DIY.\n\n### Onboard I2C device\n\n| Sensor  | Function                 | I2C address (7-bit address) | SCL  | SDA  | Sample code            |\n| ------- | ------------------------ | --------------------------- | ---- | ---- | ---------------------- |\n| ADS1115 | ADC                      | 0x48                        | IO23 | IO24 | [script](./ads1115.py) |\n| ADXL345 | Three-axis accelerometer | 0x53                        | IO23 | IO24 | [script](./adxl345.py) |\n\n## Download\n\n[Schematic](./Grove_AI_HAT_for_Edge_Computing_v1.0_SCH_190514.pdf)"}, "/soft/maixpy/en/develop_kit_board/maix_amigo.html": {"title": "MaixAmigo", "content": "---\ntitle: MaixAmigo\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixAmigo\n---\n\n\n## Overview\n\n  SIPEED **MaixAmigo** can develop a programming learning kit, MaixAmigo integrates 30W pixel camera, expandable TF card slot, user button, 3.5'TFT display, 520mAh lithium battery, speaker, microphone, SPMOD, GROVE on the hardware Expansion interface, etc.\n\n  MaixAmigo is equipped with MaixPy by default on the software. Users can easily use MicroPython syntax to quickly develop various AIoT developments such as face recognition and object classification. At the same time, it also reserves development and debugging interfaces, which can also be used as a powerful AI learning and development board.\n\n## Appearance and function introduction\n\n### Appearance list\n\n![MaixAmigo](../../assets/hardware/maix_amigo/maix_amigo_0.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz* (double-precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen: | 3.5-inch TFT display, resolution: 320\\*480, support capacitive touch (FT6X36) |\n| Camera: | OV7740 (rear camera) and GC0328 (front camera) 30W pixels each (maximum resolution VGA:640\\*480) |\n| Battery: | Onboard rechargeable lithium polymer battery (capacity 520mAh) |\n| Onboard speaker and microphone | Integrated single audio controller ES8374 1W 8Ω speaker |\n| Onboard interface: | USB-C \\*2 (K210 debug power supply interface + compatible STM32 core board USB interface) |\n| Onboard sensors: | MSA301 three-axis acceleration sensor |\n| Lights: | Three monochromatic LED lights, one flashlight | \n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n| Battery: | 520mAh Lithium Battery |\n\n### Pin Resources\n\n![MaixAmigo](../../assets/hardware/maix_amigo/sipeed_maix_amigo_vi.jpg)\n\n### Hardware onboard expansion interface\n\nMaixAmigo has opened two highly extended interfaces to users: three [SP-MOD](./../modules/sp_mod/index.html) and three [Grove](./../modules/grove/index.html) .md) interface, users can easily do DIY.\n\n### Onboard I2C device\n\nMaixAmigo onboard I2C sensor/IC\n\n| IC     | Device id | I2C address (7-bit address) | MaixPy read address | Sample code |\n| ------ | --------- | --------------------------  | ------------------- | ----------- |\n| ES8374 | 0x08      | 0x10                        | D(16)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/79a5485ec983e67bb8861305a52418b29e0dc205/modules/others/es8374/es8374.py)|\n| MSA301 | 0x13      | 0x26                        | D(38)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/7fea2359a7f0c05f586be915aa8e6112262e0caa/multimedia/gui/maixui/msa301.py)|\n| AXP173 | 0x68      | 0x34                        | D(52)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/7fea2359a7f0c05f586be915aa8e6112262e0caa/multimedia/gui/maixui/pmu_axp173.py)| \n\n\n## Get started\n\nMaixAmigo also uses MaixPy to get started with AIoT. Due to the particularity of the hardware, please use MaixPy after [Configure amigo hardware](https://github.com/sipeed/MaixPy_scripts/blob/master/board/config_maix_amigo.py)(If not configured, the photos taken by the camera will be noisy) .\n\nBefore development, we need to understand and prepare related tools to reduce the pitfalls we have to follow because of insufficient preparation.\n\nSteps to get started:\n\n1. Download the required drivers and software\n2. Connect the development board to the computer and install the USB driver\n3. Update the latest firmware\n4. Download and open the latest MaixPy IDE\n5. Connect MaixPy IDE to the development board Run MaixPy sample program\n\n### Software and hardware preparation\n\nHardware preparation:\n\n  - **Computer** one\n  - **MaixAmigo** Development Board\n  - One **reliable** USB Type-C data cable: pay attention to a **reliable** data cable\n\nSoftware preparation:\n\n  - USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n  - Kflash_gui: [https://dl.sipeed.com/MAIX/tools/kflash_gui](https://dl.sipeed.com/MAIX/tools/kflash_gui)\n  - MaixPy IDE: [https://dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5](https://dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5)\n  - Routine library: [https://github.com/sipeed/MaixPy_scripts](https://github.com/sipeed/MaixPy_scripts)\n\n###  install driver\n\nWhen we get Maix Amigo and connect to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n  <img src=\"../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Win10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install it manually:\n    ![](../../assets/get_started/win_device_2.png)\n\n1. Open the link in the previous section to download the driver\n    ![](../../assets/get_started/win_device_3.png)\n1. Click Install\n    ![](../../assets/get_started/drives.gif)\n1. After the installation is complete, you can see in the device manager that two serial devices have been identified\n    ![](../../assets/get_started/win_device_4.png)\n\n\n### Update the firmware to the latest version\n\n  After the user gets the development board, the on-board firmware may not be the latest version by default, so there will be more or less bugs during use.\n  We need to update the firmware version to the latest version at this time\n\n  View update method: [Update Firmware](../get_started/upgrade_maixpy_firmware.html)\n\n  **If you use the amigo development board, please burn the dedicated amigo firmware greater than or equal to v0.6.2_12 (for example: maixpy_v0.6.2_12_gf18990aa3_amigo_tft(ips)_xxxx.bin). The difference from the standard maixpy ​​firmware is that it has built-in amigo Hardware configuration (config.json), and the screen types are divided into ips and tft. Burning any screen type firmware can be started, but the display of different screens will be abnormal (the normal red maixpy ​​welcome page), so According to the actual situation, it can be burned and confirmed again. **\n\n\n### Run the first program `Hello World`\n\n\n- LCD real-time preview Camera (when connecting with MaixPy IDE, select Maixduino)\n\n\n```python\n# -*- coding: UTF-8 -*-\nimport sensor, image, time, lcd\nfrom fpioa_manager import fm\n\n# -------------\nlcd.init(freq=20000000)\n\nwhile True:\n    try:\n        sensor.reset(choice=1)\n        sensor.set_pixformat(sensor.YUV422)\n        sensor.set_framesize(sensor.QVGA)\n        sensor.skip_frames(time=2000)\n        for i in range(100):\n            img = sensor.snapshot()\n            lcd.display(img)\n    except Exception as e:\n        print(e)\n\n    try:\n        sensor.reset(choice=2)\n        sensor.set_pixformat(sensor.YUV422)\n        sensor.set_framesize(sensor.QVGA)\n        sensor.skip_frames(time=2000)\n        for i in range(100):\n            img = sensor.snapshot().rotation_corr(z_rotation = +90)\n            lcd.display(img)\n\n    except Exception as e:\n        print(e)\n\n```\n## Download\n\nMaix-Amigo data download: [Sipeed-Amigo](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Amigo)\n\nMaix-Amigo specification download: [Sipeed-Amigo](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Amigo/ProductSpecification)\n\nMaix-Amigo IPS version Schematic download: [Maix_Amigo_2970(Schematic).pdf][Maix_Amigo_2970(Schematic).pdf]\n\nMaix-Amigo TFT version Schematic download: [Maix_Amigo_2960(Schematic).pdf][Maix_Amigo_2960(Schematic).pdf]\n\n[Maix_Amigo_2970(Schematic).pdf]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Amigo/2970/Maix_Amigo_2970(Schematic).pdf\n[Maix_Amigo_2960(Schematic).pdf]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Amigo/2960/Maix_Amigo_2960(Schematic).pdf"}, "/soft/maixpy/en/develop_kit_board/core_module.html": {"title": "Sipeed M1/M1W (Lichee Dan)", "content": "---\ntitle: Sipeed M1/M1W (Lichee Dan)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Sipeed M1/M1W (Lichee Dan)\n---\n\n\n1. M1/M1W\n\n![M1/M1W](./../../assets/hardware/m1_m1w/M1_Dan.png)\n![M1/M1W](./../../assets/hardware/m1_m1w/M1_pin.png)\n\nM1: K210 all-pin leads, built-in 8M SRAM in chip, built-in 16M Flash in module\nM1W is the version with WiFi (esp8285)\n\n| Module | WIFI | FLASH | SRAM | Description |\n| --- | --- | --- | --- | --- |\n| M1 | None | 16MiB | 8MiB | --- |\n| M1W | ES8285 | 16MiB | 8MiB | --- |\n| M1n | None | 16MiB | 8MiB | --- |\n\n1. M1n\n\n![M1n](./../../assets/hardware/m1n/M1n.png)\n\nThe M1n core module adopts the M.2 golden finger interface and has a 24Pin FPC base onboard. Compared with M1/M1W, users can quickly integrate K210 into their own creative or commercial products.\n\n\n1. Download\n\nChip K210 Datasheet: Kendryte official website\n\nM1n data download: [dl.sipeed.com](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-M1n)\nM1n schematic download: [Sipeed M1n Datasheet V1.0.pdf](https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-M1n/Sipeed%20M1n%20Datasheet%20V1.0.pdf)"}, "/soft/maixpy/en/develop_kit_board/maix_cube.html": {"title": "MaixCube", "content": "---\ntitle: MaixCube\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixCube\n---\n\n\n## Overview\n\n  SIPEED **MaixCube** can develop programming learning kit, MaixCube integrates 30W camera, expandable TF card slot, user buttons, IPS 1.3 inch display, 200mAh lithium battery, speaker, microphone, SPMOD, GROVE expansion interface, etc. on the hardware.\n  MaixCube is equipped with MaixPy by default on the software. Users can easily use MicroPython syntax to quickly get started with AI IoT development, develop face recognition, object recognition and other AI applications. At the same time, it also reserves development and debugging interfaces, which can also be used as a powerful AI learning development board.\n\n## Appearance and function introduction\n\n### Appearance list\n\n![Maix Cube](../../assets/hardware/maix_cube/maixcube_product_appearance.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz (double precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen: | 1.3 inch **IPS** Screen: Resolution **240*240** |\n| Camera: | Equipped with **0V7740** **30W** pixels **Sensor** |\n| Buttons: | Reset button, power button (short press to turn on, long press *8S* to turn off), three-way button |\n| USB: | Type-C interface, positive and negative blind plug |\n| Audio: | Support audio recording, playback, driver IC (ES8374) |\n| Onboard sensors: | Three-axis acceleration sensor (MSA301) |\n| Lights: | Onboard two RGB LEDs, one flashlight |\n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n| Power management: | AXP173 control unit, 200mAh lithium battery, support user charge and discharge control |\n\n### Pin Resources\n\n![Maix Cube](../../assets/hardware/maix_cube/maixcube_resources.png)\n\n### Onboard expansion interface\n\nMaix Cube opens two highly expanded interfaces to users: one [SP-MOD](../modules/sp_mod/index.html) and one [Grove](./../modules/grove/index.html) Interface, users can easily DIY\n\n### Onboard I2C device\n\nMaixCube onboard I2C sensor/IC\n\n| IC     | Device id | I2C address (7-bit address) | MaixPy read address | Sample code |\n| ------ | --------- | --------------------------  | ------------------- | ----------- |\n| ES8374 | 0x08      | 0x10                        | D(16)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/79a5485ec983e67bb8861305a52418b29e0dc205/modules/others/es8374/es8374.py)|\n| MSA301 | 0x13      | 0x26                        | D(38)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/7fea2359a7f0c05f586be915aa8e6112262e0caa/multimedia/gui/maixui/msa301.py)|\n| AXP173 | 0x68      | 0x34                        | D(52)               |[code](https://github.com/sipeed/MaixPy_scripts/blob/7fea2359a7f0c05f586be915aa8e6112262e0caa/multimedia/gui/maixui/pmu_axp173.py)| \n\n\n## Get started\n\nBecause MaixCube comes with its own GUI demo interface and sample programs, you can play with the preset programs first when you get the board.\nAfter that, we will start to use MaixCube to get started with AIoT with MaixPy.\n\nBefore development, we need to understand and prepare related tools to reduce the pitfalls we have to follow because of insufficient preparation.\n\nSteps to get started:\n\n1. Download the required drivers and software\n2. Connect the development board to the computer and install the USB driver\n3. Update the latest firmware\n4. Download and open the latest MaixPy IDE\n5. Connect MaixPy IDE to the development board Run MaixPy sample program\n\n### Software and hardware preparation\n\nHardware preparation:\n\n  - **Computer** one\n  - **MaixCube** Development Board\n  - One **reliable** USB Type-C data cable: pay attention to a **reliable** data cable\n\nSoftware preparation:\n\n  - USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n  - Kflash_gui: [https://dl.sipeed.com/MAIX/tools/kflash_gui](https://dl.sipeed.com/MAIX/tools/kflash_gui)\n  - MaixPy IDE: [https://dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5](https://dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5)\n  - Routine library: [https://github.com/sipeed/MaixPy_scripts](https://github.com/sipeed/MaixPy_scripts)\n\n###  install driver\n\nWhen we get the Maix Cube and connect to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n  <img src=\"../../assetcs/../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Win10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install it manually:\n    ![](../../assetcs/../assets/get_started/win_device_2.png)\n\n1. Open the link in the previous section to download the driver\n    ![](../../assetcs/../assets/get_started/win_device_3.png)\n1. Click Install\n    ![](../../assets/get_started/drives.gif)\n1. After the installation is complete, you can see in the device manager that two serial devices have been identified\n    ![](../../assetcs/../assets/get_started/win_device_4.png)\n\n\n### Update the firmware to the latest version\n\n  After the user gets the development board, the on-board firmware may not be the latest version by default, so there will be more or less bugs during use.\n  We need to update the firmware version to the latest version at this time\n\n  View update method: [Update Firmware](../get_started/upgrade_maixpy_firmware.html)\n\n\n\n### Run the first program `Hello World`\n\n\n- LCD real-time preview Camera (when connecting with MaixPy IDE, select Maixduino)\n\n```python\nimport sensor, image, time, lcd\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.skip_frames(time = 2000)\nsensor.set_hmirror(1)\nsensor.set_vflip(1)\n\nclock = time.clock()\n\nlcd.init(type=2)\nlcd.rotation(2)\n\nwhile(True):\n    clock.tick()\n    img = sensor.snapshot()\n    print(clock.fps())\n    img.draw_string(60, lcd.height()-120, \"fps:\"+str(clock.fps()), lcd.GREEN, scale=2)\n    lcd.display(img)\n\n```\n\n## Download\n\nSipeed-Maix-Cube data download: [Sipeed-Maix-Cube](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maix-Cube)\n\nSipeed-Maix-Cube specification download: [Sipeed-Maix-Cube](https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maix-Cube/ProductSpecification/Sipeed%20Maix%20Cube%20Datasheet%20V1 .0.pdf)\n\nSipeed-Maix-Cube schematic download: [Sipeed-Maix-Cube][Sipeed-Maix-Cube]\n\n[Sipeed-Maix-Cube]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maix-Cube/Maix-Cube-2757/Maix-Cube-2757(Schematic).pdf"}, "/soft/maixpy/en/develop_kit_board/maix_duino.html": {"title": "MaixDuino", "content": "---\ntitle: MaixDuino\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixDuino\n---\n\n\n## Overview\n\n  SIPEED MaixDuino is a development board compatible with Arduino based on our M1 module (main control: Kendryte K210)\n  <br/>MaixDuino integrates camera, TF card slot, user buttons, TFT display, MaixDuino expansion interface, etc., users can use MaixDuino to easily build a face recognition access control system, and also reserve development and debugging interfaces, which can also be used As a powerful AI learning development board.\n\n## Appearance and function introduction\n\n### Appearance list\n\n![MaixDuino](../../assets/hardware/maix_duino/maixduino_4.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz* (double-precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen (package): | 2.4 inch TFT, screen resolution: 320\\*240 |\n| Camera (package): | 30W pixel GC0328 camera |\n| DVP: | Standard Camera DVP 24PIN interface |\n| Power + USB: | USB Type-C interface |\n| ESP32: | ESP32 SPI connection (ESP32 supports WIFI and Bluetooth), PAM8403A |\n| DAC: | I2C DAC |\n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n\n### Pin Resources\n\n![MaixDuino](../../assets/hardware/maix_duino/sipeed_maixduin_pins.png)\n\n## Download\n\nSipeed-Maix-Duino data download: [Sipeed-Maix-Duino](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maixduino/)\n\nSipeed-Maix-Duino specification download: [Sipeed-Maix-Duino](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maixduino/Specifications)\n\nSipeed-Maix-Duino schematic download: [Sipeed-Maix-Duino][Sipeed-Maix-Duino]\n\n[Sipeed-Maix-Duino]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maixduino/Maixduino_2832/Maixduino_2832(Schematic).pdf"}, "/soft/maixpy/en/develop_kit_board/get_hardware.html": {"title": "How to choose a development board", "content": "---\ntitle: How to choose a development board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: How to choose a development board\n---\n\n\nTo start using MaixPy, you must need a K210 development board, you can get your favorite hardware from Sipeed's official Taobao store:\n[Sipeed Official Taobao Store](https://sipeed.taobao.com/)\n\n## Required hardware\n\n### A development board\n\nSince MaixPy has many early product lines, the specific development board and parameter list are as follows, users can choose the corresponding development board according to their own practical ability and needs\n\n> The onboard ROM of MaixPy series development board is 16MB SPI FLASH, RAM: 6MB (general purpose) + 2MB (KPU dedicated)\n\n<table border=\"2\">\n    <tr>\n        <th colspan=3>MaixPy series development board</th>\n    </tr>\n    <tr>\n        <td>Description</td>\n        <td>Physical image</td>\n        <td>Description</td>\n    </tr>\n        <td>Maix Amigo</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_amigo/sipeed_maix_amigo_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Amigo</a>\n        </td>\n        <td>3.5-inch large screen, reserved three Grove ports, three SPMOD ports (one of which is a gamepad port)</td>\n    <tr>\n        <td>Maix Cube</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_cube/sipeed_maix_cube_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Cube</a>\n        </td>\n        <td>Mini development board, leads to Grove/Spmod interface</td>\n    </tr>\n    <tr>\n        <td>Maix Dock(M1W)</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_dock/sipeed_maix_dock_m1w.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Dock(M1W)</a>\n            </td>\n        <td>All pins are led out, using M1W module (integrated ESP8285)</td>\n    </tr>\n    <tr>\n        <td>Maix Dock(M1)</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_dock/sipeed_maix_dock_m1.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Dock(M1)</a>\n        </td>\n        <td>All pins lead out, using M1 module </td>\n    </tr>\n    <tr>\n        <td>Maix Bit</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_bit/sipeed_maix_bit_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Bit</a>\n        </td>\n        <td>All pins lead out, 2x20pin, the smallest system board</td>\n    </tr>\n    <tr>\n        <td>Maix Duino</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_duino/sipeed_maix_duino_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Duino</a>\n        </td>\n        <td>Compatible with Arduino, supports ESP32 WIFI, supports reading of 5 ADC channels of ESP32</td>\n    </tr>\n    <tr>\n        <td>Grove AI HAT</td>\n         <td>\n             <img src=\"../../assets/hardware/grove_ai_hat/grove_ai_hat.jpg\" height=\"200\"></br>\n             </p><a href=\"https://sipeed.taobao.com/\">Click to buy Grove AI HAT</a>\n         </td>\n         <td>Onboard accelerometer and high-precision ADC, lead to multiple Grove/Spmod interfaces, which can be used as Raspberry Pi accessories</td>\n     </tr>\n    <tr>\n        <td>Maix GO</td>\n        <td>\n            <img src=\"../../assets/hardware/maix_go/sipeed_maix_go_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix GO</a>\n        </td>\n        <td>Discontinued</td>\n    </tr>\n    <tr>\n        <td>Maix Nano</td>\n        <td>\n            <img src=\"../../assets/hardware/m1n/sipeed_maix_m1n_400x400.jpg\" height=\"200\"></br>\n            <img src=\"../../assets/hardware/m1n/sipeed_maix_nano_400x400.jpg\" height=\"200\">\n            </p><a href=\"https://sipeed.taobao.com/\">Click to buy Maix Nano</a>\n        </td>\n        <td>Core development board</td>\n    </tr>\n</table>\n\n### USB Type-C cable\n\n<img src=\"../../assets/hardware/other/usb_type_c.png\" height=\"300\" alt=\"type_c\">\n\nType-C was chosen because it supports positive and negative insertion, which is very friendly to development\n\nYou can ask if it is included in the official purchase from Taobao. At present, most Android phones are also using Type-C cables\n\n> **USB data cable note: ** Due to the uneven quality of USB cables on the market, the wires used (mainly the core material) are different, and the better data cable uses tinned copper, copper wire, copper foil wire, and bare wire. Copper, etc., the line resistance is small, the voltage drop at both ends of the data line is small, and copper clad steel, copper clad iron, the line resistance is large, the voltage drop at both ends of the data line is large, causing the actual voltage and current supplied to the development board Small, make the development board in an abnormal working state; therefore, it is recommended to use a reliable data cable (generally the quality of the data cable attached to the mobile phone is relatively reliable)\n\n### Screen\n\n**The screen is strongly recommended to buy!**\n\nFrom Taobao official purchase, you can ask whether it is included. It is recommended that users buy a board or package with LCD to facilitate the visual display of the results when running the program later.\n\n| 板型                      | 屏幕驱动 IC | 支持分辨率 | 备注 |\n| ------------------------- | ----------- | ---------- | ---- |\n| Maix Cube(IPS)            | ST7789      | 240\\*240   | ---  |\n| Maix Amigo                | ILI9486     | 320\\*480   | ---  |\n| Maix Amigo(IPS version)   | ILI9486     | 320\\*480   | ---  |\n| Maix Nano(without screen) | ---         | ---        | ---  |\n| Maix Dock                 | ST7789      | 320\\*240   | ---  |\n| Maix Bit                  | ST7789      | 320\\*240   | ---  |\n| Maix Dock                 | ST7789      | 320\\*240   | ---  |\n| Maix Go                   | ST7789      | 320\\*240   | ---  |\n| Grove AI HAT              | ST7789      | 320\\*240   | ---  |\n### camera\n\nOn sale are: OV2640 (conventional, M12), OV7740, GC0328;\n\nSince the resolution supported by the K210 DVP interface is VGA (640*480 30W), you can actually use a camera with 30W pixels.\n\nAs of MaixPy firmware version: `MaixPy 0.5.0_160`, the supported camera models are as follows\n\n| Model   | Device id | Pixel | Description                    | Remarks |\n| ------- | --------- | ----- | ------------------------------ | ------- |\n| OV2640  | 0x2642    | 200W  | Better support                 |         |\n| OV7740  | 0x7742    | 30W   | Better support                 |         |\n| OV3660  | 0x3660    | 300W  | Compatible operation           |         |\n| GC0328  | 0x9d      | 30W   | Better support                 |         |\n| GC2145  | 0x2145    | 200W  | Compatible operation           |         |\n| MT9D111 | 0x1519    | 200W  | Can run, support is incomplete |         |\n| OV5640  | 0x5640    | 500W  | Better support                 | ---     |\n\n\nAs of the firmware version `MicroPython v0.5.0-173`, the related camera test conditions are as follows:\n\n| Hardware model                             | Monocular or binocular camera that passed the test |\n| ------------------------------------------ | -------------------------------------------------- |\n| M1/M1W Module Series (Maixduino, Dock, Go) | OV2640, GC0328, OV7740, GC2145, OV5640             |\n| M1n Module Series (Nano, Cube)             | OV2640, GC0328, OV7740, GC2145, OV5640             |\n| MaixBit                                    | OV2640, GC0328, OV7740, GC2145, OV5640             |\n| Maix Amigo                                 | OV7740 (rear shot), GC0328 (front shot)            |\n\n- The color mode of the current camera\n\n| YUV422 | RGB565 & YUV422 |\n| ------ | --------------- |\n| OV2640 | OV5640          |\n| OV7740 | GC2145          |\n| GC0328 | OV5642          |\n\n\nYou can ask for the model from Taobao official purchase, OV7740 frame rate is relatively high; OV2640 is relatively old, and the picture quality is slightly inferior to GC0328\n\n> Note: Many users ask which one supports the highest frame rate when they come up. In fact, the frame rate will be different in addition to the hardware, and in the program you use, the frame rate will also be different due to the different processing procedures of the program, so The specific maximum frame rate cannot be marked here (so as not to mislead users).\n\n### Micro SD card (TF card) (optional)\n\nFiles can be manipulated without using a Micro SD card. A part of the internal Flash has been reserved as a file system, but the Flash speed is very slow!\n\nIn order to facilitate the quick operation of picture files, you can choose to buy a `Micro SD` card, 　 MaixPy 　 built-in SPI SD card protocol driver,\n\nWhen buying, try to choose a new Micro SD card with fast speed protocol, such as SD 2nd generation protocol, Class10 memory card\n\nBecause the K210 does not have SDIO hardware peripherals, it uses SPI to communicate with the SD card. Of course, the quality of SD cards on the market is uneven, and the SPI mode may not be compatible. Try to buy a regular card. If you really need it, please customize it yourself. Drive~~\n\nFor example: the two cards on the left side of the picture below are not supported by MaixPy drivers, the middle and right ones are supported, but the class10 card in the middle has the fastest speed (up to 128GB tested available)\n> I have also tested several SanDisk, Kingston, and Samsung cards purchased online, and found that one of the Samsung cards cannot be used\n\n![TF SDCard](../../assets/hardware/other/tf_sdcard.png)\n\n[**Sipeed official store SD card purchase link**](https://item.taobao.com/item.htm?spm=a1z10.5-c.w4002-21231188711.12.5a7f7379ZEhEdC&id=587713418483), the card’s SPI protocol only It supports the V1 version, so the reading rate is low. It is recommended to buy other SD cards that support the SPI V2 protocol. The SD card can be selected in the Taobao store development board package.\n\n### ST-Link (used to update the firmware of STM32 on the development board Maix Go) (optional)\n\nIf you buy a `Maix Go`, a `STM32` chip is integrated on it to simulate the `USB to serial port` tool and to simulate `JTAG`, if you want to update its firmware later, it is recommended to buy a `ST-Link `Spare; if you don't need `JTAG` function, you don't need to buy it\n\n### JTAG debugger (optional)\n\n- **Note:**\n\n**!!! After burning ken_gen.bin, the JTAG debugging function of K210 will be permanently disabled**\n\n`K210` This chip supports `JTAG` debugging. If you need the debugging function, you need to use the `JTAG` debugger. Please consult and purchase at the official Taobao store of `Sipeed`.\n\nIf it is a `Maix Go` development board, you do not need to purchase a separate `JTAG` debugger. The `Maix Go` development board integrates a `STM32` chip, which can simulate `JTAG` (`STM32` uses `CMSIS-DAP` or `open-ec` firmware), `open-ec` firmware is not currently supported, and will be supported in the future, please refer to the description of the `open-ec` github project homepage"}, "/soft/maixpy/en/develop_kit_board/develop_kit_board.html": {"title": "MaixPy series development board", "content": "---\ntitle: MaixPy series development board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy series development board\n---\n\n\n-------\n\n## MaixPy Development Board\n\nAt present, MaixPy series development boards have the following models:\n\n- Maix Go\n- Maix Dock\n- Maix Duino\n- Maix Bit\n- Maix Cube\n- Maix Amigo\n\n## Difference comparison\n\n| Model | USB IC | Core Module | Remarks |---| --- |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Maix Go <img src=\"../../assets/dk_board/maix_go/Go.jpg\" width=\"260\"> |Maix Go | STM32 | M1W | --- | --- |\n| Maix Dock <img src=\"../../assets/dk_board/maix_dock/Dan_Dock.png\" width=\"260\">| CH340 | M1/M1W | --- | --- | --- |\n| Maix Duino <img src=\"../../assets/dk_board/maix_duino/maixduino_0.png\" width=\"260\"> | CH552 | M1 | --- | --- | --- |\n| Maix Bit <img src=\"../../assets/dk_board/maix_bit/BiT.png\" width=\"260\"> | CH552/CH340 | --- | --- | --- | --- |\n| Maix Cube <img src=\"../../assets/dk_board/maix_cube/maixcube_2020-06-13_06-31-29.png\" width=\"260\"> | GD32/CH552 | M1n | --- |- - | --- |\n|Maix Amigo <img src=\"\" width=\"260\"> | GD32 | M1n | --- | --- | --- |"}, "/soft/maixpy/en/develop_kit_board/core_k210.html": {"title": "K210 module core board", "content": "---\ntitle: K210 module core board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: K210 module core board\n---\n\n\n![K210](./../../assets/hardware/k210/k210-front-background.jpg)\n\nKendryte K210 is a system-on-chip (SoC) that integrates machine vision and machine hearing capabilities. It uses TSMC's ultra-low power 28-nanometer advanced manufacturing process, with dual-core 64-bit processors, and has good power consumption performance and stability And reliability. The program strives for zero-threshold development, which can be deployed in the user's products in the shortest time, giving the product artificial intelligence.\n\nKendryte K210 is located in the SoC of the AI ​​and IoT market, and it is also a very convenient MCU.\n\nThe Chinese meaning of Kendryte is **Kanzhi(堪智)**, and Kanzhi is derived from Geophysical Prospecting. The main application field of this chip is the Internet of Things field, and it is developed in the field of Internet of Things, so it is Prospecting; this chip mainly provides Artificial intelligence solutions are explored in the field of artificial intelligence, so they are intellectual exploration.\n\nHave machine vision capabilities\nWith machine hearing ability\nBetter low-power vision processing speed and accuracy\nEquipped with a convolutional artificial neural network hardware accelerator KPU, which can perform convolutional artificial neural network operations with high performance\nTSMC 28nm advanced manufacturing process, temperature range -40°C to 125°C, stable and reliable\nSupport firmware encryption, which is difficult to crack with ordinary methods\nUnique programmable IO array makes product design more flexible\nLow voltage, lower power consumption compared with systems with the same processing capacity\n3.3V/1.8V dual voltage support, no level conversion required, cost saving\n\n1. AI solutions\n## 1.1. Machine Vision\n\nKendryte K210 has machine vision capabilities and is a zero-threshold machine vision embedded solution. It can perform convolutional neural network calculations with low power consumption.\n\nThe chip can achieve the following machine vision capabilities:\n\nGeneral target detection based on convolutional neural network\nImage classification task based on convolutional neural network\nFace detection and face recognition\nGet the size and coordinates of the detected target in real time\nReal-time acquisition of the types of detected targets\n\n1.2. Machine hearing\n\nKendryte K210 has machine hearing capabilities. The chip comes with a high-performance microphone array audio processor, which can perform real-time sound source orientation and beamforming.\n\nThe chip can achieve the following machine hearing capabilities:\n\nSound source orientation\nSound field imaging\nBeamforming\nWake up\nSpeech Recognition\n\n1.3. Hybrid vision/auditory solutions\nKendryte K210 can combine machine vision and machine hearing capabilities to provide more powerful functions. On the one hand, in the application, it can not only assist machine vision to track the target through sound source localization and sound field imaging, but also obtain the target position through general target detection. After assisting the machine hearing to perform beamforming on the position. On the other hand, the direction of the person can be obtained through the image from the camera, so that the microphone array can be directed to the person through beamforming. At the same time, the direction of a speaker can also be determined according to the microphone array , Turn the camera to point at the person.\n\n2. Download\n\nKendryte official website download page One of the must-see datasheets\n\nKendryte Github"}, "/soft/maixpy/en/develop_kit_board/maix_bit.html": {"title": "Maix Bit", "content": "---\ntitle: Maix Bit\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Bit\n---\n\n\n## Appearance and function introduction\n\n### Appearance list\n\n![Maix Bit](../../assets/hardware/maix_bit/maix_bit.png)\n\n### Onboard functions\n\n| Project | Description |\n| --- | --- |\n| CPU: | Dual-core 64bit RISC-V / 400MHz (double precision FPU integration) |\n| Memory: | 8MiB 64bit on-chip SRAM |\n| Storage: | 16MiB Flash, support micro SDXC expansion storage (max 128GB) |\n| Screen (package): | 2.4 inch TFT, screen resolution: 320\\*240 |\n| Camera (package): | 200W pixels (actual use 30W), 0V2640 model M12 camera |\n| TF card slot: | Multimedia resource expansion, support large-capacity storage |\n\n### Pin Resources\n\n![](./../../assets/hardware/maix_bit/maixbit_pin_maps.svg)\n\n## Download\n\nSipeed-Maix-Bit data download: [Sipeed-Maix-Bit](https://dl.sipeed.com/shareURL/MAIX/HDK/Sipeed-Maix-Bit)\n\nSipeed-Maix-Bit specification download: [Sipeed-Maix-Bit](https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maix-Bit/Specifications/Sipeed_Maix_Bit_Specification_V2.0.pdf)\n\nSipeed-Maix-Bit schematic download: [Sipeed-Maix-Bit][Sipeed-Maix-Bit]\n\n[Sipeed-Maix-Bit]: https://dl.sipeed.com/fileList/MAIX/HDK/Sipeed-Maix-Bit/Maix-Bit%20V2.0(with%20MEMS%20microphone)/Maix-Bit%20V2 .0(Schematic).pdf"}, "/soft/maixpy/en/contribute/app_doc_template.html": {"title": "MaixPy_DOC example tutorial template", "content": "---\ntitle: MaixPy_DOC example tutorial template\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy_DOC example tutorial template\n---\n\n\n\nThis article explains the specifications and precautions followed by document contributors in writing tutorials, please write documents based on this article;\nIf you have any doubts about the template format and content, please go to the project repository [MaixPy_DOC](https://github.com/sipeed/MaixPy_DOC) to submit `ISSUE`.\n\n🙇‍ Thank you for your enthusiastic support!\n\n\n- About documentation tools\n\n> The document is written using `MarkDown` syntax, and the overall document project is built using `gitbook`; here it is recommended to use `Typora` and `VS Code` with `MarkDown` plug-in as a text editor\n\n- About document storage\n\n> Please save the example tutorial document to the path `./MaixPy_DOC/zh (here distinguish Chinese and English, Chinese: zh, English: en)/application/xxx (specific classification, please refer to the subsequent description for classification suggestions)/xxx (specific routine Name, it is recommended to use English name)`.md\n\n> It is recommended to use relative links for the pictures referenced in the document, and store the picture files in the folder `[file name].assets` in the same directory as the document;\n\n- Establish storage path for document classification\n\n> The recommended naming (storage path) that is strongly related to hardware peripherals is: ``\n\n> The recommended naming (storage path) that is strongly related to image is: `image`\n\n> The recommended naming (storage path) strongly related to KPU is: `KPU`\n\n> The suggested naming (storage path) of a more comprehensive routine is: `demo`\n\n\n\n> The following is the content of the document template:\n\n\n# MaixPy Example Tutorial-XXX\n\n## I. Overview:\n\n> 1. Describe the effect of this routine\n>\n> 2. Briefly explain the operation steps\n>\n\n\n## Two, preparation:\n\n> Explain the hardware and software environment to be prepared\n\n- Preliminary knowledge\n\n- Hardware\n\n    > Graphic description of the development board && peripheral modules used\n\n- Software\n\n    > Graphic description of the software tools used, MaixPy version\n    > If you use third-party software tools, you can attach the relevant name or download link\n\n### Specific steps\n\n\n### code\n\n```python\nxxxxx\n```\n\n\n### Effect\n\n> It is recommended to add pictures to show the actual running effect\n\n## Question && Feedback\n\n\n-----\n\n- Contributor description:\n\n> Here is an entry point for contributors\n\n    Author:\n\n    Contact (Email):\n\n    Blog:"}, "/soft/maixpy/en/contribute/code_convention.html": {"title": "MaixPy programming specification", "content": "---\ntitle: MaixPy programming specification\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy programming specification\n---\n\n\nThis is a development guide for **MaixPy** developers. **MaixPy** as an open source software, it needs to be completed by different people in a cooperative way. This document is a guide for developers.\n\n**MaixPy** developers please follow this programming style. At the same time, users who use MaixPy can also use this document to understand some conventions in the MaixPy code so that they can easily grasp the implementation of MaixPy.\n\n## Normative principles\n\n- [x] Simple, avoid obscure syntax\n- [x] Strict and logical thinking\n- [x] Simple, concise naming and refined code\n- [x] Performance, optimized by algorithm, compiler and hardware\n\n## Directory structure && file name\n\n- Directory Structure\n\nThe entire project is divided into subdirectories according to functional modules, and each subdirectory is divided into header files and source file directories to make the structure clear and easy to understand.\nIf the catalog name has no special requirements, please use all lowercase; the catalog name should reflect part of the meaning, and the components directory can reflect the meaning of components.\n\n- File structure\n\nIf there is no special requirement for the file name (if you quote other places, you can keep the corresponding name), please use all lowercase. In addition, in order to avoid the problem of duplicate file names, please try not to use generalized and frequently used names in some places.\n\n## Header file definition\n\nC language header files need to define a symbol in order to avoid repeated inclusion. Please use the following definition of this symbol\nstyle of:\n\n```c\n#ifndef __FILE_H__\n#define __FILE_H__\n/* header file content */\n#endif\n```\n\nThat is, \"__\" is used on both sides of the defined symbol to avoid duplication. In addition, it can also be changed according to whether the file name contains multiple words.\nUse \"_\" to connect.\n\n## File header comment\n\nThe header of each source file should include the corresponding copyright information, Change Log record:\n\n```c\n/**\n * File: maixpy_main.h\n * This file is part of MaixPy\n * Copyright 2019 Sipeed Co.,Ltd. MaixPy Development Team\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n```\n\nFor example, the above form is adopted.\n\n## Structure definition\n\nPlease use lowercase English names for structure names, and use \"_\" to connect words to words, for example:\n\n```c\nstruct lcd_config\n{\n    int width;\n    int height;\n};\n```\n\nAmong them, \"{\", \"}\" occupies a line independently, and the following member definitions are defined by indentation.\n\nFor the type definition of structure, please use the structure name plus \"_t\" as the name, for example:\n\n```c\n    typedef struct lcd_config lcd_config_t;\n```\n\n## Macro definition\n\nIn MaixPy, please use uppercase English names as macro definitions, and use \"_\" between words to connect, for example:\n\n```c\n    #define MAIXPY_TRUE 1\n```\n\n## Function name, declaration\n\nPlease use lowercase English for the function name, and use \"_\" to connect between words. Provide APIs for upper-level applications\nInterface must be declared in the corresponding header file; if the function entry parameter is empty, void must be used as the entry parameter\nNumber, for example:\n\n```c\n    maixpy_err_t lcd_init(void);\n```\n\n## Comment writing\n\nPlease use English as comments. Using Chinese comments will mean that you need to switch back and forth between Chinese and English input methods when writing code to interrupt the idea of ​​writing code. And the use of English annotations can better communicate with technicians outside of China.\n\nThere should not be too many comments on the source code. More explanation should be what the code does. Only when individual key points need some corresponding suggestive comments to explain how a complex algorithm works. Comments on the statement can only be written above or on the right, other positions are illegal.\n\n## Indentation and branching\n\nPlease use 4 spaces for indentation. If there is no special meaning, please branch after \"{\" and use indentation on the next line, for example:\n\n```c\nif (condition)\n{\n    /* others */\n}\n```\n\nThe only exception is the switch statement. The switch-case statement uses the alignment of the case statement with the switch.\nE.g:\n\n```c\nswitch (value)\n{\ncase value1:\n    break;\ncase value2:\n    break;\ndefalut:\n    break;\n}\n```\n\nThe case statement is aligned with the previous switch statement, and the subsequent statements are indented.\n\nOn the branch, if there is no special consideration, please **do not use more than two blank lines in a row** in the code.\n\n## Braces and spaces\n\nFrom the perspective of code reading, it is recommended that each curly brace occupy a separate line instead of following the statement, for example:\n\n```c\nif (condition)\n{\n    /* others */\n}\n```\n\nThe matching braces occupies a single line, and the code will have a corresponding level when reading it without confusion.\n\nSpace It is recommended to leave a space before the non-function bracket call to distinguish it from the previous one, for example:\n\n```c\nif (x <= y)\n{\n    /* others */\n}\n\nfor (index = 0; index <MAX_NUMBER; index ++)\n{\n    /* others */\n}\n```\n\nIt is recommended to leave a space before the brackets (including if, for, while, switch statements involved), and a space between the operator and the string in the operation expression. In addition, do not leave spaces on both sides of the expression in parentheses, for example:\n\n```c\nif (x <= y)\n{\n    /* other */\n}\n```\n\nThe spaces on both sides of the brackets are not allowed.\n\n## log information\n\nIn MaixPy, the commonly used log method is printk, and the py terminal is mp_print, and after we increase or decrease the MaixPy function, it is recommended to delete or comment out the unnecessary printk\n\nBut **note**, the final submitted code cannot contain `printk` and `printf` functions, they can only be used during debugging! ! ! Otherwise it will cause disconnection when using the IDE\n\nThe log output should be designed to be turned off under normal circumstances (for example, it can be turned on by a variable or macro), and\nWhen the log is actually output, the log is an easy way to understand and locate the problem. The \"heavenly book\" log system is bad and unreasonable.\n\n## Function\n\nIn kernel programming, functions should be as concise as possible and only complete relatively independent simple functions. The implementation of the function should not be too long, and the implementation of the function should be too long. You should reflect on how you can modify (or split) the function to make the function more concise and understandable.\n\n## Use astyle to format code automatically\n\nparameter:\n\n    --style=allman\n    --indent=spaces=4\n    --indent-preproc-block\n    --pad-oper\n    --pad-header\n    --unpad-paren\n    --suffix=none\n    --align-pointer=name\n    --lineend=linux\n    --convert-tabs\n    --verbose\n\n\n## Specification Reference\n\n- AliOS-Things - [《AliOS Things Coding Style Guide》](https://github.com/alibaba/AliOS-Things/wiki/AliOS-Things-Coding-Style-Guide)\n\n- RT-Thread - [《RT-Thread Programming Style》](https://github.com/RT-Thread/rt-thread/blob/master/documentation/coding_style_cn.md)"}, "/soft/maixpy/en/contribute/doc_convention.html": {"title": "Document contribution specification", "content": "---\ntitle: Document contribution specification\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: document contribution specification\n---\n\n\nThere are several situations you may need to read this document:\n* Found that the document is wrong or there is content that needs to be added, and will want to participate in the modification\n* Submit tutorial/experience/open source project sharing etc.\n\n\n\nIn order to make the document look uniform in style, the content is not repeated and there is no error, and the writing needs to follow the same specification, all contributors **must** write documents according to this article;\nIf you have any doubts about the template format and content, please go to the project repository [MaixPy_DOC](https://github.com/sipeed/MaixPy_DOC) to submit `ISSUE`.\n\n\n🙇‍ Thank you for your enthusiastic support!\n\n\n## To participate in the contribution, you need to master the knowledge in advance\n\n* Use of git and github\n* Use of github PR (pull request)\n\nThere is a brief introduction in the introductory tutorial, please learn by yourself for detailed usage\n\nIf you are not confident to master these skills, you can submit [issue](https://github.com/sipeed/MaixPy_DOC/issues) to explain the problem or contribute experience, etc. We will help you to add\n\n## Introduction to the file system\n\n\nThe document is built using gitbook, and simple and efficient Markdown is used to write content. It is recommended to use `Typora` or `VS Code` with `MarkDown Preview Enhanced` plug-in as the document editor\n\n\nThe source code of the document is hosted at [github](https://github.com/sipeed/MaixPy_DOC)\n\nFor the local preview method, see [README.md](https://github.com/sipeed/MaixPy_DOC/blob/master/README.md) of the document source code\n\nThe documents are available in two languages, Chinese and English, respectively, placed in the `zh` and `en` folders, where `SUMMARY.md` is the directory item on the left side of the document, and the other `md` files are specific document files, root The `assets` directory under the directory contains image resource files common to two languages\n\n\n\n## Markdown syntax\n\nIf you haven’t touched the basic grammar of Markdown, please spend half an hour to learn it. I recommend the github tutorial: [github Markdown Tutorial](https://guides.github.com/features/mastering-markdown/)\n\nIn this article, we need to pay attention to the following points:\n\n### The grammar tags of the heading category must be separated by spaces, and a blank line is required between the headline and the main body, for example:\n\n```markdown\n## This is a secondary heading\n\n* This is list item 1\n* This is list item 2\n\n```\nThe following is not correct, and it may cause parsing errors and malformed formats.\n\n```markdown\n##This is the secondary title\n*This is list item 1\n*This is list item 2\n```\n\n### All pages have only one first-level title\n\nSince the catalog needs to be automatically generated, it is mainly to ensure that the automatically generated catalog is correct.\nWrite each page like this\n\n```\n                (At least one blank line is required, 2 lines are recommended)\n\n## Level 2 heading 1 (The first level heading cannot be used here, and a # sign cannot be used. There is also no need to write a serial number, the serial number will be automatically generated)\n                ( Skip a line )\ntext\n                (At least one blank line)\n### Third-level heading (similar to second-level heading, no need to write, it will be automatically generated)\n\ntext\n\n## Secondary Title 2\n\ntext\n\n\n```\n\n### Title number\n\nAll titles **do not need to write a number, **will be automatically generated** for example\n\n```\n## Title One\n\n### Subtitle 1\n\n## Title Two\n```\nfinal effect:\n\n```\n1. Title One\n  1.1 Subheading 1\n\n2. Title Two\n \n```\n\nIf manually written, the final display will be repeated, so be careful!\n\n\n### Link\n\nDue to the large number of pages and the need to link to resources such as pictures, relative paths are used when writing links.\nFor example, the directory structure is as follows\n```\nassets/ (Put common resource files)\n|\n      ----pic000.png\nen/\n|\n   ----- get_started/\n|\n                  ---- assets/ (Put the common resource file of md file in get_started directory)\n|\n                             ------ pic.png\n|\n                  ---- get_hardware.md\n|\n                  ---- how_to_read.md\nzh/\n```\n\nIf you paste an image in `get_hardware.md`, put the image in the `assets` folder, and use the following code to reference the image\n```\n![pic](assets/pic.png)\n![pic](../../assets/pic000.png)\n```\n\n\n### Mixed Chinese and English\n\nWhen writing Chinese documents, try to use spaces to separate Chinese mixed with English, and try to use full-width symbols for punctuation.\nMainly to make the document more conspicuous.\nsuch as:\n\n---------\n\n```markdown\nIn Micropython, we often use `deinit` to represent the destructor, not to set the default value like STM32\n```\nIn Micropython, we often use `deinit` to represent the destructor, not to set the default value like STM32\n\n----------\n\n```markdown\nIn Micropython, we often use deinit to represent the destructor instead of setting the default value like STM32\n```\n\nIn Micropython, we often use deinit to represent the destructor instead of setting the default value like STM32\n\n---------\n\n\n## table of Contents\n\n* Multiple languages ​​are placed in different directories, `en` and `zh` directories\n\n* The generated document directory is edited in the folder `SUMMARY.md` of the corresponding language\n\n* The source document folder should correspond to a folder as much as possible for a functional module, and the resource files (pictures) should be placed in the `assets` folder directory under the root directory of the corresponding md document, so that both Chinese and English documents can refer to the same pictures and generate The URL is the same, and it is more convenient to add, delete and modify at the same time.\n* At the same time, in order to be able to use both Chinese and English documents, try not to mark Chinese or English in the picture. You can mark the label, and then the document is explained with the label. The pictures for a specific language are placed in the `assets` directory under the current path:\n\n```\nassets/ (Put public resource files, both Chinese and English can be cited)\nen/\n|\n   ----- get_started/\n|\n                  ---- assets/ (resource files of md files in the get_started directory, only for English use)\n|\n                  ---- get_hardware.md\n|\n                  ---- how_to_read.md\nzh/\n```\n\n## file name\n\n* The file name is special except `README.md`, other file names use lowercase + underscore naming method, such as `get_hardware.md`\n\n\n\n## Chinese and English (multilingual) page file directory structure and file name are the same\n\nSince there is a multi-language switch option in the last generated page, after clicking switch, the same path of the corresponding language will be directly accessed, so the directory structure and file name in Chinese and English must be the same.\n\nFor example, when English is accessing `en/get_started/how_to_read.md`, after clicking the language switch button, it will automatically visit `zh/get_started/how_to_read.md`, if this file does not exist, it will report a `404` error!\n\n\n## Contents and links\n\nTry to guide readers to use the table of contents, and use the jump links in the text with caution. If the links jump chaotically, the document will look messy and it will be more difficult to read.\n\n## Module documentation content\n\n* The header of the file contains module introduction, resource introduction, usage notes, and routines\n* Need to point out the constructor, function, constant, etc.\n* **Note that you can't be lazy, just simply translate the function name again, you need to explain in detail the function of the function, the value range of the parameters and the points of attention**\n\n## Multi-version management\n\nIn addition to supporting Chinese and English (multi-language) documents (not automatic translation, manual modification is required), multi-version management is also done.\n\nEach version is a branch, and there are requirements for the branch name, which are:\n* `master` branch is the main branch\n* `dev` branch is the development branch\n* Other historical versions of releases start with lowercase `v`, for example, create a branch called `v1.2`\n\nAfter creating a new branch, you need to modify the version link in `book.json` in the directory of each language version, otherwise readers cannot find the entry\n\nYou can preview locally under the newly created branch (see the root directory `README.md` for preview method). Note that the page previewed at this time is the content of the current branch. If you want to preview the content of other branches locally, you need to switch to other branches before previewing That's it.\n\nAfter confirming that the correct modification is completed, push the branch to the remote (github), the automatic build system will automatically build and publish to the pages branch, and the effect can be seen after the construction is completed and the URL is accessed."}, "/soft/maixpy/en/index.html": {"title": "Introduction to MaixPy documentation", "content": "---\ntitle: Introduction to MaixPy documentation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Introduction to MaixPy documentation\n---\n\n\n<div class=\"title_pic\">\n    <div class=\"logo_maixpy\">\n    <img src=\"../assets/maixpy/maixpy.png\" alt=\"maixpy ​​logo\">\n    </div>\n    <span class=\"logo_sipeed\">\n    <img src=\"../assets/sipeed/sipeed_logo_4.svg\" alt=\"sipeed logo\">\n    </span>\n    <span class=\"logo_mpy\">\n    <img src=\"../assets/maixpy/micropython.png\" alt=\"micropython logo\">\n    </span>\n    <br/>\n</div>\n\n\n<table role=\"table\" class=\"center_table\">\n    <thead>\n        <tr>\n            <th>Site navigation</th>\n            <th>Address</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td><strong>MaixPy</strong> The only official document official website</td>\n            <td><span class=\"limit_width\">Official website:</span> <span class=\"\"><a href=\"https://maixpy.sipeed.com\" rel=\"nofollow\"><strong>maixpy. sipeed.com</strong></a></span><br><span class=\"limit_width\">Chinese site: </span><span class=\"\"><a href=\"https://cn.maixpy.sipeed.com\" rel=\"nofollow\"><strong>cn.maixpy.sipeed.com</strong></a></span>\n            <br><span class=\"limit_width\">Site on github: </span><span class=\"\"><a href=\"https://en.maixpy.sipeed.com\" rel=\"nofollow\"><strong>en.maixpy.sipeed.com</strong></a></span>\n            </td>\n        </tr>\n        <tr>\n            <td><strong>MaixPy</strong> demo repository</td>\n            <td><span class=\"limit_width\">github:</span> <span class=\"\"><a href=\"https://github.com/sipeed/MaixPy_scripts\"><strong>github/maixpy_script </strong></a></span> <br><span class=\"limit_width\">Domestic:</span><span class=\"\"><a href=\"https://gitee.com/Sipeed/maixpy_scripts \"rel=\"nofollow\"><strong>gitee/maixpy_scripts</strong></a></span></td>\n        </tr>\n        <tr>\n            <td>MaixPy source code</td>\n            <td><span class=\"limit_width\"></span><span class=\"\"><a href=\"https://github.com/sipeed/MaixPy\"><strong>github: MaixPy</strong> </a></span></td>\n        </tr>\n        <tr>\n            <td>Hardware data download</td>\n            <td><span class=\"limit_width\"></span><span class=\"\"><a href=\"http://dl.sipeed.com/MAIX/HDK\" rel=\"nofollow\"><strong> dl.sipeed.com</strong></a></span></td>\n        </tr>\n        <tr>\n            <td>Sipeed WIKI</td>\n            <td><span class=\"limit_width\"></span><span class=\"\"><a href=\"https://wiki.sipeed.com\" rel=\"nofollow\"><strong>wiki.sipeed. com</strong></a></span></td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n\n\n## About MaixPy\n\n\n[**MaixPy**](https://maixpy.sipeed.com/zh/maixpy.sipeed.com) is to port [Micropython](http://micropython.org/) to [K210](https:/ /canaan-creative.com/product/kendryteai) (a 64-bit dual-core RISC-V CPU with hardware FPU, convolution accelerator, FFT, Sha256) is a project that supports the normal operation of the MCU and integrates hardware acceleration. `AI` machine vision and microphone array, `1TOPS` computing power core module is less than `￥50`, in order to quickly develop intelligent applications in the field of `AIOT` with extremely low cost and practical size.\n\n> MicroPython is a parser based on the grammar of Python3. It contains most of the basic grammar of Python3. It mainly runs on embedded chips with limited performance and memory. (Note that Micropython does not include all the syntax of Python3)\n\n\n\n**MaixPy** makes programming on K210 easier and faster. We also open source the source code on [**github**](https://github.com/sipeed/MaixPy)\n\nThere are many interesting things you can do with MaixPy. Specifically, you can <a href= \"what_maix_do.html\" target=\"_blank\">look here</a>\n\n## Concise code example\n\nFor example, if we need to scan the devices on the **I2C** bus, there is no need for complicated development environment and engineering, just send the following code through the serial port to achieve:\n\n```python\nfrom machine import I2C # Import built-in library\n\ni2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29) # Define an I2C object, use I2C0, frequency 100kHz, SCL pin is IO28, SDA pin is IO29\ndevices = i2c.scan() # call function to scan device\nprint(devices) # print device\n```\n\nSimilarly, we need to implement a **breathing light**, just the following code:\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](api_reference/builtin_py/board_info.md) is required before use.\n\n```python\nfrom machine import Timer,PWM\nfrom board import board_info\nimport time\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)\nch = PWM(tim, freq=500000, duty=50, pin=board_info.LED_G)\nduty=0\ndir = True\nwhile True:\n    if dir:\n        duty += 10\n    else:\n        duty -= 10\n    if duty>100:\n        duty = 100\n        dir = False\n    elif duty<0:\n        duty = 0\n        dir = True\n    time.sleep(0.05)\n    ch.duty(duty)\n```\n\n**Real-time photos**:\n\n```python\nimport sensor\nimport image\nimport lcd\n\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\nwhile True:\n    img=sensor.snapshot()\n    lcd.display(img)\n```\n\n**AI Object Detection**:\n\n```python\nimport KPU as kpu\nimport sensor\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.set_windowing((224, 224))\n\nmodel = kpu.load(\"/sd/mobilenet.kmodel\") # load model\nwhile(True):\n    img = sensor.snapshot() # take picture by camera\n    out = kpu.forward(task, img)[:] # inference, get one-hot output\n    print(max(out)) # print max probability object ID\n```\nplease read doc before run it!\n\n## The content of this document\n\nAll about MaixPy, including:\n* How to choose and get a suitable module or development board\n* How to get started\n* Library and interface (API) document query\n* Detailed step-by-step tutorial\n* Sharing from the community (tutorial or open source project)\n\n**In order to avoid encountering difficult problems during the learning process, please read from top to bottom according to the directory structure on the left, especially the chapters written in the front, do not skip**\n\n\n## Can run MaixPy development board\n\nFirst of all, we need to choose a development board that suits us. For the MaixPy model of each model, please click: [Development board and accessories purchase guide](./develop_kit_board/get_hardware.html), and there are also hardware parameters and corresponding development boards in the catalog. data\n\nTo get these boards, you can visit the official website of Sipeed [www.sipeed.com](https://www.sipeed.com/), or [official Taobao shop](https://sipeed.taobao.com/ )\n## MaixPy source code\n\n`MaixPy` source code refers to the `Micropython` parser running on `K210`, written in `C language`, source code is hosted on [github](https://github.com/sipeed/MaixPy), if you just want to use MaixPy, you don't need to know the source code, but you can also give MaixPy project a star [here](https://github.com/sipeed/MaixPy);\n\nIf you want to participate in the development of MaixPy’s built-in functions, you can download for development, and welcome everyone to submit a PR\n\n\nThis project is mainly maintained by &copy;<a href=\"https://www.sipeed.com\" style=\"color: #f14c42\">Sipeed</a> Co.,Ltd., and accepts contributions from the open source community, For specific contributions, see [Contributor List](https://github.com/sipeed/MaixPy/graphs/contributors)\n\n## MaixPy document source code\n\n\nThe source code of the document is hosted at [github](https://github.com/sipeed/MaixPy_DOC), if the document has typos or improvements, you can submit a PR, and the document will be updated after the PR is passed\n\nNote: Before editing the document, **must** look at the [document writing specification](contribute/doc_convention.md), only the modifications that conform to the document specification will be approved\n\n\n\n## Feedback\n\nFor questions about this document or function or source code, you are also welcome to submit an issue:\n\n* [Feedback](https://github.com/sipeed/MaixPy/issues)\n\n\n## communicate with\n\nIf you have any questions, try to submit `issue` to the feedback address above, so that you can leave a record. Others can also check it. Before submitting, search to see if anyone has raised the same issue.\n\nThe following communication methods provide assistance:\n\n<table role=\"table\">\n    <thead>\n        <tr>\n            <th>Communication method</th>\n            <th>Address</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>issue(recommend)</td>\n            <td><a href=\"https://github.com/sipeed/MaixPy/issues\">https://github.com/sipeed/MaixPy/issues</a></td>\n        </tr>\n        <tr>\n            <td>BBS</td>\n            <td><a href=\"https://bbs.sipeed.com\" rel=\"nofollow\">https://bbs.sipeed.com</a></td>\n        </tr>\n        <tr>\n            <td>MaixPy AI QQ group</td>\n            <td>878189804</td>\n        </tr>\n        <tr>\n            <td>MaixPy AI QQ Group (Second Group)</td>\n            <td>1129095405</td>\n        </tr>\n        <tr>\n            <td>telgram</td>\n            <td><a href=\"https://t.me/sipeed\" rel=\"nofollow\">https://t.me/sipeed</a></td>\n        </tr>\n        <tr>\n            <td>E-mail (commercial cooperation)</td>\n            <td><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"../assets/sipeed/support_email.jpg\"><img src=\"../assets/sipeed/support_email.jpg\" alt=\" email\" style=\"max-width:100%;\"></a></td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n------------"}, "/soft/maixpy/en/what_maix_do.html": {"title": "What can MaixPy do", "content": "---\ntitle: What can MaixPy do\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: What can MaixPy do\n---\n\nMost of them integrated to MaixPy, or some of them include in [Maixduino](https://Maixduino.sipeed.com) or from other developers\n\n\n## Face recognition\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hS_mcGptXeo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## draw picture Turorial\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/el6CB-h9Lo0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Openmv and Record video\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fpJZIisYKao\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## MobileNet\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9hGWvLRDhrM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Face detection\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BGctumZuhao\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## NES gamer emulator\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/y7-hM2UHuNw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## MNIST\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WhJuCODEfpQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## Play video\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BbrdCNxnxv0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## Feature map display\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jA6JQ3Wevdw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## GBA game emulator\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kPpH_cA83-I\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## Game Quake I\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/poBBrIWt_HE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n[source code](https://github.com/elect-gombe/quake-k210)\n\n\n## Game Doom\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fRjF498k2r4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n[source code](https://github.com/elect-gombe/k210-doom)\n\n## MMD 3D rendering\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/L7xmXQgnf3c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n<video src=\"http://dl.cdn.sipeed.com/k210_mmd.MOV\" controls=\"controls\">\nyour browser does not support the video tag\n</video>\n\n[source code](https://github.com/elect-gombe/k210_mmd)\n\n\n## Gimbal face track\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7bpNVzFbGa0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## Mic array\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wb2Dnd-Wk60\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## LittlevGL\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Bcwkg3qOwY8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n\n## FFT spectrum\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HvBVj-QgaB8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"}, "/soft/maixpy/en/modules/sp_mod/sp_lcd1.14.html": {"title": "Use of SP_LCD1.14", "content": "---\ntitle: Use of SP_LCD1.14\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Use of SP_LCD1.14\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_lcd1.14.png\"/>\n\nSP_LCD has a 1.14' inch LCD, 8P FPC (0.5mm pitch) interface TFT LCD screen, 180° viewing angle.\n\n## Parameters\n\n* Screen size: 1.14 inches\n* Resolution: 240*135\n* Color: 132 RGB channels\n* Communication interface: SPI\n* Effective display area: 21.7mm * 10.8mm\n* Working voltage: 2.5V~4.8V\n* Working temperature: -30°C~85°C\n\nFor detailed module information, please refer to [LCD114 Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_lcd114)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_lcd114 module.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_lcd114), the module will display the picture after running.\n\nThe procedure is as follows:\n\n```python\n# init\nips = SPLCD114(spi1, cs, dc, rst, busy, IPS_WIDTH, IPS_HEIGHT, IPS_MODE)\n\n# create an'image' and fill it\nimg = image.Image()\nimg.draw_rectangle(80, 80, 30, 30)\n\n# display\nips.display(img)\n```\n\nThe main steps are:\n\n* Initialization (the parameters from left to right are: SPI object, chip select pin, reset pin, busy flag pin, screen width, screen height, screen orientation).\n\n* Create Image.\n  \n* Call display to display the picture (the incoming parameter is the Image object)."}, "/soft/maixpy/en/modules/sp_mod/sp_lora.html": {"title": "Use of SP_LORA", "content": "---\ntitle: Use of SP_LORA\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SP_LORA\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_lora.png\"/>\n\nSP_LoRa module uses M-XL8 module, which has built-in LoRaTM modem and adjustable power amplifier LoRa module, which has high performance and high reliability.\n\n## Parameters\n\n* Working frequency: 370MHz~1200Mhz\n* Transmitting power: 20dBm (maximum)\n* Communication interface: SPI\n* Antenna: External antenna, IPEX or welding\n* Receiving sensitivity: -148dbm\n* RSSI dynamic range: 127dB\n* Working voltage: 1.8V~6.3V\n* Working temperature: -40°C~80°C\n\nFor detailed module information, please refer to [LoRa Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_lora)\n\n## Instructions\n\n1. Preparation: Two development boards with the latest firmware burned, two sp_lora modules.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [sample code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_lora), and run the two development boards to send and receive separately Function, you can view the received and sent information on the terminal.\n\nThe procedure is as follows:\n\n```python\n# init\nlora = SX127x(spi=spi1, pin_ss=cs)\n\n# lora reset\nrst.value(0)\ntime.sleep_ms(10)\nrst.value(1)\ntime.sleep_ms(100)\nlora.init()\n\n####### receiver ##########\nreceive(lora)\n\n######## sender ###########\n# send(lora)\n\n'''output\nmpfs [/flash]> runfile lora_send.py\n    transfer 6400 of 14576\n    transfer 12800 of 14576\n    transfer 14576 of 14576\n[Warning] function is used by fm.fpioa.GPIOHS7(pin:23)\nLoRa Sender\nSending packet:\nHello(0)\n\nmpfs [/sd]> runfile lora_recv.py\n    transfer 6400 of 14576\n    transfer 12800 of 14576\n    transfer 14576 of 14576\n[Warning] function us used by fm.fpioa.GPIOHS7(pin:23)\nLoRa Receiver\n[Memory-free: 470080 allocated: 48064]\n*** Received message ***\nHello(0)\nwith RSSI: <bound_method 800d19e0 <SX127x object at 800f5700>.<function packetRssi at 0x800d3180>>\n'''\n```\n\nThe debugging and running tool used here is mpfshell, which is convenient to open two terminals to run scripts at the same time.\n\nThe main steps are:\n\n* Create LoRa object (parameters: SPI object, chip selection pin)\n\n* Reset (pull the reset pin low or high), initialization.\n  \n* Start sending or receiving."}, "/soft/maixpy/en/modules/sp_mod/sp_rfid.html": {"title": "Use of SP_RFID", "content": "---\ntitle: Use of SP_RFID\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Use of SP_RFID\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_rfid.png\"/>\n\nThe FM17510 used in this module is a highly integrated non-contact reader/writer chip working at 13.56MHz. It supports the non-contact reader/writer mode conforming to the ISO/IEC 14443 TypeA protocol, and the program is compatible with MFRC522.\n\n## Parameters\n\n* Support ISO/IEC 14443 TypeA reader mode\n* Reader mode supports M1 encryption algorithm\n* ISO14443 TYPEA supports communication rate 106kbps, 212kbps, 424kbps\n* Support SPI serial interface, up to 10Mbps\n* Voltage range 2.2V~3.6V\n* 64Byte transmit and receive buffer FIFO\n* Multiple low power consumption modes: Soft powerdown mode Hard powerdown mode\n* Built-in CRC coprocessor\n* Support low-power external card detection function\n* Working voltage: 2.2V~3.6V\n* Working temperature: -40°C~85°C\n\nFor detailed module information, please refer to [RFID Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_rfid)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_rfid module, M1 card.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_rfid), and put the card close to the module antenna after running. See the card reading information printed by the terminal.\n\nThe procedure is as follows:\n\n```python\n# Init module\nMIFAREReader = MFRC522(spi1, cs)\n# Scan for cards\n(status, ataq) = MIFAREReader.MFRC522_Request(MIFAREReader.PICC_REQALL)\n# Get uid\n(status, uid) = MIFAREReader.MFRC522_Anticoll()\nif status == MIFAREReader.MI_OK:\n    # Bind card by uid\n    MIFAREReader.MFRC522_SelectTag(uid)\n    # Authenticate block 0x11 by key\n    status = MIFAREReader.MFRC522_Auth(MIFAREReader.PICC_AUTHENT1A, 0x11, key, uid)\n    if status == MIFAREReader.MI_OK:\n        # Write 16 bytes from block 0x11\n        MIFAREReader.MFRC522_Write(0x11, data)\n        # Read 16 bytes from block 0x11\n        MIFAREReader.MFRC522_Read(0x11)\n        \n'''output\n>>> [Warning] function is used by fm.fpioa.GPIOHS20(pin:36)\nWelcome to the MFRC522 data read/write example\nCard detected type: 0x400\nCard read UID: 110,159,46,15\nSize: 8\nSector 11 will now be filled with 1~16:\n4 backdata &0x0F == 0x0A 10\nData written\nstart to read\nSector 18 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\nCard detected type: 0x400\nCard read UID: 110,159,46,15\nSize: 8\nSector 11 will now be filled with 1~16:\n4 backdata &0x0F == 0x0A 10\nError while writing\nData written\n'''\n```\n\nIt is mainly divided into several steps:\n\n* Create MFRC522 object (parameters: SPI object, chip selection pin).\n\n* Scan the card and get ATQA (i.e. card type code), ATQA corresponding card types are as follows:\n\n\n  | ATQA | Type |\n  | :----: | :----------------- |\n  | 0x4400 | Mifare_UltraLight |\n  | 0x0400 | Mifare_One(M1 S50) |\n  | 0x0200 | Mifare_One(M1 S70) |\n  | 0x0800 | Mifare_Pro(X) |\n  | 0x4403 | Mifare_DESFire |\n  \n* Get card UID\n\n* Binding the card through UID (anti-collision, to ensure that the selected card can execute the transaction correctly, and is not affected by another card on site)\n\n* Authenticate a certain sector in the card (M1 (S50) default password is 16 0xff)\n\n* Read/write card information (take one block (16 bytes) as the basic read and write unit)"}, "/soft/maixpy/en/modules/sp_mod/sp_bt.html": {"title": "Use of SP_BT", "content": "---\ntitle: Use of SP_BT\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SP_BT\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_bt.png\"/>\n\nSP_BT is a Bluetooth serial port transparent transmission module with ultra-low power characteristics and high reliability. It is controlled by AT commands. The Bluetooth version is BLE 5.0 (compatible with BLE4.0, BLE4.2) and the default serial port baud rate is 9600.\n\n## Parameters\n\n* Receiving sensitivity: -97dm\n* Transmitting power: 4db (maximum)\n* Communication interface: UART\n* Antenna: Onboard antenna\n* Master-slave support: slave\n* Working frequency: 2.4G\n* Working temperature: -40°C~85°C\n* Working voltage: 1.8V~3.6V\n\nFor detailed module information, please refer to [BT Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_bt)\n\n## Instructions for use\n\n1. Preparation: The development board with the latest firmware, sp_bt module, Bluetooth debugging assistant.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_bt), use the Bluetooth debugging assistant to connect and send after running Data, you can view the received and sent information on the terminal.\n\nThe procedure is as follows:\n\n```python\n# set uart rx/tx func to io_6/7\nfm.register(TX, fm.fpioa.UART1_TX)\nfm.register(RX, fm.fpioa.UART1_RX)\n# init uart\nuart = UART(UART.UART1, 9600, 8, 1, 0, timeout=1000, read_buf_len=4096)\n\nset_name(uart, name)\nprint(\"wait data: \")\nwhile True:\n  read_data = uart.read()\n  if read_data:\n      print(\"recv:\", read_data)\n      uart.write(read_data) # send data back\n      print(\"wait data: \")\n```\n\nThe main steps are:\n\n* Initialize the serial port (the baud rate is 9600 by the module default baud rate)\n\n* Set the module broadcast name\n\n* Wait for connection, send back after receiving the data and printing\n\n## Connection process\n\n* After the module is initialized, it is not connected (indicator: ACT flashes, STA is always off).\n  \n* After the Bluetooth debugging assistant is connected, the module becomes connected (indicators: ACT is always on, STA is always on).\n  \n* The services displayed by the Bluetooth debugging assistant after connection are as follows:\n  \n  <img src=\"../../../assets/hardware/module_spmod/sp_bt_screenshot.png\" alt=\"bt_server\"/>\n  \n  In the above figure, you can see that there is a service with a UUID of ffe0 that has two characteristics.Turn on the Write and Notify of the transparent transmission (ffe1) to start sending/receiving data."}, "/soft/maixpy/en/modules/sp_mod/sp_eink.html": {"title": "Use of SP_EINK", "content": "---\ntitle: Use of SP_EINK\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SP_EINK\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_eink.png\"/>\n\nThe GDEW0154M09 used by the SP_EINK module is a 1.54” electronic ink screen with a 24P FPC (0.5mm pitch) interface.\n\n## Parameters\n\n* Screen size: 1.54 inches\n* Effective display area: 27.6mm * 27.6mm\n* Color: black/white/red display\n* Communication interface: SPI\n* Working temperature: -40°C~85°C\n* Working voltage: 2.3V~3.6V\n\nFor detailed module information, please refer to [EINK Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_eink)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_eink module.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_eink), the module will display the picture after running.\n\nThe procedure is as follows:\n\n```python\n# init\nepd = SPEINK(spi1, cs, dc, rst, busy, EPD_WIDTH, EPD_HEIGHT)\nepd.init()\n\n# create red image\nimg_r = image.Image()\nimg_r = img_r.resize(EPD_WIDTH, EPD_HEIGHT)\nimg_r.draw_line(0, 0, 100, 100)\n\n# create black/white image\nimg_bw = image.Image()\nimg_bw = img_bw.resize(EPD_WIDTH, EPD_HEIGHT)\nimg_bw.draw_line(100, 50, 200, 100)\n\n# display\nepd.display(img_r, img_bw)\n\n# sleep mode\nepd.sleep()\n```\n\nThe main steps are as follows:\n\n* Create SPEINK object (parameters: SPI object, chip select pin, reset pin, busy flag pin, horizontal resolution, vertical resolution, screen rotation angle (0, 90, 180, 270)), initialize.\n\n* Create red and black images, set to screen size and fill the image.\n\n* Call display (parameters are: red image, black image), the screen will flash and the image will be displayed at this time.\n  \n* Go to sleep."}, "/soft/maixpy/en/modules/sp_mod/sp_weather.html": {"title": "Use of SP_WEATHER", "content": "---\ntitle: Use of SP_WEATHER\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Use of SP_WEATHER\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_weather.png\"/>\n\nThe SP_Weather weather module has two sensors, the magnetic sensor QMC7983, which is a three-axis magnetic sensor with built-in sensitivity compensation and NTC. It has excellent dynamic range and accuracy and ultra-low power consumption. The temperature, humidity and air pressure sensor BME280 can simultaneously measure temperature Humidity and atmospheric pressure.\n\n## Parameters\n\n### Magnetic sensor QMC7983\n\n* Magnetic induction range: ±30 Gauss\n* Accuracy: 1mG per LSB\n* RMS noise: 2mG\n* External interface: I2C, default address 0x2C, can be adjusted by selecting resistance\n* Working voltage: 2.6V~3.6V\n* Working temperature: -30°C ~ 85°C\n\n### Temperature, Humidity and Pressure Sensor BME280\n\n* The key parameters of the temperature sensor\n  * Measuring range: -40°C~85\n  * Accuracy:\n  \n|range(°C)|accuracy(°C)|\n|----|----|\n|25|±0.5|\n|0~65|±1.0|\n|-20~0|±1.25|\n|-40~-20|±1.5|\n\n* Key parameters of humidity sensor\n  * Response time (τ63%): 1 s\n  * Accuracy tolerance: ±3% relative humidity\n  * Hysteresis: ±1% relative humidity\n* Key parameters of air pressure sensor\n  * RMS noise: 0.2Pa (equivalent to 1.7cm)\n  * Offset temperature coefficient: ±1.5 Pa/K (equivalent to ±12.6cm when the temperature changes at 1℃)\n* External interface: I2C, default address 0x76, can be adjusted by selecting resistance\n* Working voltage: 1.71V~3.6V\n* Working temperature: -30°C ~ 85°C\n\nFor detailed module information, please refer to [Meteorological Module Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_weather)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_weather module.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_weather), you can see the magnetism printed on the terminal after running Sensor and air pressure temperature and humidity sensor data\n\nThe procedure is as follows:\n\n```python\nweather=SPWEATHER(i2c=i2c_bus) # create sp_weather\nwhile 1:\n    time.sleep_ms(500)\n    print(weather.qmc_read_xyz) # QMC7983 read data\n    print(weather.bme_values) # BME280 read data\n\n'''output\n>>> I2C devices:[44, 118]\n0x32\n6\n(228, 123, 156)\n('31.0C', '1017.75hPa', '34.32%')\n(235, 130, 185)\n('30.75C', '1017.74hPa', '34.31%')\n(235, 130, 161)\n('30.7C', '1017.82hPa', '34.32%')\n'''\n```\n\nThe main steps are:\n\n* Create SPWEATHE (parameter: I2C object).\n\n* Read magnetic sensor data and temperature and humidity data. (The data read are all tuples)"}, "/soft/maixpy/en/modules/sp_mod/sp_tof.html": {"title": "Use of SP_TOF", "content": "---\ntitle: Use of SP_TOF\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SP_TOF\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_tof.png\"/>\n\nThe VL53L0X used by SP_TOF is a new generation of time-of-flight (ToF) laser ranging module, which can provide accurate distance measurement regardless of the reflectivity of the target, with a red laser sight to assist in observing the ranging point.\n\n## Parameters\n\n* Measuring distance: up to 2000mm (dark environment), 1000mm (bright environment)\n* Working refresh rate: 50Hz\n* Measuring angle: 27° (front)\n* Communication interface: I2C\n* Working voltage: 2.6V~3.5V\n* Working temperature: -40°C~80°C\n\nFor detailed module information, please refer to [TOF Specification and Data Manual](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_tof)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_tof module.\n\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_tof), and aim the laser aiming head to measure after running Click to see the distance information printed by the terminal.\n\nThe procedure is as follows:\n\n```python\n# create obj and read distance\ntof = VL53L0X(i2c)\nwhile True:\n    mm = tof.read()\n    utime.sleep_ms(100)\n    print(mm)\n\n'''output\n>>> [41]\n536mm\n538mm\n533mm\n535mm\n529mm\n532mm\n'''\n```\n\nThe main steps are:\n\n* Create TOF object (parameter: I2C object).\n\n* The reading distance, if the reading distance is 8190, it means that the range has been exceeded."}, "/soft/maixpy/en/modules/sp_mod/sp_ethernet.html": {"title": "Use of SP_Ethernet", "content": "---\ntitle: Use of SP_Ethernet\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SP_Ethernet\n---\n\n\n<img src=\"../../../assets/hardware/module_spmod/sp_ethernet.png\">\n\nThis module uses W5500 as the main control chip, which is an embedded Ethernet controller that integrates a full hardware TCP/IP protocol stack.\n\n## Parameters\n\n* Working voltage: 2.6V~3.6V\n* Working current: <132mA\n* Sleep current: <15mA\n* Communication interface: SPI\n* Operating temperature range: -40℃ ~ 85℃\n\nFor detailed module information, please refer to [Ethernet Specification](http://api.dl.sipeed.com/shareURL/MAIX/HDK/sp_mod/sp_ethernet)\n\n## Instructions\n\n1. Preparation: The development board with the latest firmware, sp_ethernet module, and network cable.\n2. Run: Connect the module, modify the configuration surrounded by config in [Sample Code](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/spmod/sp_ethernet), the module will print the communication data after running.\n\nThe procedure is as follows:\n\n```python\nspi1 = SPI(4, mode=SPI.MODE_MASTER, baudrate=600 * 1000,\n            polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck=WIZNET5K_SPI_SCK, mosi=WIZNET5K_SPI_MOSI, miso = WIZNET5K_SPI_MISO)\n\n# create wiznet5k nic\nnic = network.WIZNET5K(spi = spi1, cs = WIZNET5K_SPI_CS)\nprint(\"Static IP: \", nic.ifconfig())\n```\n\n* Create SPI and use SPI to create WIZNET5K wired network card\n* Print current IP information\n\nRelated API reference: [wiznet5k API](../../api_reference/machine/network.md#WIZNET5K_Module)"}, "/soft/maixpy/en/modules/sp_mod/index.html": {"title": "SP-MOD", "content": "---\ntitle: SP-MOD\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: SP-MOD\n---\n\n\n## SP-MOD interface\n\nSP-MOD is sipeed module, simplify PMOD, super module, Sipeed official main recommendation and use, 8P 2.54mm 2x4 double row female, support communication protocol as follows:\n\n![](./../../../assets/hardware/module_spmod/sp_mod.svg)\n\n## Peripheral Module\n\nThe following modules all use SP-MOD standard interface modules.\n\n* [SP_BT Bluetooth transparent transmission](./sp_bt.html)\n* [SP_LoRa Wireless Communication](./sp_lora.html)\n* [SP_RFID Radio Frequency Identification](./sp_rfid.html)\n* [SP_TOF Ranging](./sp_tof.html)\n* [SP_Eink Electronic Ink Screen](./sp_eink.html)\n* [SP_LCD1.14 IPS screen](./sp_lcd1.14.html)\n* [SP_Weather weather sensor](./sp_weather.html)\n* [SP_Ethernet wired network port](./sp_ethernet.html)"}, "/soft/maixpy/en/modules/on_chip/uart.html": {"title": "Use of UART", "content": "---\ntitle: Use of UART\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of UART\n---\n\n\nFor details on UART, please refer to [UART-API Document](../../api_reference/machine/uart.html).\n\n## Instructions\n\n* Import UART module from machine\n\n```python\nfrom machine import UART\n```\n\n* The pin used for configuration is UART function\n\n```python\nfm.register(10, fm.fpioa.UART1_TX, force=True)\nfm.register(11, fm.fpioa.UART1_RX, force=True)\n```\n\n* Create UART object\n\n```python\nuart = UART(UART.UART1, 115200, 8, 1, 0, timeout=1000, read_buf_len=4096)\n```\n\n* Read and write data\n\n```python\nuart.write(b'hello world')\nread_data = uart.read()\n```\n\n## Example\n\nSend back the data received by the serial port\n\n```python\nfrom fpioa_manager import fm\nfrom machine import UART\nimport time\n\n# need your connect hardware IO 10/11 to loopback\nfm.register(10, fm.fpioa.UART1_TX, force=True)\nfm.register(11, fm.fpioa.UART1_RX, force=True)\n\nuart = UART(UART.UART1, 115200, 8, 1, 0, timeout=1000, read_buf_len=4096)\n\nuart.write(b'hello world')\n\nwhile True:\n    read_data = uart.read()\n    if read_data:\n        print(\"recv:\", read_data)\n        uart.write(read_data) # send data back\n        print(\"wait data: \")\n\nuart.deinit()\ndel uart\n```"}, "/soft/maixpy/en/modules/on_chip/spi.html": {"title": "Use of SPI", "content": "---\ntitle: Use of SPI\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use of SPI\n---\n\n\nFor details about SPI, please refer to [SPI-API Document](../../api_reference/machine/spi.html).\n\n## Instructions\n\n### Host Mode\n\n* Import SPI module from machine\n\n```python\nfrom machine import SPI\n```\n\n* The pins used for configuration are chip select GPIO function and SPI function.\n\n```python\nfm.register(25,fm.fpioa.GPIOHS10, force=True)#cs\ncs = GPIO(GPIO.GPIOHS10, GPIO.OUT)\n\nfm.register(28,fm.fpioa.SPI1_D0, force=True)#mosi\nfm.register(26,fm.fpioa.SPI1_D1, force=True)#miso\nfm.register(27,fm.fpioa.SPI1_SCLK, force=True)#sclk\n```\n\n* Create SPI object\n\n```python\nspi1 = SPI(SPI.SPI1, mode=SPI.MODE_MASTER, baudrate=10000000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB)\n```\n\n* Use chip select GPIO to select the slave, read and write data through SPI\n\n```python\ncs.value(0)\nspi1.write_readinto(w, r)\ncs.value(1)\n```\n\n### Slave mode\n\nK210 SPI slave mode only supports three-wire communication, so this mode is not implemented in MaixPy. For slave mode, please refer to [SPI_SLAVE C SDK implementation](https://github.com/kendryte/kendryte-standalone-demo/tree/develop /spi_slave).\n\n## Example\n\n* Select the chip select GPIO corresponding to the slave and send and receive data\n\n```python\nfrom machine import SPI\nfrom fpioa_manager import fm\nfrom Maix import GPIO\n\nm.register(25,fm.fpioa.GPIOHS10, force=True)#cs\ncs = GPIO(GPIO.GPIOHS10, GPIO.OUT)\n\nfm.register(28,fm.fpioa.SPI1_D0, force=True)#mosi\nfm.register(26,fm.fpioa.SPI1_D1, force=True)#miso\nfm.register(27,fm.fpioa.SPI1_SCLK, force=True)#sclk\n\nspi1 = SPI(SPI.SPI1, mode=SPI.MODE_MASTER, baudrate=10000000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB)\n\nw = b'\\xFF'\nr = bytearray(1)\n\ncs.value(0)\nprint(spi1.write_readinto(w, r))\ncs.value(1)\n```"}, "/soft/maixpy/en/modules/on_chip/i2s.html": {"title": "Use of I2S (Integrated Circuit Audio Bus)", "content": "---\ntitle: Use of I2S (Integrated Circuit Audio Bus)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: the use of I2S (integrated circuit built-in audio bus)\n---\n\n\nFor a detailed introduction to the I2S audio bus, please refer to [I2S-API Document](./../../api_reference/Maix/i2s.html).\n\n## Instructions\n\n* Import I2S module from Maix\n\n```python\nfrom Maix import I2S\n```\n\n* Create I2S object\n\n```python\ni2s_dev = I2S(device_num)\n```\n\n* Configuration parameters\n\n```python\ni2s_dev.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE)\ni2s_dev.set_sample_rate(sample_rate)\n```\n\n* Read or play data\n\n```python\ni2s_dev.record(256)#sampling points number must be smaller than 256\n```\n\n## Routine\n\nCollect data and play it directly\n\n```python\nfrom Maix import I2S\nimport time\nfrom fpioa_manager import *\n\nfm.register(20,fm.fpioa.I2S0_IN_D0)#GO\nfm.register(19,fm.fpioa.I2S0_WS)\nfm.register(18,fm.fpioa.I2S0_SCLK)\nfm.register(34,fm.fpioa.I2S2_OUT_D1)\nfm.register(35,fm.fpioa.I2S2_SCLK)\nfm.register(33,fm.fpioa.I2S2_WS)\nsample_rate = 44*1000\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE)\nrx.set_sample_rate(sample_rate)\ntx = I2S(I2S.DEVICE_2)\ntx.channel_config(tx.CHANNEL_1, tx.TRANSMITTER, align_mode = I2S.RIGHT_JUSTIFYING_MODE)\ntx.set_sample_rate(sample_rate)\nwhile True:\n    audio = rx.record(256)#sampling points number must be smaller than 256\n    tx.play(audio)\n```"}, "/soft/maixpy/en/modules/on_chip/wdt.html": {"title": "Use of WDT (Watchdog)", "content": "---\ntitle: Use of WDT (Watchdog)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: the use of WDT (watchdog)\n---\n\n\nFor detailed introduction of WDT, please refer to [WDT API Document](../../api_reference/machine/wdt.html).\n\n## Instructions\n\nThe watchdog is mainly used to protect the normal operation of the system. The principle of action is that after the watchdog is started, a dog feeding operation must be executed regularly in the program. When the system is disturbed and cannot operate normally, the dog feeding operation cannot be executed regularly. At this time, the watchdog will generate an internal reset, allowing the system to restart.\n\n* Import WDT module from machine\n\n```python\nfrom machine import WDT\n```\n\n* Define the callback function and create the WDT object\n\n```python\ndef on_wdt(self):\n    print(self.context(), self)\n    #self.feed()\n    ## release WDT\n    #self.stop()\n\n# test callback wdt\nwdt1 = WDT(id=1, timeout=4000, callback=on_wdt, context={})\n```\n\n* Feed the dog\n\n```python\nwdt1.feed()\n```\n\n*Dog feeding operation can be performed in the callback function*\n\n* Turn off watchdog\n\n```python\nwdt1.stop()\n```\n\n## Example\n\n1. Close after feeding the dog once\n2. Do not feed the dog to reset the system\n\n```python\nimport time\nfrom machine import WDT\n\n#'''\n# test default wdt\nwdt0 = WDT(id=0, timeout=3000)\nprint('into', wdt0)\ntime.sleep(2)\nprint(time.ticks_ms())\n# 1.test wdt feed\nwdt0.feed()\ntime.sleep(2)\nprint(time.ticks_ms())\n# 2.test wdt stop\nwdt0.stop()\nprint('stop', wdt0)\n# 3.wait wdt work\n#while True:\n    #print('idle', time.ticks_ms())\n    #time.sleep(1)\n#'''\n\n#'''\ndef on_wdt(self):\n    print(self.context(), self)\n    #self.feed()\n    ## release WDT\n    #self.stop()\n\n# test callback wdt\nwdt1 = WDT(id=1, timeout=4000, callback=on_wdt, context={})\nprint('into', wdt1)\ntime.sleep(2)\nprint(time.ticks_ms())\n# 1.test wdt feed\nwdt1.feed()\ntime.sleep(2)\nprint(time.ticks_ms())\n# 2.test wdt stop\nwdt1.stop()\nprint('stop', wdt1)\n# 3.wait wdt work\n#while True:\n    #print('idle', time.ticks_ms())\n    #time.sleep(1)\n#'''\n\n#'''\n## test default and callback wdt\ndef on_wdt(self):\n    print(self.context(), self)\n    #self.feed()\n    ## release WDT\n    #self.stop()\n\nwdt0 = WDT(id=0, timeout=3000, callback=on_wdt, context=[])\nwdt1 = WDT(id=1, timeout=4000, callback=on_wdt, context={})\n## 3.wait wdt work\nwhile True:\n    #wdt0.feed()\n    print('idle', time.ticks_ms())\n    time.sleep(1)\n#'''\n\n'''output\ninto [MAIXPY]WDT:(800cc560; id=0, timeout=3000, callback=800abcf8, context=800abcf8)\n550247\n552247\nstop [MAIXPY]WDT:(800cc560; id=0, timeout=3000, callback=800abcf8, context=800abcf8)\ninto [MAIXPY]WDT:(800cc5e0; id=1, timeout=4000, callback=800cc5a0, context=800cc5c0)\n554261\n556261\nstop [MAIXPY]WDT:(800cc5e0; id=1, timeout=4000, callback=800cc5a0, context=800cc5c0)\nidle 556268\nidle 557269\nidle 558269\n[] [MAIXPY]WDT:(800cc680; id=0, timeout=3000, callback=800cc620, context=800cc640)\nidle 559275\n{} [MAIXPY]WDT:(800cce40; id=1, timeout=4000, callback=800cc620, context=800cc6c0)\nidle 560282\nidle 561283\n\n[MAIXPY] Pll0:freq:806000000\n[MAIXPY] Pll1:freq:398666666\n[MAIXPY] Pll2:freq:45066666\n[MAIXPY] cpu:freq:403000000\n[MAIXPY] kpu:freq:398666666\n[MAIXPY] Flash:0xef:0x17\n[MaixPy] gc heap=0x800c9850-0x80149850(524288)\n[MaixPy] init end\n\n __ __ _____ __ __ _____ __ __\n| \\/ | /\\ |_ _| \\ \\ / / | __ \\ \\ \\ / /\n| \\ / | / \\ | | \\ V / | |__) | \\ \\_/ /\n| |\\/| | / /\\ \\ | |> <| ___/ \\ /\n| | | | / ____ \\ _| |_ /. \\ | | | |\n|_| |_| /_/ \\_\\ |_____| /_/ \\_\\ |_| |_|\n\nOfficial Site: https://www.sipeed.com\nWiki: https://maixpy.sipeed.com\n\nMicroPython v0.5.1-174-gf18990aa3-dirty on 2021-01-11; Sipeed_M1 with kendryte-k210\nType \"help()\" for more information.\n'''\n```"}, "/soft/maixpy/en/modules/on_chip/gpio.html": {"title": "Use of GPIO", "content": "---\ntitle: Use of GPIO\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: use of GPIO\n---\n\nFor detailed introduction of GPIO, please refer to [GPIO-API Document](../../api_reference//Maix/gpio.html).\n\n## Instructions\n\n* Register an IO as a GPIO function\n\n```python\nfrom Maix import GPIO\nfrom fpioa_manager import fm\n\nfm.register(io_number,fm.fpioa.GPIO0)\n```\n\n* Set GPIO as input or output mode\n\n```python\ngpio=GPIO(GPIO.GPIO0,GPIO.OUT)\n```\n\n* Read or set GPIO level\n\n```python\ngpio.value(1)\n```\n\n## Example\n\nTurn on the LED\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../../api_reference/builtin_py/board_info.html) is required before use.\n\n```python\nimport utime\nfrom Maix import GPIO\nfrom board import board_info\nfrom fpioa_manager import fm\n\nfm.register(board_info.LED_R,fm.fpioa.GPIO0)\nled_r=GPIO(GPIO.GPIO0,GPIO.OUT)\nutime.sleep_ms(500)\nled_r.value(0)\nfm.unregister(board_info.LED_R)\n```"}, "/soft/maixpy/en/modules/on_chip/timer.html": {"title": "Use of Timer", "content": "---\ntitle: Use of Timer\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: the use of Timer (timer)\n---\n\n\nFor detailed introduction of Timer, please refer to [Timer-API Document](../../api_reference/machine/timer.html).\n\n## Instructions\n\n* Import Timer module from machine\n\n```python\nfrom machine import Timer\n```\n\n* Create a Timer object\n\n```python\ndef on_timer(timer):\n    print(\"time up:\",timer)\n    print(\"param:\",timer.callback_arg())\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=1, unit=Timer.UNIT_S, callback=on_timer, arg=on_timer, start=False, priority=1, div=0)\n```\n\n* Start the timer, at this time the timer will execute the callback function regularly\n\n```python\ntim.start()\n```\n\n* Stop the timer\n\n```python\ntim.stop()\n```\n\n## Example\n\nExecute callback function regularly\n\n```python\nfrom machine import Timer\n\ndef on_timer(timer):\n    print(\"time up:\",timer)\n    print(\"param:\",timer.callback_arg())\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=1, unit=Timer.UNIT_S, callback=on_timer, arg=on_timer, start=False, priority=1, div=0)\n\nprint(\"period:\",tim.period())\n\ntim.start()\ntime.sleep(5)\ntim.stop()\ntime.sleep(5)\ntim.restart()\ntime.sleep(5)\ntim.stop()\ndel tim\n```"}, "/soft/maixpy/en/modules/on_chip/i2c.html": {"title": "Use of I2C", "content": "---\ntitle: Use of I2C\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: the use of I2C\n---\n\n\nFor detailed introduction of I2C, please refer to [I2C-API Document](../../api_reference/machine/i2c.html).\n\n## Instructions\n\n### Host Mode\n\n* Create I2C (software simulation or hardware) objects\n\n```python\nfrom machine import I2C\nfrom fpioa_manager import fm\n# i2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29) # hardware i2c\ni2c = I2C(I2C.I2C4, freq=100000, scl=28, sda=29,gscl=fm.fpioa.GPIOHS3,gsda=fm.fpioa.GPIOHS2) # software i2c\n```\n\n* Scan slaves, return all slave addresses\n\n```python\ndevices = i2c.scan()\n```\n\n* Read and write data to the slave\n\n```python\nfor device in devices:\n    i2c.writeto(device, b'123')\n    i2c.readfrom(device, 3)\n```\n\n### Slave mode\n\n* Create slave callback function\n\n```python\ncount = 0\ndef on_receive(data):\n    print(\"on_receive:\",data)\n\ndef on_transmit():\n    count = count+1\n    print(\"on_transmit, send:\",count)\n    return count\n\ndef on_event(event):\n    print(\"on_event:\",event)\n```\n\n* Create I2C object\n\n```python\nfrom machine import I2C\ni2c = I2C(I2C.I2C0, mode=I2C.MODE_SLAVE, scl=28, sda=29, addr=0x24, addr_size=7, on_receive=on_receive, on_transmit=on_transmit, on_event=on_event)\n```\n\n## Example\n\n* Read all slave addresses and send and receive data respectively\n\n```python\nfrom machine import I2C\n\ni2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29) # software i2c\n\ndevices = i2c.scan()\nprint(devices)\n\nfor device in devices:\n    i2c.writeto(device, b'123')\n    i2c.readfrom(device, 3)\n```\n\n* Slave mode example\n\n```python\nfrom machine import I2C\n\ncount = 0\n\ndef on_receive(data):\n    print(\"on_receive:\",data)\n\ndef on_transmit():\n    count = count+1\n    print(\"on_transmit, send:\",count)\n    return count\n\ndef on_event(event):\n    print(\"on_event:\",event)\n\ni2c = I2C(I2C.I2C0, mode=I2C.MODE_SLAVE, scl=28, sda=29, addr=0x24, addr_size=7, on_receive=on_receive, on_transmit=on_transmit, on_event=on_event)\n```"}, "/soft/maixpy/en/modules/on_chip/pwm.html": {"title": "Use of PWM", "content": "---\ntitle: Use of PWM\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Use of PWM\n---\n\n\nFor details on PWM, please refer to [PWM-API Document](../../api_reference/machine/pwm.html).\n\n## Instructions\n\n* Import PWM and Timer modules from machine\n\n```python\nfrom machine import Timer,PWM\n```\n\n* Create Timer and PWM\n\n```python\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)\nch = PWM(tim, freq=500000, duty=50, pin=boad_info.LED_G)\n```\n\n* Change the duty cycle, the set pin will output waveforms with different duty cycles\n\n```python\nch.duty(duty)\n```\n\n## Example\n\nControl the brightness of LED_G\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../../api_reference/builtin_py/board_info.html) is required before use.\n\n```python\nfrom machine import Timer,PWM\nimport time\nfrom board import board_info\nfrom fpioa_manager import fm\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)\nch = PWM(tim, freq=500000, duty=50, pin=boad_info.LED_G)\nduty=0\ndir = True\nwhile True:\n    if dir:\n        duty += 10\n    else:\n        duty -= 10\n    if duty>100:\n        duty = 100\n        dir = False\n    elif duty<0:\n        duty = 0\n        dir = True\n    time.sleep(0.05)\n    ch.duty(duty)\n```"}, "/soft/maixpy/en/modules/others/servo.html": {"title": "steering gear", "content": "---\ntitle: steering gear\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: steering gear\n---\n\n\n## caveat!Please use an external power supply, do not use a computer to supply power to the steering gear.\n\n## Instructions\n\nThe steering gear needs to use PWM output with different duty ratios to control its rotation angle. First, you need to prepare the steering gear\n\n* Import the PWM module, create a PWM object, and connect the PWM output pin to the servo signal input\n\n```python\nfrom machine import Timer,PWM\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)\nS1 = PWM(tim, freq=50, duty=0, pin=17)\n```\n\n* Output different duty cycle waveforms to control the servo\n\n```python\nS1.duty((angle+90)/180*10+2.5)\n```\n\nPWM control API reference: [PWM API](../../api_reference/machine/pwm.html)\n\n## Routine\n\n* Control the servo to rotate at different angles: [Servo](https://github.com/sipeed/MaixPy_scripts/blob/79a5485ec983e67bb8861305a52418b29e0dc205/modules/others/Servo/Servo.py)\n\n* Servo pan/tilt: [gimbal](https://github.com/sipeed/MaixPy_scripts/tree/master/application/gimbal)"}, "/soft/maixpy/en/modules/others/binocular_camera.html": {"title": "Binocular camera", "content": "---\ntitle: Binocular camera\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: binocular camera\n---\n\n\n![](../../../assets/hardware/module/camera_binocular.png)\n\n## Instructions\n\nNeed to prepare a binocular camera\n\n* Import and initialize the binocular camera\n\n```python\nimport sensor\nsensor.binocular_reset()\nsensor.shutdown(False)\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.shutdown(True)\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\n```\n\n* Turn on the camera and capture images\n\n```python\nsensor.shutdown(True)\nimg=sensor.snapshot()\n```\n\nFor API details, please refer to: [Sensor API](../../api_reference/machine_vision/sensor.html)\n\n## Routine\n\nCapture image and display on LCD\n\n[demo_binocular](https://github.com/sipeed/MaixPy_scripts/blob/5a03ab549d06cd713f2c0d19f0c18fbd24c69025/hardware/demo_binocular.py)"}, "/soft/maixpy/en/modules/others/htpa.html": {"title": "HTPA thermal infrared temperature measurement module", "content": "---\ntitle: HTPA thermal infrared temperature measurement module\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: HTPA thermal infrared temperature measurement module\n---\n\n\n<img src=\"./../../../assets/hardware/other/htpa32x32.png\">\n<img src=\"../../../assets/hardware/other/htpat_scale_240x240.png\">\n\nCan be used for non-contact temperature measurement.\n\n## Parameters\n\n* Power supply voltage (DC): 3.3V\n* Current consumption: 5.5(±1.0)mA\n* Clock frequency (sensor): 5(±3)MHz\n* Ambient temperature range: -20 ~ 85℃\n* Target temperature range: -20 ~ >1000°C\n* Frame rate (full frame): 2 ~ 27hz\n* Frame rate (quarter frame): 8 ~ 110hz\n* Noise equivalent temperature difference (best optics): 140mK@1Hz\n* Communication method: I2C\n\n## Instructions\n\nMaixPy has implemented htpa in modules (you need to enable the module when the firmware is compiled to be available).\n\n* Import and create htpa\n\n```python\nfrom machine import I2C\nfrom modules import htpa\ndev = htpa(i2c=I2C.I2C0, scl_pin=7, sda_pin=6, i2c_freq=1000000)\n```\n\n* Get the temperature of all points in the detection range\n\n```python\ntemperature = dev.temperature()\n```\n\nAPI details refer to [modules.htpa](../../api_reference/extend/htpa.html)\n\n## Routine\n\n* Draw temperature distribution graph on LCD: [htpa demo](https://github.com/sipeed/MaixPy_scripts/blob/79a5485ec983e67bb8861305a52418b29e0dc205/modules/others/heimann_HTPA_32x32/HTPA_32x32_demo.py)\n\n## More\n\n* Module information: [32x32 Thermopile Array](https://www.heimannsensor.com/32x32)\n* Detailed tutorial: [thermal infrared heimann (Hyman) HTPA 32x32d](https://neucrack.com/p/199)"}, "/soft/maixpy/en/modules/others/onewire.html": {"title": "Use of onewire (single bus)", "content": "---\ntitle: Use of onewire (single bus)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Use of onewire (single bus)\n---\n\n## Instructions\n\n* Import onewire module from modules\n\n```python\nfrom modules import onewire\n```\n\n* Create onewire object\n\n```python\nfm.register(14, fm.fpioa.GPIOHS2, force=True)\nbus = onewire(fm.fpioa.GPIOHS2)\n```\n\n* Search, read and write data and other operations\n\n## Routine\n\nds18b20 temperature reading: [onwire_ds18b20](https://github.com/sipeed/MaixPy_scripts/blob/80f4eb71d3481b6f119f25f39f7c9b37404b99ce/hardware/demo_onewire_ds18x20.py)"}, "/soft/maixpy/en/modules/others/index.html": {"title": "other modules", "content": "---\ntitle: other modules\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: other modules\n---\n\n\n* [Binocular camera](./binocular_camera.html)\n* [esp32 ADC analog to digital conversion](./esp32_read_adc.html)\n* [HTPA infrared temperature measurement](./htpa.html)\n* [Serial infrared lens](./mlx90640.html)\n* [Servo](./servo.html)"}, "/soft/maixpy/en/modules/others/esp32_read_adc.html": {"title": "ESP32 ADC", "content": "---\ntitle: ESP32 ADC\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ESP32 ADC\n---\n\n## How to use ESP32 to get ADC analog\n\nSince K210 does not have the function of ADC to read analog quantity, this function can only be obtained from hardware such as ESP32 and ESP82XX. The most basic purpose of ADC is to realize a touchable button contact.\n\n### ESP32 sample code\n\n```python\n# Uasge see readme.md\n# from network_esp32 import wifi\n\nimport time, network\nfrom Maix import GPIO\nfrom fpioa_manager import fm\n\nclass wifi():\n    # IO map for ESP32 on Maixduino\n    fm.register(25,fm.fpioa.GPIOHS10)#cs\n    fm.register(8,fm.fpioa.GPIOHS11)#rst\n    fm.register(9,fm.fpioa.GPIOHS12)#rdy\n    print(\"Use Hareware SPI for other maixduino\")\n    fm.register(28,fm.fpioa.SPI1_D0, force=True)#mosi\n    fm.register(26,fm.fpioa.SPI1_D1, force=True)#miso\n    fm.register(27,fm.fpioa.SPI1_SCLK, force=True)#sclk\n    nic = network.ESP32_SPI(cs=fm.fpioa.GPIOHS10, rst=fm.fpioa.GPIOHS11, rdy=fm.fpioa.GPIOHS12, spi=1)\n\nprint(\"ESP32_SPI firmware version:\", wifi.nic.version())\n\n# get ADC0 ADC1 ADC2\nadc = wifi.nic.adc((0,1,2))\nprint(adc)\n\nwhile True:\n    try:\n        # get ADC0~5\n        adc = wifi.nic.adc()\n    except Exception as e:\n        print(e)\n        continue\n    for v in adc:\n        print(\"%04d\" %(v), end=\" \")\n    print(': adc')\n\n'''\n    MicroPython v0.5.1-136-g039f72b6c-dirty on 2020-11-18; Sipeed_M1 with kendryte-k210\n    Type \"help()\" for more information.\n    >>>\n    raw REPL; CTRL-B to exit\n    >OK\n    (2370, 3102, 3071)\n    2017 2753 0977 2709 0963 0855: adc\n    0617 0757 0150 0095 0133 0153: adc\n    1319 1478 0955 0939 0698 0619: adc\n    2403 3231 3299 3298 1483 0779: adc\n    1119 1815 1274 1315 0230 0255: adc\n    0951 0951 0295 0283 0319 0399: adc\n    2175 2769 2576 2579 1487 1104: adc\n    1995 2846 2647 2699 0839 0441: adc\n'''\n```\n\n\n### OSError: Get version fail\n\nJust try again, usually esp32 has not been initialized successfully.\n\n```shell\nTraceback (most recent call last):\n  File \"<stdin>\", line 15, in <module>\n  File \"<stdin>\", line 24, in wifi\nOSError: Get version fail\n>\n```\n\n### ESP82XX implementation ideas\n\n> The document does not explain this part of the content.\n\nQuery the ADC value through AT+SYSADC. In Espressif's ESP82XX AT firmware, the default is GPIO12.\n\nRead the value directly to use."}, "/soft/maixpy/en/modules/others/mlx90640.html": {"title": "MLX90640 serial infrared lens module", "content": "---\ntitle: MLX90640 serial infrared lens module\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MLX90640 serial infrared lens module\n---\n\n<div style=\"center\">\n<img src=\"./../../../assets/hardware/other/mlx90640_hot_map3.jpg\">\n<img src=\"../../../assets/hardware/other/k210_mlx90640_hot_map2.jpg\">\n</div>\n\nCan be used for non-contact temperature measurement.\n\n## Parameters\n\n* Resolution: 32x24\n* Measuring range: -40°C~300°C\n* Temperature resolution: 0.1°C\n* Measurement accuracy: ±2°C\n* Repeatability: ±2°C\n* Response frequency: 8HZ\n* Working voltage: 3.3~5V\n* Working current: 42mA\n* Working temperature: -40°C~85°C\n* Size: 17.27mmx33mm\n\n## Instructions\n\nThe module uses serial port or I2C for communication. After confirming that the wiring is correct, the measurement data can be read from the serial port.\n\n## Routine\n\n* Display infrared thermal imaging pictures on LCD: [demo mlx90640](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/others/mlx90640)\n\n## More\n\n* Module details: [Far infrared thermal sensor array (32x24 RES)](https://www.melexis.com/en/product/MLX90640/Far-Infrared-Thermal-Sensor-Array)\n* Detailed tutorial: [mlx90640](https://neucrack.com/p/189)"}, "/soft/maixpy/en/modules/grove/grove_rgb_led_ring.html": {"title": "Grove-RGB LED Ring (LED strip)", "content": "---\ntitle: Grove-RGB LED Ring (LED strip)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Grove-RGB LED Ring (LED strip)\n---\n\n\n<div class=\"grove_pic\">\n<img src=\"../../../assets/hardware/module_grove/grove_led_ring.jpg\">\n</div>\n\nThe Grove-RGB LED ring uses 3535 size LEDs, and the LEDs are embedded with embedded microcontrollers. Each WS2813 driver chip can be addressed and located inside the LED. Each LED is driven by a constant current, so even if the voltage changes, the color will be very consistent.\n\n## Parameters\n\n|Item | Value |\n| --- | --- |\n|Working voltage| 3.3V/5V|\n|Quiet current |0.7mA/LED|\n|RGB channel constant current |16mA/LED|\n|Refresh frequency |2Hz|\n|Reset time |>280μs|\n|Working temperature |-25～85℃|\n|Storage temperature |-40～105℃|\n\n## Instructions\n\nMaixPy has implemented the WS2812 driver in the modules module.\n\n* To create a ws2812 object, only a single signal line is needed\n\n```python\nfrom modules import ws2812\nled_io, led_num = 24, 24\nws = ws2812(led_io, led_num)\n```\n\n* Set the color of a certain light and display it\n\n```python\nfor i in range(led_num):\n    ws.set_led(i, (0, 0, 0))\nws.display()\n```\n\n## Routine\n\n[Grove-RGB LED Ring example](https://github.com/sipeed/MaixPy_scripts/blob/master/modules/grove/ws2812/ws2812.py)\n\n## More\n\n* API manual: [modules.ws2812](../../api_reference/extend/ws2812.html)\n\n* Module details: [Seeed Grove-LED_ring](https://wiki.seeedstudio.com/Grove-LED_ring/)"}, "/soft/maixpy/en/modules/grove/grove_ultrasonic_ranger.html": {"title": "Grove-Ultrasonic Ranger (Ultrasonic Ranger)", "content": "---\ntitle: Grove-Ultrasonic Ranger (Ultrasonic Ranger)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Grove-Ultrasonic Ranger (Ultrasonic Ranger)\n---\n\n\n<div class=\"grove_pic\">\n<img src=\"../../../assets/hardware/module_grove/ultrasonic.jpg\">\n</div>\n\nGrove-Ultrasonic Ranger is a non-contact ranging module with a working frequency of 40KHz. The trigger and echo signals of Grove_Ultrasonic_Ranger share a SIG pin.\n\n## Parameters\n\n| Item    |Value  |\n| -------- | ----------- |\n|Working voltage |3.2~5.2V |\n|Working current |8ma |\n|Ultrasonic frequency | 40kHz |\n|Measuring range |2-350cm |\n|Resolution | 1cm |\n|Output | PWM |\n|Size | 50mm x 25mm x 16mm|\n|Weight | 13g |\n|Measurement angle |15° |\n|Working temperature |-10~60°C |\n|Trigger signal |10uS TTL |\n|Echo signal |TTL |\n\n## Instructions\n\nMaixPy has implemented ultrasonic driver in the modules module.\n\n* Import ultrasonic class and create object\n\n```python\nfrom modules import ultrasonic\ndevice = ultrasonic(fm.fpioa.GPIOHS0)\n```\n\n* Get the current measurement distance (cm)\n\n```python\ndistance = device.measure(unit = ultrasonic.UNIT_CM, timeout = 3000000)\n```\n\n## Routine\n\n[Grove-Ultrasonic Ranger example](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/grove/ultrasonic)\n\n## More\n\n* API manual: [modules.ultrasonic](../../api_reference/extend/ultrasonic.html)\n\n* Module details: [Seeed Grove-Ultrasonic_Ranger](https://wiki.seeedstudio.com/Grove-Ultrasonic_Ranger/)"}, "/soft/maixpy/en/modules/grove/grove_chainable_rgb_led.html": {"title": "Grove-Chainable RGB LED (Linkable LED lights)", "content": "---\ntitle: Grove-Chainable RGB LED (Linkable LED lights)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Grove-Chainable RGB LED (linkable LED lights)\n---\n\n\n<div class=\"grove_pic\">\n<img src=\"../../../assets/hardware/module_grove/grove_rgb_led.jpg\">\n</div>\n\nGrove-Chainable RGB LED uses 2-wire transmission (data and clock) to communicate with the MCU. This 2-wire transmission can be used to cascade multiple modules. Built-in clock regeneration can extend the transmission distance. The Grove module is suitable for any project based on colored LEDs.\n\n## Parameters\n\n|Item|Value|\n|----|----|\n|Working voltage|5V |\n|Electric current|20mA|\n|Communication protocol|serial communication|\n\n\n## Instructions\n\n* Import the RGB_LED class in the routine warehouse and create an RGB_LED object\n\n```python\nfrom RGB_LED import RGB_LED\nled = RGB_LED(clk_pin, data_pin, led_num, clk_gpiohs_num, data_gpiohs_num, True)\n```\n\n* Set the color of a light, the color value is rgb format\n\n```python\nfor i in range(led_num):\n    led.set_RGB(i, r, g, b)\n```\n\n## Routine\n\n[Grove-Chainable RGB LED example](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/grove/chainable_RGB_LED)\n\n## More\n\nModule details: [Seeed Grove-Chainable RGB LED](https://wiki.seeedstudio.com/Grove-Chainable_RGB_LED/)"}, "/soft/maixpy/en/modules/grove/index.html": {"title": "Grove", "content": "---\ntitle: Grove\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Grove\n---\n\n\nModules using Grove standard interfaces, Grove is a unified interface system used by the Seeed team, and currently supports a large number of modules.\n\n## Grove interface\n\nThe cables of the Grove interface have 4 colors, and users can quickly distinguish them according to the colors\n![](../../../assets/hardware/module_grove/grove_interface.jpg)\n\n| pin | color | description |\n| --- | --- | --- |\n| pin 1 | yellow | (for example, SCL on I2C Grove Connectors) |\n| pin 2 | white | (for example, SDA on I2C Grove Connectors) |\n| pin 3 | Red | VCC (All Grove ports are VCC in red) |\n| pin 4 | black | GND (all Grove ports are GND in black) |\n\nGrove module mainly has 4 kinds of interfaces:\n\n1. Grove Digital digital interface:<br/>\n    The Grove digital interface consists of four standard wires of Grove plugs.<br/>\n    The two signal lines are usually called D0 and D1.<br/>\n    Most modules only use D0, but some (like LED Bar Grove displays) use both. Usually the core board will call the first Grove connector on the board as D0, and the second as D1. The first The connector will be connected to the DO/D1 pin of the main control chip, the second connector will be connected to the D1/D2 pin of the main control chip, and the following connectors will be deduced by analogy.\n\n| pin | Function | Note |\n| --- | --- | --- |\n| pin1 | Dn First digital input | — |\n| pin2 | Dn+1 The second digital input | — |\n| pin3 | VCC power supply pin 5V/3.3V | — |\n| pin4 | GND ground | — |\n\n\n2. Grove UART :<br/>\n    The Grove UART is a special digital input and output interface.<br/>\n    It uses pins 1 and 2 for serial input and transmission. <br/>\n    Pin 1 is the RX line (used to receive data, so it is input),\n    Among them, pin 2 is the TX line (used to transmit data to the Grove module).\n\n| pin | Function | Note |\n| --- | --- | --- |\n| pin1 | RX | Serial Receive |\n| pin2 | TX | Serial transmission |\n| pin3 | VCC | Power supply pin 5V/3.3V |\n| pin4 | GND | Ground |\n\n3. Grove I2C:<br/>\n    There are many types of I2C Grove sensors available.<br/>The Grove on MaixCube only supports 3.3V sensors\n\n  The Grove I2C connector has a standard layout. Pin 1 is the SCL signal, and pin 2 is the SDA signal\n\n| pin | Function | Note |\n| --- | --- | --- |\n| pin1 | SCL | I2C clock |\n| pin2 | SDA | I2C data |\n| pin3 | VCC | Power supply pin, 5V/3.3V |\n| pin4 | GND | Ground |\n\nFor details, please refer to: [Grove_System](https://wiki.seeedstudio.com/cn/Grove_System/)\n\n## Peripheral Module\n\nThe following peripherals all use Grove interface\n\n* [Ultrasonic Ranger](./grove_ultrasonic_ranger.html)\n* [Chainable RGB LED light](./grove_chainable_rgb_led.html)\n* [RGB LED Ring strip](./grove_rgb_led_ring.html)"}, "/soft/maixpy/en/how_to_ask.html": {"title": "How to ask questions gracefully", "content": "---\ntitle: How to ask questions gracefully\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: how to ask questions gracefully\n---\n\n\n## When asking questions in various places, you will find several phenomena:\n\n* No one answered after asking the question\n* It took a long time for the question to be answered\n* The other party always dislikes himself too much\n\n\n## Before asking questions, make sure that you have already studied Getting Started Guide\n\nThe **Getting Started** chapter of this document is the basis of the basics of using `MaixPy`, no matter whether you have development experience, a big man or a novice, please be sure to read and operate it from front to back.\n\nMany problems will be solved in this process. Don’t ask questions in QQ groups, forums, issues, or emails at the beginning. Many problems explained in the document at the beginning may not receive timely answers from the community, which saves everyone’s attention. Time, but also for a better community environment, everyone grows better together, please understand each other\n\n\n## When asking questions, try to do the following points, which will greatly increase the probability of the problem being solved quickly:\n\n### Clear the problem, figure out what happened and what I did, including:\n\n* What effect and function do I want to achieve?\n\n* In order to achieve this effect, how did I do it, and what is the detailed process?\n\n* During the implementation process, what error occurred and what was the phenomenon (for example, what error was reported, what was the **complete** error content?)\n\n* Have I read the error message carefully? Does the error message indicate the cause and solution of the error?\n\n* Based on these error messages and careful thinking, can the problem be solved?\n\n* Search for documents, issues, and whether you can find solutions to problems with search engines\n\n### If the problem cannot be solved by yourself, you need to ask others for advice, and you need to consider:\n\n* Who to ask, where to ask, who will be more likely to answer my question? And how about real-time?\n\n* What data and phenomena should I provide him to be willing to help me solve the problem quickly?\n  * Provide my purpose (to let the respondent know what you are doing)\n  * Provide a complete implementation process, as well as the phenomena that occurred in the process (it is convenient for the respondent to follow your process to do it again, that is, the problem reproduces)\n  * Give the wrong place and indicate where the phenomenon or result is different from what you expected! (Let the respondent know where it did not meet expectations)\n  * Provide the error information that appears, it needs to be complete, as many screenshots as possible, more logs, don't cut a small picture stingly, or give a part of the log (because the respondent may not have done this for a long time , Forget some details, you need to quickly recall the screenshots and complete logs; and according to the detailed logs, you can quickly locate the problem)\n\n* How can I be more sincere when asking questions? Even if I am noob, everyone is willing to answer\n\n\n\n### Question template\n\n\nAsk the question as elegant as possible, without adding extra modal particles, complaining vocabulary, consider every word and punctuation, and think about the question from the perspective of the answerer, how to let the answerer help him solve the problem quickly, the number of words is too few The description is unclear, too many words make people impatient\n\n#### Title\n\nWherever you ask (including `QQ group`), draw up a title of about `30` for your question to clarify the central idea of ​​the question, including:\n* Question category, is it asking questions, submitting bugs, sharing experience, etc. Let everyone know what you want to do on the screen full of text\n* One sentence to clarify the central idea of ​​the problem, such as `Run the camera sample program, report an error reset fail, it may be a hardware problem`\n\nSo the title after synthesis can look like this:\n* `[MaixPy question] Run the camera sample program and report an error reset fail. Could it be a hardware problem?\n\nSuch a title must **not** appear:\n* `Ah ah ah ah why my board is not working again`\n* `Why my code can't run anymore`\n* `Why is my screen black?`\n* `[MaixPy question] I received the development board, the development board screen is red, a line of small characters, why? `\n* `I run the xxx program and something went wrong`\n\nYou can ask:\n* `[MaixPy question] My board cannot be started after I connected the power reversely. How can I tell where the board is burned? If so, how can I save it?`~\n* `[MaixPy BUG] pix_to_ai did not convert the last pixel`\n\n#### Content\n\nFirst of all, from the perspective of the answerer, if the question is asked:\n* First of all, we must know what the other party is going to do and what goals to achieve\n* In order to achieve this goal, where did he refer to the steps to do it\n* What specific steps were actually taken, and then there was a problem at that step, so I can follow his steps to try to reproduce the phenomenon. If this problem seems to be difficult to solve and there are no steps to reproduce, it may take a lot of time to reproduce. Let’s put it aside and solve other problems first.\n* What is the specific problem? If he only tells the problem, how do I know what is wrong with him, maybe it is unwell? So this is very important. He needs to explain the phenomenon when the problem occurred, and indicate what is different from the expectation. Otherwise, I have to guess what is the difference between the comparison and the expectation. The time to solve the problem has increased.\n* If something goes wrong, I may need his log file so that I can look at the source code based on the log for analysis, otherwise it may be difficult to solve the problem, then this problem can be seen later\n\nIn summary, you can ask questions like this:\n\n* Explain in detail your goals, what you want to do, and what the phenomenon should look like\n* Do I refer to any documents, codes or teaching?\n* How to reproduce the error: how to do it, write each step in detail until the problem occurs\n* Explain in detail the phenomenon when the error occurs, and how it is different from what was expected, it is necessary to prove that the problem does occur\n* Attached log files, screenshots, and even videos. The logs and screenshots must be complete. Don’t just take a small part. The answerer may find some problems you haven’t noticed from your complete logs and screenshots. This is very important !\n* In addition, pay attention to the format of the pasted code, don’t display it messy after pasting, and it won’t enter your eyes. Try to copy and run it\n* Finally, I would like to express my gratitude to the community friends who answered the question"}, "/soft/maixpy/en/dnn/index.html": {"title": "Deep learning and KPU basic knowledge", "content": "---\ntitle: Deep learning and KPU basic knowledge\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: deep learning and KPU basics\n---\n\n\n## What can I learn after reading this chapter?\n\n1. Understand some basic content of deep learning\n2. Understand the characteristics of KPU inside K210\n3. Understand the problems that may be encountered during the use of KPU and the solutions to the problems\n\n## Overview\n\nIn this chapter, we will introduce some basic knowledge of deep learning and K210 internal KPU, as well as the problems that you are likely to encounter in this part. Deep learning and the application examples it covers are a very large field, and no one can make it clear with a document. I hope that this document can give you a certain understanding of deep learning, and if there is a problem beyond the description of this document, you can solve the problem through search engine queries and other means.\n\n---\n\n## About Deep Learning\n\nBefore introducing deep learning, let's first introduce neural networks.\n\n​ What is a neural network? It is an algorithmic mathematical model that imitates the behavioral characteristics of animal neural networks and performs distributed parallel information processing.\n\nBelow, let us give a simple example to illustrate what it does.\n\nIn fact, to some extent, when we were in elementary school, we had already begun to use neural network-related ideas to solve practical problems. At this time, you may be full of question marks QAQ. Don't be afraid, let me come one by one. Now, suppose there is an equation `y = kx + b`. I believe you must have seen this equation countless times. In fact, we can regard this equation as the \"model\" of the neural network, the unknown \"k\" as the weight of the neural network, and \"b\" as the bias of the neural network. At this time we need to train this neural network model. In fact, the training process is the process of solving the global optimal weights and biases on the data set. At this time, suppose this equation satisfies \"x=1, y=2\", \"x=2, y=4\". This satisfying condition is the data set mentioned above. Through the training of this network in the human brain, we can know that the optimal weight of the entire network is 2, and the optimal bias is 0. At this point, the training of the neural network is completed.\n\nHowever, it is worth mentioning that the ultimate goal of training is always prediction. Throughout the ages, so many neural networks have consumed a lot of computing resources to find suitable weights and biases. All are to be able to find a correspondence between input data and output data. For an excellent neural network, its input data should be random and uncertain (not trained in the data set). The output data is accurate and reliable. Going back to the above, we trained the neural network \"y = 2x + 0\". At this time, the data x in the dataset is \"1\" and \"2\". At this time, in order to evaluate the performance of the model, we input the non-data set data \"3\". At this time, through the neural network forward propagation, the output value \"6\" is obtained. So far, the prediction of the neural network model is completed.\n\nI used a very simple demo to explain what the neural network is doing. Let's take a look at the real neural network model.\n\n![Fully connected neural network model](https://i.loli.net/2020/06/30/PVxMcSde8YJ4Q9b.jpg)\n\nThe above picture shows a more common fully connected neural network model (Fully connected neural network). Comparing this network structure with the previous \"y = 2x + 0\" network, we can find the following differences:\n\n1. The number of input data is uncertain (there can be n inputs)\n2. The number of output data is uncertain (there can be n outputs)\n3. The number of parameters is uncertain (there can be n fully connected layers in the figure, and each layer can contain n neurons, resulting in the number of parameters being n)\n\nThe model construction process can be regarded as the process of determining the number of parameters (when the network layer structure is determined, the number of parameters is also determined), and the model training process can be regarded as the process of determining the global optimal parameters on the data set. The prediction process of the model can be regarded as the process of input data * parameter = prediction result. (*Represents some kind of calculation)\n\nAfter having a certain understanding of neural networks, deep learning will be introduced next. You can think of deep learning as an improved neural network algorithm. The relationship between it and several other terms is: machine learning is a subset of artificial intelligence, and deep learning and neural networks are a subset of machine learning.\n\nThe difference between neural network and deep learning, as well as the advantages of deep learning, etc., due to limited space, can not be introduced here. If you are interested, you can query through search engines.\n\n## About KPU\n\nThe K210 SOC is equipped with a KPU (Neural Network Processor), which is a general neural network processor, which can realize convolutional neural network calculations with low power consumption, and always obtain the size, coordinates and type of the detected target. Detect and classify faces or objects.\n\nThe KPU on the K210 has the following features:\n\n1. Support fixed-point models trained by mainstream training frameworks according to specific restriction rules\n2. There is no direct limit to the number of network layers, and each layer of convolutional neural network parameters can be configured separately, including the number of input and output channels, input and output row width and column height\n3. Support two convolution kernels 1x1 and 3x3\n4. Support any form of activation function\n5. The maximum supported neural network parameter size is 5.5MiB to 5.9MiB when working in real time\n6. The maximum supported network parameter size during non-real-time work is (Flash capacity-software volume)\n\nThe internal structure of KPU is shown in the figure below.\n\n![K210 KPU structure](https://i.loli.net/2020/06/30/Q9tPOjyMWFiTwxA.png)\n\nYou can click [here](https://maixpy.sipeed.com/zh/libs/Maix/kpu.html?h=kpu) to view related APIs and Demos of KPU under Maixpy.\n\n## Common problems in the use of KPU\n\n### 1. What size model can KPU load?\n\nWhen k210 runs c code, it can load about 6MB model.\nWhen running maixpy ​​(mini), a model of about 3MB can be loaded.\nWhen running maixpy ​​(full version), a model of about 2MB can be loaded.\n\n### 2. What model can be loaded and run by KPU?\n\nThe kmodel converted by nncase can be loaded and run by kpu.\n\nClick [here](https://github.com/kendryte/nncase/blob/master/docs/USAGE_ZH.md) for nncase instructions\nnncase tflite ops support click [here](https://github.com/kendryte/nncase/blob/master/docs/tflite_ops.md)\nClick [here](https://github.com/kendryte/nncase/blob/master/docs/FAQ_ZH.md) for nncase frequently asked questions\n\n### 3. How can KPU load the model?\n\n1. Load the model in the TF card\n\n   ```python\n   kpu.load(\"/sd/test.kmodel\")\n   ```\n\n2. Load the model in Flash\n\n   ```python\n   kpu.load(offset)\n   ```\n\n   The offset here is the offset address of the model in the flash. The model can be burned into the internal flash of the k210 through k-flash\n\n### 4. What should I do if an error \"memory overflow\" is reported?\n\nThis problem is generally caused by the model being too large. You can try the following solutions in turn:\n\n1. Change the firmware of maixpy ​​mini version\n2. Perform model pruning optimization\n3. Abandon the development under maixpy ​​firmware, and use Kanzhi C SDK for development.\n\n### 5. What should I do if the error \"load error, only support kmodel v3/v4\" is reported?\n\nIf this problem occurs, you can try the following solutions:\n\n1. If loading the model in the flash, please make sure that the flash offset is filled in correctly and that there is no conflict with the maixpy ​​firmware.\n2. If it is kmodel V4 converted using nncase 0.2.0, please try to convert using nncase 0.1.0 to generate kmodel V3. (As of 2020/06/30, the loading bug of kmodel v4 by maixpy ​​has not been fixed yet)\n\n### 6. I want to select and load different models (for example, press the button to run the target classification, press the button again to run the target detection), how should I write the program?\n\nBecause of the limited flash, it is recommended to load all k210 models into the TF card. Because the internal RAM is limited, before switching between different models for `kpu.load(k210model)`, please execute `kpu.deinit(k210model)` to release the model in SRAM. Otherwise it will report an error \"memory overflow\"."}, "/soft/maixpy/en/dnn/ml_mnist.html": {"title": "mnist handwritten number recognition", "content": "---\ntitle: mnist handwritten number recognition\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: mnist handwritten digit recognition\n---\n\n\n```python\nimport sensor,lcd,image\nimport KPU as kpu\n\nlcd.init()\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.set_windowing((224, 224)) #set to 224x224 input\nsensor.set_hmirror(0) #flip camera\n\ntask = kpu.load(0x200000) #load model from flash address 0x200000\nsensor.run(1)\n\nimg_lcd=image.Image()\n\nwhile True:\n    img = sensor.snapshot()\n    #lcd.display(img,oft=(0,0)) #display large picture\n    img1=img.to_grayscale(1) #convert to gray\n    img2=img1.resize(28,28) #resize to mnist input 28x28\n    a=img2.invert() #invert picture as mnist need\n    a=img2.strech_char(1) #preprocessing pictures, eliminate dark corner\n    img2x2=img2.resize(28*2,28*2) #scale to display\n    a=img_lcd.draw_image(img2x2,0,0)#display small 28x28 picture\n    a=img2.pix_to_ai(); #generate data for ai\n    #watch conv0\n    a=kpu.set_layers(task, 1)\n    fmap=kpu.forward(task,img2) #run neural network model\n    for i in range(0,16):\n        tmp=kpu.fmap(fmap,i)\n        tmpx2=tmp.resize(14*2,14*2) #scale to display\n        a=img_lcd.draw_image(tmpx2,(i%8)*14*2,28*2+14*2*int(i/8))\n    #watch conv1\n    a=kpu.set_layers(task, 2)\n    fmap=kpu.forward(task,img2) #run neural network model\n    for i in range(0,32):\n        tmp=kpu.fmap(fmap,i)\n        tmpx2=tmp.resize(7*2,7*2) #scale to display\n        a=img_lcd.draw_image(tmpx2,(i%16)*7*2,28*2+14*2*2+7*2*int(i/16))\n    #watch conv2\n    a=kpu.set_layers(task, 8)\n    fmap=kpu.forward(task,img2) #run neural network model\n    for i in range(0,10):\n        tmp=kpu.fmap(fmap,i)\n        tmpx2=tmp.resize(4*2,4*2) #scale to display\n        a=img_lcd.draw_image(tmpx2,i*4*2,28*2+14*2*2+7*2*2)\n    #watch softmax\n    a=kpu.set_layers(task, 11)\n    fmap=kpu.forward(task,img2)\n    plist=fmap[:]\n    for i in range(0,10):\n        cc = int(plist[i]*256)\n        a=img_lcd.draw_rectangle(i*16, 28*2+14*2*2+7*2*2+4*2+10, 16, 16, color = (cc, cc, cc), thickness = 1, fill = True)\n        a=img_lcd.draw_string(i*16+5, 28*2+14*2*2+7*2*2+4*2+10+16, str(i), color = (255, 255, 255) , scale = 2, mono_space = False)\n    #show result\n    lcd.display(img_lcd,oft=(0,0))\n```"}, "/soft/maixpy/en/api_reference/Maix/freq.html": {"title": "Maix.freq", "content": "---\ntitle: Maix.freq\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix.freq\n---\n\n\nFrequency module, support program to modify cpu and kpu frequency\n\n## Method\n\n\n\n### freq.set(cpu, pll1, kpu_div)\n\nSet cpu or kpu frequency, after setting it will automatically restart to take effect\n\nPlease note that the performance of some peripherals may change after the frequency is set\n\n```python\nfrom Maix import freq\nfreq.set(cpu ​​= 400, kpu = 400)\n```\n\nThe configuration file will be saved in the file system `/flash/freq.conf`, please do not modify this file, if the file does not exist, it will be created automatically\n\n#### Parameters\n\nParameters that are not set will retain their previous values\n\n**Note**: If the `cpu` frequency setting is less than `60MHz`, the default `REPL` serial port baud rate will be set to `9600`\n\n* `cpu`: The cpu frequency you want to set, the range is [26,600] (the chip is up to `800` but has voltage requirements. The series supported by `MaixPy` does not support up to `800`, the default is `400`, different boards May behave differently, not too high for stability\n\n* `pll1`: The output frequency of `pll1`, the value range is [26,1200] (the chip is up to 1800, MaixPy is limited to 1200), the default is `400`\n\n* `kpu_div`: `kpu` clock frequency division, value range [1,16], default `1`. `kpu` frequency = `pll1`/`kpu_div`, for example, if you want to set the `kpu` frequency to `400`, you only need to set `pll1` to `400` and `kpu_div` to `1`. Note the `kpu` frequency range: [26,600]\n\n#### return value\n\nIf the frequency has not changed, it returns to null.\nIf the frequency changes, the machine will automatically restart. Before using this interface, please confirm whether the current situation can be restarted\n\n\n### freq.get()\n\nGet the currently set frequency parameter\n\n#### return value\n\n`cpu` frequency and `kpu` frequency, returned as a tuple, such as `(400,400)`\n\n### freq.get_cpu()\n\nGet the current frequency of `cpu`\n\n#### return value\n\n`cpu` frequency\n\n\n### freq.get_kpu()\n\nGet the currently set `kpu` frequency\n\n#### return value\n\nCurrent `kpu` frequency"}, "/soft/maixpy/en/api_reference/Maix/i2s.html": {"title": "I2S", "content": "---\ntitle: I2S\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: I2S\n---\n\nThe I2S module is mainly used to drive I2S devices. There are 3 I2S devices in k210, and each device has 4 channels. The pins need to be mapped and managed before use.\n\n## Module function\n\n### Constructor\n\nCreate a new I2S object\n\n```\nfrom Maix import I2S\ni2s_dev = I2S(device_num)\n```\n\n#### Parameters\n\n`device_num` I2S number, use the specified I2S, you can use `I2S.` to press the tab key to complete\n\n#### return value\n\nReturns an `I2S` object\n\n### Channel configuration function\n\nUsed to configure the I2S channel, the pins need to be mapped before\n\n```\ni2s_dev.channel_config(channel, mode, resolution, cycles, align_mode)\n```\n#### Parameters\n\n* `channel`: I2S channel number\n\n* `mode`: Channel transmission mode, there are a total of receiving and sending modes, recording is receiving, playing is sending\n\n* `resolution`: Channel resolution, that is, the number of received data bits\n\n* `cycles`: the number of single data clocks\n\n* `align_mode`: channel alignment mode\n\n#### return value\n\nno\n\n### Set the sampling rate\n\nUsed to configure I2S sampling rate\n\n```\ni2s_dev.set_sample_rate(sample_rate)\n```\n#### Parameters\n\n`sample_rate`: int type, sampling rate\n\n#### return value\n\nno\n\n### Receive audio\n\nUse I2S to receive audio data\n\n```\naudio = i2s_dev.record(points)\n```\n#### Parameters\n\n* `points`: The number of audio points collected at one time\n\n#### return value\n\n`audio`: an `audio` audio object\n\n### Send audio\n\nUse I2S to send audio data\n\n```\ni2s_dev.play(audio)\n```\n#### Parameters\n\n* `audio`: The audio object sent\n\n#### return value\nno\n\n## Routine\n\n### Routine 1\n\nCollect data and play it directly\n\n```python\nfrom Maix import I2S\nimport time\nfrom fpioa_manager import *\n\nfm.register(20,fm.fpioa.I2S0_IN_D0)#GO\nfm.register(19,fm.fpioa.I2S0_WS)\nfm.register(18,fm.fpioa.I2S0_SCLK)\nfm.register(34,fm.fpioa.I2S2_OUT_D1)\nfm.register(35,fm.fpioa.I2S2_SCLK)\nfm.register(33,fm.fpioa.I2S2_WS)\nsample_rate = 44*1000\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE)\nrx.set_sample_rate(sample_rate)\ntx = I2S(I2S.DEVICE_2)\ntx.channel_config(tx.CHANNEL_1, tx.TRANSMITTER, align_mode = I2S.RIGHT_JUSTIFYING_MODE)\ntx.set_sample_rate(sample_rate)\nwhile True:\n    audio = rx.record(256)#sampling points number must be smaller than 256\n    tx.play(audio)\n```\n\n### Routine 2\n\nThe collected data is converted into Audio and played\n\n```python\nfrom Maix import I2S\nfrom Maix import Audio\nfrom Maix import FFT\nimport time\nfrom fpioa_manager import *\n\nfm.register(20,fm.fpioa.I2S0_IN_D0)\nfm.register(19,fm.fpioa.I2S0_WS)\nfm.register(18,fm.fpioa.I2S0_SCLK)\nfm.register(34,fm.fpioa.I2S2_OUT_D1)\nfm.register(35,fm.fpioa.I2S2_SCLK)\nfm.register(33,fm.fpioa.I2S2_WS)\n\nrx = I2S(I2S.DEVICE_0)\nrx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE)\nrx.set_sample_rate(16000)\ntx = I2S(I2S.DEVICE_2)\ntx.channel_config(tx.CHANNEL_1, tx.TRANSMITTER, align_mode = I2S.RIGHT_JUSTIFYING_MODE)\ntx.set_sample_rate(16000)\n\nwhile True:\n    audio = rx.record(256)\n    audio_data = audio.to_bytes()\n    play_audio = Audio(audio_data)\n    tx.play(play_audio)\n```"}, "/soft/maixpy/en/api_reference/Maix/index.html": {"title": "Maix library", "content": "---\ntitle: Maix library\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maix library\n---\n\n\n\n* [FPIOA](fpioa.md)\n* [GPIO](gpio.md)\n* [KPU](kpu.md)\n* [FFT](fft.md)\n* [I2S](i2s.md)\n* [Audio](audio.md)\n* [freq](freq.md)\n* [utils](utils.md)"}, "/soft/maixpy/en/api_reference/Maix/gpio.html": {"title": "GPIO", "content": "---\ntitle: GPIO\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: GPIO\n---\n\n\nGeneral Purpose Input Output (General Purpose Input/Output) is abbreviated as GPIO, or bus extender.\n\nThere are high-speed GPIO (GPIOHS) and general-purpose GPIO on K210\nOn K210, GPIO has the following characteristics:\n* High-speed GPIO:\n\n  The high-speed GPIO is GPIOHS, 32 in total. It has the following characteristics:\n  * Configurable input and output signals\n  * Each IO has an independent interrupt source\n  * Interrupt supports edge trigger and level trigger\n  * Each IO can be assigned to one of the 48 pins on FPIOA\n  * Configurable up and down\n\n* General GPIO:\n\n    There are 8 general-purpose GPIOs with the following characteristics:\n    * 8 IOs use one interrupt source\n    * Configurable input and output signals\n    * Configurable trigger IO total interrupt, edge trigger and level trigger\n    * Each IO can be assigned to one of the 48 pins on FPIOA\n\n\n**note**:\n\nThe following GPIOHS has been used by default, try not to use it unless necessary in the program:\n\n| GPIOHS | Function |\n| --- | --- |\n| GPIOHS31 | LCD_DC |\n| GPIOHS30 | LCD_RST |\n| GPIOHS29 | SD_CS |\n| GPIOHS28 | MIC_LED_CLK |\n| GPIOHS27 | MIC_LED_DATA |\n\n\n\n## Constructor\n\n```python\nclass GPIO(ID, MODE, PULL, VALUE)\n```\n\nCreate a new SPI object with the specified parameters\n\n### Parameters\n\n* `ID`: the used GPIO pin (must use the constant in GPIO to specify)\n\n* `MODE`: GPIO mode\n\n  • GPIO.IN is the input mode\n\n  • GPIO.OUT is the output mode\n\n* `PULL`: GPIO pull-up mode\n\n  • GPIO.PULL_UP pull up\n\n  ​• GPIO.PULL_DOWN pull down\n\n  ​• GPIO.PULL_NONE neither pull up nor pull down\n\n\n## Method\n\n\n### value\n\nModify/read GPIO pin status\n\n```python\nGPIO.value([value])\n```\n\n#### Parameters\n\n* `[value]`: Optional parameter, if this parameter is not empty, it returns the current GPIO pin status\n\n\n#### return value\n\nIf the `[value]` parameter is not empty, return the current GPIO pin status\n\n\n### irq\n\nConfigure an interrupt handler to be called when the trigger source of `pin` is active. If the pin mode is pin.in, the trigger source is the external value on the pin.\n\n```python\nGPIO.irq(CALLBACK_FUNC,TRIGGER_CONDITION,GPIO.WAKEUP_NOT_SUPPORT,PRORITY)\n```\n\n#### Parameters\n\n\n* `CALLBACK_FUNC`: Interrupt callback function, which is called when the interrupt is triggered, an entry function `pin_num`\n\n  ​• PIN_NUM returns the GPIO pin number that triggered the interrupt (only GPIOHS supports interrupts, so the pin number here is also the pin number of GPIOHS)\n\n* `TRIGGER_CONDITION`: Interrupt trigger mode of GPIO pin\n\n  ​• GPIO.IRQ_RISING rising edge trigger\n\n  ​• GPIO.IRQ_FALLING falling edge trigger\n\n  ​• GPIO.IRQ_BOTH triggers on both rising and falling edges\n\n\n#### return value\n\nno\n\n### disirq\n\nClose interrupt\n\n```python\nGPIO.disirq()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### mode\n\nSet GPIO input and output mode\n\n```python\nGPIO.mode(MODE)\n```\n\n#### Parameters\n\n* MODE\n\n  • `GPIO.IN` input mode\n\n  • `GPIO.PULL_UP` pull-up input mode\n  \n  • `GPIO.PULL_DOWN` pull-down input mode\n\n  • `GPIO.OUT` output mode\n\n#### return value\n\nno\n\n## Constant\n\n* `GPIO0`: GPIO0\n* `GPIO1`: GPIO1\n* `GPIO2`: GPIO2\n* `GPIO3`: GPIO3\n* `GPIO4`: GPIO4\n* `GPIO5`: GPIO5\n* `GPIO6`: GPIO6\n* `GPIO7`: GPIO7\n* `GPIOHS0`: GPIOHS0\n* `GPIOHS1`: GPIOHS1\n* `GPIOHS2`: GPIOHS2\n* `GPIOHS3`: GPIOHS3\n* `GPIOHS4`: GPIOHS4\n* `GPIOHS5`: GPIOHS5\n* `GPIOHS6`: GPIOHS6\n* `GPIOHS7`: GPIOHS7\n* `GPIOHS8`: GPIOHS8\n* `GPIOHS9`: GPIOHS9\n* `GPIOHS10`: GPIOHS10\n* `GPIOHS11`: GPIOHS11\n* `GPIOHS12`: GPIOHS12\n* `GPIOHS13`: GPIOHS13\n* `GPIOHS14`: GPIOHS14\n* `GPIOHS15`: GPIOHS15\n* `GPIOHS16`: GPIOHS16\n* `GPIOHS17`: GPIOHS17\n* `GPIOHS18`: GPIOHS18\n* `GPIOHS19`: GPIOHS19\n* `GPIOHS20`: GPIOHS20\n* `GPIOHS21`: GPIOHS21\n* `GPIOHS22`: GPIOHS22\n* `GPIOHS23`: GPIOHS23\n* `GPIOHS24`: GPIOHS24\n* `GPIOHS25`: GPIOHS25\n* `GPIOHS26`: GPIOHS26\n* `GPIOHS27`: GPIOHS27\n* `GPIOHS28`: GPIOHS28\n* `GPIOHS29`: GPIOHS29\n* `GPIOHS30`: GPIOHS30\n* `GPIOHS31`: GPIOHS31\n* `GPIO.IN`: input mode\n* `GPIO.OUT`: output mode\n* `GPIO.PULL_UP`: pull up\n* `GPIO.PULL_DOWN`: pull down\n* `GPIO.PULL_NONE`: neither pull up nor pull down\n* `GPIO.IRQ_RISING`: rising edge trigger\n* `GPIO.IRQ_FALLING`: falling edge trigger\n* `GPIO.IRQ_BOTH`: trigger on both rising and falling edges\n\n\n### DEMO1: Turn on the LED\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nimport utime\nfrom Maix import GPIO\nfrom board import board_info\nfrom fpioa_manager import fm\n\nfm.register(board_info.LED_R,fm.fpioa.GPIO0)\nled_r=GPIO(GPIO.GPIO0,GPIO.OUT)\nutime.sleep_ms(500)\nled_r.value()\nfm.unregister(board_info.LED_R)\n```\n\n### DEMO2: Press the button to light up the LED\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nimport utime\nfrom Maix import GPIO\nfrom board import board_info\nfrom fpioa_manager import fm\n\nfm.register(board_info.LED_R,fm.fpioa.GPIO0)\nled_b = GPIO(GPIO.GPIO0,GPIO.OUT)\nled_b.value(1)\n\nfm.register(board_info.BOOT_KEY, fm.fpioa.GPIOHS1)\nkey = GPIO(GPIO.GPIOHS1, GPIO.IN)\n\nutime.sleep_ms(100)\nwhile True:\n    if key.value() == 0: # Wait for the button to be pressed\n        led_b.value(0)\n        utime.sleep_ms(1000)\n        break\n    utime.sleep_ms(10)\n\n\nled_b.value(1)\n\nfm.unregister(board_info.LED_R)\nfm.unregister(board_info.BOOT_KEY)\n```\n\n### DEMO3: Wait for the key to trigger an interrupt within 3 seconds\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nimport utime\nfrom Maix import GPIO\nfrom board import board_info\nfrom fpioa_manager import fm\n\ndef test_irq(pin_num):\n    print(\"key\", pin_num, \"\\n\")\n\nfm.register(board_info.BOOT_KEY, fm.fpioa.GPIOHS0)\nkey = GPIO(GPIO.GPIOHS0, GPIO.IN, GPIO.PULL_NONE)\n\nutime.sleep_ms(100)\nkey.irq(test_irq, GPIO.IRQ_BOTH, GPIO.WAKEUP_NOT_SUPPORT,7)\nutime.sleep_ms(3000) # Wait for the trigger within 3 seconds\n\nkey.disirq() # Disable interrupt\nfm.unregister(board_info.BOOT_KEY)\n```"}, "/soft/maixpy/en/api_reference/Maix/fft.html": {"title": "FFT operation", "content": "---\ntitle: FFT operation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: FFT operation\n---\n\nFFT fast Fourier transform module, which performs Fourier transform on input data and returns the corresponding frequency amplitude. FFT fast Fourier operation can convert time domain signal into frequency domain signal\n\n## Module function\n\n### Operation function\n\nInput time domain data and perform Fourier transform\n\n```\nimport FFT\nres = FFT.run(data, points, shift)\n```\n\n#### Parameters\n\n* `data`: input time domain data, `bytearray` type\n\n* `points`: FFT calculation points, only supports 64, 128, 256 and 512 points\n\n* `shift`: shift, default is 0\n\n####  return value\n\n`res`: Returns the calculated frequency domain data, presented as a `list` type. The list has `points` tuples, each tuple has 2 elements, the first element is the real part, and the second is Imaginary part\n\n### Frequency function\n\nFFT\n\n```\nres = FFT.freq(points, sample_rate)\n```\n\n#### Parameters\n\n* `points`: Calculate points\n\n* `sample_rate`: sample rate\n\n####  return value\n\n`res`: return a list, the list stores the frequency values ​​of all frequency points after the operation\n\n### Amplitude function\n\nUsed to calculate the amplitude of each frequency point after FFT operation. It is currently used as a test. Users can write their own amplitude processing functions in python\n\n```\namp = FFT.amplitude(FFT_res)\n```\n\n#### Parameters\n\n`FFT_res`: the result of function `run`\n\n\n#### return value\n\n`res`: Return a list that stores the amplitude of each frequency point\n\n### Routine\n\nCollect sound and perform FFT calculation, and display the calculated data as a histogram on the screen\n\nExample code: https://github.com/sipeed/MaixPy_scripts/blob/master/hardware/demo_fft_spectrum.py"}, "/soft/maixpy/en/api_reference/Maix/kpu.html": {"title": "KPU", "content": "---\ntitle: KPU\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: KPU\n---\n\n\nKPU is a general-purpose neural network processor, which can realize convolutional neural network calculations with low power consumption, obtain the size, coordinates, and types of detected objects from time to time, and detect and classify faces or objects.\n\n* KPU has the following characteristics:\n  * Support fixed-point models trained by mainstream training frameworks according to specific restriction rules\n  * There is no direct limit on the number of network layers, and each layer of convolutional neural network parameters can be configured separately, including the number of input and output channels, input and output row width and column height\n  * Support two convolution kernels 1x1 and 3x3\n  * Support any form of activation function\n  * When working in real time, the maximum supported neural network parameter size is 5.5MiB to 5.9MiB\n  * The maximum supported network parameter size during non-real-time work is (Flash capacity-software volume)\n\n\n\n\n## Routine\n\n### Run face detection\n\nModel download address: [http://dl.sipeed.com/MAIX/MaixPy/model](http://dl.sipeed.com/MAIX/MaixPy/model), download `face_model_at_0x300000.kfpkg`\n\nComplete example: [face_find](https://github.com/sipeed/MaixPy_scripts/tree/master/machine_vision/face_find)\n\n### Running feature map\n\nModel download address: [http://dl.sipeed.com/MAIX/MaixPy/model](http://dl.sipeed.com/MAIX/MaixPy/model), download `face_model_at_0x300000.kfpkg`\n\nThe model is an 8bit fixed-point model, about 380KB in size, the layer information is:\n```\n1 2 :160x120\n3 4 5 6 :80x60\n7 8 9 10: 40x30\n11~16 :20x15\n```\n\n```python\nimport sensor\nimport image\nimport lcd\nimport KPU as kpu\nindex=3\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\ntask=kpu.load(0x300000)\nimg=image.Image()\ninfo=kpu.netinfo(task)\nlayer=info[index]\nw=layer.wo()\nh=layer.ho()\nnum=int(320*240/w/h)\nlist=[None]*num\nx_step=int(320/w)\ny_step=int(240/h)\nimg_lcd=image.Image()\nwhile True:\n    img=sensor.snapshot()\n    fmap=kpu.forward(task,img,index)\n    for i in range(0,num):\n        list[i]=kpu.fmap(fmap,i)\n    for i in range(0,num):\n        list[i].stretch(64,255)\n    for i in range(0,num):\n        a=img_lcd.draw_image(list[i],((i%x_step)*w,(int(i/x_step))*h))\nlcd.display(img_lcd)\n   kpu.fmap_free(fmap)\n```\n\n-----------------------------\n\n\n## Module method\n\n### load\n\nLoad model from flash or file system\n\n```python\nKPU.load(offset, file_path)\n```\n\n#### Parameters\n\nThe `offset` and `file_path` parameters can only choose one of the two, no keywords are required, just pass the parameters directly\n\n* `offset`: the offset size of the model in the flash. For example, `0xd00000` means the model is burned at the beginning of 13M, and `0x300000` means at the place of `Flash` and `3M`\n* `file_path`: The model is the file name in the file system, such as `“/sd/xxx.kmodel”`\n\n##### Back\n\nIf it is loaded correctly, the return value will be returned, otherwise an error will be thrown. Please see the error message thrown. In addition, please refer to [here](https://github.com/sipeed/MaixPy/blob/fa3cf2c96353fa698e9386e42be8b3c9cf495114/components/kendryte_sdk/include/sipeed_kpu.h#L6-L23)\n\nIf the error code is found to be less than the value of `2000`, the firmware version is too low, and the firmware version needs to be updated\n\n* `kpu_net`: kpu network object\n\n### load_flash\n\nSame function as load method,\n\n```python\nkpu.load_flash(model_addr, is_dual_buf, batch_size, spi_speed)\n```\n\n#### Parameters\n\n* `model_addr`: Flash addr's preprocessed model burned to the offset address in flash. Note that the model file [description](https://github.com/sipeed/MaixPy_scripts/blob/master/machine_vision/load_big_model/README_ZH.md) needs to be preprocessed here.\n* `is_dual_buf`: `0`, single buffer loading, using less RAM and slower speed to dynamically load the model file; `1`, enabling double buffer loading, requires larger RAM, and running speed is relatively fast .\n* `batch_size`: When setting `is_dual_buf` to 1, load batch_size needs to be set. The recommended value is `0x4000~0x10000`, which can test the best value of the model. If `is_dual_buf` is 0 then set to 0\n* `spi_speed`: When using SPI flash to load the model file, we will temporarily set the flash to high-speed mode and set the required spi clock frequency. The value should be <= 80000000 (the actual frequency, the set value may not be equal to the actual frequency.)\n\n#### return value\n\n* `kpu_net`: kpu network object\n\n### init_yolo2\n\n\nPass in initialization parameters for the `yolo2` network model, only used when `yolo2` is used\n\n```python\nKPU.init_yolo2(kpu_net, threshold, nms_value, anchor_num, anchor)\n```\n\nsuch as:\n\n```python\nimport KPU as kpu\ntask = kpu.load(0x300000)\nanchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025)\nkpu.init_yolo2(task, 0.5, 0.3, 5, anchor)\n```\n\n#### Parameters\n\n* `kpu_net`: kpu network object, that is, the loaded model object, the return value of `KPU.load()`\n* `threshold`: Probability threshold, only if the probability of this object is greater than this value will the output result, value range: [0, 1]\n* `nms_value`: box_iou threshold, in order to prevent the same object from being framed in multiple boxes, when two boxes are framed on the same object, the intersection area of ​​the two boxes accounts for the proportion of the total occupied area of ​​the two boxes. When it is less than this value, take the box with the highest probability\n* `anchor_num`: the number of anchor points, fixed here as `len(anchors)//2`\n* `anchor`: The anchor point parameters are consistent with the model parameters. This parameter of the same model is fixed and bound to the model (it is determined when the model is trained) and cannot be changed to other values.\n\n#### return value\n\n* `success`: `bool` type, success\n\n\n### deinit\n\nRelease the memory occupied by the model and release it immediately, but the variables are still there, you can use the way of `del kpu_net_object` to delete,\nIn addition, you can also just use `del kpu_net_object` to mark that the object has been deleted. The next time `GC` performs memory collection or manually calls `gc.collect()`, the memory will be automatically released\n\n```python\nKPU.deinit(kpu_net)\n```\n\nsuch as:\n\n```python\nimport KPU as kpu\nimport gc\ntask = kpu.load(0x300000)\nkpu.deinit(task)\ndel task\ngc.collect()\n```\n\nor:\n\n```python\nimport KPU as kpu\nimport gc\ntask = kpu.load(0x300000)\ndel task\ngc.collect()\n```\n\n\n#### Parameters\n\n`kpu_net`: `kpu_net` object returned by `KPU.load()`\n\n#### return value\n\n* `success`: `bool` type, success\n\n\n### run_yolo2\n\n```python\nimport KPU as kpu\nimport image\ntask = kpu.load(offset or file_path)\nanchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025)\nkpu.init_yolo2(task, 0.5, 0.3, 5, anchor)\nimg = image.Image()\nkpu.run_yolo2(task, img) #This is wrong, please refer to the routine\n```\n\n#### Parameters\n\n* `kpu_net`: kpu_net object returned by kpu_load\n* `image_t`: the image collected from the sensor\n\n##### Back\n\n* `list`: list of kpu_yolo2_find\n\n### forward\n\nCalculate the loaded network model to the specified number of layers, and output the feature map of the target layer\n\n```python\nfmap=KPU.forward(kpu_net, img, end_layer)\n```\n\n```python\nimport KPU as kpu\ntask = kpu.load(offset or file_path)\n...\nfmap=kpu.forward(task,img, 3)\n```\n\n#### Parameters\n\n* `kpu_net`: kpu_net object\n* `img`: image `image.Image` object\n* `end_layer`: Specify which layer is calculated to the network, the value starts from `0`\n\n##### Back\n\n* `fmap`: Feature map object, containing feature maps of all channels in the current layer\n\n\n### fmap\n\nTake the specified channel data of the feature map to the `image.Image` object\n\n```python\nimg=KPU.fmap(fmap, channel)\n```\n\n#### Parameters\n\n* `fmap`: Feature map object\n* `channel`: Specify the channel number of the feature map, starting from `0`\n\n##### Back\n\n* `img`: The grayscale image generated by the feature image corresponding to the channel, type `image.Image`\n\n\n### fmap_free\n\nRelease feature map object\n```python\nKPU.fmap_free(fmap)\n```\n\n#### Parameters\n\n* `fmap`: Feature map object\n\n##### Back\n\n* None\n\n### netinfo\n\nGet the network structure information of the model\n\n```python\ninfo_list = kpu.netinfo(task)\n```\n\n#### Parameters\n\n* `kpu_net`: kpu_net object, `KPU.load()` return value\n\n##### Back\n\n* `info_list`: information list of all layers, including information:\n  * `index`: the number of the current layer in the network\n  * `wi`: input width\n  * `hi`: input height\n  * `wo`: output width\n  * `ho`: output height\n  * `chi`: Number of input channels\n  * `cho`: Number of output channels\n  * `dw`: Whether it is a depth wise layer\n  * `kernel_type`: Convolution kernel type, 0 is 1x1, 1 is 3x3\n  * `pool_type`: Pooling type, 0 no pooling; 1: 2x2 max pooling; 2:...\n  * `para_size`: the number of bytes of the convolution parameter of the current layer\n\n\n### set_outputs\n\n```python\nsuccess = set_outputs(kput_net, out_idx, width, height, channel)\n```\n\nManually set the shape of the output layer. For the V4 kmodel model converted from nncase v0.2.0,\nAfter `load`, you need to call this function to manually set the output layer shape, V3 model does not need\n\n\n#### Parameters\n\n* `kpu_net`: kpu_net object\n* `out_idx`: The following table of the output layer, starting from `0`, for example, the first output layer is `0`\n* `width`: layer width, if it is a one-dimensional output, it is `1`\n* `height`: layer height, if it is a one-dimensional output, it is `1`\n* `channnel`: The number of layer channels, if it is a one-dimensional output, then here is the length of the one-dimensional output\n\n##### Back\n\n* `success`: Whether the setting is successful, if not, please pay attention to the output prompt information, refer to [error code](https://github.com/sipeed/MaixPy/blob/fa3cf2c96353fa698e9386e42be8b3c9cf495114/components/kendryte_sdk/include/sipeed_kpu. h#L6-L23)\n\n\n### memtest\n\nPrint memory usage, including `GC` memory and system heap memory\n\n* Note that executing this function will automatically execute `gc.collect()` to collect memory once, and then print the remaining memory of `GC`\n* The system heap memory is for reference only and may not be accurate. Sometimes it may appear that the memory has been released, but the display is still not released. The actual memory can be allocated to prevail.\n\n```python\nKPU.memtest()\n```\n### face_encode\n\nQuantify the feature map returned by `forward`. For more details, please see: [kpu issue](https://github.com/sipeed/MaixPy/issues/342)\n\n```python\nfeature = kpu.face_encode(fmap[:])\n```\n\n#### Parameters\n\n`fmap[:]`: `list` type, convert the return value of the `forward` function into a list\n\n#### return value\n\n`feature`: `list` type, quantified list\n\n### face_compare\n\nCompare the quantized value returned by face_encode with the entered face\n\n```python\nscore = kpu.face_compare(record_ftrs[j], feature)\n```\n\n#### Parameters\n\n`record_ftrs[j] `: `list` type, with recorded face data\n`feature`: `list` type, face data to be compared, return value of `face_encode`\n\n#### return value\n\n`score`: `int` type, compare score (0~100), the higher the score, the greater the similarity"}, "/soft/maixpy/en/api_reference/Maix/fpioa.html": {"title": "FPIOA (Field Programmable Input and Output Array)", "content": "---\ntitle: FPIOA (Field Programmable Input and Output Array)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: FPIOA (Field Programmable Input and Output Array)\n---\n\n\nK210 supports each peripheral to be mapped to any pin at will, using FPIOA function to achieve.\n\n**note**:\n\nThe following GPIOHS have been used by default, try not to use them unless necessary in the program:\n\n| GPIOHS | Function | Description |\n| --- | --- | --- |\n| GPIOHS5 | LCD_DC | LCD read and write signal pin |\n| GPIOHS4 | LCD_RST | LCD reset chip pin |\n| GPIOHS29 | SD_CS | SD card SPI chip select |\n| GPIOHS28 | MIC_LED_CLK | SK9822_DAT |\n| GPIOHS27 | MIC_LED_DATA | SK9822_CLK |\n\n\n\n## Class `FPIOA`\n\n### Method\n\n#### help(func)\n\nDisplay peripherals and their brief descriptions\n\n##### Parameters\n\n* `func`: Peripheral name (function/number), no parameters can be passed, then all peripheral names will be displayed in the form of a table that is a brief description, this table can also be found at the end of this page ([Appendix: Peripheral ](#Appendix:-peripheral table));</br>\n   If you pass a parameter, pass an integer value, and print the name and description of the peripheral after finding the peripheral corresponding to the number,</br>\n   For example, `FPIOA.JTAG_TCLK` or `fm.fpioa.JTAG_TCLK` (`fm` is introduced later on this page) or `0`\n\nsuch as:\n\n```python\nfrom Maix import FPIOA\n\nfpioa = FPIOA()\nfpioa.help()\nfpioa.help(0)\nfpioa.help(fpioa.JTAG_TCLK)\nfm.fpioa.help()\nfm.fpioa.help(fm.fpioa.JTAG_TCLK)\n\n```\n\n##### Back\n\nPeripheral name and its brief description\n\n#### set_function(pin, func)\n\nSet the peripheral function corresponding to the pin, that is, pin mapping\n\n##### Parameters\n\n* `pin`: pin number, value [0, 47], please see the circuit diagram for specific pin connections, you can also use `board_info.` and then press the `TAB` button to complete to get the common pins of the board, such as `board_info.LED_G`\n* `func`: Peripheral function, pass an integer value, you can get it through `fm.fpioa.help()` or check the [Appendix: Peripheral Table](#Appendix:-Peripheral Table) table at the end of this page\n\nFor example, you need to map the pin connected to the `green LED` to the `high-speed GPIO0`:\n\n```python\nfpioa = FPIOA()\nfpioa.set_function(board_info.LED_G, fm.fpioa.GPIOHS0)\n```\n\n#### get_Pin_num(func)\n\nGet which pin the peripheral is mapped to\n\n##### Parameters\n\n* `func`: Peripheral function, pass an integer value, you can get it through `fm.fpioa.help()` or check the [Appendix: Peripheral Table](#Appendix:-Peripheral Table) table at the end of this page\n\nsuch as:\n\n```python\nfpioa = FPIOA()\nfpioa.set_function(board_info.LED_G, fm.fpioa.GPIOHS0)\npin = fpioa.get_Pin_num(fm.fpioa.GPIOHS0)\nif pin == board_info.LED_G:\n    print(\"set function ok\")\n```\n## Appendix: Peripheral Table\n\n| Peripheral Function (func) | Brief Description |\n| --- | --- |\n| JTAG_TCLK | JTAG Test Clock |\n| JTAG_TDI | JTAG Test Data In |\n| JTAG_TMS | JTAG Test Mode Select |\n| JTAG_TDO | JTAG Test Data Out |\n| SPI0_D0 | SPI0 Data 0 |\n| SPI0_D1 | SPI0 Data 1 |\n| SPI0_D2 | SPI0 Data 2 |\n| SPI0_D3 | SPI0 Data 3 |\n| SPI0_D4 | SPI0 Data 4 |\n| SPI0_D5 | SPI0 Data 5 |\n| SPI0_D6 | SPI0 Data 6 |\n| SPI0_D7 | SPI0 Data 7 |\n| SPI0_SS0 | SPI0 Chip Select 0 |\n| SPI0_SS1 | SPI0 Chip Select 1 |\n| SPI0_SS2 | SPI0 Chip Select 2 |\n| SPI0_SS3 | SPI0 Chip Select 3 |\n| SPI0_ARB | SPI0 Arbitration |\n| SPI0_SCLK | SPI0 Serial Clock |\n| UARTHS_RX | UART High speed Receiver |\n| UARTHS_TX | UART High speed Transmitter |\n| RESV6 | Reserved function |\n| RESV7 | Reserved function |\n| CLK_SPI1 | Clock SPI1 |\n| CLK_I2C1 | Clock I2C1 |\n| GPIOHS0 | GPIO High speed 0 |\n| GPIOHS1 | GPIO High speed 1 |\n| GPIOHS2 | GPIO High speed 2 |\n| GPIOHS3 | GPIO High speed 3 |\n| GPIOHS4 | GPIO High speed 4 |\n| GPIOHS5 | GPIO High speed 5 |\n| GPIOHS6 | GPIO High speed 6 |\n| GPIOHS7 | GPIO High speed 7 |\n| GPIOHS8 | GPIO High speed 8 |\n| GPIOHS9 | GPIO High speed 9 |\n| GPIOHS10 | GPIO High speed 10 |\n| GPIOHS11 | GPIO High speed 11 |\n| GPIOHS12 | GPIO High speed 12 |\n| GPIOHS13 | GPIO High speed 13 |\n| GPIOHS14 | GPIO High speed 14 |\n| GPIOHS15 | GPIO High speed 15 |\n| GPIOHS16 | GPIO High speed 16 |\n| GPIOHS17 | GPIO High speed 17 |\n| GPIOHS18 | GPIO High speed 18 |\n| GPIOHS19 | GPIO High speed 19 |\n| GPIOHS20 | GPIO High speed 20 |\n| GPIOHS21 | GPIO High speed 21 |\n| GPIOHS22 | GPIO High speed 22 |\n| GPIOHS23 | GPIO High speed 23 |\n| GPIOHS24 | GPIO High speed 24 |\n| GPIOHS25 | GPIO High speed 25 |\n| GPIOHS26 | GPIO High speed 26 |\n| GPIOHS27 | GPIO High speed 27 |\n| GPIOHS28 | GPIO High speed 28 |\n| GPIOHS29 | GPIO High speed 29 |\n| GPIOHS30 | GPIO High speed 30 |\n| GPIOHS31 | GPIO High speed 31 |\n| GPIO0 | GPIO pin 0 |\n| GPIO1 | GPIO pin 1 |\n| GPIO2 | GPIO pin 2 |\n| GPIO3 | GPIO pin 3 |\n| GPIO4 | GPIO pin 4 |\n| GPIO5 | GPIO pin 5 |\n| GPIO6 | GPIO pin 6 |\n| GPIO7 | GPIO pin 7 |\n| UART1_RX | UART1 Receiver |\n| UART1_TX | UART1 Transmitter |\n| UART2_RX | UART2 Receiver |\n| UART2_TX | UART2 Transmitter |\n| UART3_RX | UART3 Receiver |\n| UART3_TX | UART3 Transmitter |\n| SPI1_D0 | SPI1 Data 0 |\n| SPI1_D1 | SPI1 Data 1 |\n| SPI1_D2 | SPI1 Data 2 |\n| SPI1_D3 | SPI1 Data 3 |\n| SPI1_D4 | SPI1 Data 4 |\n| SPI1_D5 | SPI1 Data 5 |\n| SPI1_D6 | SPI1 Data 6 |\n| SPI1_D7 | SPI1 Data 7 |\n| SPI1_SS0 | SPI1 Chip Select 0 |\n| SPI1_SS1 | SPI1 Chip Select 1 |\n| SPI1_SS2 | SPI1 Chip Select 2 |\n| SPI1_SS3 | SPI1 Chip Select 3 |\n| SPI1_ARB | SPI1 Arbitration |\n| SPI1_SCLK | SPI1 Serial Clock |\n| SPI_SLAVE_D0 | SPI Slave Data 0 |\n| SPI_SLAVE_SS | SPI Slave Select |\n| SPI_SLAVE_SCLK | SPI Slave Serial Clock |\n| I2S0_MCLK | I2S0 Master Clock |\n| I2S0_SCLK | I2S0 Serial Clock(BCLK) |\n| I2S0_WS | I2S0 Word Select(LRCLK) |\n| I2S0_IN_D0 | I2S0 Serial Data Input 0 |\n| I2S0_IN_D1 | I2S0 Serial Data Input 1 |\n| I2S0_IN_D2 | I2S0 Serial Data Input 2 |\n| I2S0_IN_D3 | I2S0 Serial Data Input 3 |\n| I2S0_OUT_D0 | I2S0 Serial Data Output 0 |\n| I2S0_OUT_D1 | I2S0 Serial Data Output 1 |\n| I2S0_OUT_D2 | I2S0 Serial Data Output 2 |\n| I2S0_OUT_D3 | I2S0 Serial Data Output 3 |\n| I2S1_MCLK | I2S1 Master Clock |\n| I2S1_SCLK | I2S1 Serial Clock(BCLK) |\n| I2S1_WS | I2S1 Word Select(LRCLK) |\n| I2S1_IN_D0 | I2S1 Serial Data Input 0 |\n| I2S1_IN_D1 | I2S1 Serial Data Input 1 |\n| I2S1_IN_D2 | I2S1 Serial Data Input 2 |\n| I2S1_IN_D3 | I2S1 Serial Data Input 3 |\n| I2S1_OUT_D0 | I2S1 Serial Data Output 0 |\n| I2S1_OUT_D1 | I2S1 Serial Data Output 1 |\n| I2S1_OUT_D2 | I2S1 Serial Data Output 2 |\n| I2S1_OUT_D3 | I2S1 Serial Data Output 3 |\n| I2S2_MCLK | I2S2 Master Clock |\n| I2S2_SCLK | I2S2 Serial Clock(BCLK) |\n| I2S2_WS | I2S2 Word Select(LRCLK) |\n| I2S2_IN_D0 | I2S2 Serial Data Input 0 |\n| I2S2_IN_D1 | I2S2 Serial Data Input 1 |\n| I2S2_IN_D2 | I2S2 Serial Data Input 2 |\n| I2S2_IN_D3 | I2S2 Serial Data Input 3 |\n| I2S2_OUT_D0 | I2S2 Serial Data Output 0 |\n| I2S2_OUT_D1 | I2S2 Serial Data Output 1 |\n| I2S2_OUT_D2 | I2S2 Serial Data Output 2 |\n| I2S2_OUT_D3 | I2S2 Serial Data Output 3 |\n| RESV0 | Reserved function |\n| RESV1 | Reserved function |\n| RESV2 | Reserved function |\n| RESV3 | Reserved function |\n| RESV4 | Reserved function |\n| RESV5 | Reserved function |\n| I2C0_SCLK | I2C0 Serial Clock |\n| I2C0_SDA | I2C0 Serial Data |\n| I2C1_SCLK | I2C1 Serial Clock |\n| I2C1_SDA | I2C1 Serial Data |\n| I2C2_SCLK | I2C2 Serial Clock |\n| I2C2_SDA | I2C2 Serial Data |\n| CMOS_XCLK | DVP System Clock |\n| CMOS_RST | DVP System Reset |\n| CMOS_PWDN | DVP Power Down Mode |\n| CMOS_VSYNC | DVP Vertical Sync |\n| CMOS_HREF | DVP Horizontal Reference output |\n| CMOS_PCLK | Pixel Clock |\n| CMOS_D0 | Data Bit 0 |\n| CMOS_D1 | Data Bit 1 |\n| CMOS_D2 | Data Bit 2 |\n| CMOS_D3 | Data Bit 3 |\n| CMOS_D4 | Data Bit 4 |\n| CMOS_D5 | Data Bit 5 |\n| CMOS_D6 | Data Bit 6 |\n| CMOS_D7 | Data Bit 7 |\n| SCCB_SCLK | SCCB Serial Clock |\n| SCCB_SDA | SCCB Serial Data |\n| UART1_CTS | UART1 Clear To Send |\n| UART1_DSR | UART1 Data Set Ready |\n| UART1_DCD | UART1 Data Carrier Detect |\n| UART1_RI | UART1 Ring Indicator |\n| UART1_SIR_IN | UART1 Serial Infrared Input |\n| UART1_DTR | UART1 Data Terminal Ready |\n| UART1_RTS | UART1 Request To Send |\n| UART1_OUT2 | UART1 User-designated Output 2 |\n| UART1_OUT1 | UART1 User-designated Output 1 |\n| UART1_SIR_OUT | UART1 Serial Infrared Output |\n| UART1_BAUD | UART1 Transmit Clock Output |\n| UART1_RE | UART1 Receiver Output Enable |\n| UART1_DE | UART1 Driver Output Enable |\n| UART1_RS485_EN | UART1 RS485 Enable |\n| UART2_CTS | UART2 Clear To Send |\n| UART2_DSR | UART2 Data Set Ready |\n| UART2_DCD | UART2 Data Carrier Detect |\n| UART2_RI | UART2 Ring Indicator |\n| UART2_SIR_IN | UART2 Serial Infrared Input |\n| UART2_DTR | UART2 Data Terminal Ready |\n| UART2_RTS | UART2 Request To Send |\n| UART2_OUT2 | UART2 User-designated Output 2 |\n| UART2_OUT1 | UART2 User-designated Output 1 |\n| UART2_SIR_OUT | UART2 Serial Infrared Output |\n| UART2_BAUD | UART2 Transmit Clock Output |\n| UART2_RE| UART2 Receiver Output Enable |\n| UART2_DE | UART2 Driver Output Enable |\n| UART2_RS485_EN | UART2 RS485 Enable |\n| UART3_CTS | UART3 Clear To Send |\n| UART3_DSR | UART3 Data Set Ready |\n| UART3_DCD | UART3 Data Carrier Detect |\n| UART3_RI | UART3 Ring Indicator |\n| UART3_SIR_IN | UART3 Serial Infrared Input |\n| UART3_DTR | UART3 Data Terminal Ready |\n| UART3_RTS | UART3 Request To Send |\n| UART3_OUT2 | UART3 User-designated Output 2 |\n| UART3_OUT1 | UART3 User-designated Output 1 |\n| UART3_SIR_OUT | UART3 Serial Infrared Output |\n| UART3_BAUD | UART3 Transmit Clock Output |\n| UART3_RE | UART3 Receiver Output Enable |\n| UART3_DE | UART3 Driver Output Enable |\n| UART3_RS485_EN | UART3 RS485 Enable |\n| TIMER0_TOGGLE1 | TIMER0 Toggle Output 1 |\n| TIMER0_TOGGLE2 | TIMER0 Toggle Output 2 |\n| TIMER0_TOGGLE3 | TIMER0 Toggle Output 3 |\n| TIMER0_TOGGLE4 | TIMER0 Toggle Output 4 |\n| TIMER1_TOGGLE1 | TIMER1 Toggle Output 1 |\n| TIMER1_TOGGLE2 | TIMER1 Toggle Output 2 |\n| TIMER1_TOGGLE3 | TIMER1 Toggle Output 3 |\n| TIMER1_TOGGLE4 | TIMER1 Toggle Output 4 |\n| TIMER2_TOGGLE1 | TIMER2 Toggle Output 1 |\n| TIMER2_TOGGLE2 | TIMER2 Toggle Output 2 |\n| TIMER2_TOGGLE3 | TIMER2 Toggle Output 3 |\n| TIMER2_TOGGLE4 | TIMER2 Toggle Output 4 |\n| CLK_SPI2 | Clock SPI2 |\n| CLK_I2C2 | Clock I2C2 |"}, "/soft/maixpy/en/api_reference/Maix/utils.html": {"title": "Maix.utils", "content": "---\ntitle: Maix.utils\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maix.utils\n---\n\n\n## gc_heap_size([size])\n\nGet or set the GC heap size, if the memory is not enough, you can consider setting it larger\n\n### Parameters\n\nNone or pass in the new GC heap size.\n* If there is no parameter, just get the heap size;\n* If there are parameters, set the heap size, and then automatically restart\n\n### return value\n\nGC heap size\n\n-Use case\n\n```python\nimport Maix\n# Maix.utils.gc_heap_size(0x80000) # The firmware default configuration is 500KB\nMaix.utils.gc_heap_size(0x96000) # 600KB\n```\n\n## flash_read(flash_offset, size)\n\nRead data of size specified size (number of bytes) from internal flash\n\n### Parameters\n\nflash_offset: flash address offset\n\nflash_offset: flash address offset\n\n## heap_free()\n\n```shell\n>>> Maix.utils.gc_heap_size()\n524288\n>>> Maix.utils.heap_free()\n4374528\n```\n\n\n-----\n\nThe script test conditions in the article are:\n\n-MaixDock\n-MaixPy v0.5.0_246 (standard firmware)"}, "/soft/maixpy/en/api_reference/machine_vision/image/image.html": {"title": "image (machine vision)", "content": "---\ntitle: image (machine vision)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: image (machine vision)\n---\n\n\nPorted to `openmv`, same function as `openmv`\n\n## Routine\n\n### Routine 1: Find green\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\ngreen_threshold = (0, 80, -70, -10, -0, 30)\nwhile True:\nimg=sensor.snapshot()\nblobs = img.find_blobs([green_threshold])\nif blobs:\nfor b in blobs:\ntmp=img.draw_rectangle(b[0:4])\ntmp=img.draw_cross(b[5], b[6])\nc=img.get_pixel(b[5], b[6])\nlcd.display(img)\n```\n\n### Example 2: Display fps\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\n\nclock = time.clock()\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\nsensor.skip_frames(30)\nwhile True:\n    clock.tick()\n    img = sensor.snapshot()\n    fps =clock.fps()\n    img.draw_string(2,2, (\"%2.1ffps\" %(fps)), color=(0,128,0), scale=2)\n    lcd.display(img)\n```\n\n\n### Example 3: Scan the QR code\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\n\nclock = time.clock()\nlcd.init()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.set_vflip(1)\nsensor.run(1)\nsensor.skip_frames(30)\nwhile True:\n    clock.tick()\n    img = sensor.snapshot()\n    res = img.find_qrcodes()\n    fps =clock.fps()\n    if len(res)> 0:\n        img.draw_string(2,2, res[0].payload(), color=(0,128,0), scale=2)\n        print(res[0].payload())\n    lcd.display(img)\n\n```\n\n> If a lens is used, the picture will be distorted and the picture needs to be corrected\n> Use the `lens_corr` function to correct, such as `2.8`mm, `img.lens_corr(1.8)`\n\n\n\n\n## Function\n\nFunction can also press `Ctrl+F` on this page and use the browser's search function to search `image.` to mark the function\n\n### image.rgb_to_lab(rgb_tuple)\n\nReturn the tuple of RGB888 format rgb_tuple (r, g, b) corresponding to the tuple (l, a, b) of LAB format.\n\n> RGB888 means 8 bits each for red, green and blue (0-255). In LAB, the range of L is 0-100, and the range of a/b is -128 to 127.\n\n### image.lab_to_rgb(lab_tuple)\n\nReturn the tuple in LAB format lab_tuple (l, a, b) and the corresponding tuple (r, g, b) in RGB888 format.\n\n> RGB888 means 8 bits each for red, green and blue (0-255). In LAB, the range of L is 0-100, and the range of a/b is -128 to 127.\n\n### image.rgb_to_grayscale(rgb_tuple)\n\nReturns the gray value corresponding to the tuple rgb_tuple (r, g, b) in RGB888 format.\n\n> RGB888 means 8 bits each for red, green and blue (0-255). The gray value ranges from 0-255.\n\n### image.grayscale_to_rgb(g_value)\n\nReturns the tuple (r, g, b) in RGB888 format corresponding to the gray value g_value.\n\n> RGB888 means 8 bits each for red, green and blue (0-255). The gray value ranges from 0-255.\n\n### image.load_decriptor(path)\n\nLoad a descriptor object from the disk.\n\npath is the path where the descriptor file is saved.\n\n### image.save_descriptor(path, descriptor)\n\nSave the descriptor object descriptor to disk.\n\npath is the path where the descriptor file is saved.\n\n### image.match_descriptor(descritor0, descriptor1[, threshold=70[, filter_outliers=False]])\n\nFor LBP descriptors, this function returns an integer that reflects the difference between the two descriptors. This distance measurement is particularly necessary. This distance is a measure of similarity. The closer this measure is to 0, the better the matching of LBPF feature points.\n\nFor ORB descriptors, this function returns a kptmatch object. See above.\n\nthreshold is used to filter ambiguous matching services for ORB keys.\nA lower threshold value will be closely tied to the key point matching algorithm. The threshold value is between 0-100 (int). The default value is 70.\n\nfilter_outliers is used to filter outliers for ORB key points. Feature points allow users to increase the threshold value. The default setting is False.\n\n## HaarCascade class-feature descriptor\n\nHaar Cascade feature descriptors are used in the `image.find_features()` method. It has no methods for users to call.\n\n### Constructor\n\nclass image.HaarCascade(path[, stages=Auto])\n\nLoad a Haar Cascade from a Haar Cascade binary file (format suitable for OpenMV Cam). If you pass the \"frontalface\" string instead of a path, this constructor will load a built-in frontalface Haar Cascade into memory. In addition, you can also load Haar Cascade into memory through \"eye\". Finally, this method returns the loaded Haar Cascade object, which is used to use image.find_features().\n\nThe default value of stages is the number of stages in Haar Cascade. However, you can specify a lower value to speed up the running of the feature detector, which of course will bring a higher false alarm rate.\n\n> You can make your own Haar Cascades to work with your OpenMV Cam. First, use Google to search for \"<thing> Haar Cascade\" to check if someone has made an OpenCV Haar Cascade for the object you want to detect. If not, then you need to do it yourself (huge workload). For how to make your own Haar Cascade, see here For how to convert OpenCV Haar Cascades into a mode that your OpenMV Cam can read, see this script\n\nQ: What is Haar Cascade?\n\nAnswer: Haar Cascade is a series of comparative checks to determine whether an object is present in the image. This series of comparative inspections is divided into multiple stages, and the operation of the latter stage is based on the completion of the previous stage. Contrast checking is not complicated, but a process like checking whether the center of the image is slightly more vertical than the edges. Large-scale inspections are carried out first in the early stage, and more and smaller areas are inspected in the later stage.\n\nQ: How are Haar Cascades made?\n\nAnswer: Haar Cascades trains the generator algorithm through positive and negative images. For example, use hundreds of pictures containing cats (which have been marked as containing cats) and hundreds of pictures that do not contain cats (which have been marked differently) to train this generation algorithm. This generation algorithm will finally generate a Haar Cascades for detecting cats.\n\n## Similarity Class-Similarity Object\n\nThe similarity object is returned by `image.get_similarity`.\n\n### Constructor\n\nclass image.similarity\n\nPlease call the image.get_similarity() function to create this object.\n\n#### Method\n\n##### similarity.mean()\nReturns the mean value of the similarity difference of 8x8 pixel block structure. The range is [-1/+1], where -1 is completely different and +1 is completely the same.\n\nYou can also get this value by index [0].\n\n##### similarity.stdev()\nReturns the standard deviation of the similarity difference of the 8x8 pixel block structure.\n\nYou can also get this value via index [1].\n\n##### similarity.min()\nReturns the minimum value of the similarity difference of the 8x8 pixel block structure. Where -1 is completely different and +1 is completely the same.\n\nYou can also get this value via index [2].\n\n> By looking at this value, you can quickly determine whether any 8x8 pixel blocks between the two images are very different, that is, far below +1.\n\n##### similarity.max()\n\nReturns the minimum value of the similarity difference of the 8x8 pixel block structure. Where -1 is completely different and +1 is completely the same.\n\nYou can also get this value through index [3].\n\n> By looking at this value, you can quickly determine whether any 8x8 pixel blocks between the two images are the same. That is much larger than -1.\n\n## Histogram class-histogram object\n\nThe histogram object is returned by `image.get_histogram`. The grayscale histogram has a channel that contains multiple bins. All binaries are normalized so that their sum is 1. RGB565 has three channels containing multiple binary. All binaries are normalized so that their sum is 1.\n\n### Constructor\n\nclass image.histogram\n\nPlease call the `image.get_histogram()` function to create this object.\n\n### Method\n\n#### histogram.bins()\n\nReturns a list of floating point numbers in the gray histogram. You can also get this value by index [0].\n\n#### histogram.l_bins()\n\nReturns the list of floating point numbers of the L channel of the RGB565 histogram LAB. You can also get this value by index [0].\n\n#### histogram.a_bins()\n\nReturns the list of floating point numbers of the A channel of the RGB565 histogram LAB. You can also get this value via index [1].\n\n#### histogram.b_bins()\n\nReturns the list of floating point numbers of channel B of RGB565 histogram LAB. You can also get this value via index [2].\n#### histogram.get_percentile(percentile)\n\nCalculate the CDF of the histogram channel and return a value of the histogram passed in percentile (0.0-1.0) (floating point number).\n\nTherefore, if you pass in 0.1, the method will tell you which binary will make the accumulator cross 0.1 when it is added to the accumulator.\n\nThis is very effective for determining the minimum value (0.1) and max (0.9) of the color distribution when there is no anomalous utility to spoil your adaptive color tracking results.\n\n#### histogram.get_threhsold()\n\nUse Otsu’s method to calculate the optimal threshold, dividing each channel of the histogram into two halves. This method returns an image.threshold object. This method is particularly useful for determining the optimal image.binary() threshold.\n\n#### histogram.get_statistics()\n\nCalculate the average, median, mode, standard deviation, minimum, maximum, lower quartile, and upper quartile of each color channel in the histogram, and return a statistics object. You can also use histogram.statistics() and histogram.get_stats() as aliases for this method.\n\n\n\n\n\n## Percentile class-percentage value object\n\nThe percentage value object is returned by `histogram.get_percentile`. The gray percentage value has one channel. Do not use l_*, a_* or b_* methods. The RGB565 percentage value has three channels. Use the l_*, a_* and b_* methods.\n\n### Constructor\n\nclass image.percentile\n\nPlease call the histogram.get_percentile() function to create this object.\n\n### Method\n\n#### percentile.value()\n\nReturns the gray percentage value (the value range is 0-255).\n\nYou can also get this value by index [0].\n\n#### percentile.l_value()\n\nReturns the percentage value of the L channel of RGB565 LAB (value range is 0-100).\n\nYou can also get this value by index [0].\n\n#### percentile.a_value()\n\nReturns the percentage value of the A channel of RGB565 LAB (the value range is -128-127).\n\nYou can also get this value via index [1].\n\n#### percentile.b_value()\n\nReturns the percentage value of the B channel of RGB565 LAB (the value range is -128-127).\n\nYou can also get this value via index [2].\n\n## Threhsold Class-Threshold Object\n\nThe threshold object is returned by histogram.get_threshold.\n\nGrayscale images have one channel. There are no l_*, a_*, and b_* methods.\n\nThe RGB565 threshold has three channels. Use l_*, a_*, and b_* methods.\n\n### Constructor\n\nclass image.threshold\n\nPlease call the histogram.get_threshold() function to create this object.\n\n#### Method\n\n#### threhsold.value()\n\nReturns the threshold of the grayscale image (between 0 and 255).\n\nYou can also get this value by index [0].\n\n#### threhsold.l_value()\n\nReturn the L threshold (between 0 and 100) in the RGB565 image LAB.\n\nYou can also get this value by index [0].\n\n#### threhsold.a_value()\n\nReturn the A threshold (between -128 and 127) in the RGB565 image LAB.\n\nYou can also get this value via index [1].\n\n#### threhsold.b_value()\n\nReturn the B threshold (between -128 and 127) in the RGB565 image LAB.\n\nYou can also get this value via index [2].\n\n## class Statistics – Statistical data object\n\nThe statistical data object is returned by histogram.get_statistics or image.get_statistics.\n\nThe grayscale statistics have one channel, using methods other than l_*, a_* or b_*.\n\nThe RGB565 percentage value has three channels. Use the l_*, a_* and b_* methods.\n\n### Constructor\n\nclass image.statistics\nPlease call histogram.get_statistics() or image.get_statistics() function to create this object.\n\n### Method\n\n#### statistics.mean()\n\nReturns the average gray value (0-255) (int).\n\nYou can also get this value by index [0].\n\n#### statistics.median()\n\nReturns the median gray value (0-255) (int).\n\nYou can also get this value via index [1].\n\n#### statistics.mode()\n\nReturns the gray mode value (0-255) (int).\n\nYou can also get this value via index [2].\n\n#### statistics.stdev()\n\nReturns the gray standard deviation (0-255) (int).\n\nYou can also get this value through index [3].\n\n#### statistics.min()\n\nReturns the minimum value of gray scale (0-255) (int).\n\nYou can also get this value via index [4].\n\n#### statistics.max()\n\nReturns the maximum gray value (0-255) (int).\n\nYou can also get this value via index [5].\n\n#### statistics.lq()\n\nReturns the quarter value (0-255) (int) in grayscale.\n\nYou can also get this value via index [6].\n\n#### statistics.uq()\n\nReturns the quarter value of the gray scale (0-255) (int).\n\nYou can also get this value via index [7].\n\n#### statistics.l_mean()\n\nReturns the mean value of L (0-255) (int) in RGB5656 LAB.\n\nYou can also get this value by index [0].\n\n#### statistics.l_median()\n\nReturns the median (0-255) (int) of L in RGB5656 LAB.\n\nYou can also get this value via index [1].\n\n#### statistics.l_mode()\n\nReturns the mode (0-255) (int) of L in RGB5656 LAB.\n\nYou can also get this value via index [2].\n\n#### statistics.l_stdev()\n\nReturns the standard deviation value of L in RGB5656 LAB (0-255) (int).\n\nYou can also get this value through index [3].\n\n#### statistics.l_min()\n\nReturns the minimum value of L in RGB5656 LAB (0-255) (int).\n\nYou can also get this value via index [4].\n\n#### statistics.l_max()\n\nReturns the maximum value of L in RGB5656 LAB (0-255) (int).\n\nYou can also get this value via index [5].\n\n#### statistics.l_lq()\n\nReturns the lower quartile of L in RGB5656 LAB (0-255) (int).\n\nYou can also get this value via index [6].\n\n#### statistics.l_uq()\n\nReturns the upper quartile (0-255) (int) of L in RGB5656 LAB.\n\nYou can also get this value via index [7].\n\n#### statistics.a_mean()\n\nReturns the mean value (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value through index [8].\n\n#### statistics.a_median()\n\nReturns the median value (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value via index [9].\n\n#### statistics.a_mode()\n\nReturns the mode (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value via index [10].\n\n#### statistics.a_stdev()\n\nReturns the standard deviation value (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value through the index [11].\n\n#### statistics.a_min()\n\nReturns the minimum value of A in RGB5656 LAB (0-255) (int).\n\nYou can also get this value through the index [12].\n\n#### statistics.a_max()\n\nReturns the maximum value of A (0-255) (int) in RGB5656 LAB.\n\nYou can also get this value through the index [13].\n\n#### statistics.a_lq()\n\nReturns the lower quartile (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value through the index [14].\n\n#### statistics.a_uq()\n\nReturns the upper quartile (0-255) (int) of A in RGB5656 LAB.\n\nYou can also get this value via index [15].\n\n#### statistics.b_mean()\n\nReturns the mean value of B in RGB5656 LAB (0-255) (int).\n\nYou can also get this value via index [16].\n\n#### statistics.b_median()\n\nReturns the median (0-255) (int) of B in RGB5656 LAB.\n\nYou can also get this value via index [17].\n\n#### statistics.b_mode()\n\nReturns the mode (0-255) (int) of B in RGB5656 LAB.\n\nYou can also get this value through the index [18].\n\n#### statistics.b_stdev()\n\nReturns the standard deviation of B in RGB5656 LAB (0-255) (int).\n\nYou can also get this value through index [19].\n\n#### statistics.b_min()\n\nReturns the minimum value (0-255) (int) of B in RGB5656 LAB.\n\nYou can also get this value via index [20].\n\n#### statistics.b_max()\n\nReturns the maximum value of B in RGB5656 LAB (0-255) (int).\n\nYou can also get this value through the index [21].\n\n#### statistics.b_lq()\n\nReturns the lower quartile of B in RGB5656 LAB (0-255) (int).\n\nYou can also get this value through the index [22].\n\n#### statistics.b_uq()\n\nReturns the upper quartile (0-255) (int) of B in RGB5656 LAB.\n\nYou can also get this value through the index [23].\n\n## Blob class-color block object\n\nThe color block object is returned by `image.find_blobs`.\n\n### Constructor\n\nclass image.blob\n\nPlease call the image.find_blobs() function to create this object.\n\n### Method\n\n#### blob.rect()\n\nReturns a rectangular tuple (x, y, w, h), which is used in other image methods such as image.draw_rectangle of the color block bounding box.\n\n#### blob.x()\n\nReturns the x coordinate (int) of the bounding box of the color patch.\n\nYou can also get this value by index [0].\n\n#### blob.y()\nReturns the y coordinate (int) of the bounding box of the color patch.\n\nYou can also get this value via index [1].\n\n#### blob.w()\n\nReturns the w coordinate (int) of the bounding box of the color patch.\n\nYou can also get this value via index [2].\n\n#### blob.h()\n\nReturns the h coordinate (int) of the bounding box of the color patch.\n\nYou can also get this value through index [3].\n\n#### blob.pixels()\n\nReturns the number of pixels that are part of the color block (int).\n\nYou can also get this value via index [4].\n\n#### blob.cx()\n\nReturns the center x position of the color block (int).\n\nYou can also get this value via index [5].\n#### blob.cy()\n\nReturns the center x position of the color block (int).\n\nYou can also get this value via index [6].\n\n#### blob.rotation()\n\nReturns the rotation of the color block (unit: radians). If the color block resembles a pencil or pen, then this value is the only value between 0-180. If the color block is round, then this value has no effect. If this color block has no symmetry at all, you can only get a 0-360 degree rotation.\n\nYou can also get this value via index [7].\n\n#### blob.code()\n\nReturns a 16-bit binary number, where one bit is set for each color threshold, which is part of the color block. For example, if you use image.find_blobs to find three color thresholds, this color block can be set to 0/1/2 bits. Note: Unless you call image.find_blobs with merge=True, you can only set one bit per color block. Then multiple color blocks with different color thresholds can be merged together. You can also use this method and multiple thresholds to implement color code tracking.\n\nYou can also get this value through index [8].\n\n#### blob.count()\n\nReturns the number of multiple color blocks merged into this color block. Only when you call image.find_blobs with merge=True, this number is not 1.\n\nYou can also get this value via index [9].\n\n#### blob.area()\n\nReturn the border area around the color block (w * h)\n\n#### blob.density()\n\nReturns the density ratio of this color patch. This is the number of pixels in the bounding box area of ​​the color block. In general, a lower density ratio means that the object is not locked well.\n\n## Line class-line object\n\nThe line object is returned by `image.find_lines`, `image.find_line_segments` or `image.get_regression`.\n\n### Constructor\n\nclass image.line\n\nPlease call image.find_lines(), image.find_line_segments(), or image.get_regression() function to create this object.\n\n### Method\n\n#### line.line()\n\nReturn a straight line tuple (x1, y1, x2, y2) for use in other image methods such as image.draw_line.\n\n#### line.x1()\n\nReturns the x coordinate component of the p1 vertex of the line.\n\nYou can also get this value by index [0].\n\n#### line.y1()\n\nReturns the p1 y component of the line.\n\nYou can also get this value via index [1].\n\n#### line.x2()\n\nReturns the p2 x component of the line.\n\nYou can also get this value via index [2].\n\n#### line.y2()\n\nReturns the p2 y component of the line.\n\nYou can also get this value through index [3].\n\n#### line.length()\n\nThe length of the return line is sqrt(((x2-x1)^2) + ((y2-y1)^2).\n\nYou can also get this value via index [4].\n\n#### line.magnitude()\n\nReturns the length of the straight line after Hough transformation.\n\nYou can also get this value via index [5].\n\n#### line.theta()\n\nReturns the angle of the straight line after Hough transformation (0-179 degrees).\n\nYou can also get this value via index [7].\n\n#### line.rho()\n\nReturns the p-value of the straight line after Hough transform.\n\nYou can also get this value through index [8].\n\n## Circle class-round object\n\nThe circular object is returned by `image.find_circles`.\n\n### Constructor\n\nclass image.circle\n\nPlease call the image.find_circles() function to create this object.\n\n### Method\n\n#### circle.x()\n\nReturns the x position of the circle.\n\nYou can also get this value by index [0].\n\n#### circle.y()\n\nReturns the y position of the circle.\n\nYou can also get this value via index [1].\n\n#### circle.r()\n\nReturns the radius of the circle.\n\nYou can also get this value via index [2].\n\n#### circle.magnitude()\n\nReturns the size of the circle.\n\nYou can also get this value through index [3].\n\n## Rect Class-Rectangle Object\n\nThe rectangle object is returned by `image.find_rects`.\n\n### Constructor\n\nclass image.rect\n\nPlease call the image.find_rects() function to create this object.\n\n### Method\n\n#### rect.corners()\n\nReturns a list of four tuples (x, y) consisting of the four corners of the rectangular object. The four corners are usually returned in clockwise order starting from the upper left corner.\n\n#### rect.rect()\n\nReturns a rectangle tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of the bounding box of the rectangle.\n\n#### rect.x()\n\nReturns the x position of the upper left corner of the rectangle.\n\nYou can also get this value by index [0].\n\n#### rect.y()\n\nReturns the y position of the upper left corner of the rectangle.\n\nYou can also get this value via index [1].\n\n#### rect.w()\n\nReturns the width of the rectangle.\n\nYou can also get this value via index [2].\n\n#### rect.h()\n\nReturns the height of the rectangle.\n\nYou can also get this value through index [3].\n\n#### rect.magnitude()\n\nReturns the size of the rectangle.\n\nYou can also get this value via index [4].\n\n## QRCode class-QR code object\n\nThe QR code object is returned by `image.find_qrcodes`.\n\n### Constructor\n\nclass image.qrcode\n\nPlease call the image.find_qrcodes() function to create this object.\n\n### Method\n\n#### qrcode.corners()\n\nReturns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in clockwise order starting from the upper left corner.\n\n#### qrcode.rect()\n\nReturns a rectangular tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of the bounding box of the QR code.\n\n#### qrcode.x()\n\nReturns the x coordinate (int) of the bounding box of the QR code.\n\nYou can also get this value by index [0].\n\n#### qrcode.y()\n\nReturns the y coordinate (int) of the bounding box of the QR code.\n\nYou can also get this value via index [1].\n\n#### qrcode.w()\n\nReturns the w coordinate (int) of the bounding box of the QR code.\n\nYou can also get this value via index [2].\n\n#### qrcode.h()\n\nReturns the h coordinate (int) of the bounding box of the QR code.\n\nYou can also get this value through index [3].\n\n#### qrcode.payload()\n\nReturns the string of the QR code payload, such as URL.\n\nYou can also get this value via index [4].\n\n#### qrcode.version()\n\nReturns the version number (int) of the QR code.\n\nYou can also get this value via index [5].\n\n#### qrcode.ecc_level()\n\nReturns the ECC level of the QR code (int).\n\nYou can also get this value via index [6].\n\n#### qrcode.mask()\n\nReturns the mask (int) of the QR code.\n\nYou can also get this value via index [7].\n\n#### qrcode.data_type()\n\nReturns the data type of the QR code.\n\nYou can also get this value through index [8].\n\n#### qrcode.eci()\n\nReturns the ECI of the QR code. ECI stores the code of the data bytes stored in the QR code. If you want to process a QR code that contains more than standard ASCII text, you need to check this value.\n\nYou can also get this value via index [9].\n\n#### qrcode.is_numeric()\n\nIf the data type of the QR code is digital, it returns True.\n\n#### qrcode.is_alphanumeric()\n\nIf the data type of the QR code is alphanumeric, it returns True.\n\n#### qrcode.is_binary()\n\nIf the data type of the QR code is binary, it returns True. If you are serious about handling all types of text, you need to check whether eci is True to determine the text encoding of the data. Usually it is just standard ASCII, but it may also be UTF8 with two-byte characters.\n\n#### qrcode.is_kanji()\n\nIf the data type of the QR code is Kanji, it returns True. After setting it to True, you need to decode the string yourself, because each character of the Kanji is 10 digits, and MicroPython does not support parsing this type of text.\n\n## AprilTag Class – AprilTag Object\n\nThe AprilTag object is returned by `image.find_apriltags`.\n\n### Constructor\n\nclass image.apriltag\n\nPlease call the image.find_apriltags() function to create this object.\n\n### Method\n\n#### apriltag.corners()\n\nReturns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in clockwise order starting from the upper left corner.\n\n#### apriltag.rect()\n\n\nReturn a rectangular tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of AprilTag bounding box.\n\n#### apriltag.x()\n\nReturns the x coordinate (int) of the AprilTag bounding box.\n\nYou can also get this value by index [0].\n\n#### apriltag.y()\n\nReturns the y coordinate (int) of the bounding box of AprilTag.\n\nYou can also get this value via index [1].\n\n#### apriltag.w()\n\nReturns the w coordinate (int) of the bounding box of AprilTag.\n\nYou can also get this value via index [2].\n\n#### apriltag.h()\n\nReturns the h coordinate (int) of the bounding box of AprilTag.\n\nYou can also get this value through index [3].\n\n#### apriltag.id()\n\nReturns the numeric ID of AprilTag.\n\nTAG16H5 -> 0 to 29\nTAG25H7 -> 0 to 241\nTAG25H9 -> 0 to 34\nTAG36H10 -> 0 to 2319\nTAG36H11 -> 0 to 586\nARTOOLKIT -> 0 to 511\nYou can also get this value via index [4].\n\n#### apriltag.family()\n\nReturn to AprilTag's digital home.\n\nimage.TAG16H5\nimage.TAG25H7\nimage.TAG25H9\nimage.TAG36H10\nimage.TAG36H11\nimage.ARTOOLKIT\nYou can also get this value via index [5].\n\n#### apriltag.cx()\n\nReturns the center x position (int) of AprilTag.\n\nYou can also get this value via index [6].\n\n#### apriltag.cy()\n\nReturns the center y position (int) of AprilTag.\n\nYou can also get this value via index [7].\n\n#### apriltag.rotation()\n\nReturns the curl of AprilTag in radians (int).\n\nYou can also get this value through index [8].\n\n#### apriltag.decision_margin()\n\nReturn the color saturation of AprilTag matching (value 0.0-1.0), where 1.0 is the best.\n\nYou can also get this value via index [9].\n\n#### apriltag.hamming()\n\nReturns the acceptable digital error value of AprilTag.\n\nTAG16H5 -> can accept up to 0 bit errors\nTAG25H7 -> can accept up to 1 bit error\nTAG25H9 -> Accept up to 3 errors\nTAG36H10 -> can accept up to 3 errors\nTAG36H11 -> can accept up to 4 errors\nARTOOLKIT -> can accept up to 0 errors\nYou can also get this value via index [10].\n#### apriltag.goodness()\n\nReturns the color saturation of the AprilTag image (value 0.0-1.0), where 1.0 is the best.\n\n> Currently this value is usually 0.0. In the future, we can enable a function called \"tag refinement\" to realize the detection of smaller AprilTags. However, this feature now reduces the frame rate below 1 FPS.\n\nYou can also get this value through the index [11].\n\n#### apriltag.x_translation()\n\nReturns the transformation in the x direction from the camera. The unit of the distance is unknown.\n\nThis method is useful for determining the position of AprilTag far away from the camera. However, factors such as the size of AprilTag and the lens you use will affect the determination of the attribution of the X unit. For ease of use, we recommend that you use a lookup table to convert the output of this method into useful information for your application.\n\nNote: The direction here is from left to right.\n\nYou can also get this value through the index [12].\n\n#### apriltag.y_translation()\n\nReturns the transformation in the y direction from the camera. The unit of the distance is unknown.\n\nThis method is useful for determining the position of AprilTag far away from the camera. However, the size of the AprilTag and the lens you use will affect the determination of the Y unit. For ease of use, we recommend that you use a lookup table to convert the output of this method into useful information for your application.\n\nNote: The direction here is from top to bottom.\n\nYou can also get this value through the index [13].\n\n#### apriltag.z_translation()\n\nReturns the transformation in the z direction from the camera. The unit of the distance is unknown.\n\nThis method is useful for determining the position of AprilTag far away from the camera. However, the size of the AprilTag and the lens you use will affect the determination of the Z unit. For ease of use, we recommend that you use a lookup table to convert the output of this method into useful information for your application.\n\nNote: The direction here is from front to back.\n\nYou can also get this value through the index [14].\n\n#### apriltag.x_rotation()\n\nReturns the rotation of AprilTag on the X plane in radians. Example: Looking at AprilTag, move the camera from left to right.\n\nYou can also get this value via index [15].\n\n#### apriltag.y_rotation()\n\nReturns the rotation of AprilTag in radians on the Y plane. Example: Visually observe AprilTag and move the camera from top to bottom.\n\nYou can also get this value via index [16].\n\n#### apriltag.z_rotation()\n\nReturns the rotation of the AprilTag in radians on the Z plane. Example: Look at AprilTag and rotate the camera.\n\nNote: This is just a renamed version of apriltag.rotation().\n\nYou can also get this value via index [17].\n\n## DataMatrix Class-Data Matrix Object\n\nThe data matrix object is returned by `image.find_datamatrices`.\n\n## Constructor\n\nclass image.datamatrix\n\nPlease call the image.find_datamatrices() function to create this object.\n\n### Method\n\n#### datamatrix.corners()\n\nReturns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in clockwise order starting from the upper left corner.\n\n#### datamatrix.rect()\n\nReturn a rectangular tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of the bounding box of the data matrix.\n\n#### datamatrix.x()\n\nReturns the x coordinate (int) of the bounding box of the data matrix.\n\nYou can also get this value by index [0].\n\n#### datamatrix.y()\n\nReturns the y coordinate (int) of the bounding box of the data matrix.\n\nYou can also get this value via index [1].\n\n#### datamatrix.w()\n\nReturns the w width of the bounding box of the data matrix.\n\nYou can also get this value via index [2].\n\n#### datamatrix.h()\n\nReturns the h height of the bounding box of the data matrix.\n\nYou can also get this value through index [3].\n\n#### datamatrix.payload()\n\nReturns the string of the payload of the data matrix. Example: string.\n\nYou can also get this value via index [4].\n\n#### datamatrix.rotation()\n\nReturns the curl (floating point number) of the data matrix in radians.\n\nYou can also get this value via index [5].\n\n#### datamatrix.rows()\n\nReturns the number of rows of the data matrix (int).\n\nYou can also get this value via index [6].\n\n#### datamatrix.columns()\n\nReturns the number of columns of the data matrix (int).\n\nYou can also get this value via index [7].\n\n#### datamatrix.capacity()\n\nReturns the number of characters that this data matrix can hold.\n\nYou can also get this value through index [8].\n\n#### datamatrix.padding()\n\nReturns the number of unused characters in this data matrix.\n\nYou can also get this value via index [9].\n\n## BarCode Class-Barcode Object\n\nThe barcode object is returned by image.find_barcodes.\n\n## Constructor\n\nclass image.barcode\n\nPlease call the image.find_barcodes() function to create this object.\n\n### Method\n\n#### barcode.corners()\n\nReturns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in clockwise order starting from the upper left corner.\n\n#### barcode.rect()\n\nReturn a rectangular tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of the bounding box of the data matrix.\n\n#### barcode.x()\n\nReturns the x coordinate (int) of the bounding box of the barcode.\n\nYou can also get this value by index [0].\n\n#### barcode.y()\n\nReturns the y coordinate (int) of the bounding box of the barcode.\n\nYou can also get this value via index [1].\n\n#### barcode.w()\n\nReturns the w width (int) of the bounding box of the barcode.\n\nYou can also get this value via index [2].\n\n#### barcode.h()\n\nReturns the h height (int) of the bounding box of the barcode.\n\nYou can also get this value through index [3].\n\n#### barcode.payload()\n\nReturns the string of the payload of the barcode. Example: Quantity.\n\nYou can also get this value via index [4].\n\n#### barcode.type()\n\nReturns the enumeration type (int) of the barcode.\n\nYou can also get this value via index [5].\n\nimage.EAN2\nimage.EAN5\nimage.EAN8\nimage.UPCE\nimage.ISBN10\nimage.UPCA\nimage.EAN13\nimage.ISBN13\nimage.I25\nimage.DATABAR\nimage.DATABAR_EXP\nimage.CODABAR\nimage.CODE39\nimage.PDF417-To be enabled in the future (e.g. not yet available for normal use).\nimage.CODE93\nimage.CODE128\n\n#### barcode.rotation()\n\nReturns the curl (floating point number) of the barcode in radians.\n\nYou can also get this value via index [6].\n\n#### barcode.quality()\n\nReturns the number of times the barcode was detected in the image (int).\n\nWhen scanning a barcode, each new scan line can decode the same barcode. Each time this process is performed, the value of the barcode will increase accordingly.\n\nYou can also get this value via index [7].\n\n## Displacement class-displacement object\n\nThe displacement object is returned by image.find_displacement.\n\n### Constructor\n\nclass image.displacement\n\nPlease call the image.find_displacement() function to create this object.\n\n### Method\n\n#### displacement.x_translation()\n\nReturns the x translation pixel between two images. This is a precise sub-pixel, so it is a floating point number.\n\nYou can also get this value by index [0].\n\n#### displacement.y_translation()\n\nReturns the y translation pixel between two images. This is a precise sub-pixel, so it is a floating point number.\n\nYou can also get this value via index [1].\n\n#### displacement.rotation()\n\nReturns the z-shift pixel between two images. This is a precise sub-pixel, so it is a floating point number.\n\nYou can also get this value via index [2].\n\n#### displacement.scale()\n\nReturns the arc of rotation between two images.\n\nYou can also get this value through index [3].\n\n#### displacement.response()\n\nReturns the quality of the result of displacement matching between two images. Range 0-1. Displacement objects with a response less than 0.1 may be noise.\n\nYou can also get this value via index [4].\n\n## Kptmatch class – feature point object\n\nThe feature point object is returned by `image.match_descriptor`.\n\n### Constructor\n\nclass image.kptmatch\n\nPlease call the image.match_descriptor() function to create this object.\n\n### Method\n\n#### kptmatch.rect()\n\nReturn a rectangular tuple (x, y, w, h), used in other image methods such as image.draw_rectangle of the bounding box of the feature point.\n\n#### kptmatch.cx()\n\nReturns the center x position of the feature point (int).\n\nYou can also get this value by index [0].\n\n#### kptmatch.cy()\n\nReturns the center y position (int) of the feature point.\n\nYou can also get this value via index [1].\n\n#### kptmatch.x()\n\nReturns the x coordinate (int) of the bounding box of the feature point.\n\nYou can also get this value via index [2].\n\n#### kptmatch.y()\n\nReturns the y coordinate (int) of the bounding box of the feature point.\n\nYou can also get this value through index [3].\n\n#### kptmatch.w()\n\nReturns the w width (int) of the bounding box of the feature point.\n\nYou can also get this value via index [4].\n\n#### kptmatch.h()\n\nReturns the h height (int) of the bounding box of the feature point.\n\nYou can also get this value via index [5].\n\n#### kptmatch.count()\n\nReturns the number of matched feature points (int).\n\nYou can also get this value via index [6].\n\n#### kptmatch.theta()\n\nReturns the curl of the estimated feature point (int).\n\nYou can also get this value via index [7].\n\n#### kptmatch.match()\n\nReturns a list of (x, y) tuples matching key points.\n\nYou can also get this value through index [8].\n\n## ImageWriter class-ImageWriter object\n\nThe ImageWriter object allows you to quickly write uncompressed images to disk.\n\n### Constructor\n\nclass image.ImageWriter(path)\n\nBy creating an ImageWriter object, you can write uncompressed images to disk in the simple file format used for OpenMV Cams. Then the uncompressed image can be re-read using ImageReader.\n\n### Method\n\n#### imagewriter.size()\n\nReturns the size of the file being written.\n\n#### imagewriter.add_frame(img)\n\nWrite an image to disk. Because the image is not compressed, it executes quickly, but it takes up a lot of disk space.\n\n#### imagewriter.close()\n\nClose the image stream file. You must close the file or the file will be damaged.\n\n## ImageReader class – ImageReader object\n\nThe ImageReader object allows you to quickly read uncompressed images from disk.\n### Constructor\n\nclass image.ImageReader(path)\n\nCreate an ImageReader object to play back the image data written by the ImageWriter object. The frames played back by the ImageWriter object will be played back at the same FPS as when they were written to disk.\n\n### Method\n\n#### imagereader.size()\n\nReturns the size of the file being read.\n\nimagereader.next_frame([copy_to_fb=True, loop=True])\nReturn the image object from the file written by ImageWriter. If copy_to_fb is True, the image object will be directly loaded into the frame buffer. Otherwise, the image object will be put into the heap. Note: Unless the image is small, the heap may not have enough space to store the image object. If loop is True, playback will restart after the last image of the stream is read. Otherwise, this method will return None after all frames have been read.\n\nNote: imagereader.next_frame tries to limit the playback speed by pausing the playback after reading the frame to match the frame recording speed. Otherwise, this method will quickly read and play all images at a speed of 200+FPS.\n\n#### imagereader.close()\n\nClose the file being read. You need to do this to prevent damage to the imagereader object. But because it is a read-only file, the file will not be damaged when it is not closed.\n\n## Image class-image objects\n\nImage objects are the basic objects of machine vision operations.\n\n### Constructor\n\nclass image.Image(path[, copy_to_fb=False])\n\nCreate a new image object from the file in path.\n\nSupport image files in bmp/pgm/ppm/jpg/jpeg format.\n\nIf copy_to_fb is True, the image will be directly loaded into the frame buffer, and you can load a large image. If False, the image will be loaded into the MicroPython heap, which is much smaller than the frame buffer.\n\nIn OpenMV Cam M4, if copy_to_fb is False, you should try to keep the image size below 8KB. If True, the image can be up to 160KB.\nIn OpenMV Cam M7, if copy_to_fb is False, you should try to keep the image size below 16KB. If True, the maximum image size can be 320KB.\nThe image supports the \"[]\" notation. Let image[index] = 8/16-bit value to allocate image pixels or image[index] and get an image pixel. If it is a 16-bit RGB565 grayscale image for RGB image, this pixel is 8 Bit.\n\nFor JPEG images, \"[]\" allows you to access JPEG image color patches in the form of a compressed section array. Since the JPEG image is a compressed byte stream, the reading and writing of the data group is opaque.\n\nThe image also supports read buffer operation. You can treat the image as a section array object and input the image into all types of MicroPython functions. If you want to transmit an image, you can pass it to the UART/SPI/I2C write function, which can realize automatic transmission.\n\n### Method\n\n#### image.width()\n\nReturns the width of the image in pixels.\n\n#### image.height()\n\nReturns the height of the image in pixels.\n\n#### image.format()\n\nReturn sensor.GRAYSCALE for grayscale images, sensor.RGB565 for RGB images, and sensor.JPEG for JPEG images.\n\n#### image.size()\n\nReturns the size of the image in bytes.\n\n#### image.get_pixel(x, y[, rgbtuple])\n\nGrayscale image: returns the grayscale pixel value at (x, y) position.\n\nRGB565l: Returns the RGB888 pixel tuple (r, g, b) at position (x, y).\n\nBayer image: Returns the pixel value at position (x, y).\n\nDoes not support compressed images.\n\n> image.get_pixel() and `image.set_pixel()` are the only methods that allow you to manipulate Bayer mode images. The Bayer mode image is a text image. For even rows, the pixels in the image are R/G/R/G/ etc. For odd lines, the pixels in the image are G/B/G/B/ etc. Each pixel is 8 bits.\n\n#### image.set_pixel(x, y, pixel)\nGrayscale image: Set the pixel at position (x, y) to the grayscale value pixel.\n\nRGB image: Set the pixel at position (x, y) to RGB888 tuple (r, g, b) pixel.\n\nDoes not support compressed images.\n\n> image.get_pixel() and `image.set_pixel()` are the only methods that allow you to manipulate Bayer mode images. The Bayer mode image is a text image. For even rows, the pixels in the image are R/G/R/G/ etc. For odd lines, the pixels in the image are G/B/G/B/ etc. Each pixel is 8 bits.\n\n#### image.mean_pool(x_div, y_div)\n\nFind the average value of x_div * y_div squares in the image and return the modified image composed of the average value of each square.\n\nThis method allows you to quickly shrink the image on the original image.\n\nDoes not support compressed images and bayer images.\n\n#### image.mean_pooled(x_div, y_div)\n\nFind the average value of x_div * y_div squares in the image and return a new image composed of the average value of each square.\n\nThis method allows you to create a reduced image copy.\n\nDoes not support compressed images and bayer images.\n\n#### image.midpoint_pool(x_div, y_div[, bias=0.5])\n\nFind the midpoint value of the x_div * y_div square in the image, and return the modified image composed of the midpoint value of each square.\n\nA bias of 0.0 returns the minimum value of each region, and a ``bias'' of 1.0 returns the maximum value of each region.\n\nThis method allows you to quickly shrink the image on the original image.\n\nDoes not support compressed images and bayer images.\n\n#### image.midpoint_pooled(x_div, y_div[, bias=0.5])\n\nFind the midpoint value of the x_div * y_div squares in the image, and return a new image composed of the midpoint value of each square.\n\nA bias of 0.0 returns the minimum value of each region, and a ``bias'' of 1.0 returns the maximum value of each region.\n\nThis method allows you to create a reduced image copy.\n\nDoes not support compressed images and bayer images.\n\n#### image.to_grayscale([copy=False])\n\nConvert the image to a grayscale image. This method will also modify the basic image pixels and change the image size in bytes, so it can only be performed on grayscale images or RGB565 images. Otherwise, copy must be True to create a new modified image on the heap.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.to_rgb565([copy=False])\n\nConvert the image to a color image. This method will also modify the base image pixels and change the image size in bytes, so it can only be performed on RGB565 images. Otherwise, copy must be True to create a new modified image on the heap.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.to_rainbow([copy=False])\n\nConvert the image to a rainbow image. This method will also modify the base image pixels and change the image size in bytes, so it can only be performed on RGB565 images. Otherwise, copy must be True to create a new modified image on the heap.\n\nThe rainbow image is a color image, and has a unique color value for each 8-bit mask gray-scale illumination value in the image. For example, it provides heat map colors for thermal images.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.compress([quality=50])\n\nJPEG compresses the image appropriately. Compared with compressed save heap space, using this method uses a higher quality compression ratio at the cost of destroying the original image.\n\nquality is the compression quality (0-100) (int).\n\n#### image.compress_for_ide([quality=50])\n\nJPEG compresses the image appropriately. Compared with compressed save heap space, using this method uses a higher quality compression ratio at the cost of destroying the original image.\n\nThis method compresses the image, and then formats the JPEG data by encoding every 6 bits into bytes between 128-191, and converts it to OpenMV IDE for display. This step is done to prevent the JPEG data from being mistaken for other text data in the byte stream.\n\nYou need to use this method to format the image data for display in the terminal window created by \"Open Terminal\" in OpenMV IDE.\n\nquality is the compression quality (0-100) (int).\n\n#### image.compressed([quality=50])\n\nReturn a JPEG compressed image—the original image is unprocessed. However, this method requires a large allocation of heap space, so image compression quality and image resolution must be very low.\n\nquality is the compression quality (0-100) (int).\n\n#### image.compressed_for_ide([quality=50])\n\nReturn a JPEG compressed image—the original image is unprocessed. However, this method requires a large allocation of heap space, so image compression quality and image resolution must be very low.\n\nThis method compresses the image, and then formats the JPEG data by encoding every 6 bits into bytes between 128-191, and converts it to OpenMV IDE for display. This step is done to prevent the JPEG data from being mistaken for other text data in the byte stream.\n\nYou need to use this method to format the image data for display in the terminal window created by \"Open Terminal\" in OpenMV IDE.\n\nquality is the compression quality (0-100) (int).\n\n#### image.copy([roi[, copy_to_fb=False]])\n\nCreate a copy of the image object.\n\nRoi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, the ROI will copy the entire image rectangle. But this does not apply to JPEG images.\n\nRemember that the image copy is stored in the MicroPython heap, not the frame buffer. Similarly, you need to control the image copy size below 8KB (OpenMV) or below 16KB (OpenMV Cam M7). If you want to use one copy operation to use all the heap space, this function will be abnormal. An image that is too large can easily trigger abnormalities.\n\nIf copy_to_fb is True, this method replaces the frame buffer with an image. The frame buffer has much larger space than the heap and can hold large images.\n\n#### image.save(path[, roi[, quality=50]])\n\nSave a copy of the image to the file system in path.\n\nSupport image files in bmp/pgm/ppm/jpg/jpeg format. Note: You cannot save compressed images in jpeg format into uncompressed format.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, the ROI will copy the entire image rectangle. But this does not apply to JPEG images.\n\nquality refers to the JPEG compression quality that saves the image as JPEG format when the image has not been compressed.\n\n#### image.clear()\n\nSet all pixels in the image to zero (very fast).\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images.\n\n#### image.draw_line(x0, y0, x1, y1[, color[, thickness=1]])\n\nDraw a line from (x0, y0) to (x1, y1) on the image. You can pass x0, y0, x1, y1 individually, or to tuples (x0, y0, x1, y1).\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nthickness Controls the thickness of the line in pixels.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n#### image.draw_rectangle(x, y, w, h[, color[, thickness=1[, fill=False]]])\n\nDraw a rectangle on the image. You can pass x, y, w, h individually or as a tuple (x, y, w, h).\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nthickness Controls the thickness of the line in pixels.\n\nSet fill to True to fill the rectangle.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_ellipse(cx, cy, rx, ry, rotation[, color[, thickness=1[, fill=False]]])\n\nDraws an ellipse on the image. You may either pass cx, cy, rx, ry, and the rotation (in degrees) separately or as a tuple (cx, yc, rx, ry, rotation).\n\ncolor is an RGB888 tuple for Grayscale or RGB565 images. Defaults to white. However, you may also pass the underlying pixel value (0-255) for grayscale images or a RGB565 value for RGB565 images.\n\nthickness controls how thick the edges are in pixels.\n\nPass fill set to True to fill the ellipse.\n\nReturns the image object so you can call another method using . notation.\n\nNot supported on compressed images or bayer images.\n\n#### image.draw_circle(x, y, radius[, color[, thickness=1[, fill=False]]])\n\nDraw a circle on the image. You can pass x, y, radius individually or as a tuple (x, y, radius).\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nthickness Controls the thickness of the line in pixels.\n\nSet fill to True to fill the circle.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_string(x, y, text[, color[, scale=1[, x_spacing=0[, y_spacing=0[, mono_space=True]]]]])\n\nDraw 8x10 text from the position (x, y) in the image. You can pass x, y individually or as a tuple (x, y).\n\ntext is the character string written into the image. The \\n, \\r, and \\r\\n end characters move the cursor to the next line.\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nYou can increase the scale to increase the size of the text on the image.\n\n   Only integer values ​​(for example, 1/2/3/etc).\n\nx_spacing allows you to add (if positive) or subtract (if negative) x pixels between characters to set the character spacing.\n\ny_spacing allows you to add (if it is a positive number) or subtract (if it is a negative number) y pixels between characters to set line spacing.\n\nmono_space defaults to True, which forces the text spacing to be fixed. For large text, this looks terrible. Set False to get non-fixed width character spacing, which looks much better.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_cross(x, y[, color[, size=5[, thickness=1]]])\n\nDraw a cross on the image. You can pass x, y individually or as a tuple (x, y).\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nsize controls the extension length of the crosshairs.\n\nthickness controls the pixel thickness of the edge.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_arrow(x0, y0, x1, y1[, color[, thickness=1]])\n\nDraw an arrow from (x0, y0) to (x1, y1) on the image. You can pass x0, y0, x1, y1 individually, or to tuples (x0, y0, x1, y1).\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nthickness Controls the thickness of the line in pixels.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_image(image, x, y[, x_scale=1.0[, y_scale=1.0[, mask=None[, alpha=256]]]])\n\nDraw an image whose upper left corner starts at position x, y. You can pass x, y individually or to a tuple (x, y).\n\nx_scale controls the scale of the image in the x direction (floating point number).\n\ny_scale controls the scale of the image in the y direction (floating point number).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. You can use the mask mask for drawing operations.\n\nAlpha controls the transparency of the source image drawn into the target image. 256 is to draw an opaque source image, and a value less than 256 produces a blend between the source image and the target image. 0 means not to modify the target image.\n\nDoes not support compressed images and bayer images.\n\n#### image.draw_keypoints(keypoints[, color[, size=10[, thickness=1[, fill=False]]]])\n\nDraw each point of a feature point object on the image.\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nsize controls the size of feature points.\n\nthickness Controls the thickness of the line in pixels.\n\nSet fill to True to fill the feature points.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.flood_fill(x, y[, seed_threshold=0.05[, floating_threshold=0.05[, color[, invert=False[, clear_background=False[, mask=None]]]]]]])\n\nFill the area of ​​the image from position x, y. You can pass x, y individually or to a tuple (x, y).\n\nseed_threshold controls the difference between the pixels in the filled area and the original starting pixels.\n\nfloating_threshold controls the difference between the pixels in the filled area and any adjacent pixels.\n\ncolor is an RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the basic pixel value (0-255) of the grayscale image or the byte inverted RGB565 value of the RGB565 image.\n\nPass invert as True to refill all content outside the flood_fill connection area.\n\nPass clear_background as True, and reset the remaining flood_fill pixels that have not been recolored.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask will be evaluated during flood_fill.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.binary(thresholds[, invert=False[, zero=False[, mask=None]]])\n\nSet all pixels in the image to black or white according to whether the pixel is within the threshold in the threshold list thresholds.\n\nthresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the color range you want to track. For grayscale images, each tuple needs to contain two values-the minimum gray value and the maximum gray value. Only the areas of pixels that fall between these thresholds are considered. For an RGB565 image, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)-the minimum and maximum values ​​of LAB L, A and B channels, respectively. For ease of use, this function will automatically repair the minimum and maximum values ​​of exchange. In addition, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, it is assumed that the remaining thresholds are in the maximum range.\n\nannotation\n\nTo obtain the threshold of the tracked object, simply select (click and drag) the tracked object in the IDE frame buffer. The histogram will be updated accordingly to the area. Then just write down the starting and falling positions of the color distribution in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, it is better to manually determine the threshold.\n\nYou can also determine the color threshold by entering Tools -> Machine Vision -> Threshold Editor in OpenMV IDE and dragging the slider from the GUI window.\n\ninvert Inversion threshold operation, pixels are matched outside the known color range instead of in the known color range.\n\nSet zero to True to make the threshold pixels zero and keep the pixels not in the threshold list unchanged.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n\n#### image.invert()\n\nChange the binary image 0 (black) to 1 (white) and 1 (white) to 0 (black), flipping all the pixel values ​​in the binary image very quickly.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and Bayer images.\n\n#### image.b_and(image[, mask=None])\n\nUse another image to perform a logical AND operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.b_nand(image[, mask=None])\n\nUse another image to perform logical AND operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.b_or(image[, mask=None])\n\nUse another image to perform a logical OR operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n#### image.b_nor(image[, mask=None])\n\nUse another image to perform logical NOR operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.b_xor(image[, mask=None])\n\nUse another image to perform a logical XOR operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.b_xnor(image[, mask=None])\n\nUse another image to perform logical XOR operation with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.erode(size[, threshold[, mask=None]])\n\nDelete pixels from the edge of the divided area.\n\nThis method is implemented by convolving a kernel of ((size*2)+1)x((size*2)+1) pixels on the image. If the sum of the adjacent pixel sets is less than the threshold, the central pixel of the kernel Zero.\n\nIf the threshold is not set, this method functions as the standard corrosion method. If the threshold is set, you can specify the specific pixels to be eroded, for example: set the threshold value 2 for pixels below 2.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.dilate(size[, threshold[, mask=None]])\n\nAdd pixels to the edges of the segmented area.\n\nThis method is implemented by convolving a kernel of ((size*2)+1)x((size*2)+1) pixels on the image. If the sum of the adjacent pixel sets is greater than the threshold, the central pixel of the kernel is Set up.\n\nIf the threshold is not set, this method functions as the standard corrosion method. If the threshold is set, you can specify the specific pixels to be eroded, for example: set the threshold value 2 for pixels below 2.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.open(size[, threshold[, mask=None]])\n\nPerform erosion and dilation on the image in sequence. For more information, see image.erode() and image.dilate().\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.close(size[, threshold[, mask=None]])\n\nPerform dilation and erosion on the image in sequence. For more information, see image.erode() and image.dilate().\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.top_hat(size[, threshold[, mask=None]])\n\nReturn the difference between the original image and the image after executing the image.open() function.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nDoes not support compressed images and bayer images.\n\n#### image.black_hat(size[, threshold[, mask=None]])\n\nReturn the difference between the original image and the image after executing the image.close() function.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nDoes not support compressed images and bayer images.\n\n#### image.negate()\n\nFlip (digitally invert) all pixel values ​​in the image very quickly. Perform numerical conversion on the pixel value of each color channel. Example: (255-pixel).\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.replace(image[, hmirror=False[, vflip=False[, mask=None]]])\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nSet hmirror to True to mirror the replacement image horizontally.\n\nSet vflip to True to flip the replacement image vertically.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.add(image[, mask=None])\n\nAdd two images to each other pixel by pixel.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.sub(image[, reverse=False[, mask=None]])\n\nSubtract two images from each other pixel by pixel.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nSetting reverse to True can reverse the subtraction operation from this_image-image to image-this_image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.mul(image[, invert=False[, mask=None]])\n\nMultiply two images by pixel.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nSet invert to True to change the multiplication operation from a*b to 1/((1/a)*(1/b)). In particular, this brightens the image instead of darkening it (for example, multiplication and burning operations).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.div(image[, invert=False[, mask=None]])\n\nDivide this image by another image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nSet invert to True to change the division direction from a/b to b/a.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.min(image[, mask=None])\n\nAt the pixel level, replace the pixels in this image with the smallest pixel value between this image and another image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV4.\n#### image.max(image[, mask=None])\n\nAt the pixel level, replace the pixels in this image with the maximum pixel value between this image and another image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.difference(image[, mask=None])\n\nTake the absolute value of the two images pixel by pixel. Example: For each color channel, change each pixel �� to ABS (this.pixel-image.pixel).\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.blend(image[, alpha=128[, mask=None]])\n\nFuse another image image with this image.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nAlpha controls how much other images are blended into this image. Alpha should be an integer value between 0 and 256. A value close to zero will blend more other images into this image, a value close to 256 is the opposite.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.histeq([adaptive=False[, clip_limit=-1[, mask=None]]])\n\nRun the histogram equalization algorithm on the image. Histogram equalization normalizes the contrast and brightness in the image.\n\nIf adaptive is passed as True, then an adaptive histogram equalization method will be run on the image, which is usually better than non-adaptive histogram definition, but it takes longer to run.\n\nclip_limit provides a way to limit the contrast of adaptive histogram equalization. Use a small value (for example, 10) to generate a good histogram equalization contrast limited image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.mean(size, [threshold=False, [offset=0, [invert=False, [mask=None]]]]])\n\nStandard mean fuzzy filtering using box filters.\n\nSize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nmedian(size, percentile=0.5, threshold=False, offset=0, invert=False, mask])\nRun median filtering on the image. Under the condition of preserving the edges, the median filter is the best filter to smooth the surface, but it runs very slowly.\n\nSize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\npercentile controls the percentile of the value used in the kernel. By default, each pixel is replaced with the adjacent 50th percentile (center). You can set this value to 0 when using minimum filtering, 0.25 when using lower quartile filtering, 0.75 when using upper quartile filtering, and 1 when using maximum filtering.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.mode(size[, threshold=False, offset=0, invert=False, mask])\n\nRun a mode filter on the image, replacing each pixel with the pattern of neighboring pixels. This method works well on grayscale images. However, due to the non-linear nature of this operation, many artifacts will be generated on the edges of the RGB image.\n\nSize is the size of the kernel. Take 1 (3x3 core) and 2 (5x5 core).\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.midpoint(size[, bias=0.5, threshold=False, offset=0, invert=False, mask])\n\nRun midpoint filtering on the image. This filter finds the midpoint ((max-min)/2) of the neighborhood of each pixel in the image.\n\nsize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\nBias controls the minimum/maximum degree of image blending. 0 only applies to minimum filtering, and 1 only applies to maximum filtering. You can use bias to perform minimum/maximum filtering on the image.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.morph(size, kernel, mul=Auto, add=0)\n\nConvolve the image through the filter kernel. This allows you to perform general convolution on the image.\n\nsize controls the size of the kernel to ((size*2)+1)x((size*2)+1) pixels.\n\nkernel The kernel used to convolve the image, which can be a tuple or a list of values ​​[-128:127].\n\nmul is the number used to multiply the result of the convolution pixel. If not set, it will default to a value which will prevent scaling in the convolution output.\n\nadd is the value used to add to the convolution result of each pixel.\n\nmul can adjust the global contrast, add can adjust the global brightness.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n#### image.gaussian(size[, unsharp=False[, mul[, add=0[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]]])\n\nConvolve the image by smoothing Gaussian kernel.\n\nsize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\nIf unsharp is set to True, this method will not only perform Gaussian filtering operations, but perform unsharp masking operations, thereby improving the image sharpness of the edges.\n\nmul is the number used to multiply the result of the convolution pixel. If not set, it will default to a value which will prevent scaling in the convolution output.\n\nadd is the value used to add to the convolution result of each pixel.\n\nmul can adjust the global contrast, add can adjust the global brightness.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n#### image.laplacian(size[, sharpen=False[, mul[, add=0[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]]])\n\nThe image is convolved by edge detection Laplacian kernel.\n\nsize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\nIf sharpen is set to True, then this method will change to sharpen the image instead of outputting only the edge detection image that has not been thresholded. Increase the kernel size and then increase the image clarity.\n\nmul is the number used to multiply the result of the convolution pixel. If not set, it will default to a value which will prevent scaling in the convolution output.\n\nadd is the value used to add to the convolution result of each pixel.\n\nmul can adjust the global contrast, add can adjust the global brightness.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.bilateral(size[, color_sigma=0.1[, space_sigma=1[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]])\n\nThe image is convolved through a bilateral filter. The bilateral filter smoothes the image while maintaining the edges in the image.\n\nsize is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher.\n\ncolor_sigma controls how close the color is matched with the bilateral filter. Increase this value to increase color blur.\n\nspace_sigma controls the degree of mutual blurring of pixels in space. Increase this value to increase pixel blur.\n\nIf you want to set the threshold adaptively on the output of the filter, you can pass the threshold=True parameter to start the adaptive threshold processing of the image, which will be based on the brightness of the environment pixel (related to the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.cartoon(size[, seed_threshold=0.05[, floating_threshold=0.05[, mask=None]]])\n\nWalk through the image and use the flood-fills algorithm to fill all pixel areas in the image. This effectively removes texture from the image by flattening the colors in all areas of the image. For best results, the image should have a lot of contrast so that the areas do not penetrate each other too easily.\n\nseed_threshold controls the difference between the pixels in the filled area and the original starting pixels.\n\nfloating_threshold controls the difference between the pixels in the filled area and any adjacent pixels.\n\nmask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.remove_shadows([image])\n\nRemove the shadow from the image.\n\nIf there is no \"shadow-free\" version of the current image, this method will try to remove the shadow from the image, but there is no real shadow-free image basis. This algorithm is suitable for removing shadows in a flat and uniform background. Please note that this method takes many seconds to run, and is only suitable for removing shadows in real time and dynamically generating a shadowless version of the image. Future versions of the algorithm will be applicable to more environments, but are equally slow.\n\nIf a \"no shadow\" version of the current image appears, this method will use the \"true source\" background non-shadow image to remove all shadows in the image to filter out the shadows. Non-shadow pixels are not filtered out, so you can add new objects to the scene that did not exist before, and any non-shadow pixels in those objects will be displayed.\n\nReturn the image object so that you can call another method using. Notation.\n\nOnly supports RGB565 images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.chrominvar()\n\nRemove the lighting effect from the image, leaving only the color gradient. Faster than image.illuminvar() but affected by shadows.\n\nReturn the image object so that you can call another method using. Notation.\n\nOnly supports RGB565 images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.illuminvar()\n\nRemove the lighting effect from the image, leaving only the color gradient. Slower than image.chrominvar() but not affected by shadows.\n\nReturn the image object so that you can call another method using. Notation.\n\nOnly supports RGB565 images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.linpolar([reverse=False])\n\nThe image is reprojected from Cartesian coordinates to linear polar coordinates.\n\nSet reverse = True to reproject in the opposite direction.\n\nLinear polar reprojection converts image rotation to x translation.\n\nDoes not support compressed images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.logpolar([reverse=False])\n\nThe image is reprojected from Cartesian coordinates to log-polar coordinates.\n\nSet reverse = True to reproject in the opposite direction.\n\nLog polar reprojection transforms the rotation of the image into x translation and scaling to y translation.\n\nDoes not support compressed images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.lens_corr([strength=1.8[, zoom=1.0]])\n\nPerform lens distortion correction to remove the fisheye effect of the image caused by the lens.\n\nstrength is a floating point number, which determines the degree of de-fishing effect on the image. By default, first try the value 1.8, and then adjust this value to make the image display the best effect.\n\nzoom is the value used to zoom the image. The default value is 1.0.\n\nReturn the image object so that you can call another method using. Notation.\n\nDoes not support compressed images and bayer images.\n\n #### img.rotation_corr([x_rotation=0.0[, y_rotation=0.0[, z_rotation=0.0[, x_translation=0.0[, y_translation=0.0[, zoom=1.0[, fov=60.0[, corners]]]]] ]]])\n\nCorrect the perspective problem in the image by 3D rotation of the frame buffer.\n\n`x_rotation` is the number of degrees that the image is rotated around the x axis in the frame buffer (that is, the image is rotated up and down).\n\n`y_rotation` refers to the number of degrees the image is rotated around the y axis in the frame buffer (ie, rotate the image left and right).\n\n`z_rotation` is the number of degrees the image is rotated around the z axis in the frame buffer (ie, the image is rotated to the appropriate position).\n\n`x_translation` is the number of units to move the image to the left or right after rotation. Because this conversion is applied to 3D space, the unit is not a pixel...\n\n`y_translation` is the number of units by which the image moves up or down after being rotated. Because this conversion is applied to 3D space, the unit is not a pixel...\n\n`zoom` is the multiple to zoom the image, 1.0 by default.\n\n`fov` is the field of view used internally before rotating the image in 3D space when performing 2D->3D projection. When this value is close to 0, the image is placed infinitely far from the viewport. When this value is close to 180, the image is placed in the viewport. Normally, you should not change this value, but you can modify it to change the 2D->3D mapping effect.\n\n`corners` is a list of four (x, y) tuples, representing four `corners` used to create four-point correspondence homography, mapping the first `corner` to (0,0), and the second A `corner` (image_width-1, 0), a third `corner` (image_width-1 image_height-1) and a fourth `corner` (0, image_height-1). Then apply 3D rotation after the image is remapped. This parameter allows you to use rotation_corr to do things, such as bird's-eye view conversion. E.g:\n\n```python\ntop_tilt = 10 # if the difference between top/bottom_tilt become to large this method will stop working\nbottom_tilt = 0\n\npoints = [(tilt, 0), (img.width()-tilt, 0), (img.width()-1-bottom_tilt, img.height()-1), (bottom_tilt, img.height()- 1)]\n\nimg.rotation_corr(corners=points)\n```\n\nReturn the image object so that you can use `.` to call another method.\n\nDoes not support compressed images or Bayer images.\n\n#### image.get_similarity(image)\n\nReturn a \"similarity\" object, describing two images using the SSIM algorithm to compare the similarity of the 8x8 pixel color patches between the two images.\n\nimage can be an image object, the path of an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a basic pixel value (for example, 8-bit grayscale of a grayscale image or byte-reversed RGB565 value of an RGB image).\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n#### image.get_histogram([thresholds[, invert=False[, roi[, bins[, l_bins[, a_bins[, b_bins]]]]]]])\n\nPerform normalized histogram operations on all color channels of roi and return a histogram object. Please refer to the histogram object for more information. You can also use image.get_hist or image.histogram to call this method. If you pass the thresholds list, the histogram information will only be calculated from the pixels in the threshold list.\n\nthresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the color range you want to track. For grayscale images, each tuple needs to contain two values-the minimum gray value and the maximum gray value. Only the areas of pixels that fall between these thresholds are considered. For an RGB565 image, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)-the minimum and maximum values ​​of LAB L, A and B channels, respectively. For ease of use, this function will automatically repair the minimum and maximum values ​​of exchange. In addition, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, it is assumed that the remaining thresholds are in the maximum range.\n\nannotation\n\nTo obtain the threshold of the tracked object, simply select (click and drag) the tracked object in the IDE frame buffer. The histogram will be updated accordingly to the area. Then just write down the starting and falling positions of the color distribution in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, it is better to manually determine the threshold.\n\nYou can also determine the color threshold by entering Tools -> Machine Vision -> Threshold Editor in OpenMV IDE and dragging the slider from the GUI window.\n\ninvert Inversion threshold operation, pixels are matched outside the known color range instead of in the known color range.\n\nUnless you need to use color statistics for advanced operations, just use the `image.get_statistics()` method instead of this method to view the pixel area in the image.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nbins and other bins are the number of bins used for the histogram channel. For grayscale images, use bins, and for RGB565 images, use every other channel. The bin count of each channel must be greater than 2. In addition, setting the bin count to be greater than the number of unique pixel values ​​for each channel is meaningless. By default, the histogram will have the maximum number of bins per channel.\n\nDoes not support compressed images and bayer images.\n\n#### image.get_statistics([thresholds[, invert=False[, roi[, bins[, l_bins[, a_bins[, b_bins]]]]]]])\n\nCalculate the average, median, mode, standard deviation, minimum, maximum, lower quartile and upper quartile of each color channel in roi, and return a data object. See the statistics object for more information. You can also use image.get_stats or image.statistics to call this method. If you pass the thresholds list, the histogram information will only be calculated from the pixels in the threshold list.\n\nthresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the color range you want to track. For grayscale images, each tuple needs to contain two values-the minimum gray value and the maximum gray value. Only the areas of pixels that fall between these thresholds are considered. For an RGB565 image, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)-the minimum and maximum values ​​of LAB L, A and B channels, respectively. For ease of use, this function will automatically repair the minimum and maximum values ​​of exchange. In addition, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, it is assumed that the remaining thresholds are in the maximum range.\n\nannotation\n\nTo obtain the threshold of the tracked object, simply select (click and drag) the tracked object in the IDE frame buffer. The histogram will be updated accordingly to the area. Then just write down the starting and falling positions of the color distribution in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, it is better to manually determine the threshold.\n\nYou can also determine the color threshold by entering Tools -> Machine Vision -> Threshold Editor in OpenMV IDE and dragging the slider from the GUI window.\n\ninvert Inversion threshold operation, pixels are matched outside the known color range instead of in the known color range.\n\nYou can use this method when you need to obtain information about a pixel area in an image. For example: If you want to use the frame difference method to detect motion, you need to use this method to determine the change of the image color channel, thereby triggering the motion detection threshold.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nbins and other bins are the number of bins used for the histogram channel. For grayscale images, use bins, and for RGB565 images, use every other channel. The bin count of each channel must be greater than 2. In addition, setting the bin count to be greater than the number of unique pixel values ​​for each channel is meaningless. By default, the histogram will have the maximum number of bins per channel.\n\nDoes not support compressed images and bayer images.\n\n#### image.get_regression(thresholds[, invert=False[, roi[, x_stride=2[, y_stride=1[, area_threshold=10[, pixels_threshold=10[, robust=False]]]]]]]])\n\nPerform linear regression calculation on all threshold pixels of the image. This calculation is performed by the least square method, which is usually faster, but cannot handle any outliers. If robust is True, the Theil index will be used. The Theil index calculates the median of all slopes between all threshold pixels in the image. If you set too many pixels after threshold conversion, this N^2 operation may drop your FPS below 5 even on an 80x60 image. However, as long as the number of pixels to be set after the threshold conversion is small, linear regression is still effective even when more than 30% of the threshold pixels are abnormal values.\n\nThis method returns an image.line object. How to easily use linear objects, please refer to the following blog post: https://openmv.io/blogs/news/linear-regression-line-following\n\nthresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the color range you want to track. For grayscale images, each tuple needs to contain two values-the minimum gray value and the maximum gray value. Only the areas of pixels that fall between these thresholds are considered. For an RGB565 image, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)-the minimum and maximum values ​​of LAB L, A and B channels, respectively. For ease of use, this function will automatically repair the minimum and maximum values ​​of exchange. In addition, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, it is assumed that the remaining thresholds are in the maximum range.\n\n> To obtain the threshold of the tracked object, just select (click and drag) the tracked object in the IDE frame buffer. The histogram will be updated accordingly to the area. Then just write down the starting and falling positions of the color distribution in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, it is better to manually determine the threshold.\n\nYou can also determine the color threshold by entering Tools -> Machine Vision -> Threshold Editor in OpenMV IDE and dragging the slider from the GUI window.\n\ninvert Inversion threshold operation, pixels are matched outside the known color range instead of in the known color range.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nx_stride is the number of x pixels to skip when calling the function.\n\ny_stride is the number of y pixels to skip when calling the function.\n\nIf the bounding box area after regression is less than area_threshold, None is returned.\n\nIf the number of pixels after regression is less than pixel_threshold, None is returned.\n\nDoes not support compressed images and bayer images.\n#### image.find_blobs(thresholds[, invert=False[, roi[, x_stride=2[, y_stride=1[, area_threshold=10[, pixels_threshold=10[, merge=False[, margin=0[, threshold_cb =None[, merge_cb=None]]]]]]]]]]])\n\nFind all the color blocks in the image and return a list of color block objects including each color block. Please observe the image.blob object for more information.\n\nthresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the color range you want to track. For grayscale images, each tuple needs to contain two values-the minimum gray value and the maximum gray value. Only the areas of pixels that fall between these thresholds are considered. For an RGB565 image, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi)-the minimum and maximum values ​​of LAB L, A and B channels, respectively. For ease of use, this function will automatically repair the minimum and maximum values ​​of exchange. In addition, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, it is assumed that the remaining thresholds are in the maximum range.\n\nannotation\n\nTo obtain the threshold of the tracked object, simply select (click and drag) the tracked object in the IDE frame buffer. The histogram will be updated accordingly to the area. Then just write down the starting and falling positions of the color distribution in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, it is better to manually determine the threshold.\n\nYou can also determine the color threshold by entering Tools -> Machine Vision -> Threshold Editor in OpenMV IDE and dragging the slider from the GUI window.\n\ninvert Inversion threshold operation, pixels are matched outside the known color range instead of in the known color range.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nx_stride is the number of x pixels that need to be skipped when searching for a color block. After finding the color block, the straight line filling algorithm will accurately pixel. If the color block is known to be large, you can increase x_stride to increase the speed of finding the color block.\n\ny_stride is the number of y pixels that need to be skipped when searching for a color block. After finding the color block, the straight line filling algorithm will accurately pixel. If the color block is known to be large, y_stride can be increased to increase the speed of searching for the color block.\n\nIf the bounding box area of ​​a color block is smaller than area_threshold, it will be filtered out.\n\nIf the number of pixels of a color block is less than pixel_threshold, it will be filtered out.\n\nIf merge is True, all color blocks that have not been filtered out are merged. The bounding rectangles of these color blocks overlap each other. Margin can be used to increase or decrease the size of the color block boundary rectangle in the intersection test. For example: the color blocks whose edges are 1 and the mutual boundary rectangle is 1 will be merged.\n\nCombining color blocks enables color code tracking. Each color block object has a code value code, which is a bit vector. For example: if you enter two color thresholds in image.find_blobs, the first threshold code is 1, the second code is 2 (the third code is 4, the fourth code is 8, and so on). The merged color block uses a logical OR operation on all codes so that you know the colors that produced them. This allows you to track two colors. If you use two colors to get a color block object, it may be a color code.\n\nIf you use a strict color range and cannot fully track all pixels of the target object, you may need to merge color blocks.\n\nFinally, if you want to merge color blocks, but do not want to merge color blocks of two different threshold colors, just call image.find_blobs twice, and the color blocks of different threshold values ​​will not be merged.\n\nthreshold_cb can be set to call the function of each color block after threshold filtering, so as to filter it from the list of color blocks to be merged. The callback function will receive one parameter: the color block object to be filtered. Then the callback function needs to return True to keep the color blocks or return False to filter the color blocks.\n\nmerge_cb can be set as a function to call two color blocks to be merged to prohibit or permit the merge. The callback function will receive two parameters-two color patch objects to be merged. The callback function must return True to merge color blocks, or return False to prevent color blocks from merging.\n\nDoes not support compressed images and bayer images.\n\n#### image.find_lines([roi[, x_stride=2[, y_stride=1[, threshold=1000[, theta_margin=25[, rho_margin=25]]]]]])\n\nUse Hough Transform to find all straight lines in the image. Return a list of image.line objects.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nx_stride is the number of x pixels that need to be skipped during Hough transform. If the known straight line is larger, you can increase x_stride.\n\ny_stride is the number of y pixels that need to be skipped during Hough transform. If the known straight line is larger, you can increase y_stride.\n\nthreshold controls the straight line detected from the Hough transform. Only return lines greater than or equal to threshold. The correct threshold value for the application depends on the image. Note: The magnitude of a straight line (magnitude) is the sum of the pixel sizes of all Sobel filters that make up the straight line.\n\ntheta_margin controls the merging of the monitored lines. The part where the angle of the straight line is theta_margin is merged with the part where the p value of the straight line is rho_margin.\n\nrho_margin controls the merging of the monitored lines. The part where the angle of the straight line is theta_margin and the part where the p value of the straight line is rho_margin are merged.\n\nThis method runs the Sobel filter on the image and uses the amplitude and gradient response of the filter to perform the Hough transform. No preprocessing of the image is required. However, cleaning the image filter can get more stable results.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_line_segments([roi[, merge_distance=0[, max_theta_difference=15]]])\n\nUse Hough Transform to find line segments in the image. Return a list of image.line objects.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle. The operating range is limited to pixels in the roi area.\n\nmerge_distance specifies the maximum number of pixels between two line segments that can be separated from each other without being merged.\n\nmax_theta_difference is the maximum angle difference between the two line segments to be merged by the above merge_distancede.\n\nThis method uses the LSD library (also used by OpenCV) to find line segments in the image. This is a bit slow, but very accurate, and the line segments will not jump.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_circles([roi[, x_stride=2[, y_stride=1[, threshold=2000[, x_margin=10[, y_margin=10[, r_margin=10]]]]]]])\n\nUse the Hough transform to find the circle in the image. Return a list of image.circle objects (see above).\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle. The operating range is limited to pixels in the roi area.\n\nx_stride is the number of x pixels that need to be skipped during Hough transform. If the circle is known to be larger, you can increase x_stride.\n\ny_stride is the number of y pixels that need to be skipped during Hough transform. If the circle is known to be larger, y_stride can be increased.\n\nthreshold controls the circle detected from the Hough transform. Only return circles greater than or equal to threshold. The correct threshold value for the application depends on the image. Note: The size of a circle (magnitude) is the sum of the sizes of all Sobel filter pixels that make up the circle.\n\nx_margin controls the merging of the detected circles. The round pixels are the partial merge of x_margin, y_margin and r_margin.\n\ny_margin controls the merging of the detected circles. The round pixels are the partial merge of x_margin, y_margin and r_margin.\n\nr_margin controls the merging of the detected circles. The round pixels are the partial merge of x_margin, y_margin and r_margin.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_rects([roi=Auto, threshold=10000])\n\nUse the same quad detection algorithm used to find AprilTAg to find rectangles in the image. Best for rectangles that contrast sharply with the background. AprilTag's quad detection can handle arbitrary scaling/rotation/cutting of rectangles. Returns a list of image.rect objects.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle. The operating range is limited to the pixels in the roi area.\n\nRectangles with a boundary size (by sliding the Sobel operator on all pixels on the edge of the rectangle and adding the value) less than threshold will be filtered from the returned list. The correct value of threshold depends on your application/scenario.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_qrcodes([roi])\n\nFind all QR codes in roi and return a list of image.qrcode objects. Please refer to the image.qrcode object for more information.\n\nIn order for this method to run successfully, the QR code on the image needs to be relatively flat. By using the sensor.set_windowing function to zoom in the center of the lens, the image.lens_corr function to eliminate the barrel distortion of the lens or by changing the lens with a narrower field of view, you can get a flatter QR code that is not affected by lens distortion. Some machine vision lenses do not cause barrel distortion, but their cost is much higher than the standard lenses provided by OpenMV, which are distortion-free lenses.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\nimage.find_apriltags([roi[, families=image.TAG36H11[, fx[, fy[, cx[, cy]]]]]])\nFind all AprilTags in roi, and return a list of image.apriltag objects. Please refer to the image.apriltag object for more information.\n\nCompared with two-dimensional codes, AprilTags can be detected at longer distances, poorer light, and more distorted image environments. AprilTags can deal with all kinds of image distortion problems, but two-dimensional codes cannot. In other words, AprilTags can only encode a digital ID as its payload.\n\nAprilTags can also be used for localization. Each image.apriltag object returns its three-dimensional position information and rotation angle from the camera. The position information is determined by fx, fy, cx and cy, which are the focal length and center point of the image in the X and Y directions, respectively.\n> Use the built-in tag generator tool of OpenMV IDE to create AprilTags. The label generator can create printable 8.5\"x11\" AprilTags.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nfamilies is the bit mask of the tag family to be decoded. Is a logical OR:\n\nimage.TAG16H5\nimage.TAG25H7\nimage.TAG25H9\nimage.TAG36H10\nimage.TAG36H11\nimage.ARTOOLKIT\nThe default setting is the best image.TAG36H11 tag family. Note: Each time you enable a tag family, the speed of find_apriltags will slow down slightly.\n\nfx is the focal length of the camera in the x direction in pixels. The value of the standard OpenMV Cam is (2.8 / 3.984) * 656, which is obtained by dividing the focal length in millimeters by the length of the photosensitive element in the X direction, and multiplying it by the number of pixels of the photosensitive element in the X direction (for OV7725 photosensitive element In terms of).\n\nfy is the focal length of the camera in the y direction in pixels. The value of the standard OpenMV Cam is (2.8 / 2.952) * 488, which is obtained by dividing the focal length in millimeters by the length of the photosensitive element in the Y direction, and multiplying it by the number of pixels of the photosensitive element in the Y direction (for OV7725 photosensitive element In terms of).\n\ncx is the center of the image, which is image.width()/2 instead of roi.w()/2.\n\ncy is the center of the image, ie image.height()/2, not roi.h()/2.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\nimage.find_datamatrices([roi[, effort=200]])\nFind all data matrices in roi and return a list of image.datamatrix objects. Please refer to the image.datamatrix object for more information.\n\nIn order for this method to run successfully, the rectangular code on the image needs to be relatively flat. By using the sensor.set_windowing function to zoom in at the center of the lens, the image.lens_corr function to eliminate the barrel distortion of the lens, or by changing the lens with a narrower field of view, you can get a flatter rectangular code that is not affected by lens distortion. Some machine vision lenses do not cause barrel distortion, but their cost is much higher than the standard lens provided by OpenMV, which is a distortion-free lens.\n\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\neffort controls the time used to find a rectangle code match. The default value of 200 should apply to all use cases. But you may also increase detection at the expense of frame rate, or increase frame rate at the expense of detection. Note: If effort is set below about 160, you will not be able to perform any detection; instead, you can set it to any high value you need, but if the setting is higher than 240, the detection rate will not continue to increase.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_barcodes([roi])\n\nFind all one-dimensional barcodes in roi and return a list of image.barcode objects. Please refer to the image.barcode object for more information.\n\nFor best results, please use a window of 640 length and 40/80/160 width. The lower the verticality, the faster the running speed. Since the barcode is a linear one-dimensional image, it only needs to have a higher resolution in one direction and a lower resolution in the other direction. Note: This function performs horizontal and vertical scanning, so you can use a window with a width of 40/80/160 and a length of 480. Finally, be sure to adjust the lens so that the barcode will be positioned where the focal length produces the clearest image. Fuzzy barcodes cannot be decoded.\n\nThis function supports all one-dimensional barcodes:\n\nimage.EAN2\nimage.EAN5\nimage.EAN8\nimage.UPCE\nimage.ISBN10\nimage.UPCA\nimage.EAN13\nimage.ISBN13\nimage.I25\nimage.DATABAR (RSS-14)\nimage.DATABAR_EXP (RSS-Expanded)\nimage.CODABAR\nimage.CODE39\nimage.PDF417\nimage.CODE93\nimage.CODE128\nroi is a rectangular region of interest (x, y, w, h) to be copied. If not specified, ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nDoes not support compressed images and bayer images.\n\nThis method is not available on OpenMV Cam M4.\n\nimage.find_displacement(template[, roi[, template_roi[, logpolar=False]]])\nFind the transformation offset of this image from the template. This method can be used to make optical flow. This method returns an image.displacement object that contains the result of the displacement calculation using phase correlation.\n\nroi is the rectangular area (x, y, w, h) to be processed. If not specified, it is equal to the image rectangle.\n\ntemplate_roi is the rectangular area (x, y, w, h) to be processed. If not specified, it is equal to the image rectangle.\n\nroi and template roi must have the same w/h, but x/y can be anywhere in the image. You can slide the smaller rois on the larger image to get the optical flow gradient image.\n\nimage.find_displacement usually calculates the x/y translation between two images. However, if you set logpolar = True, it will find changes in rotation and scaling between the two images. The same image.displacement object results in two possible feedbacks.\n\nDoes not support compressed images and bayer images.\n\nannotation\n\nPlease use this method on images with the same length and width (such as ``sensor.B64X64'').\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.find_number(roi)\n\nRun LENET-6 CNN (Convolutional Neural Network) trained on the MINST dataset to detect numbers in 28x28 ROI located anywhere on the image. Return a tuple containing integers and floating-point numbers, representing the detected number (0-9) and the detection confidence (0-1).\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly grayscale images are supported.\n\nannotation\n\nThis method is experimental. If you run any CNN trained on PC using Caffe in the future, this method may be deleted. The latest firmware version 3.0.0 has removed this function.\n\nThis method is not available on OpenMV Cam M4.\n\n#### image.classify_object(roi)\n\nRun CIFAR-10 CNN on the ROI of the image to detect airplanes, cars, birds, cats, deer, dogs, frogs, horses, boats and trucks. This method automatically scales the image to 32x32 internally to feed the CNN.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly supports RGB565 images.\n\nannotation\n\nThis method is experimental. If you run any CNN trained on PC using Caffe in the future, this method may be deleted.\n\nThis method is not available on OpenMV Cam M4.\n\nimage.find_template(template, threshold[, roi[, step=2[, search=image.SEARCH_EX]]])\nTry to use the normalized cross-correlation (NCC) algorithm to find the first template match in the image. Returns the bounding box tuple (x, y, w, h) of the matching position, otherwise returns None.\n\ntemplate is a small image object that matches this image object. Note: Both images must be grayscale.\n\nThreshold is a floating point number (0.0-1.0), where the smaller value increases the detection rate while increasing the false alarm rate. Conversely, a higher value will reduce the detection rate and at the same time reduce the false alarm rate.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nstep is the number of pixels that need to be skipped when searching for a template. Skipping pixels can greatly increase the speed of the algorithm. This method is only applicable to algorithms in SERACH_EX mode.\n\nsearch can be image.SEARCH_DS or image.SEARCH_EX. The algorithm used by image.SEARCH_DS to search for a template is faster than image.SEARCH_EX, but if the template is located around the edge of the image, the search may not succeed. image.SEARCH_EX can perform a more detailed search on images, but its running speed is much slower than image.SEARCH_DS.\n\nOnly grayscale images are supported.\n\n#### image.find_features(cascade[, threshold=0.5[, scale=1.5[, roi]]])\n\nThis method searches images of all regions that match Haar Cascade and returns a list of bounding box rectangle tuples (x, y, w, h) about these features. If no features are found, a blank list is returned.\n\ncascade is a Haar Cascade object. See image.HaarCascade() for details.\n\nThreshold is a floating point number (0.0-1.0), where the smaller value increases the detection rate while increasing the false alarm rate. Conversely, a higher value will reduce the detection rate and at the same time reduce the false alarm rate.\n\nscale is a floating point number that must be greater than 1.0. A higher scale factor runs faster, but its image matching is relatively poor. The ideal value is between 1.35-1.5.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly grayscale images are supported.\n\n#### image.find_eye(roi)\n\nFind the pupil in the area of ​​interest (x, y, w, h) around the eye. Returns a tuple containing the position of the pupil (x, y) in the image. If no pupil is found, return (0,0).\n\nBefore using this function, first use image.find_features() and Haar operator frontalface to search for someone's face. Then use image.find_features and Haar operator find_eye to search for eyes on the face. Finally, call this method on each eye ROI returned after calling the image.find_features function to get the coordinates of the pupil.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly grayscale images are supported.\n\n#### image.find_lbp(roi)\n\nExtract LBP (local binary mode) key points from the ROI tuple (x, y, w, h). You can use the image.match_descriptor function to compare two sets of key points to get the matching distance.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly grayscale images are supported.\n#### image.find_keypoints([roi[, threshold=20[, normalized=False[, scale_factor=1.5[, max_keypoints=100[, corner_detector=image.CORNER_AGAST]]]]]]])\n\nExtract ORB key points from the ROI tuple (x, y, w, h). You can use the image.match_descriptor function to compare two sets of key points to get the matching area. If no key point is found, None is returned.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nthreshold is a number that controls the number of extractions (values ​​0-255). For the default AGAST corner detector, this value should be around 20. For FAST corner detectors, this value is about 60-80. The lower the threshold, the more corner points you extract.\n\nnormalized is a boolean value. If True, turn off the key point extraction in multi-resolution. If you don't care about dealing with scaling issues and want the algorithm to run faster, set it to True.\n\nscale_factor is a floating point number that must be greater than 1.0. A higher scale factor runs faster, but its image matching is relatively poor. The ideal value is between 1.35-1.5.\n\nmax_keypoints is the maximum number of keypoints that a keypoint object can hold. If the key point object is too large and causes memory problems, please lower the value.\n\ncorner_detector is the corner detector algorithm used to extract the key points from the image. Can be image.CORNER_FAST or image.CORNER_AGAST. The FAST corner detector runs faster, but its accuracy is lower.\n\nOnly grayscale images are supported.\n\n#### image.find_edges(edge_type[, threshold])\n\nTurn the image into black and white, leaving only the edges as white pixels.\n\nimage.EDGE_SIMPLE-Simple threshold high-pass filtering algorithm\nimage.EDGE_CANNY-Canny edge detection algorithm\nthreshold is a binary tuple containing a low threshold and a high threshold. You can control the edge quality by adjusting this value.\n\nThe default is (100, 200).\n\nOnly grayscale images are supported.\n\nfind_hog([roi[, size=8]])\nReplace the pixels in the ROI with HOG (Histogram of Oriented Gradient) lines.\n\nroi is the rectangular tuple (x, y, w, h) of the region of interest. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to the pixels in the roi area.\n\nOnly grayscale images are supported.\n\nThis method is not available on OpenMV Cam M4.\n\n## Constant\n\n### image.SEARCH_EX\n\nExhaustive template matching search.\n\n### image.SEARCH_DS\n\nFaster template matching search.\n\n### image.EDGE_CANNY\n\nUse the Canny edge detection algorithm to perform edge detection on the image.\n\n### image.EDGE_SIMPLE\n\nUse threshold high-pass filtering algorithm to detect the edge of the image.\n\n### image.CORNER_FAST\n\nHigh-speed and low-accuracy corner detection algorithm for ORB key points\n\n### image.CORNER_AGAST\n\nLow-speed and high-accuracy algorithm for ORB key points.\n\n### image.TAG16H5\n\nBit mask enumeration of TAG1H5 tag group. Used for AprilTags.\n\n### image.TAG25H7\n\nBit mask enumeration of TAG25H7 tag group. Used for AprilTags.\n\n### image.TAG25H9\n\nBitmask enumeration of TAG25H9 tag group. Used for AprilTags.\n\n### image.TAG36H10\n\nBit mask enumeration of TAG36H10 tag group. Used for AprilTags.\n\n### image.TAG36H11\n\nBit mask enumeration of TAG36H11 tag group. Used for AprilTags.\n\n### image.ARTOOLKIT\n\nThe bit mask enumeration of the ARTOOLKIT tag group. Used for AprilTags.\n\n### image.EAN2\n\nEAN2 barcode type enumeration.\n\n### image.EAN5\n\nEAN5 barcode type enumeration.\n\n### image.EAN8\n\nEAN8 barcode type enumeration.\n\n### image.UPCE\n\nUPCE barcode type enumeration.\n\n### image.ISBN10\n\nISBN10 barcode type enumeration.\n\n### image.UPCA\n\nUPCA barcode type enumeration.\n\n### image.EAN13\n\nEAN13 barcode type enumeration.\n\n### image.ISBN13\n\nISBN13 barcode type enumeration.\n\n### image.I25\n\nI25 barcode type enumeration.\n\n### image.DATABAR\n\nDATABAR barcode type enumeration.\n\n### image.DATABAR_EXP\n\nDATABAR_EXP barcode type enumeration.\n\n### image.CODABAR\n\nEnumeration of CODABAR barcode types.\n\n### image.CODE39\n\nCODE39 barcode type enumeration.\n\n### image.PDF417\n\nPDF417 barcode type enumeration (currently not working).\n\n### image.CODE93\n\nCODE93 barcode type enumeration.\n\n### image.CODE128\n\nCODE128 barcode type enumeration."}, "/soft/maixpy/en/api_reference/machine_vision/isolated_word.html": {"title": "isolated_word (isolated word MFCC module)", "content": "---\ntitle: isolated_word (isolated word MFCC module)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: isolated_word (isolated word MFCC module)\n---\n\n\n## Class (class)\n\n### isolated_word\n\nThe isolated_word construction parameters are as follows:\n\n-`dmac`: DMA channel used for recording. [Channel 2] is used by default.\n-`i2s`: Recording device, I2S.DEVICE_0 is used by default.\n-`size`: The capacity of vocabulary templates, which means the total number of templates that can be loaded. The default is 10.\n-`shift`: Channel selection. Maix series hardware recording devices usually use mono input. Set 0 as the left channel, so 1 is the right channel.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word(dmac=2, i2s=I2S.DEVICE_0, size=10, shift=0)\n```\n\n## Method (function)\n\n### size\n\nReturns the total number of current word templates.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nsr.size()\n```\n\n### set_threshold\n\nSet the working parameters of the isolated word module.\n\n-Parameter①: Noise threshold, used for short-time zero-crossing rate calculation\n-Parameter ②: Short-time zero-crossing rate threshold, exceeding this threshold is regarded as entering the transition section.\n-Parameter ③: Short-term accumulation and threshold value. If the threshold is exceeded, it is regarded as entering the transition section.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nsr.set_threshold(0, 0, 10000)\n```\n\n### record\n\nEnter [Vocabulary Template].\n\n-Parameter ①: Save the entered template to the specified index location.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nwhile True:\n  if sr.Done == sr.record(0):\n    pass\n```\n\n### state\n\nYou can return to the following working status.\n\n\n| Function | Description |\n| --- | --- |\n| Init | The module has been initialized. |\n| Idle | The module is idling and is not working. |\n| Ready | Module recording is processing. |\n| MaybeNoise| The module determines whether it is a noise environment. |\n| Speak | The module waits for voice recording. |\n| Restrain| The data entered by the module is illegal, and the module returns to the Speak state. |\n| Done | The module voice recognition is successful, and the result can be obtained through result. |\n\n### recognize\n\nRecognize [word template].\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nwhile True:\n  if sr.Done == sr.recognize():\n    print(sr.result())\n```\n\n### result\n\nGet [Vocabulary Template] and return an array of (matched template number, matched dtw value, current frame length, matched frame length).\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nprint(sr.result())\n```\n\n### get\n\nGet 【Vocabulary Template】, and return (data frame length, data frame) array.\n\n#### return value\n\n* `frm_len`: data frame length\n* `frm_data`: data frame\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nprint(sr.get(0))\n```\n\n### set\n\nLoad [Vocabulary Template] into the module.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nprint(sr.set(1, sr.get(0)))\n```\n\n### run\n\nRun the isolated word module (recording).\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nsr.run()\n```\n\n### reset\n\nReset the isolated word module.\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nsr.reset()\n```\n\n### dtw\n\nBack to Dynamic Time Warping (DTW) algorithm Calculate the optimal matching value, the smaller the value, the better.\n\n#### return value\n\n* `dis`: Cumulative matching distance (int)\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nprint(sr.dtw(sr.get(0)))\n```\n\n### __del__\n\nTo release the orphan word module, it can be called actively, or it can be automatically collected by gc.collect().\n\n```python\nfrom speech_recognizer import isolated_word\nsr = isolated_word()\nsr.__del__()\ndel sr\n```"}, "/soft/maixpy/en/api_reference/machine_vision/sensor.html": {"title": "sensor (camera)", "content": "---\ntitle: sensor (camera)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: sensor (camera)\n---\n\n\nsensor sensor module (here specifically refers to the camera module), for camera configuration and image capture, etc., used to control the development board camera to complete the camera task.\n\n\n## Method\n\n### Initialize the monocular camera\n\nReset and initialize the monocular camera\n\n```python\nsensor.reset([, freq=24000000[, set_regs=True[, dual_buff=False]]])\n```\n\n#### Parameters\n\n* `freq`: Set the camera clock frequency, the higher the frequency, the higher the frame rate, but the image quality may be worse. The default is `24MHz`, if the camera has colored spots (ov7740), you can adjust it appropriately, such as `20MHz`\n* `set_regs`: Allow the program to write camera registers, the default is `True`. If you need to customize the reset sequence, you can set it to `False`, and then use the `sensor.__write_reg(addr, value)` function to customize the write register sequence\n* `dual_buff`: The default is `False`. Double buffering is allowed, which will increase the frame rate, but the memory usage will also increase (about 384KiB)\n* `choice`: Specify the type of camera to be searched, ov type (1), gc type (2), mt type (3), if this parameter is not passed, all types of cameras will be searched\n\n#### return value\n\nno\n\n### Reset the binocular camera\n\nReset and initialize the binocular camera\n\n> K210 has only one DVP interface and can only control one Sensor at a time. But we can use the `shudown` method to control the PWDN pin to select a specific Sensor. The remaining operations remain unchanged after the Sensor is specified. See\n\nRoutine 2\n\n```python\nsensor.binocular_reset()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### Set frame size\n\nUsed to set the output frame size of the camera, k210 supports the maximum VGA format, and the image cannot be obtained if it is larger than VGA\n\n> The screen configured on the MaixPy development board is 320*240 resolution, and it is recommended to set it to QVGA format\n\n```\nsensor.set_framesize(framesize[, set_regs=True])\n```\n\n#### Parameters\n\n* `framesize`: frame size\n* `set_regs`: Allow the program to write camera registers, the default is `True`. If you need to customize the sequence of setting the frame size, you can set it to `False`, and then use the `sensor.__write_reg(addr, value)` function to customize the write register sequence\n\n#### return value\n\n* `True`: set successfully\n* `False`: setting error\n\n### Set frame format\n\nUsed to set the camera output format\n\n> The screen configured on the MaixPy development board uses RGB565, and it is recommended to set it to RGB565 format\n\n```\nsensor.set_pixformat(format[, set_regs=True])\n```\n#### Parameters\n\n* `format`: Frame format\n* `set_regs`: Allow the program to write camera registers, the default is `True`. If you need to customize the sequence of setting the pixel format, you can set it to `False`, and then use the `sensor.__write_reg(addr, value)` function to customize the write register sequence\n\n> Available frame formats are `GRAYSCALE`, `RGB565`, `YUV422`\n\n#### return value\n\n* `True`: set successfully\n* `False`: setting error\n\n### Image capture control\n\nImage capture function control\n\n```\nsensor.run(enable)\n```\n#### Parameters\n\n* `enable`: 1 means start capturing images 0 means stop capturing images\n\n#### return value\n\n* `True`: set successfully\n* `False`: setting error\n\n\n### Take an image\n\nTake a picture with the camera\n\n```\nsensor.snapshot()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* `img`: The returned image object\n\n### Camera control\n\nTurn off the camera / switch camera\n\n```\nsensor.shutdown(enable/select)\n```\n#### Parameters\n\nMonocular camera\n* `enable`: True means to turn on the camera False means to turn off the camera\n\nBinocular camera\n* `select`: switch camera by writing 0 or 1\n\n#### return value\n\nno\n\n### Frame skip\n\nSkip the specified number of frames or skip the image within the specified time, so that the camera image is stable after changing the camera settings\n\n```\nsensor.skip_frames(n, [, time])\n```\n#### Parameters\n\n* `n`: skip n frames of images\n\n* `time`: skip the specified time, the unit is ms\n\n> If n and time are not specified, the method skips 300 milliseconds of frames; if both are specified, the method skips n number of frames, but will return after time milliseconds\n\n#### return value\n\nno\n\n### Resolution width\n\nGet the camera resolution width\n\n```\nsensor.width()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* `int` type of camera resolution width\n\n\n\n### Resolution height\n\nGet the camera resolution height\n\n```\nsensor.height()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* `int` type of camera resolution height\n\n### Get frame buffer\n\nGet the current frame buffer\n\n```\nsensor.get_fb()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* Objects of type `image`\n\n### Get ID\n\nGet the current camera ID\n\n```\nsensor.get_id()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* ID of type `int`\n\n### Set the color bar test mode\n\nSet the camera to the color bar test mode\n\n> After the color bar test mode is turned on, the camera will output a color bar image, which is often used to check whether the camera bus is connected correctly.\n```\nsensor.set_colorbar(enable)\n```\n#### Parameters\n\n* `enable`: 1 means turn on the color bar test mode 0 means turn off the color bar test mode\n\n#### return value\n\nno\n\n### Set contrast\n\nSet camera contrast\n\n```\nsensor.set_contrast(contrast)\n```\n#### Parameters\n\n* `constrast`: camera contrast, the range is [-2,+2]\n\n#### return value\n\n* `True`: set successfully\n* `False`: setting error\n\n### Set brightness\n\nSet camera brightness\n\n```\nsensor.set_brightness(brightness)\n```\n#### Parameters\n\n* `brightness`: Camera brightness, range [-2,+2]\n\n####  return value\n\n* `True`: set successfully\n* `False`: setting error\n\n### Set saturation\n\nSet camera saturation\n\n```\nsensor.set_saturation(saturation)\n```\n#### Parameters\n\n* `constrast`: camera saturation, the range is [-2,+2]\n\n#### return value\n\n* `True`: set successfully\n* `False`: setting error\n\n### Set automatic gain\n\nSet camera auto gain mode\n\n```\nsensor.set_auto_gain(enable,gain_db)\n```\n\n#### Parameters\n\n* `enable`: 1 means turn on auto gain 0 means turn off auto gain\n* `gain_db`: When auto gain is turned off, the set camera fixed gain value, the unit is dB\n\n> If you need to track the color, you need to turn off the automatic gain\n\n\n#### return value\n\nno\n\n### Get the gain value\n\nGet the camera gain value\n\n```\nsensor.get_gain_db()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\n* `float` type gain value\n\n### Set horizontal mirroring\n\nSet camera horizontal mirroring\n\n```\nsensor.set_hmirror(enable)\n```\n\n#### Parameters\n\n* `enable`: 1 means enable horizontal mirroring 0 means turn off horizontal mirroring\n\n#### return value\n\nno\n### Set the camera to flip vertically\n\nSet the camera to flip vertically\n\n```\nsensor.set_vflip(enable)\n```\n\n#### Parameters\n\n* `enable`: 1 means turn on vertical flip 0 means turn off vertical flip\n\n#### return value\n\nno\n\n### Write register\n\nWrite the specified value to the camera register\n\n```\nsensor.__write_reg(address, value)\n```\n\n#### Parameters\n\n* `address`: register address\n* `value`: write value\n\n#### return value\n\nno\n\n> Please refer to the camera data sheet for details\n\n### Read register\n\nRead camera register value\n\n```\nsensor.__read_reg(address)\n```\n\n#### Parameters\n\n* `address`: register address\n\n#### return value\n\n* `int` type of register value\n\n> Please refer to the camera data sheet for details\n\n### set_jb_quality\n\nSet the quality of the image transmitted to the IDE\n\n```\nsensor.set_jb_quality(quality)\n```\n\n#### Parameters\n\n`quality`: `int` type, image quality percentage (0~100), the larger the number, the better the quality\n\n## Routine\n\n\n### Routine 1\n\n```python\n# Monocular camera\n\nimport sensor\nimport lcd\n\nlcd.init()\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\n\nwhile True:\n    img = sensor.snapshot()\n    lcd.display(img)\n```\n\n### Routine 2\n\n```python\n# Binocular camera\n\nimport sensor\nimport image\nimport lcd\nimport time\n\nlcd.init()\n\nsensor.binocular_reset()\nsensor.shutdown(0) # Select sensor 0\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\n\nsensor.shutdown(1) # Select sensor 1\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\n\nwhile True:\n    sensor.shutdown(0) # Select sensor 0\n    img = sensor.snapshot()\n    lcd.display(img)\n    time.sleep_ms(100)\n\n    sensor.shutdown(1) # Select sensor 1\n    img = sensor.snapshot()\n    lcd.display(img)\n    time.sleep_ms(100)\n```"}, "/soft/maixpy/en/api_reference/machine_vision/lcd.html": {"title": "lcd (screen display)", "content": "---\ntitle: lcd (screen display)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: lcd (screen display)\n---\n\n\n\n\n## Function\n\n### lcd.init(type=1, freq=15000000, color=lcd.BLACK, invert = 0, lcd_type = 0)\n\nInitialize the `LCD` screen display\n\n#### Parameters\n\n* `type`: Type of device (reserved for future use):\n  * `0`: None\n  * `1`: lcd shield (default value)\n  * `2`: Maix Cube\n  * `5`: sipeed rgb screen adapter board\n> type is a key-value parameter, which must be explicitly called by writing type= in the function call\n\n* `freq`: the frequency of `LCD` (actually refers to the communication rate of `SPI`)\n\n* `color`: The color initialized by `LCD`, which can be a 16-bit `RGB565` color value, such as `0xFFFF`; or a `RGB888` tuple, such as `(236, 36, 36)`, which defaults to `lcd. BLACK`\n\n* `invert`: `LCD` inverted color display\n\n* `lcd_type`: lcd type:\n  * `0`: default type\n  * `1`: LCD_TYPE_ILI9486\n  * `2`: LCD_TYPE_ILI9481\n  * `3`: LCD_TYPE_5P0_7P0, a 5-inch or 7-inch LCD with a resolution of 800 * 480 (requires a sipeed adapter board)\n  * `4`: LCD_TYPE_5P0_IPS, 5-inch IPS LCD with a resolution of 854*489 (requires sipeed adapter board)\n  * `5`: LCD_TYPE_480_272_4P3, 4.3-inch LCD with a resolution of 480*272 (sipeed adapter board required)\n\n> MaixCube and MaixAmigo need to configure the power chip before using the LCD, otherwise the screen will be blurred. In this step, the MaixPy firmware will be configured automatically, no manual operation is required, the user only needs to understand.\n\n### lcd.deinit()\n\nLog off the `LCD` driver and release the I/O pins\n\n### lcd.width()\n\nReturns the width of `LCD` (horizontal resolution)\n\n\n### lcd.height()\n\nReturns the height (vertical resolution) of `LCD`.\n\n\n### lcd.type()\n\nReturn the type of `LCD` (reserved for future use):\n\n0: None\n1: lcd Shield\n\n### lcd.freq(freq)\n\nSet or get the frequency of `LCD` (SPI)\n\n#### Paremeters\n\n* `freq`: LCD (SPI) frequency\n\n#### Return\n\nLCD frequency\n\n\n### lcd.set_backlight(state)\n\nSet the backlight status of `LCD`, turning off the backlight will greatly reduce the power consumption of the LCD expansion board\n\n> Not implemented\n\n#### Parameters\n\n* `state`: backlight brightness, value [0,100]\n\n### lcd.get_backlight()\n\nBack to backlight state\n\n#### return value\n\nBacklight brightness, value [0,100]\n\n### lcd.display(image, roi=Auto)\n\nDisplay an image (GRAYSCALE or RGB565) on the LCD screen.\n\nroi is a rectangular tuple (x, y, w, h) of a region of interest. If not specified, it is the image rectangle\n\nIf the roi width is smaller than the lcd width, use a vertical black border to center the roi in the center of the screen (that is, fill the unoccupied area with black).\n\nIf the width of roi is greater than the width of lcd, the roi is at the center of the screen, and the mismatched pixels will not be displayed (that is, the LCD screen displays the center of roi in the form of a window).\n\nIf the height of roi is less than the height of lcd, use a vertical black border to make roi in the center of the screen (that is, fill the unoccupied area with black).\n\nIf the height of roi is greater than the height of lcd, the roi is at the center of the screen, and the mismatched pixels will not be displayed (that is, the LCD screen displays the center of roi in the form of a window).\n\n> roi is a key-value parameter, which must be explicitly called by writing roi= in the function call.\n\n* `oft`: Set the offset coordinate, after setting this coordinate, the surrounding will not be automatically filled\n\n\n### lcd.clear()\n\nClear the LCD screen to black or the specified color.\n\n#### Parameters\n\n* `color`: The color initialized by `LCD`, which can be a 16-bit `RGB565` color value, such as `0xFFFF`; or a tuple of `RGB888`, such as `(236, 36, 36)`\n\n\n### lcd.direction(dir)\n\nIt has been abandoned after `v0.3.1`, please use `lcd.rotation` and `lcd.invert` instead, do not use it unless necessary, the interface will still be reserved for debugging\n\nSet the screen orientation, and whether to mirror, etc.\n\n#### Parameters\n\n* `dir`: Under normal circumstances, `lcd.YX_LRUD` and `lcd.YX_RLDU` are recommended, and there are other values, just exchange `XY` or `LR` or `DU`\n\n### lcd.rotation(dir)\n\nSet `LCD` screen orientation\n\n#### Parameters\n\n* `dir`: value range [0,3], rotate clockwise from `0` to `3`\n\n#### return value\n\nCurrent direction, value [0,3]\n\n### lcd.mirror(invert)\n\nSet whether `LCD` is displayed on mirror\n\n#### Parameters\n\n* `invert`: Whether to display in mirror, `True` or `False`\n\n#### return value\n\nThe current setting, whether to display in a mirror, return to `True` or `False`\n\n### lcd.bgr_to_rgb(enable)\n\nSet whether to enable bgr color display\n\n#### Parameters\n\n* `enable`: Whether to enable bgr display, `True` or `False`\n\n### lcd.fill_rectangle(x, y, w, h, color)\n\nFill a rectangle area on `LCD`\n\n#### Parameters\n\n* `x`: start coordinate `x`\n* `x`: starting coordinate `y`\n* `w`: padding width\n* `h`: Fill height\n* `color`: Fill color, which can be a tuple, such as `(255, 255, 255)`, or `RGB565``uint16` value, such as red `0x00F8`\n\n## Routine\n\n### Example 1: Display English\n\n```python\nimport lcd\n\nlcd.init()\nlcd.draw_string(100, 100, \"hello maixpy\", lcd.RED, lcd.BLACK)\n\n```\n\n### Example 2: Display picture\n\n```python\nimport lcd\nimport image\n\nimg = image.Image(\"/sd/pic.bmp\")\nlcd.display(img)\n```\n\n### Example 3: Display English by displaying pictures\n\n```python\nimport lcd\nimport image\n\nimg = image.Image()\nimg.draw_string(60, 100, \"hello maixpy\", scale=2)\nlcd.display(img)\n```\n\n### Example 4: Display the image captured by the camera in real time\n\n```python\nimport sensor, lcd\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\nsensor.skip_frames()\nlcd.init()\n\nwhile(True):\n    lcd.display(sensor.snapshot())\n```"}, "/soft/maixpy/en/api_reference/machine_vision/index.html": {"title": "machine vision/hearing", "content": "---\ntitle: machine vision/hearing\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: machine vision/hearing\n---\n\n\nIt mainly contains classes related to image, display, and voice, including:\n\n* [lcd](lcd.md)\n* [sensor](sensor.md)\n* [image](./image/image.html)\n* [video](video.md)\n* [isolated_word](isolated_word.md)\n* [maix_asr](maix_asr.md)"}, "/soft/maixpy/en/api_reference/machine_vision/maix_asr.html": {"title": "maix_asr (voice recognition module)", "content": "---\ntitle: maix_asr (voice recognition module)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: maix_asr (speech recognition module)\n---\n\n\n## class (class)\n\n### maix_asr\n\nThe maix_asr construction parameters are as follows:\n\n-[address] Flash address for programming the acoustic model.\n-[i2s] Recording device, I2S.DEVICE_0 is used by default.\n-[dmac] The DMA channel used for recording. [Channel 3] is used by default.\n-[shift] Channel selection. Maix series hardware recording devices usually use mono input. Set 0 as the left channel, so 1 is the right channel.\n\n```python\nfrom speech_recognizer import asr\nclass maix_asr(asr):\n  def config(self, sets):\n    pass\nt = maix_asr(0x500000, I2S.DEVICE_0, 3, shift=0)\n```\n\nThe maix_asr module is an extended configuration interface auxiliary class that inherits the internal asr module, and is implemented as follows:\n\n```python\n\nfrom speech_recognizer import asr\n\nclass maix_asr(asr):\n\n  asr_vocab = [\"lv\", \"shi\", \"yang\", \"chun\", \"yan\", \"jing\", \"da\", \"kuai\", \"wen\", \"zhang\", \"de\", \"di\" , \"se\", \"si\", \"yue\", \"lin\", \"luan\", \"geng\", \"xian\", \"huo\", \"xiu\", \"mei\", \"yi\", \"ang\", \" ran\", \"ta\", \"jin\", \"ping\", \"yao\", \"bu\", \"li\", \"liang\", \"zai\", \"yong\", \"dao\", \"shang\", \"xia\" , \"fan\", \"teng\", \"dong\", \"she\", \"xing\", \"zhuang\", \"ru\", \"hai\", \"tun\", \"zhi\", \"tou\", \"you\", \" ling\", \"pao\", \"hao\", \"le\", \"zha\", \"zen\", \"me\", \"zheng\", \"cai\", \"ya\", \"shu\", \"tuo\", \"qu\" , \"fu\", \"guang\", \"bang\", \"zi\", \"chong\", \"shui\", \"cuan\", \"ke\", \"shei\", \"wan\", \"hou\", \"zhao\", \" jian\", \"zuo\", \"cu\", \"hei\", \"yu\", \"ce\", \"ming\", \"dui\", \"cheng\", \"men\", \"wo\", \"bei\", \"dai\" , \"zhe\", \"hu\", \"jiao\", \"pang\", \"ji\", \"lao\", \"nong\", \"kang\", \"yuan\", \"chao\", \"hui\", \"xiang\", \" bing\", \"qi\", \"chang\", \"nian\", \"jia\", \"tu\", \"bi\", \"pin\", \"xi\", \"zou\", \"chu\", \"cun\", \"wang\" , \"na\", \"ge\", \"an\", \"ning\", \"tian\", \"xiao\", \"zhong\", \"shen\", \"nan\", \"er\", \"ri\", \"zhu\", \" xin\", \"wai\", \"luo\", \"gang\", \"qing\", \"xun\", \"te\", \"cong\", \"gan\", \"lai\", \"he\", \"dan\", \"wei\" , \"die \", \"kai\", \"ci\", \"gu\", \"neng\", \"ba\", \"bao\", \"xue\", \"shuai\", \"dou\", \"cao\", \"mao\", \"bo\", \"zhou\", \"lie\", \"qie\", \"ju\", \"chuan\", \"guo\", \"lan\", \"ni\", \"tang\", \"ban\", \"su\", \"quan\", \"huan \", \"ying\", \"a\", \"min\", \"meng\", \"wu\", \"tai\", \"hua\", \"xie\", \"pai\", \"huang\", \"gua\", \"jiang\", \"pian\", \"ma\", \"jie\", \"wa\", \"san\", \"ka\", \"zong\", \"nv\", \"gao\", \"ye\", \"biao\", \"bie\", \"zui \", \"ren\", \"jun\", \"duo\", \"ze\", \"tan\", \"mu\", \"gui\", \"qiu\", \"bai\", \"sang\", \"jiu\", \"yin\", \"huai\", \"rang\", \"zan\", \"shuo\", \"sha\", \"ben\", \"yun\", \"la\", \"cuo\", \"hang\", \"ha\", \"tuan\", \"gong \", \"shan\", \"ai\", \"kou\", \"zhen\", \"qiong\", \"ding\", \"dang\", \"que\", \"weng\", \"qian\", \"feng\", \"jue\", \"zhuan\", \"ceng\", \"zu\", \"bian\", \"nei\", \"sheng\", \"chan\", \"zao\", \"fang\", \"qin\", \"e\", \"lian\", \"fa \", \"lu\", \"sun\", \"xu\", \"deng\", \"guan\", \"shou\", \"mo\", \"zhan\", \"po\", \"pi\", \"gun\", \"shuang\", \"qiang\", \"kao\", \"hong\", \"kan\", \"dian\", \"kong\", \"pei\", \"tong\", \"ting\", \"zang\", \"kuang\", \"reng\", \"ti \", \"pan\", \"heng\", \"chi\", \"lun\", \"kun\", \"han\", \"lei\", \"zuan\", \"man\", \"sen\", \"duan\", \"leng\", \"su i\", \"gai\", \"ga\", \"fou\", \"kuo\", \"ou\", \"suo\", \"sou\", \"nu\", \"du\", \"mian\", \"chou\", \"hen\" , \"kua\", \"shao\", \"rou\", \"xuan\", \"can\", \"sai\", \"dun\", \"niao\", \"chui\", \"chen\", \"hun\", \"peng\", \" fen\", \"cang\", \"gen\", \"shua\", \"chuo\", \"shun\", \"cha\", \"gou\", \"mai\", \"liu\", \"diao\", \"tao\", \"niu\" , \"mi\", \"chai\", \"long\", \"guai\", \"xiong\", \"mou\", \"rong\", \"ku\", \"song\", \"che\", \"sao\", \"piao\", \" pu\", \"tui\", \"lang\", \"chuang\", \"keng\", \"liao\", \"miao\", \"zhui\", \"nai\", \"lou\", \"bin\", \"juan\", \"zhua\" , \"run\", \"zeng\", \"ao\", \"re\", \"pa\", \"qun\", \"lia\", \"cou\", \"tie\", \"zhai\", \"kuan\", \"kui\", \" cui\", \"mie\", \"fei\", \"tiao\", \"nuo\", \"gei\", \"ca\", \"zhun\", \"nie\", \"mang\", \"zhuo\", \"pen\", \"zun\" , \"niang\", \"suan\", \"nao\", \"ruan\", \"qiao\", \"fo\", \"rui\", \"rao\", \"ruo\", \"zei\", \"en\", \"za\", \" diu\", \"nve\", \"sa\", \"nin\", \"shai\", \"nen\", \"ken\", \"chuai\", \"shuan\", \"beng\", \"ne\", \"lve\", \"qia\" , \"jiong\", \"pie\", \"seng\", \"nuan\", \"nang\", \"miu\", \"pou\", \"cen\", \"dia\", \"o\", \"zhuai\", \"yo\", \" dei\", \"n\", \"ei\", \"nou\", \"bia\", \"eng\", \"den\", \"_\"]\n\n  def get_asr_list(string='xiao-ai-fas-tong-xue'):\n    return [__class__.asr_vocab.index(t) for t in string.split('-') if t in __class__.asr_vocab]\n\n  def get_asr_string(listobj=[117, 214, 257, 144]):\n    return'-'.join([__class__.asr_vocab[t] for t in listobj if t <len(__class__.asr_vocab)])\n\n  def unit_test():\n    print(__class__.get_asr_list('xiao-ai'))\n    print(__class__.get_asr_string(__class__.get_asr_list('xiao-ai-fas-tong-xue')))\n\n  def config(self, sets):\n    self.set([(sets[key], __class__.get_asr_list(key)) for key in sets])\n\n  def recognize(self):\n    res = self.result()\n    # print(tmp)\n    if res != None:\n      sets = {}\n      for tmp in res:\n        sets[__class__.get_asr_string(tmp[1])] = tmp[0]\n        #print(tmp[0], get_asr_string(tmp[1]))\n      return sets\n    return None\n\n```\n\n### function\n\n#### config\n\nYou can configure the vocabulary list required for speech recognition. The maximum number is no more than 6 notes. If it exceeds, it will be ignored. The parameter is `'xiao-ai-ya': 0.3` corresponding Chinese pinyin string and the lowest probability of matching (threshold) And note that it does not distinguish between tones, so there is no difference between `you-hao-ya` and `ni-hao-ya`, so when designing, pay attention to whether the tone of the vocabulary will form new words.\n\nThe use case is as follows:\n\n```python\n  t.config({\n    'xiao-ai-ya': 0.3,\n    'hao-de-ya': 0.2,\n    'ni-hao-ya': 0.3,\n  })\n```\n\n#### recognize\n\nThe vocabulary configured in the config function will be recognized.\n\nThe use case is as follows:\n\n```python\ntmp = t.recognize()\n# print(tmp)\nif tmp != None:\n    print(tmp)\n```\n\nReturn result:\n\n```python\n{\n    'xiao-ai-ya': 0.9,\n    'xiao-ai': 0.2,\n}\n```\n\nIt is the same as the parameter in config, only given as the return value. You can see that there are two matching results of `小-爱-duck` and `小-爱`.\n\n#### state\n\nIt is expected that the asr module can be executed within 100ms, it will return the current module status, and the return result can be ignored. The usage is as follows:\n```python\nfrom machine import Timer\n\ndef on_timer(timer):\n  #print(\"time up:\",timer)\n  #print(\"param:\",timer.callback_arg())\n  timer.callback_arg().state()\n\n# default: maix dock / maix duino set shift=0\nt = maix_asr(0x500000, I2S.DEVICE_0, 3, shift=0) # maix bit set shift=1\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=64, callback=on_timer, arg=t)\ntim.start()\n```\n\nIt can be seen that on_timer will execute the timer.callback_arg().state() function in a 64 ms cycle, where timer.callback_arg() is an instance of the maix_asr class.\n\n#### run\n\nControl module operation (recording).\n\n#### stop\n\nThe control module stops (recording).\n\n#### __del__\n\nActively call the releaseable module, which can be actively collected by gc.collect()."}, "/soft/maixpy/en/api_reference/media/nes.html": {"title": "NES game emulator", "content": "---\ntitle: NES game emulator\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: NES game emulator\n---\n\n\nThe classic FC red and white game simulator, take us back to our childhood~~\n\n**Warning, this module is only compiled and included in the standard firmware (> 2m), and not included in other firmware. If necessary, please recompile the firmware. **\n\n## Function\n\n### init(rc_type=nes.KEYBOARD, cs, mosi, miso, clk, repeat=16, vol=5)\n\nInitialize the `NES` emulator\n\n#### Parameters\n\n* `tc_type`: remote control type, keyboard (`nes.KEYBOARD`) (note that the serial port communicates with the computer, not directly connecting the USB keyboard to the development board) or handle (`nes.JOYSTICK`).\n> It is recommended to use the `PS2` handle, the experience will be better, the keyboard may not be able to press multiple keys at the same time when inputting through the serial tool, of course, you can also write a script on the PC to forward the key value to solve the problem (go [here] (https ://github.com/sipeed/MaixPy_scripts/tree/master/multimedia/nes) Looking for it?)\n\n* `cs`: If you use the `PS2` handle of the `SPI` interface, pass in the `cs` peripheral number (note that it is not a pin number, you need to map the pin first)\n* `mosi`: If you use the `PS2` handle of the `SPI` interface, pass in the `mosi` peripheral number (note that it is not a pin number, you need to map the pin first)\n* `miso`: If you use the `PS2` handle of the `SPI` interface, pass in the `miso` peripheral number (note that it is not a pin number, you need to map the pin first)\n* `clk`: If you use the `PS2` handle of the `SPI` interface, pass in the `clk` peripheral number (note that it is not a pin number, you need to map the pin first)\n* `repeat`: This parameter is only used when using the keyboard (/serial port), it refers to the repeat rate of the keys\n* `vol`: The volume during initialization, which can be adjusted by pressing the buttons later\n\n### Basic example\n\nRun `NES` game `ROM`\n\n#### Parameters\n\n* `nes`: the path of the game `ROM`, such as `/sd/mario.nes`\n\n```python\ntry:\n  nes.init(nes.INPUT)\n  nes.load(\"/sd/mario.nes\")\n  while True:\n    nes.loop()\nfinally:\n  nes.free()\n```\n\n## hot key\n\n\n### Code input\n\n* `nes.input`: `(①No. handset handle, ②No. handset handle, menu function)`\n\n### Keyboard (/serial port)\n\n* `Move`: `W A S D`\n* `A`: `J`\n* `B`: `K`\n* `start`: `M` or `Enter`\n* `option`: `N` or `\\`\n* `Exit`: `ESC`\n* `Volume -`: `-`\n* `Volume +`: `=`\n* `Running Speed ​​-`: `R`\n* `Run speed +`: `F`\n\n### Handle\n\n* `Move`: Arrow keys `<-` `^` `V` `->`\n* `A`: `□`\n* `B`: `×`\n* `start`: `START`\n* `select`: `SELECT`\n* `Exit`: None\n* `Volume -`: `R2`\n* `Volume +`: `R1`\n* `Run speed -`: `L1`\n* `Run speed +`: `L2`\n\n## Routine\n\n> \"mario.nes\" game file please search and download by yourself\n\n## Example 0: Code input\n\n> January 28, 2021: It is now recommended to use Maix handle (I2C device) to play. The following code comment `nes.input(p1, p2, 0)` means to input the data of two handles.\n\n```python\nimport nes, lcd\nlcd.init(freq=15000000)\ntry:\n  nes.init(nes.INPUT)\n  nes.load(\"mario.nes\")\n  while True:\n    # p1 = i2c.readfrom(66, 1) # handle i2c addr\n    # p2 = i2c.readfrom(74, 1) # handle i2c addr\n    # nes.input(p1, p2, 0)\n    nes.loop()\nfinally:\n  nes.free()\n\n```\n\n## Example 1: Keyboard (serial port)\n\n```python\nimport nes, lcd\n\nlcd.init(freq=15000000)\nnes.init(nes.KEYBOARD)\nnes.load(\"/sd/mario.nes\")\n\nwhile True:\n    nes.loop()\n    \n```\n\n## Example 2: PS2 handle\n\n```python\nimport nes, lcd\nfrom fpioa_manager import fm\n\nfm.register(19, fm.fpioa.GPIOHS19)\nfm.register(18, fm.fpioa.GPIOHS18)\nfm.register(23, fm.fpioa.GPIOHS23)\nfm.register(21, fm.fpioa.GPIOHS21)\n\nlcd.init(freq=15000000)\nnes.init(nes.JOYSTICK, cs=fm.fpioa.GPIOHS19, clk=fm.fpioa.GPIOHS18, mosi=fm.fpioa.GPIOHS23, miso=fm.fpioa.GPIOHS21)\nnes.load(\"/sd/mario.nes\")\n\nwhile True:\n    nes.loop()\n\n```"}, "/soft/maixpy/en/api_reference/media/video.html": {"title": "video", "content": "---\ntitle: video\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: video (video)\n---\n\n\n\nSupports playback and recording of `avi` video\n\n## Global functions\n\n### open(path, record=False, interval=100000, quality=50, width=320, height=240, audio=False, sample_rate=44100, channels=1)\n\nOpen a file to play or record\n\n#### Parameters\n\n* `path`: file path, such as `/sd/badapple.avi`\n* `record`: Whether to record, if you select `Ture`, the video will be recorded, otherwise it will be played. Default `False`\n* `interval`: The recording frame interval, the unit is microseconds, fps = 1000000/interval, the default is `100000`, that is, `10` frames per second\n* `quality`: `jpeg` compression quality (`%`), default `50`\n* `width`: recording screen width, default `320`\n* `height`: Record screen height, default `240`\n* `audio`: Whether to record audio, default is `False`\n* `sample_rate`: Record audio sample rate, default `44100` (`44.1k`)\n* `channels`: the number of recorded audio channels, the default is `1`, which is mono\n\n#### return value\n\nReturn an object, the object returned is different according to different formats.\n\nCurrently only the `avi` format is supported, and objects created by the `avi` class are returned\n\n## Class `avi`\n\nReturned by the `video.open()` function\n\n### play()\n\nPlay video, parse the data (audio or video) every time it is called\n\n#### return value\n\n* `0`: End of playback\n* `1`: Now playing\n* `2`: Pause (reserve)\n* `3`: The currently decoded frame is a video frame\n* `4`: The currently decoded frame is an audio frame\n\n### capture(img)\n\nCapture video frames (sequential capture)\n\n#### Parameters\n\n* `img`: image object, used to store the captured image\n\n#### return value\n\n* `0`: The end of the video has been reached\n* `3`: The video frame is successfully captured\n\n### volume(volume)\n\nSet volume\n\n#### Parameters\n\n* `volume`: volume value, value range: [0,100]\n\n#### return value\n\nSet volume value, value range [0,100]\n\n\n### record()\n\nRecord video and audio. Each time you call to record one frame, the function will limit the speed. If the recording interval is not reached, it will block before reaching the set interval.\n\n#### return value\n\nThe length of the current frame of the recorded video\n\n\n\n\n## Routine\n\n### Example 1: Play `avi` video\n\nFirst of all, make sure that the video is `320x240` size, the video compression format is `mjpeg`, and the audio compression format is `PCM`.\n\nYou can download the video that can be used for testing here: [badapple.avi](http://api.dl.sipeed.com/shareURL/MAIX/MaixPy/assets)\n\n```python\nimport video,time\nfrom Maix import GPIO\n\nfm.register(34, fm.fpioa.I2S0_OUT_D1)\nfm.register(35, fm.fpioa.I2S0_SCLK)\nfm.register(33, fm.fpioa.I2S0_WS)\nfm.register(8, fm.fpioa.GPIO0)\nwifi_en=GPIO(GPIO.GPIO0,GPIO.OUT)\nwifi_en.value(0)\n\nv = video.open(\"/sd/badapple.avi\")\nprint(v)\nv.volume(50)\nwhile True:\n    if v.play() == 0:\n        print(\"play end\")\n        break\nv.__del__()\n\n```\n\nBy default, `I2S0` is used to play audio, so you need to set the pin corresponding to `I2S0`. Turn off the WiFi because the WiFi of the `Dock` board interferes with the sound quality\n\n\n### Example 2: Record `avi` video\n\n\n```python\n\nimport sensor, image, lcd, time\n\nlcd.init(freq=15000000)\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\n\nsensor.set_hmirror(1)\nsensor.set_vflip(1)\n\nsensor.run(1)\nsensor.skip_frames(30)\n\nimport video\n\nv = video.open(\"/sd/capture.avi\", audio = False, record=1, interval=200000, quality=50)\n\ntim = time.ticks_ms()\nfor i in range(50):\n    tim = time.ticks_ms()\n    img = sensor.snapshot()\n    lcd.display(img)\n    img_len = v.record(img)\n    # print(\"record\",time.ticks_ms()-tim)\n\nprint(\"record_finish\")\nv.record_finish()\nv.__del__()\n\n# play your record\nv = video.open(\"/sd/capture.avi\")\nprint(v)\nv.volume(50)\nwhile True:\n    if v.play() == 0:\n        print(\"play end\")\n        break\n\nprint(\"play finish\")\nv.__del__()\n\nlcd.clear()\n```\n\nYou can cancel the print mask to see if the actual recording interval has reached the set frame interval (for example, the `200000us` set here), the actual printing should be `200ms`,\nIf the actual frame interval is greater than the set value, it means that the actual performance does not meet the set requirements. You need to increase the set frame interval to reduce the frame rate.\nIn addition, removing the display and printing can also increase the frame rate to a certain extent.\n\n### Example 3: Sequence `avi` to capture video frames and display\n\n```python\nimport lcd\nimport video\nimport image\n\nlcd.init()\nv = video.open(\"/sd/badapple_320_240_15fps.avi\")\nprint(v)\nimg = image.Image()\nwhile True:\n    status = v.capture(img)\n    if status != 0:\n        lcd.display(img)\n    else:\n        print(\"end\")\n        break;\nv.__del__()\n```"}, "/soft/maixpy/en/api_reference/media/audio.html": {"title": "audio", "content": "---\ntitle: audio\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: audio (audio)\n---\n\n\nAbstract audio object, which can be passed in as a parameter or directly use its method to play audio\n\n## Module function\n\n###  Constructor\n\nConstruct an `Audio` object\n\n```python\naudio.Audio(array=None, path=None, points=1024)\n```\n\n#### Parameters\n\nThe interface can pass in a parameter, each parameter will determine a different audio type\n\n* `array`: `bytearray` type data, which can be converted into audio objects, the default is `None`\n\n* `path`: Open audio file path, currently only supports `wav` format, default is `None`, **Note** The keyword `path`, `audio.Audio(\"/sd/1.wav\" needs to be marked) )`This is wrong! ! `audio.Audio(path = \"/sd/1.wav\")` is correct\n\n* `points`: Open up an audio buffer with points sampling points, one sampling point is 32bit. If it is 0, the buffer will not be opened, and the default is 1024.\n\n####  return value\n\nReturns an `Audio` object\n\n\n### to_bytes: bytes conversion function\n\nConvert the audio data in the audio object to an object of type `bytearray`\n\n```\naudio_data = test_audio.to_bytes()\n```\n\n#### Parameters\n\nno\n\n####  return value\n\nThe returned audio data `bytearray` object\n\n\n### play_process: Play preprocessing function\n\nIt is used to preprocess audio objects. The audio file needs to be parsed before playing, so preprocessing is required. Here you need to pass in an I2S device for playback\n\n```\nwav_info = test_audio.play_process(i2s_dev)\n```\n\n#### Parameters\n\n* `i2s_dev`: i2s device for playback\n\n\n####  return value\n\nThe header information of the wav file, `list` type, are `numchannels` (number of channels), `samplerate` (sampling rate), `byterate` (number of data bytes per second = samplerate * numchannels * bitspersample / 8 ), `blockalign` (the number of bytes required for each sample = numchannels * bitspersample / 8), `bitspersample` (the number of bits stored in each sample, 8: 8bit, 16: 16bit, 32: 32bit), `datasize `(audio data length)\n\n### play: play function\n\nRead audio files and parse them for playback, generally used with loop\n\n\n#### Parameters\n\nno\n\n\n####  return value\n\n* `None`: The format does not support playback\n* `0`: End of playback\n* `1`: Now playing\n\n### finish: Audio post-processing function\n\nTo complete the audio playback, this function must be called after the playback is completed to recover the resources allocated by the bottom layer\n\n\n#### Parameters\n\nno\n\n####  return value\n\nno\n\n## Routine\n\nPlay `wav` audio\n\n```python\nfrom fpioa_manager import *\nfrom Maix import I2S, GPIO\nimport audio\n\n# disable wifi\nfm.register(8, fm.fpioa.GPIO0)\nwifi_en=GPIO(GPIO.GPIO0,GPIO.OUT)\nwifi_en.value(0)\n\n# register i2s(i2s0) pin\nfm.register(34,fm.fpioa.I2S0_OUT_D1)\nfm.register(35,fm.fpioa.I2S0_SCLK)\nfm.register(33,fm.fpioa.I2S0_WS)\n\n# init i2s(i2s0)\nwav_dev = I2S(I2S.DEVICE_0)\n\n# init audio\nplayer = audio.Audio(path = \"/sd/6.wav\")\nplayer.volume(40)\n\n# read audio info\nwav_info = player.play_process(wav_dev)\nprint(\"wav file head information: \", wav_info)\n\n# config i2s according to audio info\nwav_dev.channel_config(wav_dev.CHANNEL_1, I2S.TRANSMITTER,resolution = I2S.RESOLUTION_16_BIT ,cycles = I2S.SCLK_CYCLES_32, align_mode = I2S.RIGHT_JUSTIFYING_MODE)\nwav_dev.set_sample_rate(wav_info[1])\n\n# loop to play audio\nwhile True:\n    ret = player.play()\n    if ret == None:\n        print(\"format error\")\n        break\n    elif ret==0:\n        print(\"end\")\n        break\nplayer.finish()\n```"}, "/soft/maixpy/en/api_reference/index.html": {"title": "", "content": "---\ntitle:\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc:\n---"}, "/soft/maixpy/en/api_reference/extend/touchscreen.html": {"title": "touchscreen (touch screen)", "content": "---\ntitle: touchscreen (touch screen)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: touchscreen (touch screen)\n---\n\n\nThe `touchscreen` module contains basic reading touch screen operations\n\nCurrently supported touch screens:\n\n* ns2009 (default)\n\nIf you need to modify the driver model, you need to recompile the `MaixPy` source code to modify the pre-compiled supported model\n\n\n\n## Global functions\n\n### init(i2c=None, cal=None)\n\nInitialize the touch screen\n\n> API may be changed later (mainly for changes to parameters of multiple drivers)\n\n#### Parameters\n\n* `i2c`: Currently supports the touch screen of `I2C` communication. Pass in the `I2C` instance object, this parameter may be renamed or cancelled later\n* `cal`: Calibration data, a tuple of `7` integer values, which can be obtained by the `touchscreen.calibrate()` function\n\n### calibrate()\n\nCalibrate the screen so that the screen display and touch screen pixels can correspond\n\n#### return value\n\nReturn a tuple of `7` integer values, which can be saved to the file system or `flash` and passed in during initialization, so that there is no need to calibrate every time\n\n### read()\n\nRead the current screen state and the coordinate value of the pressed point\n\n#### return value\n\nA tuple `(status, x, y)` composed of `3` integer values, note that this value will always keep the previous state\n\n* `status`: status, the values ​​are `touchscreen.STATUS_PRESS`, `touchscreen.STATUS_MOVE`, `touchscreen.STATUS_RELEASE`\n* `x`: `x` axis coordinate\n* `y`: `y` axis coordinate\n\n\n## Constant\n\n### touchscreen.STATUS_PRESS\n\nThe screen is pressed, the first value of the tuple returned by the `read()` function\n\n### touchscreen.STATUS_MOVE\n\nThe screen is pressed and moved, that is, press to move, the first value of the tuple returned by the `read()` function\n\n### touchscreen.STATUS_RELEASE\n\nThe screen is no longer held down, that is, there is no click, the first value of the tuple returned by the `read()` function\n\n\n\n## Routine\n\n## Routine 1: Drawing board\n\nBlack background and white pen drawing board, use the `boot` button to clear the content\n\n> Cancel the comment of `ts.calibrate()` to start the touch screen calibration program\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nimport touchscreen as ts\nfrom machine import I2C\nimport lcd, image\nfrom board import board_info\nfrom fpioa_manager import *\n\nboard_info=board_info()\n\nfm.register(board_info.BOOT_KEY, fm.fpioa.GPIO1)\nbtn_clear = GPIO(GPIO.GPIO1, GPIO.IN)\n\nlcd.init()\ni2c = I2C(I2C.I2C0, freq=400000, scl=30, sda=31)\nts.init(i2c)\n#ts.calibrate()\nlcd.clear()\nimg = image.Image()\nstatus_last = ts.STATUS_IDLE\nx_last = 0\ny_last = 0\ndraw = False\nwhile True:\n    (status,x,y) = ts.read()\n    print(status, x, y)\n    if draw:\n        img.draw_line((x_last, y_last, x, y))\n    if status_last!=status:\n        if (status==ts.STATUS_PRESS or status == ts.STATUS_MOVE):\n            draw = True\n        else:\n            draw = False\n        status_last = status\n    lcd.display(img)\n    x_last = x\n    y_last = y\n    if btn_clear.value() == 0:\n        img.clear()\nts.__del__()\n```"}, "/soft/maixpy/en/api_reference/extend/htpa.html": {"title": "modules.htpa (HTPA thermal infrared temperature measurement module)", "content": "---\ntitle: modules.htpa (HTPA thermal infrared temperature measurement module)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: modules.htpa (HTPA thermal infrared temperature measurement module)\n---\n\n\nHyman HTPA 32x32 thermal infrared temperature measurement module\n\n<img src=\"../../../assets/hardware/other/htpa32x32.png\">\n\n## Construction method htpa(i2c, scl_pin, sda_pin, i2c_freq)\n\nCreate an instance\n\n### Parameters\n\n* `i2c`: I2C number, such as `I2C.I2C0`, the value is [0, 2] (see `machine.I2C`)\n* `scl_pin`: I2C SCL pin\n* `sda_pin`: I2C SDA pin\n* `i2c_freq`: I2C clock frequency\n\n\n### return value\n\nhtpa object\n\n\n## Instance method temperature()\n\nGet the sensor temperature value, which can only be called by the instance\n\n### return value\n\nArray, length is the width x height of the sensor, such as `32x32`\n\n## Instance method width()\n\nGet the sensor resolution width, which can only be called by the instance\n\n### return value\n\nInteger, width\n\n## Instance method height()\n\nGet the sensor resolution width, which can only be called by the instance\n\n\n## Examples\n\n[heimann_HTPA_32x32](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/others/heimann_HTPA_32x32)"}, "/soft/maixpy/en/api_reference/extend/onewire.html": {"title": "modules.onewire (single bus)", "content": "---\ntitle: modules.onewire (single bus)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: modules.onewire (single bus)\n---\n\n\nA single bus means that there is only a single signal line, which transmits data and clocks, and the data transmission is also bidirectional, saving IO ports.\n\n## Construction method onewire(gpio_num)\n\n### Parameters\n\n* `gpio_num`: GPIO number.\n\n### return value\n\n* onewire object\n\n## Instance method reset()\n\nReset\n\n### return value\n\n* bool type, whether it is successful.\n\n## Instance method readbit()\n\nRead one bit of data\n\n### return value\n\n* Int type, the data read.\n\n## Instance method readbyte()\n\nRead a byte\n\n### return value\n\n* Int type, the data read.\n\n## Instance method readbuffer(n)\n\nRead the number of bytes of the specified length\n\n### Parameters\n\n* `n`: int type, the number of bytes to be read\n\n### return value\n\n* bytearray type, the byte array read\n\n## Example method writebit(bit)\n\nWrite a bit\n\n### Parameters\n\n* `bit`: int type, bit data to be written\n\n## Example method writebyte(byte)\n\n### Parameters\n\n* `byte`: int type, byte data to be written\n\n## Example method writebuffer(buf)\n\n### Parameters\n\n* `buf`: bytearray type, data to be written\n\n## Example method select(rom_in)\n\nLet the master specify a certain slave.\n\n### Parameters\n\n* `rom_in`: bytearray type, which means that the 8byte ROM data of the slave will be specified.\n\n## Example method search(diff_in)\n\nSearch using F0H criteria\n\n### Parameters\n\n* `diff_in`: int type, the preferred path for the first search\n\n### return value\n\n* `list`: a list with elements (depth, roms), `depth` is the search depth, int type, `rom` is the device ROM code, list type.\n\n## Example method skip()\n\nSkip ROM, suitable for single node\n\n## Example method depower()\n\nRe-enable IO\n\n## Example method crc8(data_in)\n\nCalculate 8-bit cyclic redundancy check code\n\n### Parameters\n\n* `data_in`: data to be verified\n\n### return value\n\n* Return check code"}, "/soft/maixpy/en/api_reference/extend/index.html": {"title": "Peripheral Module", "content": "---\ntitle: Peripheral Module\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: peripheral module\n---\n\n\nThe peripheral modules here mainly refer to off-chip peripherals (as opposed to on-chip peripherals, such as GPIO, I2C, etc.), such as LCD, camera, touch screen, etc.\n\nThe image-related information is temporarily placed in the [Machine Vision](../machine_vision/index.html) category, including the following peripheral modules\n\n* [lcd](../machine_vision/lcd.html): display image\n* [sensor](../machine_vision/sensor.html): Get camera data, named `sensor` and it is compatible with `openmv`, of course it is not exactly the same, please read the document\n\nOther peripheral modules include:\n\n* [touchscreen](./touchscreen.html): touch screen related operations, read the touch screen click status and get the click coordinates, etc.\n* [ws2812](./ws2812.html): WS2812 single bus light strip\n* [Thermal infrared temperature sensor](./htpa.html)\n* [Ultrasonic](./ultrasonic.html)"}, "/soft/maixpy/en/api_reference/extend/ultrasonic.html": {"title": "modules.ultrasonic (ultrasonic ranging module)", "content": "---\ntitle: modules.ultrasonic (ultrasonic ranging module)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: modules.ultrasonic (ultrasonic ranging module)\n---\n\n\nGrove-Ultrasonic Ranger (ultrasonic ranging module), only a single data cable is required\n\n<div class=\"grove_pic\">\n<img src=\"./../../../assets/hardware/module_grove/ultrasonic.jpg\">\n</div>\n\n\n## Construction method ultrasonic(gpiohs)\n\n### Parameters\n\n* `gpiohs`: gpiohs number, you need to use `fm` to register the pin first, for example\n\n```python\nfrom fpioa_manager import *\nfrom modules import ultrasonic\n\nfm.register(board_info.D[6], fm.fpioa.GPIOHS0, force = True)\ndevice = ultrasonic(fm.fpioa.GPIOHS0)\n```\n\n### return value\n\nReturn object\n\n## Method measure(unit, timeout)\n\n### Parameters\n\n* `unit`: unit, take the value in the following constant\n* `timeout`: timeout time, in microseconds (us)\n\n## Constant\n\n### ultrasonic.UNIT_CM\n\nThe unit of the returned distance, cm\n\n### ultrasonic.UNIT_INCH\n\nThe unit of the returned distance, feet"}, "/soft/maixpy/en/api_reference/extend/ws2812.html": {"title": "modules.ws2812 (WS2812 light strip)", "content": "---\ntitle: modules.ws2812 (WS2812 light strip)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: modules.ws2812 (WS2812 light strip)\n---\n\n\nThis module uses the `I2S` of `K210` to drive the module, so you need to pay attention to whether there is conflict during use\n  \nCurrently supports up to 12 street light strips\n\n## Constructor\n\n```python\nfrom modules import ws2812\nclass ws2812(led_pin=-1,led_num=-1,i2s_num=I2S_DEVICE_2,i2s_chn=I2S_CHANNEL_3,i2s_dma_chn=DMAC_CHANNEL1)\n```\nCreate a new `ws2812` object by specifying parameters\n\n### Parameters\n\n* `led_pin`: The pin connected to the light strip data line, such as `board_info.D[4]`\n\n* `led_num`: How many lamp beads are in the strip\n\n* `i2s_num`: Which `I2S` device the object uses to drive, the default is `I2S_DEVICE_2`, the value range is `0-2`\n\n* `i2s_chn`: Which `I2S` channel the object uses, the default is `I2S_CHANNEL_3`, and the value range is `0-3`\n\n* `i2s_dma_chn`: DMA channel used by the object, users generally do not consider\n\n## Method\n\n\n### set_led\n\nSet the color of a certain led light\n\n```python\nclass_ws2812.set_led(num, color)\n```\n\n#### Parameters\n\n* `num`: the `N` lamp beads, starting from `0`\n\n* `color`: the assigned color of the lamp bead, which is of `tuple` type, (R,G,B)\n\n#### return value\n\nno\n\n### display\n\nStart working, call after setting\n\n```python\nclass_ws2812.display()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n## Routine 0\n\nAll 30 LED lights are red\n\n```python\nfrom modules import ws2812\nclass_ws2812 = ws2812(board_info.D[4],30)\nfor i in range(30):\n    class_ws2812.set_led(i,(0xff,0,0))\nclass_ws2812.display()\n```\n\n## Routine 1\n\nLight with red gradient\n\n```python\nfrom modules import ws2812\nclass_ws2812 = ws2812(board_info.D[4],30)\nr=0\ndir = True\nwhile True:\n    if dir:\n        r += 1\n    else:\n        r -= 1\n    if r>=255:\n        r = 255\n        dir = False\n    elif r<0:\n        r = 0\n        dir = True\n    for i in range(30):\n        a = class_ws2812.set_led(i,(r,0,0))\n    a=class_ws2812.display()\n```\n\n> For the above example, see [`MaixPy_scripts`](https://github.com/sipeed/MaixPy_scripts/tree/master/modules/grove/ws2812)"}, "/soft/maixpy/en/api_reference/standard/utime.html": {"title": "utime-time related functions", "content": "---\ntitle: utime-time related functions\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: utime-time related functions\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [time](https://docs.python.org/3.5/library/time.html#module-time).\n\nThe `utime` module provides functions for obtaining the current time and date, measuring time intervals and delays.\n\n**Time Epoch**: The Unix ported version uses the POSIX system era of 1970-01-01 00:00:00 UTC. However, the embedded port version uses the epoch of 2000-01-01 00:00:00 UTC.\n\n**Maintain actual calendar date/time**: This requires a real-time clock (RTC). On systems with underlying OS (including some RTOS), RTC may be implicit. Setting and maintaining the actual calendar time is the responsibility of the OS/RTOS and is done outside of MicroPython, it only uses the OS API to query the date/time. On bare metal porting, the system time depends on the `machine.RTC()` object. You can use `machine.RTC(). The datetime (tuple)` function sets the current calendar time and maintains it in the following ways:\n\n* Through a backup battery (may be an additional optional component on a specific circuit board).\n* Use network time protocol (need to be set by transplantation/user).\n* It is manually set by the user each time it is powered on (many boards maintain the RTC time during hard reset, but some may need to be set again in this case).\nIf the system/MicroPython RTC is not used to maintain the actual calendar time, the functions that refer to the current absolute time below this requirement may not match expectations.\n\n## Function\n\n### utime.localtime([secs])\n\nConvert the time in seconds since the epoch (see above) into an 8-tuple containing: (year, month, day, hour, minute, second, weekday, late) If seconds are not provided or none, then Used for the current time from RTC.\n\n* The year includes the century (for example, 2014).\n* Month is 1-12\n* mday is 1-31\n* Hours are 0-23\n* Minutes are 0-59\n* The second is 0-59\nWorking days from Monday to Sunday are 0-6\n* yearday is 1-366\n\n\n### utime.mktime()\n\nThis is the inverse function of local time. Its parameter is a complete 8-tuple, representing the time expressed in local time. It returns an integer, which is the number of seconds since January 1, 2000.\n\n### utime.sleep(seconds)\n\nSleep for the given number of seconds. Some circuit boards may accept seconds as floating point numbers to sleep for a few seconds. Please note that other boards may not accept floating-point parameters because of their compatibility using `sleep_ms()` and `sleep_us()` functions.\n\n### utime.sleep_ms(ms)\n\nThe delay for a given number of milliseconds should be positive or 0.\n\n### utime.sleep_us(us)\n\nThe delay for a given number of microseconds should be positive or zero.\n\n### utime.ticks_ms()\n\nReturns an incremental millisecond counter with an arbitrary reference point, which wraps around after a certain value.\n\nThe wraparound value is not explicitly disclosed, but we will call it TICKS_MAX to simplify the discussion. The period of the value is TICKS_PERIOD = TICKS_MAX + 1. TICKS_PERIOD is guaranteed to be a power of 2, but it may be different between different hardware migrations. The same period value is used for all `ticks_ms()`, `ticks_us()`, `ticks_cpu()` functions (for simplicity). Therefore, these functions will return values ​​in the range [0 .. TICKS_MAX], including the total TICKS_PERIOD value. Note that only non-negative values ​​are used. In most cases, you should treat the values ​​returned by these functions as opaque. The only operations available are the `ticks_diff()` and `ticks_add()` functions, as described below.\n\n> Note: Performing standard mathematical operations (+,-) or relational operators (<, <=, >,> =) directly on these values ​​will result in invalid results. Performing mathematical operations and then passing the result as a parameter to ticks_diff() or ticks_add() will also cause invalid results of the latter function.\n\n### utime.ticks_us()\n\nJust like'ticks_ms()` above, but within a few microseconds.\n\n### utime.ticks_cpu()\n\nSimilar to `ticks_ms()` and `ticks_us()`, but with the highest resolution in the system. This is usually the CPU clock, which is why the function is named this way. But it does not have to be the CPU clock, but can use some other timing sources available in the system (for example, high-resolution timers). The exact time unit (resolution) of this function is not specified at the'utime' module level, but the documentation for specific hardware may provide more specific information. This function is used for very detailed benchmarks or very tight real-time loops. Avoid using it in portable code.\n\n\n### utime.ticks_add(ticks, delta)\n\nThe offset value is calculated according to the given number, which can be positive or negative. Given a ticks value, this function allows the ticks value delta ticks to be calculated after or after the module arithmetic definition of the tick value (see `ticks_ms()` above). The ticks parameter must be the direct result of calling the `ticks_ms()`, `ticks_us()` or `ticks_cpu()` function (or calling `ticks_add()` from before). However, delta can be any integer or numeric expression. ticks_add() is very useful for calculating the deadline of events/tasks. (Note: You must use the `ticks_diff()` function to handle the deadline.)\n\nexample:\n\n```python\n# Find out what ticks value there was 100ms ago\nprint(ticks_add(time.ticks_ms(), -100))\n\n# Calculate deadline for operation and test for it\ndeadline = ticks_add(time.ticks_ms(), 200)\nwhile ticks_diff(deadline, time.ticks_ms())> 0:\n    do_a_little_of_something()\n\n# Find out TICKS_MAX used by this port\nprint(ticks_add(0, -1))\n```\n\n### utime.ticks_diff(ticks1, ticks2)\n\n\nMeasure the difference between the values ​​returned from the `ticks_ms()`, `ticks_us()`, or `ticks_cpu()` functions as a signed value that can be wrapped.\n\nThe order of the parameters is the same as the subtraction operator. `ticks_diff(ticks1, ticks2)` has the same meaning as `ticks1-ticks2`. However, the value returned by functions such as `ticks_ms()` may wrap around, so using subtraction directly will produce incorrect results. This is why `ticks_diff()` is needed, which implements modular (or more specifically, ring) arithmetic and produces correct results even for surrounding values ​​(as long as they are not too far apart, see below). This function returns a **signed** value in the range [-TICKS_PERIOD / 2 .. TICKS_PERIOD / 2-1] (this is the typical range definition for twos complement signed binary integers). If the result is negative, it means that ticks1 is earlier than ticks2 in time. Otherwise, it means ticks1 occurs after ticks2. If ticks1 and ticks2 are separated from each other by no more than TICKS_PERIOD / 2-1 ticks, only ** is retained. If it is not true, an incorrect result will be returned. Specifically, if two scale values ​​are separated by TICKS_PERIOD / 2-1 scale, the value will be returned by this function. However, if the real-time ticking TICKS_PERIOD/2 has been passed between them, the function will return -TICKS_PERIOD/2, that is, the result value will wrap around to the negative range of possible values.\n\nUnofficial reason for the above restriction: Suppose you are locked in a room and cannot monitor the passage of time except for the standard 12-speed clock. Then, if you look at the watch face now and no longer look at it for 13 hours (for example, if you sleep for a long time), then once you read it again, you may feel that only 1 hour has passed. To avoid this error, please check the clock regularly. Your application should do the same. The metaphor of \"sleeping too long\" also directly maps to application behavior: don't let your application run any single task for too long. Run the task step by step and time between the two.\n\n`ticks_diff()` is designed to adapt to various usage patterns, including:\n\n* Timeout polling. In this case, the sequence of events is known, and you will only deal with the positive results of `ticks_diff()`:\n\n```python\n# Wait for GPIO pin to be asserted, but at most 500us\nstart = time.ticks_us()\nwhile pin.value() == 0:\n    if time.ticks_diff(time.ticks_us(), start)> 500:\n        raise TimeoutError\n```\n\n* Scheduling events. In this case, if the event expires, the ticks_diff() result may be negative:\n\n```python\n# This code snippet is not optimized\nnow = time.ticks_ms()\nscheduled_time = task.scheduled_time()\nif ticks_diff(scheduled_time, now)> 0:\n    print(\"Too early, let's nap\")\n    sleep_ms(ticks_diff(scheduled_time, now))\n    task.run()\nelif ticks_diff(scheduled_time, now) == 0:\n    print(\"Right at time!\")\n    task.run()\nelif ticks_diff(scheduled_time, now) <0:\n    print(\"Oops, running late, tell task to run faster!\")\n    task.run(run_faster=true)\n```\n> Note: Do not pass `time()` values ​​to `ticks_diff()`, you should use regular mathematical operations on them. But please note that `time()` may (also) overflow. This is called https://en.wikipedia.org/wiki/Year_2038_problem.\n\n### utime.time()\n\nReturns the integer number of seconds since the epoch, assuming the basic RTC is set and maintained as described above. If RTC is not set, this function returns the number of seconds since the specific hardware migration reference time point (for embedded circuit boards without battery-powered RTC, usually since power-on or reset). If you want to develop portable MicroPython applications, you should not rely on this function to provide a higher precision than the second. If you need higher precision, use the `ticks_ms()` and `ticks_us()` functions. If you need calendar time, `localtime()` without parameters is a better choice.\n\n#### Difference with CPython\n\nIn CPython, this function returns the number of seconds since the Unix epoch (1970-01-01 00:00 UTC), as a floating point number, usually with microsecond precision. With MicroPython, only the Unix port uses the same epoch, and if floating-point precision allows, it returns sub-second precision. Embedded hardware usually does not have floating-point precision to represent long time ranges and sub-second precision, so they use integer values ​​with second precision. Some embedded hardware also lacks a battery-powered RTC, so it returns the number of seconds since the last power-on or other relative hardware specific point (such as reset).\n\n\n### time.ticks()\n\nEquivalent to `time.ticks_ms`\n\n\n### time.clock()\n\nGet the `clock` object\n\n#### return value\n\n`clock` object\n\n## clock object\n\nReturned by `time.clock()`\n### clock.tick()\n\nRecording start time (ms), used with `clock.fps()` to calculate `fps`\n\n#### return value\n\nNone\n\n### clock.fps()\n\nCalculate the frame rate (`fps`) based on the time from the previous call to `clock.tick()`\n\nsuch as:\n\n```python\nimport sensor\nimport time\nclock = time.clock()\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nwhile True:\nclock.tick()\nsensor.snapshot()\nprint(\"fps = \",clock.fps())\n```\n\n\n\n### clock.reset()\n\nReset all flags\n\n### clock.avg()\n\nCalculate the time consumed per frame based on the time from the previous call to `clock.tick()`"}, "/soft/maixpy/en/api_reference/standard/uhashlib.html": {"title": "uhashlib-hash algorithm", "content": "---\ntitle: uhashlib-hash algorithm\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: uhashlib-hash algorithm\n---\n\n\n\nThis module implements a subset of the corresponding [CPython](http://docs.micropython.org/en/latest/reference/glossary.html#term-cpython) module, as described below. For more information, please refer to the original CPython documentation: [hashlib](https://docs.python.org/3.5/library/hashlib.html#module-hashlib).\n\nThis module implements a hash algorithm for binary data. The exact list of available algorithms depends on the board. Among the algorithms that can be implemented:\n\nThe latest modern hash algorithm of the SHA256-SHA2 series. It is suitable for password security purposes. Unless it has a specific code size limit, it is recommended to include it in the MicroPython kernel, and it is recommended that any development board provides this feature.\n\nThere is hardware acceleration in K210, not software calculation\n\n[Example](https://github.com/sipeed/MaixPy_scripts/blob/master/basic/demo_sha256.py):\n```python\na = bytes([0]*65)\nb = hashlib.sha256(a)\nc = b.digest()\nprint(c)\n```\n\n## Constructor\n\n## Class uhashlib.sha256([data])\n\nCreate a SHA256 hash object and selectively feed data into it.\n\n\n## Method\n\n### hash.update(data)\n\nEnter more binary data into the hash.\n\n### hash.digest()\n\nReturns the hash of all data passed through the hash as a bytes object. After calling this method, no more data can be fed into the hash.\n\n**Note**: In `micropython`, using this function will complete the final calculation, instead of simply displaying the result, it can only be called once. If you want to use this value multiple times, please save it to a variable\n```python\nc = b.digest()\nprint(c)\n```\nMultiple calls will find that the return value is different\n```python\nc = b.digest()\nd = b.digest()\nprint(c == d) # False\n```\n\n### hash.hexdigest()\n\nThis method is not implemented. Use `ubinascii.hexlify(hash.digest())` to get a similar effect."}, "/soft/maixpy/en/api_reference/standard/ubinascii.html": {"title": "ubinascii-Binary/ASCII conversion", "content": "---\ntitle: ubinascii-Binary/ASCII conversion\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ubinascii-Binary/ASCII conversion\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [binascii](https://docs.python.org/3.5/library/binascii.html#module-binascii).\n\nThe module implements the conversion between binary data and its various codes in ASCII format (two directions).\n\n## Function\n\n### ubinascii.hexlify(data[, sep])\n\nConvert binary data to hexadecimal representation. Returns a byte string.\n\n#### Difference with CPython\n\nIf the additional parameter sep is provided, it will be used as a separator between hexadecimal values.\n\n### ubinascii.unhexlify(data)\n\nConvert hexadecimal data to binary representation. Returns a byte string. (Ie the inverse of hexlify)\n\n### ubinascii.a2b_base64(data)\n\nDecode base64-encoded data, ignoring invalid characters in the input. Comply with [RFC 2045 s.6.8.](https://tools.ietf.org/html/rfc2045#section-6.8) Return a bytes object.\n\n### ubinascii.b2a_base64(data)\n\nEncode binary data in base64 format, as described in [RFC 3548](https://tools.ietf.org/html/rfc3548.html). Returns the encoded data, followed by a newline character, as a bytes object."}, "/soft/maixpy/en/api_reference/standard/uzlib.html": {"title": "uzlib — zlib decompression", "content": "---\ntitle: uzlib — zlib decompression\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: uzlib — zlib decompression\n---\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [zlib](https://docs.python.org/3.5/library/zlib.html#module-zlib).\n\nThis module allows to decompress binary data compressed using the [DEFLATE](https://en.wikipedia.org/wiki/DEFLATE) algorithm (usually used in the zlib library and gzip archiver).\n\nCompression has not yet been implemented.\n\n## Function\n\n### decompress\n\nUnzip\n\n```python\nuzlib.decompress(data, wbits=0, bufsize=0)\n```\n\n#### Parameters\n\n* `wbits`: DEFLATE dictionary window size used during compression (8-15, dictionary size is a power of 2 of this value). In addition, if the value is positive, the data is assumed to be a zlib stream (using the zlib header). Otherwise, if it is negative, it is assumed to be the original DEFLATE stream.\n\n* `bufsize`: The parameter is used for compatibility with CPython and can be ignored.\n\n#### return value\n\nReturn the decompressed data as `bytes` type.\n\n### DecompIO\n\nCreate a stream wrapper that allows transparent decompression of compressed data in another stream. This allows processing of compressed streams with data larger than the available heap size. In addition to the values ​​described in decompress(), `wbits` can take the value 24..31 (16+8..15), which means that the input stream has a gzip header.\n\n```python\nclass uzlib.DecompIO(stream, wbits=0)\n```\n\n## Difference from CPython\n\nThis class is a MicroPython extension. It is included on a temporary basis and may be changed or deleted extensively in future versions."}, "/soft/maixpy/en/api_reference/standard/uos.html": {"title": "uos-basic \"operating system\" services", "content": "---\ntitle: uos-basic \"operating system\" services\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: uos-basic \"operating system\" services\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [os](https://docs.python.org/3.5/library/os.html#module-os).\n\nThe `uos` module contains functions for file system access and mounting, terminal redirection and copying, and `uname` and `urandom`.\n\n## Common functions\n\n### uos.uname()\n\nReturn a tuple (perhaps a named tuple) containing information about the underlying machine and/or its operating system. The tuple has five fields in the following order, and each field is a string:\n\n* sysname-the name of the underlying system\n* nodename-node name (/board name) (can be the same as sysname)\n* release-the version of the underlying system\n* version-MicroPython version and build date\n* machine-the identifier of the underlying hardware (for example, board, CPU)\n\n\n### uos.urandom(n)\n\nReturns a bytes object containing n random bytes. Whenever possible, it is generated by a hardware random number generator.\n\n## File system access\n\n### uos.chdir(path)\n\nChange the current directory.\n\n### uos.getcwd()\n\nGet the current directory.\n\n### uos.ilistdir([dir])\n\nThis function returns an iterator and then generates tuples corresponding to the entries in the listed directories. If no parameter is passed, it lists the current directory, otherwise it lists the directory given by dir.\n\nTuples have the form (name, type, inode[, size]):\n\n* name: is a string (if dir is a bytes object, then bytes), and is the name of the entry;\n* type: is an integer that specifies the type of entry, the directory is 0x4000, and the regular file is 0x8000;\n* inode: is an integer corresponding to the file inode, and it can be 0 for file systems without this concept.\n* Some platforms may return a 4-tuple containing the size of the entry. For file entries, size is an integer representing the size of the file, or -1 if unknown. The meaning of the current entry is currently undefined.\n\n\n### uos.listdir([dir])\n\nIf there are no parameters, please list the current directory. Otherwise, list the given directory.\n\n### uos.mkdir(path)\n\nCreate a new directory.\n\n### uos.remove(path)\n\nDelete Files.\n\n### uos.rmdir(path)\n\nDelete the directory.\n\n### uos.rename (old_path, new_path)\n\nRename the file.\n\n### uos.stat(path)\n\nGet the status of a file or directory.\n\n### uos.statvfs(path)\n\nGet the status of the file system.\n\nReturn a tuple containing file system information in the following order:\n\n* f_bsize-file system block size\n* f_frsize-fragment size\n* f_blocks-the size of fs in f_frsize unit\n* f_bfree-the number of free blocks\n* f_bavail-the number of free blocks for unprivileged users\n* f_files-number of inodes\n* f_ffree-the number of free inodes\n* f_favail-the number of free inodes for unprivileged users\n* f_flag-mount flag\n* f_namemax-maximum file name length\n\nParameters related to inodes: `f_files`, `f_ffree`, `f_avail` and `f_flags` parameters may return '0` because they are not available in hardware-specific implementations.\n\n### uos.sync()\n\nSynchronize all file systems.\n\n## Terminal redirection and copy\n\n### uos.dupterm(stream_object, index = 0)\n\nCopy or switch the MicroPython terminal (REPL) on the given `stream` class object. The stream_object parameter must implement the `readinto()` and `write()` methods. The stream should be in non-blocking mode. If there is no data available for reading, `readinto()` should return'None`.\n\nAfter calling this function, all terminal output will be repeated on this stream, and any input available on the stream will be passed to the terminal input.\n\nThe index parameter should be a non-negative integer and specify the set replication slot. A given port can implement multiple slots (slot 0 will always be available), and in this case, terminal input and output are replicated on all set slots.\n\nIf `None` is passed as a stream_object, the copy is canceled on the slot given by the index.\n\nThis function returns the previous stream-like object in the given slot.\n\n## File system mount\n\nSome ports provide a virtual file system (VFS) and the ability to install multiple \"real\" file systems in this VFS. File system objects can be installed in the root directory of the VFS, or in subdirectories in the root directory. This allows dynamic and flexible configuration of the file system seen by the Python program. Ports with this function provide `mount()` and `umount()` functions, as well as various file system implementations that may be represented by the VFS class.\n\n### uos.mount(fsobj, mount_point, *, readonly)\n\nMount the file system object fsobj to the location in the VFS specified by the mount_point string. fsobj can be a VFS object with a mount() method or a block device. If it is a block device, the file system type is automatically detected (if the file system is not recognized, an exception will be raised). mount_point can be'/' to mount fsobj under the root directory, or'/ <name>' to mount to a subdirectory under the root directory.\n\nIf readonly is \"True\", the file system is mounted as read-only.\n\nDuring the mount process, the `mount()` method is called on the file system object.\n\nIf mount_point is already mounted, `OSError(EPERM)` will be raised.\n\n### uos.umount(mount_point)\n\nUnmount the file system. mount_point can be a string naming the location of the mount, or it can be a previously mounted file system object. During the unmounting process, the method `umount()` is called on the file system object.\n\nIf mount_point cannot be found, `OSError (EINVAL)` will be raised.\n\n### class uos.VfsFat(block_dev)\n\nCreate a file system object formatted using the FAT file system. The storage of the FAT file system is provided by block_dev. You can use `mount()` to mount the object created by this constructor.\n\n#### static mkfs(block_dev)\n\nBuild a FAT file system on block_dev.\n\n## File system formatting\n\nIn MaixPy, we provide an operation to format the flash file system. If users want to clear the flash file system, they can use the interface `flash_format` to achieve\n\n### uos.flash_format()\n\nThis interface does not need to pass in parameters, directly use will format the flash of the development board. Please note that formatting will clear all files, please make sure that all files in flash need to be deleted before use\n\n## Block device\n\nA block device is an object that implements a block protocol, which is a set of methods described by the AbstractBlockDev class below. Specific implementations of this type usually allow access to memory-like functions as hardware (such as flash memory). Specific file system drivers can use block devices to store data in their file system.\n\n\n### class uos.AbstractBlockDev()...)\n\nThe building block device object. The parameters of the constructor depend on the specific block device.\n\n#### readblocks(block_num, buf)\n\nStarting from the block given by the index block_num, read the block from the device into buf (byte array). The number of blocks to be read is given by the length of buf, which will be a multiple of the block size.\n\n#### writeblocks(block_num, buf)\n\nStarting from the block given by the index block_num, write the block in buf (byte array) to the device. The number of blocks to be written is given by the length of buf, which will be a multiple of the block size.\n\n#### ioctl(op, arg)\n\nControl the block device and query its parameters. The operation to be performed is given by op, which is one of the following integers:\n\n* 1-Initialize the device (arg is not used)\n* 2-Turn off the device (arg is not used)\n* 3-Synchronization device (arg is not used)\n* 4-Get the count of the number of blocks, it should return an integer (arg is not used)\n* 5-Get the number of bytes in the block, it should return an integer, or \"None\", in this case the default value 512 is used (arg is not used)\n\n### Routine\n\n#### Routine 1\n\nTaking fat32 as an example, the following class will implement a block device that uses `bytearray` to store its data in RAM:\n\n```python\nclass RAMBlockDev:\n    def __init__(self, block_size, num_blocks):\n        self.block_size = block_size\n        self.data = bytearray(block_size * num_blocks)\n\n    def readblocks(self, block_num, buf):\n        for i in range(len(buf)):\n            buf[i] = self.data[block_num * self.block_size + i]\n\n    def writeblocks(self, block_num, buf):\n        for i in range(len(buf)):\n            self.data[block_num * self.block_size + i] = buf[i]\n\n    def ioctl(self, op, arg):\n        if op == 4: # get number of blocks\n            return len(self.data) // self.block_size\n        if op == 5: # get block size\n            return self.block_size\n```\n\nor:\n\n```python\nimport uos\n\nbdev = RAMBlockDev(512, 50)\nuos.VfsFat.mkfs(bdev)\nvfs = uos.VfsFat(bdev)\nuos.mount(vfs,'/ramdisk')\n```\n#### Routine 2\n\nTaking spiffs as an example, the following class will implement a block device, which uses `bytearray` to store its data in RAM:\n```python\n\nclass RAMFlashDev:\n    def __init__(self):\n            self.fs_size = 256*1024\n            self.fs_data = bytearray(256*1024)\n            self.erase_block = 32*1024\n            self.log_block_size = 64*1024\n            self.log_page_size = 4*1024\n    def read(self,buf,size,addr):\n            for i in range(len(buf)):\n                buf[i] = self.fs_data[addr+i]\n    def write(self,buf,size,addr):\n            for i in range(len(buf)):\n                self.fs_data[addr+i] = buf[i]\n    def erase(self,size,addr):\n            for i in range(size):\n                self.fs_data[addr+i] = 0xff\n\n```\n\n```python\n\nblkdev = RAMFlashDev.RAMFlashDev()\nvfs = uos.VfsSpiffs(blkdev)\nvfs.mkfs(vfs)\nuos.mount(vfs,'/ramdisk')\n\n```"}, "/soft/maixpy/en/api_reference/standard/ure.html": {"title": "ure-simple regular expression", "content": "---\ntitle: ure-simple regular expression\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ure-simple regular expression\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [re](https://docs.python.org/3.5/library/re.html#module-re).\n\nThis module implements regular expression operations. The supported regular expression syntax is a subset of the CPython `re` module (actually a subset of POSIX extended regular expressions).\n\n## Supported operators and special sequences\n\n* `.`: matches any character.\n\n* `[...]`: Match character set. Single characters and ranges are supported, including negative sets (eg `[^ a-c]`).\n\n* `^`: Match the beginning of the string.\n\n* `$`: match the end of the string.\n\n* `?`: Match zero or one of the previous subpatterns.\n\n* `*`: Match zero or more of the previous subpattern.\n\n* `+`: Match one or more of the previous subpatterns.\n\n* `??`: The non-greedy version of `? `, matches zero or one, and the preference is zero.\n\n* `*?`: A non-greedy version of `*`, matching zero or more, preferring the shortest match.\n\n* `+?`: Non-greedy \"+\" version, matching one or more, first matching the shortest.\n\n* `|`: Match the left or right sub-pattern of this operator.\n\n* `(...)`: grouping. Each group is capturing (the substring it captures can be accessed using the `match.group() method).\n\n* `\\d`: match numbers. Equivalent to `[0-9]`.\n\n* `\\D`: match non-digits. Equivalent to `[^ 0-9]`.\n\n* `\\s`:\n\n* `\\S`: matches whitespace. Equivalent to `[^ \\t-\\r]`.\n\n* `\\w`: ​​match \"word characters\" (ASCII only). Equivalent to `[A-Za-z0-9_]`.\n\n* `\\W`: match non-\"word characters\" (ASCII only). Equivalent to `[^A-Za-z0-9_]`.\n\n* `\\`: escape character. Except for those listed above, any other characters after the backslash are literal. For example, `\\*` is equivalent to the literal `*` (not considered as the `*` operator). Please note that `\\r`, `\\n,`, etc. are not specially processed, and are equivalent to the text letters `r`, `n`, etc. Therefore, it is not recommended to use raw Python strings (`r\"\"`) for regular expressions. For example, `r\"\\r \\n\"` is equivalent to `\"rn\"` when used as a regular expression. To match the characters of CR followed by LF, use `\"\\r\\n\"`.\n\n## Unsupported expression\n\n* Repeated calculation (`(m,n)`)\n* Named group (`(?P<name>...)`)\n* Non-capturing group (`(?:...)`)\n* More advanced assertions (`\\b, \\B`)\n* Escaping special characters like `\\r`, `\\n`-use Python's own escape\n* Other\n\n\nexample:\n\n```python\nimport ure\n\n# As ure doesn't support escapes itself, use of r\"\" strings is not\n# recommended.\nregex = ure.compile(\"[\\r\\n]\")\n\nregex.split(\"line1\\rline2\\nline3\\r\\n\")\n\n# Result:\n# ['line1','line2','line3','','']\n```\n## Method\n\n### ure.compile(regex_str[, flags])\n\nCompile the regular expression and return the [regex](http://docs.micropython.org/en/latest/library/ure.html?highlight=ure#regex) object.\n\n### ure.match(regex_str, string)\n\nCompile regex_str and match the string. The match always starts from the starting position in the string.\n\n### ure.search(regex_str, string)\n\nCompile regex_str and search for it in the string. Unlike `match`, this will search the string to match the first position of the regular expression (if the regular expression is anchored, it can still be 0).\n\n### ure.sub(regex_str, replace, string, count=0, flags=0)\n\nCompile regex_str and search for it in the string, replace all matches with replace, and return the new string.\n\nreplace can be a string or a function. If it is a string, then escape sequences of the form `\\<number>` and `\\g<number>` can be used to expand to the corresponding group (or an empty string that does not match the group). If replace is a function, then it must take one parameter (match) and should return a replacement string.\n\nIf count is specified and non-zero, then the replacement will stop after many replacements. The flags parameter is ignored.\n\nNote: The availability of this function depends on the `MicroPython port`.\n\n### ure.DEBUG\n\nThe tag value displays debugging information about the compiled expression. (Availability depends on the `MicroPython port implementation`.)\n\n\n## Regex Object\n\nThe compiled regular expression. Use `ure.compile()` to create an instance of this class.\n\n### regex.match(string) regex.search(string) regex.sub(replace, string, count=0, flags=0)\n\nSimilar to the module-level functions `match()`, `search()` and `sub()`. If the same regular expression is applied to multiple strings, the usage method will be more efficient.\n\n### regex.split(string, max_split=-1)\n\nUse regular expressions to split the string. If max_split is given, specify the maximum number of splits to perform. Returns a list of strings (if specified, there can be at most max_split + 1 elements).\n\n\n## Match Object\n\nMatch the objects returned by the `match()` and `search()` methods and pass them to the substitution function in sub().\n\n### match.group(index)\n\nReturns the matching (sub)string. The index of the entire match is 0, and the index of each capture group is 1 and higher. Only number groups are supported.\n\n### match.groups()\n\nReturn a tuple containing all substrings of the matched group.\n\nNote: The availability of this method depends on the `MicroPython port implementation`.\n\n### match.start([index]) match.end([index])\n\nReturns the index in the original string of the beginning or end of the matched substring group. The index defaults to the entire group, otherwise a group will be selected.\n\nNote: The availability of these methods depends on the `MicroPython port implementation`.\n\n### match.span([index])\n\n\nReturn the 2-tuple `(match.start(index), match.end(index))`.\n\nNote: The availability of this method depends on the implementation of `MicroPython port`."}, "/soft/maixpy/en/api_reference/standard/cmath.html": {"title": "cmath – mathematical functions for complex numbers", "content": "---\ntitle: cmath – mathematical functions for complex numbers\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: cmath – mathematical functions for complex numbers\n---\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [cmath](https://docs.python.org/3.5/library/cmath.html#module-cmath).\n\nThe `cmath` module provides some basic mathematical functions for dealing with complex numbers.\n\n\n## Function\n\n### cos\n\n```python\ncmath.cos(z)\n```\n\nReturns the cosine of `z`.\n\n### exp\n\n```python\ncmath.exp(z)\n```\n\nReturns the exponent of `z`.\n\n### log\n\n```python\ncmath.log(z)\n```\n\nReturns the natural logarithm of `z`. The branch cuts along the negative real axis.\n\n### log10\n\n```python\ncmath.log10(z)\n```\n\nReturns the base 10 logarithm of `z`. The branch cuts along the negative real axis.\n\n### phase\n\n```python\ncmath.phase(z)\n```\n\nReturns the phase, range (-pi, +pi) of the number \"z\".\n\n### polar\n\n```python\ncmath.polar(z)\n```\n\nReturn the polar form of `z` as a tuple.\n\n### rect\n\n```python\ncmath.rect(r, phi)\n```\n\nReturns the complex number of the modulus `r` and the phase `phi`.\n\n### sin\n\n```python\ncmath.sin(z)\n```\n\nReturns the sine of `z`.\n\n### sqrt\n\n```python\ncmath.sqrt(z)\n```\n\nReturns the square root of `z`.\n\n## Constants\n\n### cmath.e\n\nThe basis of natural logarithm\n\n### cmath.pi\n\nRatio of circumference to diameter"}, "/soft/maixpy/en/api_reference/standard/uheapq.html": {"title": "uheapq-heap queue algorithm", "content": "---\ntitle: uheapq-heap queue algorithm\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: uheapq-heap queue algorithm\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below.For more information, please refer to the original CPython documentation: [heapq](https://docs.python.org/3.5/library/heapq.html#module-heapq).\n\nThis module implements the heap queue algorithm.\n\nA heap queue is just a list that stores its elements in some way.\n\n\n## Function\n\n### heappush\n\n```python\nuheapq.heappush(heap, item)\n```\n\nPut elements into the heap.\n\n### heappop\n\n```python\nuheapq.heappop(heap)\n```\n\nPop the first element in the heap and return it.If the heap is empty, an `IndexError` is raised.\n\n### heapify\n\n```python\nuheapq.heapify(x)\n```\n\nConvert the list x to a heap.This is an in-place (division exchange sort) operation."}, "/soft/maixpy/en/api_reference/standard/math.html": {"title": "math-mathematical functions", "content": "---\ntitle: math-mathematical functions\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: math-mathematical functions\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [math](https://docs.python.org/3.5/library/math.html#module-math).\n\nThe `math` module provides some basic mathematical functions for handling floating point numbers.\n\n\n## Function\n\n### math.acos(x)\n\nReturns the arc cosine of `x`.\n\n### math.acosh(x)\n\nReturns the inverse hyperbolic cosine of `x`.\n\n### math.asin(x)\n\nReturns the arc sine of `x`.\n\n### math.asinh(x)\n\nReturns the inverse hyperbolic sine of `x`.\n\n### math.atan(x)\n\nReturns the arc tangent of `x`.\n\n### math.atan2(y, x)\n\nReturns the principal value of the arctangent of `y` /`x`.\n\n### math.atanh(x)\n\nReturns the inverse hyperbolic tangent of `x`.\n\n### math.ceil(x)\n\nReturns an integer, \"x\" is rounded to positive infinity.\n\n### math.copysign(x, y)\n\nReturn `x` with the sign of `y`.\n\n### math.cos(x)\n\nReturns the cosine of `x`.\n\n\n### math.cosh(x)\n\nReturns the hyperbolic cosine of `x`\n\n### math.degrees(x)\n\nReturns the radians `x` converted to degrees.\n\n### math.erf(x)\n\nError function that returns `x`.\n\n### math.erfc(x)\n\nReturns the complementary error function of `x`.\n\n### math.exp(x)\n\nReturns the exponent of `x`.\n\n### math.expm1(x)\n\nReturn `exp(x)-1`.\n\n### math.fabs(x)\n\nReturns the absolute value of `x`.\n\n### math.floor(x)\n\nReturns an integer, \"x\" is rounded towards negative infinity.\n\n### math.fmod(x, y)\n\nReturns the remainder of `x` /`y`.\n\n### math.frexp(x)\n\nDecompose floating point numbers into mantissa and exponent. The returned value is the tuple `(m, e)`, so that `x == m * 2 ** e` is completely correct. If `x == 0`, the function returns `(0.0,0)`, otherwise the relationship `0.5 <= abs(m)<1` holds.\n\n### math.gamma(x)\n\nReturns the gamma function of `x`.\n\n### math.isfinite(x)\n\nIf `x` is finite, it returns True.\n\n### math.isinf(x)\n\nIf `x` is infinite, it returns True.\n\n### math.isnan(x)\n\nIf `x` is not a number, it returns True\n\n### math.ldexp(x, exp)\n\nReturn `x *(2 ** exp)`.\n\n### math.lgamma(x)\n\nReturns the natural logarithm of the gamma function of `x`.\n\n### math.log(x)\n\nReturns the natural logarithm of `x`.\n\n### math.log10(x)\n\nReturns the base 10 logarithm of `x`.\n\n### math.log2(x)\n\nReturns the base-2 logarithm of `x`.\n\n### math.modf(x)\n\nReturns a tuple of two floating-point numbers, the fraction and integer part of \"x\". Both return values ​​have the same sign as `x`.\n\n### math.pow(x, y)\n\nReturn `x` to the power of'y`.\n\n### math.radians(x)\n\nReturns the degree `x` converted to radians.\n\n### math.sin(x)\n\nReturns the sine of `x`.\n\n### math.sinh(x)\n\nReturns the hyperbolic sine of `x`.\n\n### math.sqrt(x)\n\nReturns the square root of `x`.\n\n### math.tan(x)\n\nReturns the tangent of `x`.\n\n### math.tanh(x)\n\nReturns the hyperbolic tangent of `x`.\n\n### math.trunc(x)\n\nReturns an integer, \"x\" is rounded towards 0.\n\n## Constants\n\n### math.e\n\nThe basis of natural logarithm\n\n### math.pi\n\nRatio of circumference to diameter"}, "/soft/maixpy/en/api_reference/standard/ucollections.html": {"title": "ucollections-collection and container types", "content": "---\ntitle: ucollections-collection and container types\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ucollections-collections and container types\n---\n\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation [collections](https://docs.python.org/3.5/library/collections.html#module-collections).\n\nThis module implements advanced collections and container types to store/accumulate various objects.\n\n## Class\n\n### ucollections.deque(iterable, maxlen[, flags])\n\nDeques (deques) is a list-like container that supports O(1) append and pops from either side of the deque. Create new deques with the following parameters:\n\n* Iterable must be an empty tuple, and the new deque is created as empty.\n* Must specify maxlen, and the deque will be limited to this maximum length. Once the deque is full, any new items added will discard each other's items.\n* When adding items, the optional flag can be 1 to check overflow.\n\nIn addition to supporting bool and len, the deque object has the following methods:\n\n#### `deque.append(x)`\n\nAdd `x` to the right side of the deque. If overflow checking is enabled and there is no space left, an IndexError is raised.\n\n#### `deque.popleft()`\n\nRemove and return an item from the left side of the deque. If there are no items, an IndexError is raised.\n\n### ucollections.namedtuple(name, fields)\n\nThis is a factory function to create a new namedtuple type with a specific name and field set. namedtuple is a subclass of tuples. It can not only access its fields through numerical indexes, but also use symbolic field names to access attribute access syntax. Fields is a sequence of strings specifying the names of fields. For compatibility with CPython, it can also be a string named after a space separated field (but it is less efficient). Use example:\n\n```python\nfrom ucollections import namedtuple\n\nMyTuple = namedtuple(\"MyTuple\", (\"id\", \"name\"))\nt1 = MyTuple(1, \"foo\")\nt2 = MyTuple(2, \"bar\")\nprint(t1.name)\nassert t2.name == t2[1]\n```\n\n### ucollections.OrderedDict(...)\n\nThe `dict` type subclass, it remembers and preserves the order of the added keys. When the dict is iterated, the keys/items are returned in the order of addition:\n\n```python\nfrom ucollections import OrderedDict\n\n# To make benefit of ordered keys, OrderedDict should be initialized\n# from sequence of (key, value) pairs.\nd = OrderedDict([(\"z\", 1), (\"a\", 2)])\n# More items can be added as usual\nd[\"w\"] = 5\nd[\"b\"] = 3\nfor k, v in d.items():\n    print(k, v)\n```\n\nOutput:\n\n```python\nz 1\na 2\nw 5\nb 3\n```"}, "/soft/maixpy/en/api_reference/standard/sys.html": {"title": "sys-system specific functions", "content": "---\ntitle: sys-system specific functions\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: sys-system specific functions\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [sys](https://docs.python.org/3.5/library/sys.html#module-sys).\n\n## Function\n\n### sys.exit(retval=0)\n\nTerminate the current program with the given exit code. According to this, this function raises the \"SystemExit\" exception. If a parameter is given, its value is given as the parameter of `SystemExit`.\n\n### sys.print_exception(exc, file=sys.stdout)\n\nUse traceback to file-like object files (or `sys.stdout` by default) to print exceptions.\n\n> **Difference from CPython**\n> This is a simplified version of a function that appears in the backtracking module of CPython. Unlike traceback.print_exception(), this function only accepts outliers instead of exception types, outliers and traceback objects; the file parameter should be positional; other parameters are not supported. A traceback module compatible with CPython can be found in micropython-lib.\n\n## Constant\n\n### sys.argv\n\nThe variable parameter list when the current program is started.\n\n### sys.byteorder\n\nThe byte order of the system (\"little endian\" or \"big endian\"`).\n\n### sys.implementation\n\nAn object containing information about the current Python implementation. For MicroPython, it has the following attributes:\n\n* name-the string \"micropython\"\n* version-tuple (major, minor, micro), e.g. (1, 7, 0)\n\nThis object is the recommended way to distinguish MicroPython from other Python implementations (note that it may still not exist in very small ports).\n\n> **Difference from CPython**\n> CPython requires more attributes for this object, but the minimum requirement to actually be useful is implemented in MicroPython.\n\n### sys.maxsize\n\nThe maximum value that the native integer type can save on the current platform, or the maximum value that the MicroPython integer type can represent, if it is less than the platform maximum value (for the MicroPython port without long int support).\n\nThis attribute is very useful for detecting the \"bitness\" of the platform (32-bit and 64-bit, etc.). It is recommended not to directly compare this attribute with a value, but to calculate the number of digits:\n\n```python\nbits = 0\nv = sys.maxsize\nwhile v:\n    bits += 1\n    v >>= 1\nif bits> 32:\n    # 64-bit (or more) platform\n    ...\nelse:\n    # 32-bit (or less) platform\n    # Note that on 32-bit platform, value of bits may be less than 32\n    # (e.g. 31) due to peculiarities described above, so use \"> 16\",\n    # \"> 32\", \"> 64\" style of comparisons.\n```\n\n### sys.modules\n\nLoad the dictionary of the module. On some ports, it may not contain built-in modules.\n\n### sys.path\n\nA variable directory list for searching imported modules.\n\n### sys.platform\n\nThe platform on which MicroPython is running. For OS/RTOS ports, this is usually the identifier of the OS, for example, `\"LINUX\"`. For bare metal ports, it is the identifier of the circuit board, such as `\"pyboard\"` for the original MicroPython reference board. Therefore, it can be used to distinguish one board from another. If you need to check whether your program is running on MicroPython (compared to other Python implementations), please use `sys.implementation`.\n\n### sys.stderr\n\nStandard error `stream`.\n\n### sys.stdin\n\nStandard input `stream`.\n\n### sys.stdout\n\nStandard output `stream`.\n\n### sys.version\n\nThe implemented Python version, returns a string\n\n### sys.version_info\n\nThe implemented Python version, which returns a tuple of integers"}, "/soft/maixpy/en/api_reference/standard/ujson.html": {"title": "ujson – JSON encoding and decoding", "content": "---\ntitle: ujson – JSON encoding and decoding\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ujson – JSON encoding and decoding\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [json](https://docs.python.org/3.5/library/json.html#module-json).\n\nThis module allows conversion between Python objects and JSON data formats.\n\n## Function\n\n### dump\n\n```python\nujson.dump(obj, stream)\n```\n\nSerialize `obj` into a JSON string and write it to the given stream.\n\n### dumps\n\n```python\nujson.dumps(obj)\n```\n\nReturns `obj` represented as a JSON string.\n\n### load\n\n```python\nujson.load(stream)\n```\n\nParse the given stream, interpret it as a JSON string and deserialize the data into Python objects. Return the result object.\n\nThe parsing continues until the end of the file is encountered. If the data in the stream is not formed correctly, a ValueError will be raised.\n\n### loads\n\n```python\nujson.loads(str)\n```\n\nParse the JSON str and return an object. If the string format is wrong, ValueError is raised."}, "/soft/maixpy/en/api_reference/standard/ustruct.html": {"title": "ustruct-Packing and unpacking primitive data types", "content": "---\ntitle: ustruct-Packing and unpacking primitive data types\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ustruct-packing and unpacking primitive data types\n---\n\n\n\nThis module implements a subset of the corresponding `CPython` module, as described below. For more information, please refer to the original CPython documentation: [struct](https://docs.python.org/3.5/library/struct.html#module-struct).\n\nSupported size/byte order prefixes: `@`, `<`, `>`, `!`.\n\nSupported format codes: `b`, `B`, `h`, `H`, `i`, `I`, `l`, `L`, `q`, `Q`, `s`, ` P`, `f`, `d` (the latter 2 depends on floating point support).\n\n## Function\n\n### calcsize\n\n```python\nustruct.calcsize(fmt)\n```\n\nReturns the number of bytes required to store the given `fmt`.\n\n### pack\n\n```python\nustruct.pack(fmt, v1, v2, ...)\n```\n\nPack the values ​​`v1`, `v2`, `...` according to the format string `fmt`. The return value is a bytes object of the encoded value.\n\n### pack_into\n\n```python\nustruct.pack_into(fmt, buffer, offset, v1, v2, ...)\n```\n\nAccording to the format string `fmt`, the values ​​`v1`, `v2`, `...` are packed into a buffer starting from offset. Counting from the end of the buffer may be negative.\n\n### unpack\n\n```python\nustruct.unpack(fmt, data)\n```\n\nUnpack from `data` according to the format string `fmt`. The return value is a tuple of decompressed values.\n\n### unpack_from\n\n```python\nustruct.unpack_from(fmt, data, offset=0)\n```\n\nAccording to the format string `fmt` starts from `offset` and unpacks from `data`. `offset` may be a negative number, counting from the end of the buffer. The return value is a tuple of decompressed values."}, "/soft/maixpy/en/api_reference/standard/uerrno.html": {"title": "uerrno — system error code", "content": "---\ntitle: uerrno — system error code\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: uerrno — system error code\n---\n\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [errno](https://docs.python.org/3.5/library/errno.html#module-errno).\n\nThis module describes the error identifier of the `OSError` error. The specific code inventory depends on `Micropython porting`, and the error will be explained in the specific error function.\n\n\n## Constant\n\n### EEXIST, EAGAIN, etc.\n\nError codes based on ANSI C / POSIX standards. All error codes begin with \"E\". As mentioned above, the code inventory depends on the port of MicroPython. Errors can usually be accessed as `exc.args[0]`, where `exc` is an instance of `OSError`. Example usage:\n\n```python\ntry:\n    uos.mkdir(\"my_dir\")\nexcept OSError as exc:\n    if exc.args[0] == uerrno.EEXIST:\n        print(\"Directory already exists\")\n```\n\n### uerrno.errorcode\n\nThe dictionary maps numeric error codes to strings with signed error codes (see above):\n\n```python\n>>> print(uerrno.errorcode[uerrno.EEXIST])\nEEXIST\n```"}, "/soft/maixpy/en/api_reference/standard/index.html": {"title": "Standard Library", "content": "---\ntitle: Standard Library\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: standard library\n---\n\n\n* [cmath](cmath.md)\n* [gc](gc.md)\n* [math](math.md)\n* [sys](sys.md)\n* [ubinascii](ubinascii.md)\n* [ucollections](ucollections.md)\n* [uctypes](uctypes.md)\n* [uerrno](uerrno.md)\n* [uhashlib](uhashlib.md)\n* [uheapq](uheapq.md)\n* [ujson](ujson.md)\n* [uos](uos.md)\n* [ure](ure.md)\n* [uselect](uselect.md)\n* [usocket](usocket.md)\n* [ustruct](ustruct.md)\n* [utime](utime.md)\n* [uzlib](uzlib.md)"}, "/soft/maixpy/en/api_reference/standard/uctypes.html": {"title": "uctypes-access to binary data in a structured way", "content": "---\ntitle: uctypes-access to binary data in a structured way\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: uctypes-access to binary data in a structured way\n---\n\n\nThis module implements \"external data interface\" for MicroPython. The idea behind it is similar to CPython's `ctypes` module, but the actual API is different, streamlined and optimized for small size. The basic idea of ​​this module is to define a data structure layout with data roughly the same as the functions allowed by the C language, and then use the familiar dot syntax to access it to reference subfields.\n\n> **Warning**\n>\n> The uctypes module allows access to any memory address of the machine (including I/O and control registers). Using it carelessly may cause crashes, data loss, and even hardware failure.\n\n> **Also refer to**\n>\n> **[ustruct](ustruct.md) module**\n>\n> Standard Python methods for accessing binary data structures (does not scale well to large and complex structures).\n\n\nRoutine:\n\n```python\nimport uctypes\n\n# Example 1: Subset of ELF file header\n# https://wikipedia.org/wiki/Executable_and_Linkable_Format#File_header\nELF_HEADER = {\n    \"EI_MAG\": (0x0 | uctypes.ARRAY, 4 | uctypes.UINT8),\n    \"EI_DATA\": 0x5 | uctypes.UINT8,\n    \"e_machine\": 0x12 | uctypes.UINT16,\n}\n\n# \"f\" is an ELF file opened in binary mode\nbuf = f.read(uctypes.sizeof(ELF_HEADER, uctypes.LITTLE_ENDIAN))\nheader = uctypes.struct(uctypes.addressof(buf), ELF_HEADER, uctypes.LITTLE_ENDIAN)\nassert header.EI_MAG == b\"\\x7fELF\"\nassert header.EI_DATA == 1, \"Oops, wrong endianness. Could retry with uctypes.BIG_ENDIAN.\"\nprint(\"machine:\", hex(header.e_machine))\n\n\n# Example 2: In-memory data structure, with pointers\nCOORD = {\n    \"x\": 0 | uctypes.FLOAT32,\n    \"y\": 4 | uctypes.FLOAT32,\n}\n\nSTRUCT1 = {\n    \"data1\": 0 | uctypes.UINT8,\n    \"data2\": 4 | uctypes.UINT32,\n    \"ptr\": (8 | uctypes.PTR, COORD),\n}\n\n# Suppose you have address of a structure of type STRUCT1 in \"addr\"\n# uctypes.NATIVE is optional (used by default)\nstruct1 = uctypes.struct(addr, STRUCT1, uctypes.NATIVE)\nprint(\"x:\", struct1.ptr[0].x)\n\n\n# Example 3: Access to CPU registers. Subset of STM32F4xx WWDG block\nWWDG_LAYOUT = {\n    \"WWDG_CR\": (0, {\n        # BFUINT32 here means size of the WWDG_CR register\n        \"WDGA\": 7 << uctypes.BF_POS | 1 << uctypes.BF_LEN | uctypes.BFUINT32,\n        \"T\": 0 << uctypes.BF_POS | 7 << uctypes.BF_LEN | uctypes.BFUINT32,\n    }),\n    \"WWDG_CFR\": (4, {\n        \"EWI\": 9 << uctypes.BF_POS | 1 << uctypes.BF_LEN | uctypes.BFUINT32,\n        \"WDGTB\": 7 << uctypes.BF_POS | 2 << uctypes.BF_LEN | uctypes.BFUINT32,\n        \"W\": 0 << uctypes.BF_POS | 7 << uctypes.BF_LEN | uctypes.BFUINT32,\n    }),\n}\n\nWWDG = uctypes.struct(0x40002c00, WWDG_LAYOUT)\n\nWWDG.WWDG_CFR.WDGTB = 0b10\nWWDG.WWDG_CR.WDGA = 1\nprint(\"Current counter:\", WWDG.WWDG_CR.T)\n```\n\n\n## Define the structure layout\n\nThe structure layout is defined by a \"descriptor\"-a Python dictionary that encodes field names as keys and other attributes needed to access them as associated values:\n\n```python\n{\n    \"field1\": <properties>,\n    \"field2\": <properties>,\n    ...\n}\n```\n\nCurrently, `uctypes` needs to specify the offset of each field. The offset is given in bytes from the beginning of the structure.\n\nThe following are coding examples for various field types:\n\n* Scalar type:\n\n```python\n\"field_name\": offset | uctypes.UINT32\n```\n\nIn other words, the value is a scalar type identifier and is ORed with the field offset (in bytes) at the beginning of the structure.\n\n* Recursive structure:\n\n```python\n\"sub\": (offset, {\n    \"b0\": 0 | uctypes.UINT8,\n    \"b1\": 1 | uctypes.UINT8,\n})\n```\n\nThat is, the value is a 2-tuple, the first element is the offset, and the second is the structure descriptor dictionary (note: the offset in the recursive descriptor is related to the structure it defines). Of course, the recursive structure can be specified not only through the literal dictionary, but also by referring to the structure descriptor dictionary (defined above) by name.\n\n* Array of primitive type:\n\n```python\n\"arr\": (offset | uctypes.ARRAY, size | uctypes.UINT8),\n```\n\nThat is, the value is a 2-tuple, the first element is the ARRAY flag and the offset are ORed, and the second is the number of elements in the scalar element type ORed array.\n\n*Aggregate type array:\n\n```python\n\"arr2\": (offset | uctypes.ARRAY, size, {\"b\": 0 | uctypes.UINT8}),\n```\n\nThat is, the value is a 3-tuple, the first element of which is the ARRAY flag, which is related to the offset, the second is the number of elements in the array, and the third is the element type descriptor.\n\n*Pointers to primitive types:\n\n```python\n\"ptr\": (offset | uctypes.PTR, uctypes.UINT8),\n```\n\nThat is, the value is a 2-tuple, the first element is the PTR flag and the offset is ORed, and the second element is the scalar element type.\n\n*Pointer to aggregate type:\n\n```python\n\"ptr2\": (offset | uctypes.PTR, {\"b\": 0 | uctypes.UINT8}),\n```\n\nThat is, the value is a 2-tuple, the first element of which is the OR operation of the PTR flag and the offset, and the second element is the descriptor of the pointed type.\n\n*Bitfield:\n\n```python\n\"bitf0\": offset | uctypes.BFUINT16 | lsbit << uctypes.BF_POS | bitsize << uctypes.BF_LEN,\n```\n\nThat is, value is a scalar value that contains a given positioning field (the type name is similar to a scalar type, but the prefix is ​​\"BF\"), which is ORed with the offset of the scalar value containing the bit field, and further compared with the bit position And the value of bit length is \"OR\" operation. The bit fields within the scalar value are shifted by BF_POS and BF_LEN bits respectively. The bit field position counts from the least significant bit (position with 0) of the scalar, and is the number of rightmost bits of the field (in other words, it is the number of bits that the scalar needs to be shifted to the right to extract the bit field).\n\nIn the above example, first extract the UINT16 value at offset 0 (this detail may be important when accessing hardware registers, requiring specific access size and alignment), and then the rightmost bit is the lsbit bit of this UINT16 The bit field, and length is bitsize bits, will be extracted. For example, if lsbit is 0 and bitsize is 8, then it will effectively access the least significant byte of UINT16.\n\nNote that bit field operations are independent of the target byte order, especially the above example will access the least significant byte of UINT16 in little-endian and big-endian structures. But it depends on the least significant bit being numbered as 0. Some targets may use a different number in their native ABI, but \"uctypes\" always uses the standardized number described above.\n\n## Module content\n\n### class uctypes.struct(addr, descriptor, layout_type=NATIVE)\n\nInstantiate the \"external data structure\" object based on the address of the structure in memory, the descriptor (encoded as a dictionary) and the layout type (see below).\n\n### uctypes.LITTLE_ENDIAN\n\nThe layout type of the little-endian compression structure. (Packing means that each field occupies the number of bytes defined in the descriptor, that is, the alignment is 1).\n\n### uctypes.BIG_ENDIAN\n\nThe layout type of big-endian compression structure.\n\n### uctypes.NATIVE\n\nThe layout type of the native structure-data byte order and alignment conform to the ABI of the system running MicroPython.\n\n### uctypes.sizeof(struct, layout_type=NATIVE)\n\nReturns the size of the data structure in bytes. The struct parameter can be a structure class or a specific instantiated structure object (or its aggregate field).\n\n### uctypes.addressof(obj)\n\nReturns the address of the object. The parameters should be bytes, byte arrays or other objects that support the buffer protocol (the address of the buffer is actually returned).\n\n### uctypes.bytes_at(addr, size)\n\nCapture memory as bytes object with given address and size. Since the bytes object is immutable, the memory is actually copied and copied into the bytes object, so if the memory content changes later, the created object will retain the original value.\n\n### uctypes.bytearray_at(addr, size)\n\nCapture the memory of the given address and size as a bytearray object. Unlike the bytes_at() function above, the memory is captured by reference, so it can also be written, and you will access the current value at the given memory address.\n\n### uctypes.UINT8 uctypes.INT8 uctypes.UINT16 uctypes.INT16 uctypes.UINT32 uctypes.INT32 uctypes.UINT64 uctypes.INT64\n\nThe integer type of the structure descriptor. Provides 8, 16, 32, and 64-bit constants, including signed and unsigned.\n\n### uctypes.FLOAT32 uctypes.FLOAT64\n\nThe floating-point type of the structure descriptor.\n\n### uctypes.VOID\n\nVOID is an alias of UINT8, used to conveniently define the void pointer of C: (uctypes.PTR, uctypes.VOID).\n### uctypes.PTR uctypes.ARRAY\n\nEnter constants for pointers and arrays. Please note that the structure has no explicit constants, it is implicit: the aggregation type without the PTR or ARRAY flag is a structure.\n\n## Structure descriptors and instantiated structure objects\n\nGiven a structure descriptor dictionary and its layout type, you can use the `uctypes.struct()` constructor to instantiate a specific structure instance at a given memory address. Memory addresses usually come from the following sources:\n\n*The predefined address when accessing the hardware registers on the bare metal system. Look up these addresses in the data sheet of the specific MCU/SoC.\n\n*As the return value of calling some FFI (foreign function interface) functions.\n\n*From uctypes.addressof(), when you want to pass parameters to the FFI function, or access certain data of I/O (for example, data read from a file or network socket).\n\n\n## Structure Object\n\nStructure objects allow access to a single field using standard dot notation: `my_struct.substruct1.field1. If the field is a scalar type, getting it will produce the original value (Python integer or floating point number) corresponding to the value contained in the field. Scalar fields can also be assigned to.\n\nIf a field is an array, you can use the standard subscript operator [] to access its individual elements-read and assign at the same time.\n\nIf a field is a pointer, it can be dereferenced using the [0] syntax (corresponds to the C * operator, although [0] also applies to C). It also supports subscribing to pointers with other integer values ​​(but 0), with the same semantics as in C.\n\nAll in all, access to structure fields usually follows C syntax, except for pointer dereference, when you need to use the [0] operator instead of *.\n\n## Limit\n\n\n* Access to non-scalar fields will cause intermediate objects to be allocated to represent them. This means that special attention should be paid to the layout of structures that need to be accessed when memory allocation is disabled (for example from interrupts). suggestions below:\n  * Avoid access to nested structures. For example, instead of mcu_registers.peripheral_a.register1, a separate layout descriptor is defined for each peripheral and accessed as peripheral_a.register1. Or just cache specific peripherals: peripheral_a = mcu_registers.peripheral_a. If the register consists of multiple bit fields, you need to cache the reference to a specific register: reg_a = mcu_registers.peripheral_a.reg_a.\n  * Avoid using other non-scalar data, such as arrays. For example, use peripheral_a.register0 instead of peripheral_a.register[0]. Similarly, another method is to cache intermediate values, such as register0 = peripheral_a.register [0].\n* The offset range supported by the `uctypes` module is limited. The exact range of support is considered an implementation detail, and the general recommendation is to split the structure definition into a maximum value from a few kilobytes to tens of kilobytes. In most cases, this is a natural situation. For example, it does not make sense to define all MCU registers in a structure (expanded to 32-bit address space), but to define peripheral blocks through peripheral blocks. In some extreme cases, you may need to manually divide the structure of several parts (for example, if you access a native data structure with a multi-megabyte array in the middle, although this will be a very synthetic situation). )"}, "/soft/maixpy/en/api_reference/standard/gc.html": {"title": "gc-memory recovery", "content": "---\ntitle: gc-memory recovery\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: gc-memory recovery\n---\n\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [gc](https://docs.python.org/3.5/library/gc.html#module-gc).\n\n## Function\n\n### gc.enable()\n\nEnable automatic garbage collection.\n\n### gc.disable()\n\nDisable automatic garbage collection. Heap memory can still be allocated, and garbage collection can still be started manually using `gc.collect()`.\n\n### gc.collect()\n\nRun garbage collection.\n\n### gc.mem_alloc()\n\nReturns the number of bytes of heap RAM allocated.\n\n#### Difference to CPython\n\nThis feature is a MicroPython extension.\n\n### gc.mem_free()\n\nReturns the number of bytes of available heap RAM, or -1 if the remaining amount of heap is unknown.\n\n#### Difference with CPython\n\nThis feature is a MicroPython extension.\n\n### gc.threshold([amount])\n\nSet or query other GC allocation thresholds. Generally, the collection is triggered only when the new allocation cannot be met, that is, under out of memory (OOM) conditions. If you call this function, in addition to OOM, a set will be triggered every time a large number of bytes are allocated (in total, because so many bytes were allocated last time). The amount is usually specified as less than the full heap size, with the intention to trigger the collection before the heap is exhausted, and hope that the early collection can prevent excessive memory fragmentation. This is a heuristic measurement whose effect varies from application to application, as well as the optimal value of the measurement parameter.\n\nCalling the function without parameters will return the current value of the threshold. A value of -1 indicates a disabled allocation threshold.\n\n#### Difference with CPython\n\nThis function is a MicroPython extension. CPython has a similar function-`set_threshold()`, but due to different GC implementations, its signature and semantics are different."}, "/soft/maixpy/en/api_reference/standard/usocket.html": {"title": "usocket – socket module", "content": "---\ntitle: usocket – socket module\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: usocket-socket module\n---\n\n\nThis module implements a subset of the corresponding CPython module, as described below. For more information, please refer to the original CPython documentation: [socket](https://docs.python.org/3.5/library/socket.html#module-socket).\n\nThis module provides access to the BSD socket interface\n\n> **Difference from CPython**\n\n> In order to improve efficiency and consistency, the socket object in MicroPython directly implements the `stream` (class file) interface. In CPython, you need to use the `makefile()` method to convert the socket into a file-like object. MicroPython still supports this method (but no operation), so if it is compatible with CPython, be sure to use it.\n\n## Socket address format\n\nThe native socket address format of the `usocket` module is the opaque data type returned by the getaddrinfo function, which must be used to parse text addresses (including numeric addresses):\n\n```python\nsockaddr = usocket.getaddrinfo('www.micropython.org', 80)[0][-1]\n# You must use getaddrinfo() even for numeric addresses\nsockaddr = usocket.getaddrinfo('127.0.0.1', 80)[0][-1]\n# Now you can use that address\nsock.connect(addr)\n```\n\nUsing `getaddrinfo` is the most effective (in terms of memory and processing power), and it is also a portable way to use addresses.\n\nHowever, the `socket` module (note the difference from the native MicroPython `usocket` module described here) provides a CPython-compatible way to specify addresses using tuples, as described below. Please note that depending on the `MicroPython port`, the socket module can be built in or needs to be installed from `micropython-lib` (as in the case of \"MicroPython Unix port\"), and some ports still only accept numeric addresses in tuples Format and requires the use of the `getaddrinfo` function to resolve the domain name.\n\nIn general:\n\n* Always use `getaddrinfo` when writing portable applications.\n* If your port supports fast hacking and interactive use, the tuple address described below can be used as a shortcut.\n\nThe tuple address format of the `socket` module:\n\n* IPv4: (ipv4_address, port), where ipv4_address is a string with a dotted number IPv4 address, for example, \"8.8.8.8\", the port number and integer port number are in the range of 1-65535. Please note that domain names are not accepted as ipv4_address, they should be resolved first using usocket.getaddrinfo().\n\n* IPv6: (ipv6_address, port, flowinfo, scopeid), where ipv6_address is a string with a colon number IPv6 address, for example: `\"2001:db8::1\"`, port is an integer port number in the range of 1-65535. flowinfo must be 0. scopeid is the interface scope identifier of the link local address. Please note that domain names are not accepted as ipv6_address, they should be resolved using `usocket.getaddrinfo()` first. The availability of IPv6 support depends on the `MicroPython port`.\n\n## Method\n\n### usocket.socket(af=AF_INET, type=SOCK_STREAM, proto=IPPROTO_TCP)\n\nCreate a new socket using the given address series, socket type and protocol number. Please note that in most cases there is no need to specify proto (not recommended because some MicroPython ports may omit the `IPPROTO_ *` constants). Instead, the type parameter will automatically select the required protocol:\n\n```python\n# Create STREAM TCP socket\nsocket(AF_INET, SOCK_STREAM)\n# Create DGRAM UDP socket\nsocket(AF_INET, SOCK_DGRAM)\n```\n\n### usocket.getaddrinfo(host, port, af=0, type=0, proto=0, flags=0)\n\nConvert the host / port parameter to a 5-tuple sequence, which contains all the necessary parameters for creating a socket to connect to the service. The parameters af, type and proto (which have the same meaning as the `socket()` function) can be used to filter which address is returned. If the parameter is not specified or is zero, all address combinations can be returned (requires filtering on the user side).\n\nThe resulting 5-tuple list has the following structure:\n\n```python\n(family, type, proto, canonname, sockaddr)\n```\n\nThe following example shows how to connect to a given URL:\n\n```python\ns = usocket.socket()\n# This assumes that if \"type\" is not specified, an address for\n# SOCK_STREAM will be returned, which may be not true\ns.connect(usocket.getaddrinfo('www.micropython.org', 80)[0][-1])\n```\n\n\nIt is recommended to use filter parameters:\n\n```python\ns = usocket.socket()\n# Guaranteed to return an address which can be connect'ed to for\n# stream operation.\ns.connect(usocket.getaddrinfo('www.micropython.org', 80, 0, SOCK_STREAM)[0][-1])\n```\n\n> Difference with CPython\n\n> If this function fails, CPython will raise a `socket.gaierror` exception (subclass of `OSError`). MicroPython does not have `socket.gaierror` and directly raises OSError. Please note that the error number of `getaddrinfo()` forms a separate namespace and may not match the error number in the `uerrno` module. In order to distinguish `getaddrinfo()` errors, they are represented by negative numbers, while standard system errors are positive numbers (the error number can be accessed using the `e.args[0]` attribute from the exception object). The use of negative values ​​is a temporary detail and may change in the future.\n\n### usocket.inet_ntop(af, bin_addr)\n\nConvert the binary network address bin_addr of a given address family af into a text representation:\n\n\n```python\n>>> usocket.inet_ntop(usocket.AF_INET, b\"\\x7f\\0\\0\\1\")\n'127.0.0.1'\n```\n\n\n### usocket.inet_pton(af, txt_addr)\n\nConvert the text network address txt_addr of a given address family af into binary representation:\n\n```python\n>>> usocket.inet_pton(usocket.AF_INET, \"1.2.3.4\")\nb'\\x01\\x02\\x03\\x04'\n```\n\n\n## Constant\n\n### usocket.AF_INET usocket.AF_INET6\n\nAddress family types. Availability depends on the specific `MicroPython port`.\n\n### usocket.SOCK_STREAM usocket.SOCK_DGRAM\n\nThe socket type.\n\n### usocket.IPPROTO_UDP usocket.IPPROTO_TCP\n\nIP protocol number. Availability depends on the specific `MicroPython port`. Note that you do not need to specify them when calling `usocket.socket()`, because `SOCK_STREAM` socket type will automatically select `IPPROTO_TCP` and `SOCK_DGRAM`-`IPPROTO_UDP`. Therefore, the only practical use of these constants is as a parameter to `setsockopt()`.\n\n### usocket.SOL_*\n\nSocket option level (parameter of `setsockopt()`). The exact inventory depends on the `MicroPython port`.\n\n### usocket.SO_*\n\nSocket options (parameters of `setsockopt()`). The exact inventory depends on the `MicroPython port`.\n\n\n## Class socket\n\n### Method\n\n#### socket.close()\n\nMark that the socket is closed and release all resources. Once this happens, all future operations on the socket object will fail. If the protocol supports it, the remote end will receive the EOF indication.\n\nSockets are automatically closed when they are garbage collected, but it is recommended that you \"close\" them immediately after finishing them.\n\n#### (maixpy ​​not implemented) socket.bind(address)\n\nBind the socket to the address. The socket must not be bound.\n\n#### (maixpy ​​not implemented) socket.listen([backlog])\n\nMake the server accept connections. If backlog is specified, it must be at least 0 (if low, set it to 0); and specify the number of unaccepted connections that the system will allow before rejecting new connections. If not specified, the default reasonable value is selected.\n\n#### (maixpy ​​not implemented) socket.accept()\n\nAccept the connection. The socket must be bound to an address and listen for connections. The return value is a pair (conn, address), where conn is a new socket object that can be used to send and receive data on the connection, and address is the address of the socket bound to the other end of the connection.\n\n#### socket.connect(address)\n\nConnect to the remote socket at the address.\n\n#### socket.send(bytes)\n\nSend data to the socket. The socket must be connected to the remote socket. Returns the number of bytes sent, which may be less than the data length (\"short write\").\n\n#### socket.sendall(bytes)\n\nSend all data to the socket. The socket must be connected to the remote socket. Unlike `send()`, this method will try to send all data by continuously sending data blocks.\n\nThe behavior of this method on non-blocking sockets is undefined. Therefore, on MicroPython, it is recommended to use the `write()` method, which has the same \"no short write\" strategy to block the socket and will return the number of bytes sent on the non-blocking socket.\n\n#### socket.recv(bufsize)\n\nReceive data from the socket. The return value is a byte object representing the received data. The maximum amount of data received at one time is specified by bufsize.\n\n#### socket.sendto(bytes, address)\n\nSend data to the socket. The socket should not be connected to the remote socket, because the target socket is specified by the address.\n\n#### socket.recvfrom(bufsize)\n\nReceive data from the socket. The return value is a pair (byte, address), where bytes is the byte object representing the received data, and address is the address of the socket that sends the data.\n\n#### socket.setsockopt(level, optname, value)\n\nSet the value of the given socket option. The required symbolic constants are defined in the socket module (SO_* etc.). The value can be an integer or a byte-like object representing a buffer.\n#### socket.settimeout(value)\n\nNote: Not every port supports this method, see below.\n\nPrevent socket operations from setting timeouts. The value parameter can be a non-negative floating point number representing seconds, or it can be None. If a non-zero value is given, if the timeout value has elapsed before the operation is completed, subsequent socket operations will raise an \"OSError\" exception. If zero is given, the socket is in non-blocking mode. If None is given, the socket is in blocking mode.\n\nNot every \"MicroPython port\" supports this method. A more portable and universal solution is to use the uselect.poll object. This allows multiple objects to be waited at the same time (not just on sockets, but on generic `stream` objects that support polling). example:\n\n```python\n# Instead of:\ns.settimeout(1.0) # time in seconds\ns.read(10) # may timeout\n\n# Use:\npoller = uselect.poll()\npoller.register(s, uselect.POLLIN)\nres = poller.poll(1000) # time in milliseconds\nif not res:\n    # s is still not ready for input, i.e. operation timed out\n```\n\n> Difference with CPython\n\n> CPython raises `socket.timeout` exception in case of timeout, which is a subclass of OSError. MicroPython directly raises an `OSError`. If you use `except OSError`: to catch exceptions, your code will be valid in both MicroPython and CPython.\n\n#### socket.setblocking(flag)\n\nSet the blocking or non-blocking mode of the socket: if the flag is false, the socket is set to non-blocking, otherwise it is set to blocking mode.\n\nThis method is shorthand for certain `settimeout()` calls:\n\n`sock.setblocking(True)` is equivalent to `sock.settimeout(None)`\n`sock.setblocking(False)` i is equivalent to `sock.settimeout(0)`\n\n#### socket.makefile(mode='rb', buffering=0)\n\nReturns the file object associated with the socket. The exact return type depends on the parameters given to makefile(). Support is limited to binary mode ('rb','wb' and'rwb'). CPython parameters: encoding, errors and newlines are not supported.\n\n> Difference with CPython\n\n> Since MicroPython does not support buffered streams, the value of the buffer parameter is ignored and treated as 0 (unbuffered).\n\n> Difference with CPython\n\n> Closing the file object returned by makefile() will also close the original socket.\n\n#### socket.read([size])\n\nRead the size bytes from the slot. Return a bytes object. If no size is given, it will read all the data available in the socket until EOF; therefore, the method will not return until the socket is closed. This function attempts to read the requested data (there is no \"short read\"). However, for non-blocking sockets, this may not be possible, and then less data will be returned.\n\n#### socket.readinto(buf[, nbytes])\n\nRead bytes into buf. If nbytes is specified, at most multiple bytes are read. Otherwise, read at most len ​​(buf) bytes. Just like read(), this method follows the \"no short read\" strategy.\n\nReturn value: The number of bytes read and stored in buf.\n\n#### socket.readline()\n\nRead a line, ending with a newline character.\n\nReturn value: the row read.\n\n\n#### socket.write(buf)\n\nWrite the byte buffer to the socket. This function will try to write all data to the socket (no \"short write\"). However, for non-blocking sockets, this may not be possible, and the return value will be less than the length of buf.\n\nReturn value: The number of bytes written.\n\n#### exception usocket.error\n\nMicroPython does not have this exception.\n\n> Difference with CPython\n\n> CPython used to have a `socket.error` exception and is now deprecated. It is an alias of `OSError`. In MicroPython, use `OSError` directly.\n\n\n\n\n## Routine\n\n### Example 1: Download the picture and display it\n\n> Note the need to set WiFi SSID and password\n\n```python\nimport socket\nimport network\nimport gc\nimport os\nimport lcd, image\n\nfm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX)\nfm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX)\nuart = machine.UART(machine.UART.UART2,115200,timeout=1000, read_buf_len=4096)\nnic=network.ESP8285(uart)\nnic.connect(\"Sipeed_2.4G\",\"------\")\n\nsock = socket.socket()\naddr = socket.getaddrinfo(\"dl.sipeed.com\", 80)[0][-1]\nsock.connect(addr)\nsock.send('''GET /MAIX/MaixPy/assets/Alice.bmp HTTP/1.1\nHost: dl.sipeed.com\ncache-control: no-cache\n\n''')\n\nimg = b\"\"\nsock.settimeout(5)\nwhile True:\n    data = sock.recv(4096)\n    if len(data) == 0:\n        break\n    print(\"rcv:\", len(data))\n    img = img + data\n\nprint(len(img))\nimg = img[img.find(b\"\\r\\n\\r\\n\")+4:]\nprint(len(img))\nprint(\"save to /sd/Alice.bmp\")\nf = open(\"/sd/Alice.bmp\",\"wb\")\nf.write(img)\nf.close()\nprint(\"save ok\")\nprint(\"display\")\nimg = image.Image(\"/sd/Alice.bmp\")\nlcd.init()\nlcd.display(img)\n```\n\n\n\n### Example 2: Sending pictures\n\n```python\n\nimport os\nimport socket\nimport network\nimport gc\n\nfm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX)\nfm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX)\nuart = machine.UART(machine.UART.UART2,115200,timeout=1000, read_buf_len=4096)\nnic=network.ESP8285(uart)\nnic.connect(\"Sipeed_2.4G\",\"-------\")\n\naddr = (\"192.168.0.183\", 3456)\nsock = socket.socket()\nsock.connect(addr)\nsock.settimeout(5)\n\nf = open(\"/sd/Alice.bmp\",\"rb\")\nwhile True:\n    img = f.read(2048)\n    if not img or (len(img) == 0):\n        break\n    sock.send(img)\nf.close()\nsock.close()\n```"}, "/soft/maixpy/en/api_reference/machine/uart.html": {"title": "machine.UART", "content": "---\ntitle: machine.UART\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.UART\n---\n\n\nThe uart module is mainly used to drive the asynchronous serial port on the development board, and uart can be configured freely. There are 3 uarts in k210, and each uart can be freely mapped.\n\n## Construction\n\n### Pin mapping\n\nBefore using uart, we need to use fm to map and manage the chip pins. As shown below, set PIN10 as the sending pin of uart2 and PIN11 as the receiving pin of uart2\n```\nfm.register(board_info.PIN10,fm.fpioa.UART2_TX)\nfm.register(board_info.PIN11,fm.fpioa.UART2_RX)\n```\n\n### Constructor\n\n```\nuart = machine.UART(uart,baudrate,bits,parity,stop,timeout, read_buf_len)\n```\n\nCreate a new UART object with the specified parameters\n\n#### Parameters\n\n* `uart` UART number, use the specified UART, which can be completed by pressing the tab key in `machine.UART.`\n* `baudrate`: UART baud rate\n* `bits`: UART data width, support `5/6/7/8` (the default serial port used by REPL (UARTHS) only supports 8-bit mode), default `8`\n* `parity`: Parity bit, support `None`, `machine.UART.PARITY_ODD`, `machine.UART.PARITY_EVEN` (the default serial port (UARTHS) used by REPL only supports None), the default is `None`\n* `stop`: stop bit, support `1`, `1.5`, `2`, default `1`\n* `timeout`: Serial port receiving timeout time\n* `read_buf_len`: serial port receive buffer, serial port receives data through interrupt, if the buffer is full, it will automatically stop data receiving\n\n#### return value\n\n* UART object\n\n## Method\n\n### init\n\nIt is used to initialize uart, which is generally initialized when constructing the object, here is used to reinitialize uart\n```\nuart.init(baudrate,bits,parity,stop,timeout, read_buf_len)\n```\n\n#### Parameters\n\nSame as constructor, but does not require the first UART number\n\n#### return value\n\nno\n\n### read\n\nUsed to read the data in the serial buffer\n\n```\nuart.read(num)\n```\n#### Parameters\n\n* `num`: The number of bytes read, generally fill in the buffer size, if the number of data in the buffer is not as large as `num`, then only the remaining data in the buffer will be returned\n\n#### return value\n\n* `bytes` type of data\n\n### readline\n\nUsed to read one line of serial buffer data\n\n```\nuart.readline(num)\n```\n* `num`: the number of rows read\n\n#### return value\n\n*`bytes` type of data\n\n\n### write\n\nUsed to send data using serial port\n\n```\nuart.write(buf)\n```\n#### Parameters\n\n* `buf`: Need to send to data\n\n#### return value\n\n* The amount of data written\n\n### deinit\n\nLog off the UART hardware and release the occupied resources\n\n```\nuart.deinit()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### repl_uart()\n\nGet the serial port object used for REPL\n\n#### return value\n\nThe serial port object used for REPL, the default initialization bit is `115200 8 N 1`\n\n\n## Routine\n\n\n### Routine 1\n\nBefore running mileage, please make sure that `PIN15` has been connected to `PIN10`, and `PIN17` has been connected to `PIN9`\n\nAfter running the program, you can see the printed information of `baudrate:115200 bits:8 parity:0 stop:0 ---check Successfully` in the terminal\n\n```python\nfrom fpioa_manager import fm\nfrom machine import UART\nfm.register(board_info.PIN15,fm.fpioa.UART1_TX)\nfm.register(board_info.PIN17,fm.fpioa.UART1_RX)\nfm.register(board_info.PIN9,fm.fpioa.UART2_TX)\nfm.register(board_info.PIN10,fm.fpioa.UART2_RX)\nuart_A = UART(UART.UART1, 115200, 8, None, 1, timeout=1000, read_buf_len=4096)\nuart_B = UART(UART.UART2, 115200, 8, None, 1, timeout=1000, read_buf_len=4096)\nwrite_str ='hello world'\nfor i in range(20):\n    uart_A.write(write_str)\n    read_data = uart_B.read()\n    read_str = read_data.decode('utf-8')\n    print(\"string = \",read_str)\n    if read_str == write_str:\n        print(\"baudrate:115200 bits:8 parity:None stop:1 ---check Successfully\")\nuart_A.deinit()\nuart_B.deinit()\ndel uart_A\ndel uart_B\n```\n\n### Routine 2\n\nAT module serial port\n\n```python\nfm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX)\nfm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX)\nuart = machine.UART(machine.UART.UART2,115200,timeout=1000, read_buf_len=4096)\n```\n### Routine 3\n\nModify the baud rate of the REPL serial port\n\n```python\nfrom machine import UART\nrepl = UART.repl_uart()\nrepl.init(1500000, 8, None, 1, read_buf_len=2048)\n```\n\n### Routine 3\n\nModify the REPL serial port\n\n```python\nfrom machine import UART\n\nfm.register(board_info.PIN15,fm.fpioa.UART1_TX)\nfm.register(board_info.PIN17,fm.fpioa.UART1_RX)\nuart = machine.UART(UART.UART1, 115200)\nUART.set_repl_uart(uart)\n```"}, "/soft/maixpy/en/api_reference/machine/spi.html": {"title": "machine.SPI", "content": "---\ntitle: machine.SPI\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.SPI\n---\n\n\nSPI (Serial Peripheral Interface) is a synchronous serial protocol composed of a master and a slave.\n\nThe standard 4-wire mode consists of SCK (SCLK), CS (chip select), MOSI, MISO 4 wires connected to the master and slave\n\nOn K210, SPI has the following characteristics:\n\n* There are 4 SPI devices. SPI0, SPI1, SPI3 can only work in master mode, and SPI2 can only work in slave mode. On MaixPy, SPI3 has been used to connect SPI Flash as a reserved hardware resource.\n* Support 1/2/4/8 line full duplex mode. In MaixPy, currently only supports standard (Motorola) 4-wire full duplex mode (ie SCK, MOSI, MISO, CS four pins)\n* The highest transmission rate 45M: 1/2 frequency, about 200Mbps\n* Support DMA\n* 4 hardware chip selects that can be configured with any pin\n\n\n\n## Constructor\n\n```python\nspi = machine.SPI(id, mode=SPI.MODE_MASTER, baudrate=500000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck, mosi, miso, cs0, cs1, cs2, cs3)\n```\n\nCreate a new SPI object with the specified parameters\n\n### Parameters\n\n* `id`: SPI ID, value range [0,4], currently only supports 0, 1, 4, and can only be in master mode, 2 can only be used as a slave, currently not implemented, 3 reserved, 4 uses soft Simulate SPI (.SPI_SOFT)\n* `mode`: SPI mode, `MODE_MASTER` or `MODE_MASTER_2` or `MODE_MASTER_4` or `MODE_MASTER_8` or `MODE_SLAVE`, currently only supports `MODE_MASTER`\n* `baudrate`: SPI baud rate (frequency)\n* `polarity`: Polarity, the value is 0 or 1, which means the polarity of SPI when idle, 0 represents low level, 1 represents high level\n* `phase`: phase, the value bit is 0 or 1, indicating that the data is collected on the first or second edge of the clock, 0 means the first one, 1 means the second\n* `bits`: data width, the default value is 8, the value range is [4,32]\n* `firstbit`: Specify whether the transmission is in MSB or LSB order, the default is `SPI.MSB`\n* `sck`: SCK (clock) pin, the pin value can be passed directly, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `mosi`: MOSI (host output) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `miso`: MISO (host input) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `cs0`: CS0 (chip select) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `cs1`: CS1 (chip select) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `cs2`: CS2 (chip select) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `cs3`: CS3 (chip select) pin, the pin value can be directly passed, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `d0~d7`: data pins, used in non-standard 4-wire mode, currently reserved. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n\n## Method\n\n### init\n\nSimilar constructor\n\n```python\nspi.init(id, mode=SPI.MODE_MASTER, baudrate=500000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck, mosi, miso, cs0)\n```\n\n#### Parameters\n\nSame as constructor\n\n\n#### return value\n\nno\n\n\n### read\n\nRead data\n\n```python\nspi.read(nbytes, write=0x00, cs=SPI.CS0)\n```\n\n#### Parameters\n\n* `nbytes`: the length to be read\n* `cs`: select the chip select pin, the pins have been set for `cs0`~`cs3` during initialization, here only need to select `SPI.CS0`~`SPI.CS3`, the default is `SPI .CS0`\n* `write`: Because it is full duplex, set the value of the `MOSI` pin when reading, the default is `0x00`, that is, it is always low\n\n\n#### return value\n\n`bytes` type data\n\n\n### readinto\n\nRead the data and put it in the specified variable\n\n```python\nspi.readinto(buf, write=0x00, cs=SPI.CS0)\n```\n\n#### Parameters\n\n\n* `buf`: `bytearray` type, the length is defined, the data is saved here after reading\n* `cs`: select the chip select pin, the pins have been set for `cs0`~`cs3` during initialization, here only need to select `SPI.CS0`~`SPI.CS3`, the default is `SPI .CS0`\n* `write`: Because it is full duplex, set the value of the `MOSI` pin when reading, the default is `0x00`, that is, it is always low\n\n\n#### return value\n\nno\n\n### write\n\nsend data\n\n```python\nspi.write(buf, cs=SPI.CS0)\n```\n\n#### Parameters\n\n* `buf`: `bytearray` type, which defines the data and length\n* `cs`: select the chip select pin, the pins have been set for `cs0`~`cs3` during initialization, here only need to select `SPI.CS0`~`SPI.CS3`, the default is `SPI .CS0`\n\n#### return value\n\nno\n\n### write_readinto\n\nSend data and read data to variables at the same time, that is, full duplex\n\n```python\nspi.write(write_buf, read_buf, cs=SPI.CS0)\n```\n\n#### Parameters\n\n* `write_buf`: `bytearray` type, which defines the data and length to be sent\n* `read_buf`: `bytearray` type, which defines the storage location of the received data\n* `cs`: select the chip select pin, the pins have been set for `cs0`~`cs3` during initialization, here only need to select `SPI.CS0`~`SPI.CS3`, the default is `SPI .CS0`\n\n#### return value\n\nno\n\n### deinit/\\__del\\__\n\nLog off SPI, release hardware, turn off SPI clock\n\n```python\nspi.deinit()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n#### Examples\n\n```python\nspi.deinit()\n```\nor\n```\ndel spi\n```\n\n## Constant\n\n* `SPI0`: SPI 0\n* `SPI1`: SPI 1\n* `SPI2`: SPI 2\n* `MODE_MASTER`: as the master mode\n* `MODE_MASTER_2`: as the master mode\n* `MODE_MASTER_4`: as master mode\n* `MODE_MASTER_8`: as the master mode\n* `MODE_SLAVE`: as a slave mode\n* `MSB`: MSB, that is, send the high or high byte first\n* `LSB`: LSB, that is, send the low or low byte first\n* `CS0`: Chip select 0\n* `CS1`: Chip Select 1\n* `CS2`: Chip Select 2\n* `CS3`: Chip Select 3\n\n\n## Routine\n\n### Example 1: Basic read and write\n\n```python\nfrom machine import SPI\n\nspi = SPI(SPI.SPI1, mode=SPI.MODE_MASTER, baudrate=10000000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB, sck=28, mosi=29, miso=30, cs0= 27)\nw = b'1234'\nr = bytearray(4)\nspi.write(w)\nspi.write(w, cs=SPI.CS0)\nspi.write_readinto(w, r)\nspi.read(5, write=0x00)\nspi.readinto(r, write=0x00)\n```"}, "/soft/maixpy/en/api_reference/machine/wdt.html": {"title": "machine.WDT", "content": "---\ntitle: machine.WDT\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.WDT\n---\n\n\nMaixPy's WDT watchdog module is used to restart the system when the application crashes and eventually enters an unrecoverable state. Once started, when the hardware is running without regular feeding (feed), it will automatically reset after a timeout.\n\n## Constructor\n\n```python\nfrom machine import WDT\nwdt0 = WDT(id=1, timeout=4000, callback=on_wdt, context={})\n```\n\nCreate a new WDT object with specified parameters\n\n### Parameters\n\n* `id`: When this watchdog object must be initialized, an ID (0 ~ 2) must be specified to distinguish the watchdog used.\n* `timeout`: Watchdog timeout time, in milliseconds (ms).\n* `callback`: (Optional) A callback function that can be executed after timeout.\n* `context`: (Optional) The parameters passed to the callback function.\n\n## Method\n\n### feed\n\n\"Feed\" the watchdog to prevent it from resetting the system. The app should use the call in the right place and make sure to \"feed\" the watchdog only after verifying that everything is working properly.\n\n```python\nwdt0.feed()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### stop\n\nStop the current watchdog object\n\n```python\nwdt0.stop()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n## Routine\n\n\n### Routine 1 (Basic use)\n\nFeed the dog once and stop feeding the dog to reset the system\n\n```python\nimport time\nfrom machine import WDT\n\n#'''\n# test default wdt\nwdt0 = WDT(id=0, timeout=3000)\nprint('into', wdt0)\ntime.sleep(2)\nprint(time.ticks_ms())\n# 1.test wdt feed\nwdt0.feed()\ntime.sleep(2)\nprint(time.ticks_ms())\n# 2.test wdt stop\n# wdt0.stop()\n```\n\n### Routine 2 (advanced use)\n\nFeed the dog in the callback function and the system runs normally\n\n```python\nimport time\nfrom machine import WDT\ndef on_wdt(self):\n    print(self.context(), self)\n    self.feed()\n    ## release WDT\n    #self.stop()\n\n# test callback wdt\nwdt1 = WDT(id=1, timeout=4000, callback=on_wdt, context={})\nprint('into', wdt1)\ntime.sleep(2)\nprint(time.ticks_ms())\n# 1.test wdt feed\nwdt1.feed()\ntime.sleep(2)\nprint(time.ticks_ms())\n# 2.test wdt stop\n# wdt1.stop()\n# print('stop', wdt1)\n# 3.wait wdt work\nwhile True:\n    print('idle', time.ticks_ms())\n    time.sleep(1)\n```"}, "/soft/maixpy/en/api_reference/machine/network.html": {"title": "network", "content": "---\ntitle: network\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: network\n---\n\n\nThis module is used to initialize various network card drivers. The network card has the functions of connecting routing, disconnecting routing, viewing the connection information of the network card, and checking whether it is connected.\n\nTo use `WiFi` please make sure that the antenna is connected\n\n### [esp8285](##network.ESP8285(uart))\nOn some development boards, a network card module that uses `AT` to interact, such as `esp8285`, is connected to `k210` through a serial port\n\nPin `8` is the enable pin. You can create a `GPIO` object to control its high and low levels to achieve enable and disable, or you can use it to reset (low first and then high), and you need to wait for a while after reset Time to operate,\nYou can view the routine [network_espat.py](https://github.com/sipeed/MaixPy_scripts/blob/79a5485ec983e67bb8861305a52418b29e0dc205/network/network_espat.py)\n\n### [esp32](##network.ESP32_SPI(cs,rst,rdy,mosi,miso,sclk))\nCurrently there is an `esp32` module in the `MaixDuino` development board which is connected to `k210` through `spi`\nThere is also a separate `TF` plug-in module\n\n\n## network.ESP8285(uart)\n\nConstruct an `ESP8285` network card object. To use this method, you need to pass in a `uart` object. On the `dock` and `GO` currently supported by `MaixPy`, the AT command module is used as the `WiFi`. So the `uart` object is the object that communicates with the `AT` module, you can check the `uart` module routine\n\nCalling this method will initialize `ESP8285` and throw an exception if it fails\n\n\n### Parameters\n\n* `uart`: UART object communicating with AT module\n\n### return value\n\n* `ESP8285`: NIC object\n\n## ESP8285\n\n### connect(ssid, key)\n\nConnect hotspot (AP/router)\n\n#### Parameters\n\n* `ssid`: the `SSID` of the hotspot\n* `key`: hotspot password\n\n#### return value\n\nNone, if an error occurs, an exception will be thrown\n\n### 2.2. ifconfig\n\nView wifi connection information, currently network does not support setting network card configuration\n\n```\nnic.ifconfig()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\n`tuple` type, elements are all strings: `(ip, netmask, gateway, dns_server, dhcp_server, mac, ssid)`, if not found or invalid, the value is `\"0\"`\n\n\n### isconnected\n\nCheck if wifi is connected\n\n```\nnic.isconnected()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\n`True`: connected\n`False`: disconnect\n\n### disconnect\n\nDisconnect wifi connection\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### scan\n\nScan the surrounding hotspot information\n\n#### Parameters\n\nno\n\n#### return value\n\nA `list` object, each element contains a string, the string comes from the response of the `AT` module, and the content is the same as described in the `AT command document` of `esp8285`, as follows:\n`ecn, ssid, rssi,mac, channel, freq offset, freq cali, pairwise_cipher, group_cipher, bgn, wps`\n\n* `ecn`: Encryption method\n  * 0: OPEN\n  * 1: WEP\n  * 2: WPA_PSK\n  * 3: WPA2_PSK\n  * 4: WPA_WPA2_PSK\n  *5: WPA2_Enterprise (Previously, AT does not support connecting to this encrypted AP)\n* `ssid`: string parameter, AP's SSID\n* `rssi`: signal strength\n* `mac`: string parameter, AP's MAC address\n* `channel`: channel number\n* `freq offset`: AP frequency offset, unit: kHz. Divide this value by 2.4 to get the ppm value\n* `freq cali`: frequency offset calibration value\n* `pairwise_cipher`:\n  * 0: CIPHER_NONE\n  * 1: CIPHER_WEP40\n  * 2: CIPHER_WEP104\n  * 3: CIPHER_TKIP\n  * 4: CIPHER_CCMP\n  * 5: CIPHER_TKIP_CCMP\n  * 6: CIPHER_UNKNOWN\n* `group_cipher`: The definition is the same as `pairwise_cipher`\n* `bgn`: bit0 stands for b mode; bit1 stands for g mode; bit2 stands for n mode\n         If the corresponding bit is 1, it means the mode is enabled; if the corresponding bit is 0, the mode is not enabled.\n* `wps`: 0, WPS is not enabled; 1, WPS is enabled\n\nFor example:\n```\ninfo_strs = ['4,\"ChinaNet-lot0\",-79,\"c8:50:e9:e8:21:3e\",1,-42,0,4,3,7,1', '4,\"TOPSTEP2G4 \",-7\n0,\"f8:e7:1e:0d:0d:f8\",1,-57,0,4,4,7,0']\n```\nThis may seem strange, because the information of each AP is a string of characters, and there are integers and strings in the information. The strings are enclosed in double quotes, so after you get this string, you need to process it again. Use again, such as:\n```python\ndef wifi_deal_ap_info(info):\n    res = []\n    for ap_str in info:\n        ap_str = ap_str.split(\",\")\n        info_one = []\n        for node in ap_str:\n            if node.startswith('\"'):\n                info_one.append(node[1:-1])\n            else:\n                info_one.append(int(node))\n        res.append(info_one)\n    return res\n\ninfo_strs = ['4,\"ChinaNet-lot0\",-79,\"c8:50:e9:e8:21:3e\",1,-42,0,4,3,7,1', '4,\"TOPSTEP2G4 \",-70,\"f8:e7:1e:0d:0d:f8\",1,-57,0,4,4,7,0']\n\ninfo = wifi_deal_ap_info(info_strs)\nprint(info)\n```\n\nThe output is:\n\n```\n[[4,'ChinaNet-lot0', -79,'c8:50:e9:e8:21:3e', 1, -42, 0, 4, 3, 7, 1], [4,'TOPSTEP2G4', -70,'f8:e7:1e:0d:0d:f8', 1, -57, 0, 4, 4, 7, 0]]\n```\n\nThen for example, we need to get all the `SSID` of `AP` only need to use\n```\nfor ap_info in info:\n    print(ap_info[1])\n```\n\n### enable_ap(ssid, key, chl=5, ecn=3)\n\n* **Warning: As of November 26, 2020, MaixPy sockets have not yet implemented functions such as listen / bind / accpet. **\n\nOpen hotspot\n\n#### Parameters\n\n* `ssid`: SSID\n* `key`: password\n* `chl`: Channel number of WiFi signal\n* `ecn`: Encryption method, including `OPEN``WPA2_PSK`, etc., refer to the constant part of `ESP8285` on this page, the default value is `3`, which is `ESP8285.WPA2_PSK`, for example\n```python\nnic = network.ESP8285(uart)\nnic.enable_ap(\"maixpy\", \"12345678\", 5, nic.OPEN)\n```\nor\n```\nnic.enable_ap(\"maixpy\", \"12345678\", 5, network.ESP8285.OPEN)\n```\n\n\n\n### disable_ap()\n\nTurn off hotspot\n\n\n### Constant\n\n#### OPEN\n\nThe hotspot encryption method does not require a password\n\n#### WPA_PSK\n\nThe hotspot encryption method is `WPA_PSK`\n\n#### WPA2_PSK\n\nThe hotspot encryption method is `WPA2_PSK`\n\n#### WPA_WPA2_PSK\n\nThe encryption method of the hotspot is `WPA_WPA2_PSK`\n\n## Routine\n\n\nRefer to [routines in the network directory](https://github.com/sipeed/MaixPy_scripts/tree/master/network)\n\n\n## network.ESP32_SPI(cs,rst,rdy,mosi,miso,sclk)\n\nTo construct an `ESP32_SPI` network card object, you need to pass in the corresponding `GPIOHS FUNC`\n\nIf the number of incoming parameters is incorrect, an error will be returned\n\n**Note** If SPI and SD do not conflict on maixduino, you need to set ESP32_SPI as the hardware SPI configuration.\n\n### Parameters\n\n* `fpioa_func` corresponding to pin function\n\n### return value\n\n* `ESP32_SPI` network card object\n\n\n## ESP32_SPI\n\n### adc\n\nRead the `adc` value of the `esp32` module\n\n#### Parameters\n\nno\n\n#### return value\n\n`tunple`, the value of `adc` for 5 channels<br>The order is `\"PIN36\", \"PIN39\", \"PIN34\", \"PIN35\", \"PIN32\"`\n\n#### Routine\n\n[demo_esp32_read_adc.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/demo_esp32_read_adc.py)\n\n\n## network.WIZNET5K(spi, cs)\n\nConstruct a `WIZNET5K` network card object. To use this method, you need to pass in a `spi` object and a `cs` pin.\n\nCalling this method will initialize `WIZNET5K` and throw an exception if it fails\n\n\n### Parameters\n\n* `spi`: Responsible for communication with WIZNET5K module\n* `cs`: spi communication chip selection footer\n\n### return value\n\n* `WIZNET5K`: NIC object\n\n## WIZNET5K\n\n### dhclient\n\nDHCP dynamically obtain IP\n\n```\nnic.dhclient()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\n* `True`: Get success\n* `False`: Get failed\n\n### ifconfig\n\n```\nnic.ifconfig()\n```\n\n#### Parameters\n\n* No reference: query network card information\n* Incoming `(ip, netmask, gateway, dns_server)` string tuple: configure network card, `ip` ip address, `netmask` subnet mask, `gateway` gateway IP address, `dns_server` DNS service IP address .\n\n#### return value\n\n* No parameters: return `tuple`, the elements are all strings, `(ip, netmask, gateway, dns_server)`, if not found or invalid, the value is `\"0\"`\n* Pass parameter: return `None`\n\n### isconnected\n\nCheck if the network is connected\n\n```\nnic.isconnected()\n```\n#### Parameters\n\nno\n\n#### return value\n\n* `True`: already connected\n* `False`: disconnect\n\n#### Routine\n\n[network_wiznet5k.py](https://github.com/sipeed/MaixPy_scripts/blob/master/network/network_wiznet5k.py)"}, "/soft/maixpy/en/api_reference/machine/index.html": {"title": "machine", "content": "---\ntitle: machine\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: machine\n---\n\n\nThe machine library mainly contains various interfaces related to hardware, as follows:\n\n* [I2C](i2c.md)\n* [SPI](spi.md)\n* [Timer](timer.md)\n* [PWM](pwm.md)\n* [UART](uart.md)\n\n\n## Method machine.unique_id()\n\nGet unique ID\n\n\n### return value\n\n32-byte unique ID\n\n## Method machine.reset()\n\nReboot"}, "/soft/maixpy/en/api_reference/machine/machine.html": {"title": "machine", "content": "---\ntitle: machine\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: machine\n---\n\n\n\n\n## unique_id"}, "/soft/maixpy/en/api_reference/machine/timer.html": {"title": "machine.Timer", "content": "---\ntitle: machine.Timer\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.Timer\n---\n\n\nThe hardware timer can be used to trigger tasks or process tasks regularly. After the set time is up, an interrupt can be triggered (call the callback function), and the accuracy is higher than the software timer.\nIt should be noted that timers may behave differently in different hardware. MicroPython's Timer class defines the basic operation of executing a callback within a given time period (or executing a callback after a delay), and allows more non-standard behaviors to be defined on specific hardware (so it cannot be ported to other boards).\n\nThere are 3 timers, each timer has 4 channels available\n\n## Constructor\n\n```python\ntim = machine.Timer(id, channel, mode=Timer.MODE_ONE_SHOT, period=1000, unit=Timer.UNIT_MS, callback=None, arg=None, start=True, priority=1, div=0)\n```\n\nCreate a new Timer object with the specified parameters\n\n### Parameters\n\n* `id`: Timer ID, [0~2] \\(Timer.TIMER0~TIMER2\\)\n* `channel`: Timer channel, [Timer.CHANNEL0~Timer.CHANNEL3]\n* `mode`: Timer mode, `MODE_ONE_SHOT` or `MODE_PERIODIC` or `MODE_PWM`\n* `period`: Timer period, after starting the timer `period` time, the callback function will be called, (0,~)\n* `unit`: Set the unit of the period, the default bit is milliseconds (`ms`), `Timer.UNIT_S` or `Timer.UNIT_MS` or `Timer.UNIT_US` or `Timer.UNIT_NS`\n* `callback`: Timer callback function, defines two parameters, one is the timer object `Timer`, the second is the parameter `arg` that you want to pass in the definition object, please see the explanation of `arg` parameters for more\n> Note: The callback function is called in the interrupt, so please don't take too long in the callback function and do dynamic allocation switch interrupt etc.\n* `arg`: The parameter that you want to pass to the callback function as the second parameter of the callback function\n* `start`: Whether to start the timer immediately after the object is successfully constructed, `True`: start immediately, `False`: not start immediately, you need to call the `start()` function to start the timer\n* `priority`: hardware timer interrupt priority, related to a specific CPU, in K210, the value range is [1,7], the smaller the value, the higher the priority\n* `div`: hardware timer divider, value range [0,255], default is 0, clk_timer (timer clock frequency) = clk_pll0 (phase-locked loop 0 frequency)/2^(div+1)\n> clk_timer*period(unit:s) should be <2^32 and >=1\n\n\n## Method\n\n### init\n\nSimilar constructor\n\n```python\ntim.init(id, channel, mode=Timer.MODE_ONE_SHOT, period=1000, unit=Timer.UNIT_MS, callback=None, arg=None, start=True, priority=1, div=0)\n```\n\n#### Parameters\n\nSimilar constructor\n\n#### return value\n\nno\n\n\n### callback_arg\n\nGet the set parameters passed to the callback function, which can only be called by the `Timer` object, the class `Timer` cannot be called\n\n\n### callback\n\nGet or set callback function\n\n```python\ntim.callback(callback)\n```\n\n#### Parameters\n\n* `callback`: the set callback function, optional parameters, if no parameters are passed, only the previous callback function will be returned\n\n#### return value\n\nCurrent callback function\n\n#### Examples\n\n```python\ndef on_timer(timer):\n    print(\"time up:\",timer)\n    print(\"param:\",timer.callback_arg())\n\ntim.callback(on_timer)\nprint(on_timer, tim.callback())\n```\n\n### period\n\nGet or set the timing period\n\n```python\ntim.period(period)\n```\n\n#### Parameters\n\n* `period`: Optional parameter, configure the period, if no parameter is passed, only the current period value will be returned\n\n#### return value\n\nCurrent period value\n\n#### Examples\n\n```python\ntim.period(2000)\nprint( tim.period())\n```\n\n### start\n\nStart timer\n\n```python\ntim.start()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n#### Examples\n\n```python\ntim.start()\n```\n\n### stop\n\nStop timer\n\n```python\ntim.stop()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### restart\n\nRestart timer\n\n```python\ntim.restart()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### deinit/\\__del\\__\n\nLog off the timer, log off the hardware occupation, turn off the hardware clock\n\n```python\ntim.deinit()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n#### Examples\n\n```python\ntim.deinit()\n```\nor\n```python\ndel tim\n```\n\n## Constant\n\n* `TIMER0`: Timer0 id\n* `TIMER1`: Timer1 id\n* `TIMER2`: Timer2 id\n* `CHANNEL0`: Timer channel 0\n* `CHANNEL1`: Timer channel 1\n* `CHANNEL2`: Timer channel 2\n* `CHANNEL3`: Timer channel 3\n* `MODE_ONE_SHOT`: Timer runs only once (callback once)\n* `MODE_PERIODIC`: Timer always runs (continuous callback)\n* `MODE_PWM`: The timer is not used as a callback function to generate PWM\n* `UNIT_S`: unit of second (s)\n* `UNIT_MS`: unit milliseconds (ms)\n* `UNIT_US`: unit microsecond (us)\n* `UNIT_NS`: unit nanosecond (ns)\n\n\n## Routine\n\n### Routine 1\n\nPrint information after 3 seconds\n\n```python\nfrom machine import Timer\n\ndef on_timer(timer):\n    print(\"time up:\",timer)\n    print(\"param:\",timer.callback_arg())\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_ONE_SHOT, period=3000, callback=on_timer, arg=on_timer)\nprint(\"period:\",tim.period())\n```\n\n### Routine 2\n\nPrint messages every 1 second, stop for 5 seconds and restart again, turn off and log off the timer after 5 seconds\n\n```python\nimport time\nfrom machine import Timer\n\ndef on_timer(timer):\n    print(\"time up:\",timer)\n    print(\"param:\",timer.callback_arg())\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=1, unit=Timer.UNIT_S, callback=on_timer, arg=on_timer, start=False, priority=1, div=0)\nprint(\"period:\",tim.period())\ntim.start()\ntime.sleep(5)\ntim.stop()\ntime.sleep(5)\ntim.restart()\ntime.sleep(5)\ntim.stop()\ndel tim\n```"}, "/soft/maixpy/en/api_reference/machine/i2c.html": {"title": "machine.I2C", "content": "---\ntitle: machine.I2C\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.I2C\n---\n\n\n\nI2C bus protocol, simply use two lines (SCL, SDA) to control multiple slaves (master mode).\n\n* Support master mode and slave mode\n* 7-bit/10-bit addressing mode\n* Standard mode <=100Kb/s\n* Fast mode <=400Kb/s\n* Super fast mode <=1000Kb/s\n* High-speed mode 3.4Mb/s\n\n## Constructor\n\n```python\nclass machine.I2C(id, mode=I2C.MODE_MASTER, scl=None, sda=None, gscl=None, gsda=None, freq=400000, timeout=1000, addr=0, addr_size=7, on_recieve=None, on_transmit =None, on_event=None)\n```\n\nCreate a new I2C object with the specified parameters\n\n### Parameters\n\n* `id`: I2C ID, [0~2] \\(I2C.I2C0~I2C.I2C2\\) [3~5] \\(I2C.I2C3~I2C.I2C5, I2C_SOFT\\) is the number of soft analog I2C\n* `mode`: Mode, master (`I2C.MODE_MASTER`) and slave (`I2C.MODE_SLAVE`) modes\n* `scl`: SCL pin, just pass the pin number directly, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `sda`: SDA pin, just pass the pin number directly, the value range: [0,47]. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `gscl`: GPIOHS corresponding to SCL, only need to be passed when using software to simulate I2C, the default is the same as `scl`.\n* `gsda`: GPIOHS corresponding to SDA, only need to be passed when using software to simulate I2C, the default is the same as `sda`.\n* `freq`: I2C communication frequency, supports standard 100Kb/s, fast 400Kb/s, and higher rates (hardware supports ultra-fast mode 1000Kb/s, and high-speed mode 3.4Mb/s)\n* `timeout`: timeout time, currently this parameter is reserved, the setting is invalid\n* `addr`: slave address, if it is in master mode, don’t need to set, slave mode means slave (local) address\n* `addr_size`: address length, supports 7-bit addressing and 10-bit addressing, the value is `7` or `10`\n* `on_recieve`: Receive callback function in slave mode\n* `on_transmit`: send callback function in slave mode\n* `on_event`: event function in slave mode (start event and end event)\n\n## Method\n\n### init\n\nSimilar constructor\n\n```python\ni2c = I2C.init(id, mode=Timer.MODE_MASTER, scl, sda, gscl, gsda, freq=400000, timeout=1000, addr=0, addr_size=7, on_recieve=None, on_transmit=None, on_event=None)\n```\n\n#### Parameters\n\nSame as constructor\n\n\n\n#### return value\n\nno\n\n\n### scan\n\nScan the slave on the I2C bus\n\n```python\ni2c.scan()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nlist object, contains all scanned slave addresses\n\n\n### readfrom\n\nRead data from the bus\n\n```python\ni2c.readfrom(addr, len, stop=True)\n```\n\n#### Parameters\n\n* `addr`: slave address\n* `len`: data length\n* `stop`: Whether to generate a stop signal, keep it, currently only the default value Ture can be used\n\n#### return value\n\nThe read data, `bytes` type\n\n### readfrom_into\n\nRead the data and put it in the specified variable\n\n```python\ni2c.readfrom_into(addr, buf, stop=True)\n```\n\n#### Parameters\n\n* `addr`: slave address\n* `buf`: `bytearray` type, the length is defined, the data read is stored here\n* `stop`: Whether to generate a stop signal, keep it, currently only the default value Ture can be used\n\n#### return value\n\nno\n\n### writeto\n\nSend data to slave\n\n```python\ni2c.writeto(addr, buf, stop=True)\n```\n\n#### Parameters\n\n\n* `addr`: slave address\n* `buf`: The data to be sent\n* `stop`: Whether to generate a stop signal, keep it, currently only the default value Ture can be used\n\n#### return value\n\nNumber of bytes sent successfully\n\n### readfrom_mem\n\nRead slave register\n\n```python\ni2c.readfrom_mem(addr, memaddr, nbytes, mem_size=8)\n```\n\n#### Parameters\n\n* `addr`: slave address\n* `memaddr`: slave register address\n* `nbytes`: the length to be read\n* `mem_size`: register width, the default is 8 bits\n\n#### return value\n\nReturns the read data of `bytes` type\n\n\n### readfrom_mem_into\n\nRead the slave register value into the specified variable\n\n```python\ni2c.readfrom_mem_into(addr, memaddr, buf, mem_size=8)\n```\n\n#### Parameters\n\n* `addr`: slave address\n* `memaddr`: slave register address\n* `buf`: `bytearray` type, the length is defined, the data read is stored here\n* `mem_size`: register width, the default is 8 bits\n\n#### return value\n\nno\n\n\n### writeto_mem\n\nWrite data to slave register\n\n```python\ni2c.writeto_mem(addr, memaddr, buf, mem_size=8)\n```\n\n#### Parameters\n\n\n* `addr`: slave address\n* `memaddr`: slave register address\n* `buf`: the data to be written\n* `mem_size`: register width, the default is 8 bits\n\n#### return value\n\nno\n\n### deinit/\\__del\\__\n\nLog off the I2C hardware, release the occupied resources, and turn off the I2C clock\n\n```python\ni2c.deinit()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n#### Examples\n\n```python\ni2c.deinit()\n```\nor\n```python\ndel i2c\n```\n\n\n## Constant\n\n* `I2C0`: I2C 0\n* `I2C1`: I2C 1\n* `I2C2`: I2C 2\n* `MODE_MASTER`: as the master mode\n* `MODE_SLAVE`: as a slave mode\n* `I2C_EV_START`: Event type, start signal\n* `I2C_EV_RESTART`: Event type, restart signal\n* `I2C_EV_STOP`: Event type, end signal\n\n\n## Routine\n\n### Example 1: Scan the slave device\n\n```python\nfrom machine import I2C\n\ni2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29)\ndevices = i2c.scan()\nprint(devices)\n```\n\n### Example 2: Read and write\n\n```python\nimport time\nfrom machine import I2C\n\ni2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29)\ni2c.writeto(0x24,b'123')\ni2c.readfrom(0x24,5)\n```\n\n### Example 3: Slave mode\n\n```python\nfrom machine import I2C\n\ncount = 0\n\ndef on_receive(data):\n    print(\"on_receive:\",data)\n\ndef on_transmit():\n    count = count+1\n    print(\"on_transmit, send:\",count)\n    return count\n\ndef on_event(event):\n    print(\"on_event:\",event)\n\ni2c = I2C(I2C.I2C0, mode=I2C.MODE_SLAVE, scl=28, sda=29, addr=0x24, addr_size=7, on_receive=on_receive, on_transmit=on_transmit, on_event=on_event)\n```\n\n### Example 4: OLED(ssd1306 128x64)\n```python\nimport time\nfrom machine import I2C\n\nSSD1306_CMD = 0\nSSD1306_DATA = 1\nSSD1306_ADDR = 0x3c\n\ndef oled_init(i2c):\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xAE, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x20, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x10, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xb0, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xc8, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x00, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x10, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x40, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x81, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xff, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xa1, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xa6, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xa8, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x3F, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xa4, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xd3, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x00, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xd5, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xf0, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xd9, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x22, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xda, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x12, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xdb, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x20, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x8d, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x14, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xaf, mem_size=8)\n\n\n\ndef oled_on(i2c):\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0X8D, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0X14, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0XAF, mem_size=8)\n\ndef oled_off(i2c):\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0X8D, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0X10, mem_size=8)\n    i2c.writeto_mem(SSD1306_ADDR, 0x00, 0XAE, mem_size=8)\n\ndef oled_fill(i2c, data):\n    for i in range(0,8):\n        i2c.writeto_mem(SSD1306_ADDR, 0x00, 0xb0+i, mem_size=8)\n        i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x10, mem_size=8)\n        i2c.writeto_mem(SSD1306_ADDR, 0x00, 0x01, mem_size=8)\n        for j in range(0,128):\n            i2c.writeto_mem(SSD1306_ADDR, 0x40, data, mem_size=8)\n\ni2c = I2C(I2C.I2C0, mode=I2C.MODE_MASTER, freq=400000, scl=28, sda=29, addr_size=7)\n\ntime.sleep(1)\noled_init(i2c)\noled_fill(i2c, 0xff)\n\n```"}, "/soft/maixpy/en/api_reference/machine/pwm.html": {"title": "machine.PWM", "content": "---\ntitle: machine.PWM\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: machine.PWM\n---\n\n\nPWM: Pulse width modulation module, PWM supported by hardware, you can specify any pin (0 to 47 pins)\n\nEach PWM depends on a timer, that is, when the timer is bound with the PWM function, it cannot be used as a normal timer. Because there are 3 timers, each timer has 4 channels, that is, a maximum of 12 PWM waveforms can be generated simultaneously\n\n## Constructor\n\n```python\npwm = machine.PWM(tim, freq, duty, pin, enable=True)\n```\n\nCreate a new PWM object with specified parameters\n\n### Parameters\n\n* `tim`: Each PWM relies on a timer to generate waveforms, so a timer object needs to be passed here. The timer ID and channel number must be specified when the timer object is initialized\n* `freq`: PWM waveform frequency\n* `duty`: PWM duty cycle, refers to the percentage of the high level in the entire cycle, value: [0,100]\n* `[pin]`: PWM output pin. It is not necessary to set, but use [fm](../builtin_py/fm.html) to manage pin mapping in a unified manner.\n* `enable`: Whether to start generating the waveform immediately, the default bit is `True`, and the PWM waveform will be generated on the specified pin immediately after the object is generated\n\n## Method\n\n### init\n\nSimilar constructor\n\n```python\npwm.init(tim, freq, duty, pin, enable=True)\n```\n\n#### Parameters\n\nSame as constructor\n\n#### return value\n\nno\n\n\n### freq\n\nGet or set PWM frequency\n\n```python\npwm.freq(freq)\n```\n\n#### Parameters\n\n* `freq`: PWM frequency, optional parameter, if no parameter is passed, the step setting will only return the current frequency value\n\n#### return value\n\nActual PWM frequency currently set\n\n\n### duty\n\nGet or set the PWM duty cycle\n\n```python\npwm.duty(duty)\n```\n\n#### Parameters\n\n* `duty`: PWM duty cycle is optional, if no parameter is passed, the step setting will only return the current duty cycle value\n\n#### return value\n\nThe currently set PWM duty cycle value\n\n\n### enable\n\nEnable PWM output to generate waveform on the specified pin immediately\n\n```python\npwm.enable()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### disable\n\nDisabled PWM output, the specified pin no longer generates waveform\n\n```python\npwm.disable()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n### deinit/\\__del\\__\n\nLog off the PWM hardware, release the occupied resources, and turn off the PWM clock\n\n```python\npwm.deinit()\n```\n\n#### Parameters\n\nno\n\n#### return value\n\nno\n\n#### Examples\n\n```python\npwm.deinit()\n```\nor\n```python\ndel pwm\n```\n\n## Constant\n\nno\n\n\n## Routine\n\n\n### Routine 1 (breathing light)\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nfrom machine import Timer,PWM\nimport time\nfrom board import board_info\n\ntim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)\nch = PWM(tim, freq=500000, duty=50, pin=board_info.LED_G)\nduty=0\ndir = True\nwhile True:\n    if dir:\n        duty += 10\n    else:\n        duty -= 10\n    if duty>100:\n        duty = 100\n        dir = False\n    elif duty<0:\n        duty = 0\n        dir = True\n    time.sleep(0.05)\n    ch.duty(duty)\n```\n\n### Routine 2\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](../builtin_py/board_info.html) is required before use.\n\n```python\nimport time\nimport machine\nfrom board import board_info\n\ntim = machine.Timer(machine.Timer.TIMER0, machine.Timer.CHANNEL0, mode=machine.Timer.MODE_PWM)\nch0 = machine.PWM(tim, freq=3000000, duty=20, pin=board_info.LED_G, enable=False)\nch0.enable()\ntime.sleep(3)\nch0.freq(2000000)\nprint(\"freq:\",ch0.freq())\nch0.duty(60)\ntime.sleep(3)\nch0.disable()\n```"}, "/soft/maixpy/en/api_reference/builtin_py/pye.html": {"title": "Micropython Editor", "content": "---\ntitle: Micropython Editor\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Micropython Editor\n---\n\n\nMaixPy firmware integrates a file editor-[`pye`](https://github.com/robert-hh/Micropython-Editor), users can directly modify the files in the board through the serial terminal\n\nInstructions:\n\n```python\n\nfrom pye_mp import pye\n\npye(\"/sd/boot.py\")\n\n```"}, "/soft/maixpy/en/api_reference/builtin_py/fm.html": {"title": "fpioa_manager", "content": "---\ntitle: fpioa_manager\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: fpioa_manager\n---\n\n\n> **This document has passed the test of MaixPy 0.5.1-128. **\n\nfpioa_manager: abbreviated as `fm`, this module is used to register the internal functions and pins of the chip, and help users to manage the internal functions and pin mapping relationships.\n\n## How to understand [pin] mapping [internal function]?\n\nThe external pins and internal functions on the K210 chip are independent of each other. The pins refer to many metal contacts drawn from the chip, which are also commonly known as function pins. It can be GPIO / PWM / ADC / I2C, etc. Function pins, the traditional cognition is that the internal functions corresponding to the pins cannot be changed, but they can be reused. The K210 can change the pin functions through mapping. See the diagram below to understand the specific mapping functions.\n\nFirst, you can map (MAP) the I2C SCL/SDA to the IO6/IO7 pin, so that I2C read and write operations can be performed on this pin.\n\n```\n    +------------------------------+\n    |                              |\n    |           +---+              |\n<-----+ <-----+ |I2C|              |\n IO6|           +---+              |\n    |           |                  |\n    |           |   +----+         |\n<-----+ <-------+   |UART|         |\n IO7|               +----+         |\n    |                              |\n    |           +---+              |\n<-----+         |SPI|              |\n IO8|           +---+              |\n    |                              |\n    |             +---+            |\n<-----+           |I2S|            |\n IO9|             +---+            |\n    |                              |\n    |                              |\n    +------------------------------+\n```\n\nThen you can map (MAP) the SCLK/MOSI/MISO/CS of SPI to the IO6/IO7/IO8/IO9 pin, and you can read and write SPI on this pin.\n\n```\n    +------------------------------+\n    |                              |\n    |               +---+          |\n<------<-------<--  |I2C|          |\n IO6|            |  +---+          |\n    |            |                 |\n    |            |       +----+    |\n<------<------+  |       |UART|    |\n IO7|         |  |       +----+    |\n    |         +--+-+               |\n    |          |SPI|               |\n<------<--------+--+               |\n IO8|           |                  |\n    |           |                  |\n    |           |    +---+         |\n<------<--------+    |I2S|         |\n IO9|                +---+         |\n    |                              |\n    |                              |\n    +------------------------------+\n```\n\n## Instructions\n\nCall the register function to bind the pin to the specific hardware function (GPIO/I2C/UART/I2S/SPI), and call unregister when not in use to release the hardware function bound to the pin (or **function* *) This is different from the understanding of traditional single-chip microcomputers. K210 can map pins within a certain range to specific hardware functions.\n\nAs shown in the following code:\n\n```python\nfrom fpioa_manager import fm\n\nfm.register(11, fm.fpioa.GPIO0, force=True)\nfm.register(12, fm.fpioa.GPIOHS0, force=True)\nfm.register(13, fm.fpioa.UART2_TX)\nfm.register(14, fm.fpioa.UART2_RX)\n\n# other code\n\nfm.unregister(11)\nfm.unregister(12)\nfm.unregister(13)\nfm.unregister(14)\n```\n\n**Precautions**:\n\nThe following GPIOHS has been used by default in MaixPy, please don't use it unless necessary in the program.\n\n| GPIOHS | Function | Description |\n| --- | --- | --- |\n| GPIOHS31 | LCD_DC | LCD control signal pin |\n| GPIOHS30 | LCD_RST | LCD reset chip pin |\n| GPIOHS29 | SD_CS | SD card SPI chip select |\n| GPIOHS28 | MIC_LED_CLK | SK9822_DAT |\n| GPIOHS27 | MIC_LED_DATA | SK9822_CLK |\n\nIn addition, the following pins have been registered when MaxiPy starts up, please pay attention.\n\n### SD card\n* `Function`: SPI1_SCLK/SPI1_D0/SPI1_D1/GPIOHS29/SPI0_SS1\n* `Pin`: PIN25/PIN26/PIN27/PIN28/PIN29\n\n### LCD\n* `Function`: SPI0_SS3/SPI0_SCLK/GPIOHS30/GPIOHS31\n* `Pin`: PIN36/PIN37/PIN38/PIN39\n\n### sensor\n* `Function`: SCCB_SDA/SCCB_SCLK/CMOS_RST/CMOS_VSYNC/CMOS_PWDN/CMOS_HREF/CMOS_XCLK/CMOS_PCLK\n* `Pin`: PIN40/PIN41/PIN42/PIN43/PIN44/PIN45/PIN46/PIN47\n\n### REPL\n* `Function`: UARTHS_RX/UARTHS_TX\n* `Pin`: PIN4/PIN5\n\n## class `fm`\n\n### register(pin, func, force=True)\n\n* `pin`: Function mapping pin\n* `function`: Chip function\n* `force`: Forced allocation, if it is `True`, the same pin can be registered multiple times; `False` does not allow multiple registration of the same pin. The default is `True` to facilitate the use of `IDE` to run the program multiple times\n\nSet the peripheral function (func) corresponding to the pin (pin). The forced binding parameter (force=True) is enabled by default. It will force the specified pin function to be replaced. If it finds the last bound pin, it will A warning is issued, but it does not affect the continued execution of the code.\n\nIf force=False is set, it will be found in the register that the hardware function has been used, and an exception will pop up at this time, which is convenient for in-depth development. When some functions cannot be used.\n\n#### Instructions\n\n```python\nfrom fpioa_manager import fm\nfm.register(16, fm.fpioa.GPIO2)\nfm.register(13, fm.fpioa.GPIO2)\nfm.register(12, fm.fpioa.GPIO2, force=False)\n```\n\nIt can be seen that the occupancy status of fm.fpioa.GPIO2(pin:16) and fm.fpioa.GPIO2(pin:13) are prompted.\n\n```shell\n[Warning] function is used by fm.fpioa.GPIO2(pin:16)\nTraceback (most recent call last):\n  File \"<stdin>\", line 5, in <module>\n  File \"fpioa_manager.py\", line 20, in register\nException: [Warning] function is used by fm.fpioa.GPIO2(pin:13)\n```\n\n### unregister(pin)\n\nRelease the hardware function (GPIO/I2C/SPI/I2S/UART) on the pin.\n\n### get_pin_by_function(pin)\n\nGet the hardware function bound on the pin.\n\n### get_gpio_used()\n\nGet the usage status of all gpio, it only queries the GPIOHS / GPIO pin assignment, None means that the hardware function is not used.\n\n#### Instructions\n\n```python\nfrom fpioa_manager import fm\nfor item in fm.get_gpio_used():\n    print(item)\n```\n\n> Note: Each pin will have a default state\n```shell\n('fm.fpioa.GPIOHS0', 16)\n('fm.fpioa.GPIOHS1', 17)\n('fm.fpioa.GPIOHS2', 18)\n('fm.fpioa.GPIOHS3', 19)\n('fm.fpioa.GPIOHS4', 37)\n('fm.fpioa.GPIOHS5', 38)\n('fm.fpioa.GPIOHS6', 22)\n('fm.fpioa.GPIOHS7', 23)\n('fm.fpioa.GPIOHS8', 24)\n('fm.fpioa.GPIOHS9', 25)\n('fm.fpioa.GPIOHS10', None)\n('fm.fpioa.GPIOHS11', 27)\n('fm.fpioa.GPIOHS12', 28)\n('fm.fpioa.GPIOHS13', 29)\n('fm.fpioa.GPIOHS14', 30)\n('fm.fpioa.GPIOHS15', 31)\n('fm.fpioa.GPIOHS16', 32)\n('fm.fpioa.GPIOHS17', 33)\n('fm.fpioa.GPIOHS18', 34)\n('fm.fpioa.GPIOHS19', 35)\n('fm.fpioa.GPIOHS20', None)\n('fm.fpioa.GPIOHS21', None)\n('fm.fpioa.GPIOHS22', None)\n('fm.fpioa.GPIOHS23', None)\n('fm.fpioa.GPIOHS24', 40)\n('fm.fpioa.GPIOHS25', 41)\n('fm.fpioa.GPIOHS26', 42)\n('fm.fpioa.GPIOHS27', 43)\n('fm.fpioa.GPIOHS28', 44)\n('fm.fpioa.GPIOHS29', 26)\n('fm.fpioa.GPIOHS30', 46)\n('fm.fpioa.GPIOHS31', 47)\n('fm.fpioa.GPIO0', 8)\n('fm.fpioa.GPIO1', 9)\n('fm.fpioa.GPIO2', None)\n('fm.fpioa.GPIO3', None)\n('fm.fpioa.GPIO4', 12)\n('fm.fpioa.GPIO5', 13)\n('fm.fpioa.GPIO6', 14)\n('fm.fpioa.GPIO7', 15)\n```\n\n### help()\n\nCalling it will print out the following help description of \"Appendix: Peripheral Table\".\n\nSee [FPIOA](../Maix/fpioa.html) for details."}, "/soft/maixpy/en/api_reference/builtin_py/index.html": {"title": "built-in class (builtin_py)", "content": "---\ntitle: built-in class (builtin_py)\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: built-in class (builtin_py)\n---\n\n\nThe `builtin_py` library (builtin_py) is a user-level interface that encapsulates the underlying classes of MaixPy, which is convenient for users to use MaixPy. It includes the following:\n\n* [fpioa_manager](fm.md)\n* [board_info](board_info.md)\n* [pye](pye.md)\n\n> `board_info` is related to the board, and different board configurations are different. [Manual configuration](board_info.md) is required before use.\n\n```python\nfrom board import board_info\nfrom fpioa_manager import fm\n```"}, "/soft/maixpy/en/api_reference/builtin_py/board_info.html": {"title": "Board", "content": "---\ntitle: Board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Board\n---\n\n\n> **This document has passed the test of MaixPy 0.5.1-128. **\n\nThis is a MaixPy board-level configuration module, which can unify Python code at the user level, thereby shielding many hardware pin differences.\n\nThe effect is as follows:\n\n```python\nfrom Maix import GPIO\nfrom fpioa_manager import fm\nfrom board import board_info\nprint(board_info.LED_R)\nfm.register(board_info.LED_R, fm.fpioa.GPIO0, force=True)\nled_r = GPIO(GPIO.GPIO0, GPIO.OUT)\nled_r.value(0)\n```\n\nAnd this code supports all MaixPy hardware to run at the same time, and the printed board_info.LED_R is not the same, it ensures the consistency of the sample code.\n\n### Board configuration method\n\nCopy the python code corresponding to the following link (such as config_maix_bit.py), put it in the IDE edit box and run it to complete the import of the \"your hardware\" configuration item (config.json), which will be stored on the flash Configuration file.\n\nAfter running the configuration code, it will automatically restart. At this time, board_info.BOOT_KEY can be called in the code. In fact, board_info.BOOT_KEY refers to IO 16. The corresponding definition can be seen in config.json. If the resource does not exist, an error will be reported. If there is no hardware defined by LED, an error will be reported when the running LED is on.\n\n```python\nfrom board import board_info\n# see board/readme.md to config your sipeed's hardware.\nprint(board_info.BOOT_KEY, board_info.BOOT_KEY == 16)\n```\n\n### Maix Bit\n\n[config_maix_bit.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_bit.py)\n\n### Maix Dock\n\n[config_maix_dock.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_dock.py)\n\n### Maix Go\n\n[config_maix_go.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_go.py)\n\n### Maix Duino\n\n[config_maix_duino.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_duino.py)\n\n### Maix Cube\n\n[config_maix_cube.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_cube.py)\n\n### Maix Amigo\n\n[config_maix_amigo.py](https://github.com/sipeed/MaixPy_scripts/tree/master/board/config_maix_amigo.py)\n\n### Maix Nano\n\n> This has no hardware peripherals... So don't ask why there is no configuration code.\n\n### Create your own hardware\n\nYou can use this interface code to adapt to your hardware. For the configuration method, please refer to [MaixPy_scripts/board](https://github.com/sipeed/MaixPy_scripts/tree/master/board) There is a configuration file for your reference.\n\n### How to use board\n\nImport configuration:\n\n```python\nfrom board import board_info\nboard_info.load({\n    'PIN10': 10,\n    'BOOT_KEY': 16,\n    'WIFI_TX': 6,\n    'WIFI_RX': 7,\n    'WIFI_EN': 8,\n})\nprint('PIN10:', board_info.PIN10)\nprint('BOOT_KEY:', board_info.BOOT_KEY)\nprint('WIFI_TX:', board_info.WIFI_TX)\nprint('WIFI_RX:', board_info.WIFI_RX)\nprint('WIFI_EN:', board_info.WIFI_EN)\n```\n\nCall result:\n\n```shell\nPIN10: 10\nBOOT_KEY: 16\nWIFI_TX: 6\nWIFI_RX: 7\nWIFI_EN: 8\n```\n\n> That's it."}, "/soft/maixpy/en/get_started/get_started_power_on.html": {"title": "MaixPy Development Board Power", "content": "---\ntitle: MaixPy Development Board Power\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy development board power\n---\n\nWhen we get the MaixPy development board\n\n## Check the hardware\n\nCheck whether the hardware is damaged, and whether the camera and the screen are connected properly. Do not connect the cable reversely.\n\n\n## Connect the hardware\n\nConnect the Type C cable, one end of the computer and the other end of the development board\n\nCheck whether the device has been correctly identified:\n\nIn Windows, you can open the Device Manager to view\n\nUnder Linux, you can use `ls /dev/ttyUSB*` or `ls /dev/ttyACM*` to view, if not, you can search for `ls /dev`. The specific device name is related to the serial port chip and driver\n\n\nIf the device is not found, you need to confirm whether the driver is installed and the contact is good\n\nAfter power on, if it is a new factory development board, it may display a red background. The foreground is a simple MaixPy introduction, including the official website address. The screen is still, and it needs to be changed by the following programming.\n\n## Check the firmware version\n\nUse **Serial Terminal** to open the serial port, and then reset, see the output version information, and [github](https://github.com/sipeed/MaixPy/releases) or [master branch](http://dl. sipeed.com/MAIX/MaixPy/release/master/) firmware version comparison, consider upgrading to the latest version according to the current version\n\nsuch as:\n\n```python\n[MaixPy] init end\n\n __ __ _____ __ __ _____ __ __\n| \\/ | /\\ |_ _| \\ \\ / / | __ \\ \\ \\ / /\n| \\ / | / \\ | | \\ V / | |__) | \\ \\_/ /\n| |\\/| | / /\\ \\ | |> <| ___/ \\ /\n| | | | / ____ \\ _| |_ /. \\ | | | |\n|_| |_| /_/ \\_\\ |_____| /_/ \\_\\ |_| |_|\n\nOfficial Site: https://www.sipeed.com\nWiki: https://maixpy.sipeed.com\n\nMicroPython v0.5.0-12-g284ce83 on 2019-12-31; Sipeed_M1 with kendryte-k210\nType \"help()\" for more information.\n```\n\n**View version number:**\n\n  The version here is `v0.5.0-12-g284ce83`, you can also use the following code to view the version\n\n> **Note:** The firmware can be obtained from the download site [dl.sipeed.com](http://dl.sipeed.com/MAIX/MaixPy/release/master/)\n\n```python\nimport sys\nprint(sys.implementation.version)\n```\n\nIf you encounter problems during the development process, you can also try to update the firmware to the latest version first\n\n## Execute code\n\n* After opening the serial port terminal, press the reset button of the development board to see the printed boot information and output\n\n```shell\n>>>\n```\n\nThat is, we are waiting for us to enter the code. If there is no such symbol, there may be a program running automatically when booting up. You can press `Ctrl+C` to cancel the running program\n\n* Then enter the program to execute\n\n```python\n>>> print(\"hello world\")\nhello world\n>>>\n```\n\n## Paste and execute multiple lines of code\n\nWhen we have multiple lines of code copied from other places, such as\n\n```python\nimport os\nf = os.listdir()\nprint(f)\n```\n\n* Copy the code first\n* Press `Ctrl+E` on the serial terminal\n* Paste the code\n* Press `Ctrl+D` (note that if you did not press `Ctrl+E` before, it is a software reset command, MaixPy will soft reset), and then you can see all the codes are executed\n\n```python\n>>>\n['boot.py','main.py','freq.conf']\n>>>\n\n```\n\n> If the amount of data is relatively large, the serial port may lose data, which will result in a syntax error. You can try several times"}, "/soft/maixpy/en/get_started/knowledge_micropython.html": {"title": "MicroPython background knowledge", "content": "---\ntitle: MicroPython background knowledge\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MicroPython background knowledge\n---\n\n\nSince **MaixPy** is developed and built on top of **MicroPython**,\nThe final interface provided to users is **Micropython**, so we need to be familiar with the basic knowledge and syntax of `MicroPython` at the beginning of development using MaixPy\n\n\n## About MicroPython:\n\nMicroPython is a streamlined and efficient implementation of the programming language Python3. The syntax is consistent with Python3, but only a small part of the Python standard library is implemented. It is optimized and can be used in resource-constrained environments such as MCU and WIFI SOC. So we To use MicroPython, you need to understand its syntax.\n\nIf you have previous programming experience in **C/C++/Java** (or any other language), it is recommended\n[*(Liao Xuefeng's Python Tutorial).*](https://www.liaoxuefeng.com/wiki/1016959663602400)\n\nIf you do not have any programming experience before, recommend\n[*(Learn Python in a Stupid Way).*](https://wizardforcel.gitbooks.io/lpthw/content/)\n\n## REPL and serial port\n\nFirst, disconnect the connection between the development board and MaixPy IDE, otherwise the serial port will conflict!\n\nOpen a terminal window in MaixPy IDE\n\nprint('The quick brown fox','jumps over','the lazy dog')\n\nOutput:\n\n```\nThe quick brown fox jumps over the lazy dog\n```\n\nprint() will print each string in turn, and will output a space when it encounters a comma \",\". Therefore, the output string is spelled like this:\n\n> The quick brown fox jumps over the lazy dog\n\nprint() can also print integers or calculate results:\n\n```python\nprint(300)\n300\nprint(100 + 200)\n300\n```\n\nTherefore, we can print the result of calculating 100 + 200 more beautifully:\n\n```python\nprint('100 + 200 =', 100 + 200)\n100 + 200 = 300\n```\n\nNote that for 100 + 200, the Python interpreter automatically calculates the result 300, but '100 + 200 ='is a string instead of a mathematical formula, and Python treats it as a string.\n\n## MicroPython basic syntax\n### Variable\n\nIn Python, the equal sign `=` is an assignment statement, which can assign any data type to a variable. The same variable can be assigned repeatedly, and it can be a variable of different types, for example:\n\n```python\na = 123 # a is an integer\nprint(a)\na ='ABC' # a becomes a string\nprint(a)\n```\n\nThis kind of language with variable types is called **dynamic language**, and its counterpart is **static language**.\nA static language must specify the variable type when defining a variable. If the type does not match when assigning a value, an error will be reported. For example, Java is a static language, and the assignment statement is as follows (// means comment):\n\n```java\nint a = 123; // a is an integer variable\na = \"ABC\";// Error: Cannot assign a string to an integer variable\n```\n\nCompared with static languages, dynamic languages ​​are more flexible for this reason.\n\n### List\n\nOne of the built-in data types of Python is **list**: **list**.<br/>\n**list** is an ordered collection, elements can be added and deleted at any time.\nFor example, to list the names of all classmates in the class, you can use a **list** to indicate:\n\n```python\nclassmates = ['Michael','Bob','Tracy']\nclassmates\n['Michael','Bob','Tracy']\n```\n\nThe variable classmates is a `list`.<br/>\nUse the `len()` function to get the number of list elements:\n\n```python\nlen(classmates)\n3\n```\n\nUse the index to access the elements at each position in the list, the index starts from 0:\n\n```python\nclassmates[0]\n'Michael'\nclassmates[1]\n'Bob'\nclassmates[2]\n'Tracy'\nclassmates[3]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: list index out of range\n```\n\nWhen the index exceeds the range, Python will report an IndexError error, so make sure that the index does not exceed the range, remember that the index of the last element is len(classmates)-1.\n\nIf you want to get the last element, in addition to calculating the index position, you can also use -1 as an index to get the last element directly:\n\n```python\nclassmates[-1]\n'Tracy'\n```\n\nBy analogy, you can get the second to last and third to last:\n\n```python\nclassmates[-2]\n'Bob'\nclassmates[-3]\n'Michael'\nclassmates[-4]\nTraceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n  IndexError: list index out of range\n```\n\nOf course, the fourth from last crossed the line.\n\nThe list is a **variable** **ordered list**, so you can append elements to the list to the end:\n\n```python\nclassmates.append('Adam')\nclassmates\n['Michael','Bob','Tracy','Adam']\n```\n\nYou can also insert the element into a specified position, such as the position with index number 1:\n\n```python\nclassmates.insert(1,'Jack')\nclassmates\n['Michael','Jack','Bob','Tracy','Adam']\n```\n\nTo delete the element at the end of the list, use the pop() method:\n\n```python\nclassmates.pop()\n'Adam'\nclassmates\n['Michael','Jack','Bob','Tracy']\n```\n\nTo replace an element with another element, you can directly assign it to the corresponding index position:\n\n```python\nclassmates[1] ='Sarah'\nclassmates\n['Michael','Sarah','Tracy']\n```\n\nThe data types of the elements in the list can also be different, for example:\n\n```python\nL = ['Apple', 123, True]\n```\n\nIf there is no element in a list, it is an empty list with a length of 0:\n\n```python\nL = []\nlen(L)\n0\n```\n\n### Tuple\n\nAnother kind of ordered list is called tuple: **tuple**.<br/>\nTuple is very similar to list, but once the `tuple` is initialized, it cannot be modified. For example, it also lists the names of classmates:\n\n```python\nclassmates = ('Michael','Bob','Tracy')\n```\n\nNow, the **tuple** of classmates cannot be changed, and it does not have methods such as append(), insert(). The other methods of obtaining elements are the same as list, you can use classmates[0], classmates[ normally -1), but cannot be assigned to another element.\n\nWhat is the point of an immutable tuple? Because tuples are immutable, the code is safer.\nIf possible, try to use tuple instead of list.\n\nThe trap of tuple: When you define a tuple, the elements of the tuple must be determined at the time of definition, such as:\n\n```python\nt = (1, 2)\nt\n(1, 2)\n```\n\nHowever, to define a\nA tuple with only 1 element, if you define it like this:\n\n```python\nt = (1)\nt\n1\n```\n\nBut at this time, the definition is not tuple, t is an integer variable, and the value of variable t is 1! <br/>\nThis is because parentheses () can represent tuples and parentheses in mathematical formulas, which creates ambiguity.Therefore, Python stipulates that in this case, the calculation is based on parentheses, and the calculation result is naturally 1.\n\nTherefore, the definition of **tuple** with only 1 element must add a comma `,`, to disambiguate:\n\n```python\nt = (1,)\nt\n(1,)\n```\n\nWhen Python displays a tuple with only 1 element, it will also add a comma `,` to prevent you from misunderstanding it as a bracket in the sense of mathematical calculations.\n\n### Conditional judgment\n\nThe complete form of the if statement is:\n\n```\nif <condition judgment 1>:\n    <Execute 1>\nelif <condition judgment 2>:\n    <Execute 2>\nelif <condition judgment 3>:\n    <Execute 3>\nelse:\n    <Execute 4>\n```\n\nsuch as:\n\n```python\nage = 20\nif age >= 6:\n    print('teenager')\nelif age >= 18:\n    print('adult')\nelse:\n    print('kid')\n```\n\n### Loop\n\nThere are two types of Python loops, one is the `for...in` loop, which iterates over each element in a list or tuple in turn, see an example:\n\n```python\nnames = ['Michael','Bob','Tracy']\nfor name in names:\n    print(name)\n```\n\nExecuting this code will print each element of names in turn:\n\n```python\nMichael\nBob\nTracy\n```\n\nSo the `for x in ...` loop is to substitute each element into the variable x, and then execute the statement of the indented block.\n\nIf you want to calculate the sum of integers from 1 to 100, it is a bit difficult to write from 1 to 100. Fortunately, Python provides a range() function that can generate a sequence of integers, which can be converted to a list by the list() function.<br/>\nFor example, the sequence generated by range(5) is an integer less than 5 starting from 0:\n\n```python\nlist(range(5))\n[0, 1, 2, 3, 4]\n```\n\nrange(101) can generate a sequence of 0-100 integers, calculated as follows:\n\n```python\nsum = 0\nfor x in range(101):\n    sum = sum + x\nprint(sum)\n```\n\nThe second type of loop is the **while loop**. For example, if we want to calculate the sum of all odd numbers within 100, we can use the while loop:\n\n```python\nsum = 0\nn = 99\nwhile n> 0:\n    sum = sum + n\n    n = n-2\nprint(sum)\n```\n\n-----\n\n### Data type conversion\n\nPython's built-in common functions also include data type conversion functions, such as the int() function to convert other data types to integers:\n```python\n>>> int('123')\n123\n>>> int(12.34)\n12\n>>> float('12.34')\n12.34\n>>> str(1.23)\n'1.23'\n>>> str(100)\n'100'\n>>> bool(1)\nTrue\nfrom machine import GPIO\n```\n### Functions\n\nIn Python, to define a function, use the `def` statement, write the function name, parentheses, the parameters in the parentheses and the colon `:` in turn, and then write the function body in the indented block, and the return value of the function is returned The statement returns.\n\nLet's write a function to calculate x2:\n\n```python\ndef power(x):\n    return x * x\n```\n\nFor the power(x) function, the parameter x is a positional parameter.\n\nWhen we call the power function, we must pass in one and only one parameter x:\n\n```python\npower(5)\n25\npower(15)\n225\n```\n\nNow, what if we want to calculate x3? We can define another power3 function, but what if we want to calculate x4, x5...? We cannot define an infinite number of functions.\n\nYou may think of it, you can modify power(x) to power(x, n) to calculate xn, just do it:\n\n```python\ndef power(x, n):\n    s = 1\n    while n> 0:\n        n = n\n         - 1\n        s = s\n         * x\n    return s\n```\n\nFor this modified power(x, n) function, any n-th power can be calculated:\n\n```python\npower(5, 2)\n25\npower(5, 3)\n125\n```\n\nThe modified power(x, n) function has two parameters: x and n. These two parameters are positional parameters. When the function is called, the two values ​​passed in are assigned to the parameters x and n in order of position.\n\n### Slice\n\nIt is a very common operation to take some elements of a `list` or `tuple`. For example, a list is as follows:\n\n```python\nL = ['Michael','Sarah','Tracy','Bob','Jack']\n```\n\nTake the first 3 elements and complete the slice with one line of code:\n\n```python\nL[0:3]\n['Michael','Sarah','Tracy']\n```\n\nL[0:3] means that it starts from index 0 and ends at index 3, but does not include index 3. That is, indexes 0, 1, 2, are exactly 3 elements.\n\nIf the first index is 0, it can also be omitted:\n\n```python\nL[:3]\n['Michael','Sarah','Tracy']\n```\n\nYou can also start at index 1, and take out 2 elements:\n\n```python\nL[1:3]\n['Sarah','Tracy']\n```\n\n`tuple` is also a kind of list, the only difference is that `tuple` is immutable. Therefore, `tuple` can also be sliced, but the result of the operation is still `tuple`:\n\n```python\n(0, 1, 2, 3, 4, 5)[:3]\n(0, 1, 2)\n```\n\n`String`'xxx' can also be regarded as a kind of `list`, each element is a character. Therefore, string can also be sliced, but the result of the operation is still a string:\n\n```python\n'ABCDEFG'[:3]\n'ABC'\n```\n\n### Object\n\nPython is **object-oriented** programming, such as an LED light\n\n```python\nfrom pyb import LED\n\nred_led = LED(1)\nred_led.on()\n```\n\nLED is a **class**, red_led is an **object**, you can operate this object, such as turning on, turning off, and viewing the value.\n\n### Module\n\n### What is a module?\n\nAs the code increases, the code in a file will become longer and more difficult to understand.\n\nIn order to write maintainable code, we group many functions into different files. In Python, a `.py` file is called a **Module**.\n\nWhat are the benefits of modules?\n\nEasy to reuse code! If I wrote a module and you also wrote a module, we have two modules. We organize these modules so that everyone can write a lot less code!\n\n#### How to use modules?\n\n```python\nimport time\n\ntime.sleep_ms(500)\n```\n\n`import time` is to import the `time` module. The module can be imported through the `import` statement.\n\n### More\n\nPlease search for more MicroPython basic syntax tutorials."}, "/soft/maixpy/en/get_started/get_started_edit_file.html": {"title": "Edit and execute the file", "content": "---\ntitle: Edit and execute the file\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: edit and execute files\n---\n\n\n\n## MaixPy has a built-in file system\n\nAs mentioned earlier, `MaixPy` supports `SPIFFS` used by `Flash` (currently does not support directory creation), by default, `3MB` is allocated to `SPIFF` (from the address of `flash` `0xD00000`, `3M`), boot Automatically mount to the `/flash` directory\n\nIt also supports the `Micro SD (TF)` card of `FAT32` format `MBR` partition, and it will automatically hang under the `/sd` directory when booting up\n\nIt should be noted that the root directory is only used to mount the Flash or SD card, and the specific files are in the `/flash` or `/sd` directory\n\n## Why need to edit and execute the file\n\nIn the previous experiment, we directly typed the code in the terminal to execute sentence by sentence. This is also simple and convenient. After we enter the command, it will execute immediately and get the returned result in time. This interactive method is called **`REPL (Read Eval Print Loop: Interactive interpreter) `**,\nThe advantage of this method is that it is simple and convenient. It is very similar to the Linux terminal, except that the syntax used is replaced by MaixPy (Micropython) syntax.\n\nBut in actual operation, we want the code to be saved in the file system, and we need to run the file directly, so that we don’t have to type the code every time, which reduces a lot of trouble.\n\n\n## Edit and save the file\n\n### Method 1: Use the built-in editor [Micropython Editor(pye)](https://github.com/robert-hh/Micropython-Editor)\n\nIn MaixPy, we have built-in an open source editor [Micropython Editor(pye)](https://github.com/robert-hh/Micropython-Editor)\n\nUse `os.listdir()` to view the files in the current directory,\n\nUse `pye(\"hello.py\")` to create a file and enter the editing mode, and the instructions for using shortcut keys can be found in [here](https://github.com/robert-hh/Micropython-Editor/blob/master/Pyboard%20Editor.pdf)\n\nFor example, we write code\n\n```python\nprint(\"hello maixpy\")\n```\n\nThen press `Ctrl+S` and press `Enter` to save, press `Ctrl+Q` to exit editing\n\n**Note**: The use of this editor has certain requirements for the serial tool used. The `BackSpace` key must be set to the `DEL` function, otherwise pressing `BackSpace` will call the same function as `Ctrl+H` ( That is character replacement).\n\nIt is recommended to use `minicom` under Linux, you need to use `sudo minicom -s` to set, refer to [previous tutorial](./env_serial_tools.html)\n\nThe same is true under Windows, search the setting method according to the tool you use, such as `xshell` search `xshell How to set backspace to del` to get the result:\n\n`File` -> `Properties` -> `Terminal` -> `Keyboard`,\n\nChange the sequence of delete and backspace to ASCII 127.\n\n\n### Method 2: Use MaixPy IDE\n\nOpen `MaixPy IDE`, connect the development board\n\nEdit the file, then in the top `Tool` menu, use the `send file` function in the top `Tool` menu to send the file, it will be saved to the development board and the file name is the same as the file name on the computer\n\nOf course, you can also click `Save the opened file as boot.py` to save the code to the `boot.py` file of the development board. This file will be executed automatically next time the development board is powered on.\n\n\n\n![](../../assets/maixpy/maixpy_ide_tools.png)\n\n\n### Method Three: Use the tool [uPyLoader](https://github.com/BetaRavener/uPyLoader) to read to the PC (computer), edit and then save to the development board\n\nDownload the executable file: [release](https://github.com/BetaRavener/uPyLoader/releases)\n\n![uPyLoader](../../assets/other/uPyLoader.png)\n\nSelect the serial port and click the `Connect` button to connect to the board\n\nThe first time you run the software, you need to initialize. Click on `File->Init transfer files` to complete the initialization. This will create two files in the board, namely `__upload.py` and `__download.py`.\n\nThen double-click the file name to open the file and edit it. After editing, click `save` to save to the development board.\n\n\n### Method 4: Use the tool [rshell](https://github.com/dhylands/rshell) to read it on the PC (computer) and edit it and then save it to the development board\n\nFollow the instructions of `rshell` [Project Homepage](https://github.com/dhylands/rshell) to install `rshell`\n\n```shell\nsudo apt-get install python3-pip\nsudo pip3 install rshell\nrshell -p /dev/ttyUSB1 # Here, choose the serial port according to the actual situation\n```\n\nEdit file\n\n```python\nls /flash\nedit /flash/boot.py\n# The editor is used in the same way as vim\n```\n\n## executable file\n\nUse `os.chdir()` to switch the current directory to the directory of the file, such as `os.chdir(\"/flash\")`\n\n### Method 1: `import`\n\nThen execute `import hello`\n\nYou can see the output `hello maixpy`\n\nUsing this method is simple and easy to use, but it should be noted that currently `import` can only be used once. If the second `import`, the file will not be executed again. If you need to execute it multiple times, the following method is recommended\nAnd `import` will not execute the code under the condition of `if __name__ == \"__main__\":`, you need to pay attention\n\n### Method 2: `exec()`\n\nUse the `exec()` function to execute\n\n```python\nwith open(\"hello.py\") as f:\n    exec(f.read())\n```\n\n### Method 3: Use **MaixPy IDE** to execute\n\nOpen the file, and then click the execute button to execute it. **Note**: The execution code is similar to the `REPL` execution code, except that the program is sent to the development board and not saved to the file system. It is executed once\n\n![](../../assets/maixpy/maixpy_connect-success.png)\n\n### Method 4: Use uPyLoader to execute\n\nAfter connecting, select the file and click the `excute` button to execute the file\n\n\n### Method 5: Use ampy to run files on the computer directly\n\n[ampy](https://github.com/pycampers/ampy)\n\nExecute the command `ampy run file_in_PC.py` to execute the file located on the computer (the file will not be saved to the development board)\n\n## Does MaixPy support mounting file systems to the computer?\n\nNot supported, because the chip k210 used has no USB function and cannot simulate a U disk device, so it cannot be a virtual U disk like Microbit and STM32 Micropython"}, "/soft/maixpy/en/get_started/upgrade_maixpy_firmware.html": {"title": "Update MaixPy firmware", "content": "---\ntitle: Update MaixPy firmware\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: update MaixPy firmware\n---\n\n\n## Prepare\n\nhardware:\n\n- USB Type-C data cable\n- MaixPy development board\n- PC (computer)\n\nsoftware:\n\n- MaixPy development board USB driver\n- kflash_gui\n\n## Confirm that the driver has been installed correctly\n\nInstall the driver according to the previous instructions, and you can see the serial device in the computer, `Linux` and `Mac OS` execute `ls /dev/` to see the device number, for example, the name is `ttyUSB0` and `ttyUSB1` ; `Windows` view in device manager\n\n\n## Get the upgrade tool\n\n* Download [kflash_gui](https://github.com/sipeed/kflash_gui/releases), you will get a compressed package\n> kflash_gui is cross-platform and can work under multiple systems (including Windows, Linux, MacOS, and even Raspberry Pi)\n> If you use Kendryte's `Windows` version, some development versions may not be able to download successfully, please use the `kflash_gui` software to download\n\n* Unzip to a folder, double-click `kflash_gui.exe`(/`kflsh_gui`) to run, under `Windows`, it is recommended to right-click `fix to start page` or `fix to taskbar`, and create a new one under `Linux` A [kflash_gui.desktop](https://github.com/sipeed/kflash_gui/blob/master/kflash_gui.desktop), modify the file address, use the administrator to copy it to the `/usr/share/application` directory, and then You can see the application `kflash_gui` in the system menu interface\n\n* You can also use the command line version to download\n\n```shell\npip3 install kflash\nkflash --help\nkflash -p /dev/ttyUSB0 -b 1500000 -B goE maixpy.bin\n```\n\n## Get the firmware\n\n* The released version of the firmware can be downloaded from the [github](https://github.com/sipeed/MaixPy/releases) page\n* The latest submitted code is automatically constructed and generated firmware download: [master branch](http://dl.sipeed.com/MAIX/MaixPy/release/master/)\n\n\n\nFiles with firmware ending in `.bin` or `.kfpkg`\n>`.kfpkg` is actually a packaged version of multiple `.bin` files, which can be packaged using `kflash_gui` or [manual packaging](http://blog.sipeed.com/p/390.html)\n\n![MaixPy Firmware Type](../../assets/maixpy/firmware_type.png)\n\nFirmware naming instructions:\n\n| File name | Description | Remarks |\n| --- | --- | --- |\n| `maixpy_vx.y.z_x_xxx*.bin` | The default version of MaixPy firmware, contains most of the functions, supports connection to `MaixPy IDE`, | Factory default firmware version |\n| `maixpy_vx.y.z_x_xxx*_m5stickv.bin` | Firmware customized for M5Stickv, supports connection to `MaixPy IDE` | — |\n| `maixpy_vx.y.z_x_xxx*_with_lvgl.bin` | MaixPy firmware, supports connection to `MaixPy IDE`, with LVGL version. (LVGL is an embedded GUI framework, which is needed when writing interfaces) | — |\n| `maixpy_vx.y.z_x_xxx*_minimum.bin` | MaixPy minimum set of firmware, does not support `MaixPy IDE`, does not include `OpenMV` related algorithms and various peripheral modules | — |\n| `maixpy_vx.y.z_x_xxx*_minimum_with_ide_support.bin` | The smallest set of MaixPy firmware, supports connection to `MaixPy IDE`, does not include `OpenMV` related algorithms and various peripheral modules | Run various models, it is recommended to use this |\n| `elf_maixpy_vx.y.z_x_xxx*.7z` | elf files, ordinary users don’t need to care, used for crash debugging | — |\n| `face_model_at_0x300000.kfpkg` | Face model, placed at address 0x300000, can be downloaded separately from `.bin` for multiple downloads without conflict | — |\n\n\n\n## Download the firmware to the development board\n\n* Open the `kflash_gui` application\n\n* Then select the firmware, setting options, and click to download. For more feature introduction and usage instructions, please refer to [kflash_gui project homepage](https://github.com/sipeed/kflash_gui)\n\nWhen using, please note that the serial port cannot be occupied by other software, select the correct development board and serial port number, you can appropriately reduce the baud rate and use the low-speed mode to improve the download success rate\n\n![](../../assets/kflash_gui/kflash_gui_download.png)\n\n![](../../assets/kflash_gui_screenshot_download.png)\n\n\n> For the earliest `Maix Go`, if you confirm that the options are correct and you still cannot download, you can try to turn the three-phase dial button to the `Down` position and keep downloading\n\n### Sipeed RV JATG debugger\n\n[Sipeed USB-JTAG/TTL RISC-V debugger STLINK V2 STM8/STM32 simulator](https://item.taobao.com/item.htm?spm=a1z10.3-c.w4002-21231188706.40.505a5d544ooyDY&id=595953803239 )\n\n\n**FAQ of Programming FAQ**\n\nIf you are using `kflash_gui` to burn the following problems\n\n![Upgrade Error](../../assets/kflash_gui/kflash_gui_upgrade_error.png)\n\nYou can check in the following order\n\n* Check if the `PC` has permission to open the port. For `win10`, you need to run `kflash_gui` as an administrator.\n* Check whether the port is selected correctly (if there are two device ports, usually choose the one with the smaller port number).\n* Check whether the port is occupied by other applications (such as `Maixpy ​​IDE`, `putty`, etc.), and other applications should be closed.\n* Check if the device is selected correctly. For `Maix Bit2.0` (including M1n module), `Maix Bit (with Mic )` should be selected.\n\n> Supplementary note: Regarding the problem of Maix Bit 2.0 two serial ports\n>\n> * Only one of the serial ports is valid for serial communication and ISP download programs.\n> * Maix Bit communicates with the PC through a serial port, through the CH552T chip to realize the USB virtual serial port function, and the chip can virtualize two serial ports, in Maix Bit (M1n module backplane), we only use one serial port, but some k210 products Both serial ports are used."}, "/soft/maixpy/en/get_started/knowledge_image.html": {"title": "Background knowledge of image processing", "content": "---\ntitle: Background knowledge of image processing\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: background knowledge of image processing\n---\n\n\n\n## What is a camera?\n\nWe have all seen various cameras, such as\n\n<img src=\"../../assets/other/camera_mi.png\" height=\"200\">\n<img src=\"../../assets/hardware/module/camera.png\" height=\"200\">\n\nSo what is a camera, in the final analysis, is a device that converts optical signals into electrical signals. In computer vision, the simplest camera model is the `hole imaging model`:\n\n![](../../assets/other/Pinhole-camera.svg)\n\nThe pinhole model is an ideal camera model and does not consider the field curvature, distortion and other issues in the actual camera. But in actual use, these problems can be solved by introducing `distortion parameters` in the calibration process, so the pinhole model is still the most widely used camera model.\nSC\nThe image passes through the lens and shines on a photosensitive chip. The photosensitive chip can convert information such as the wavelength and intensity of the light into a digital signal that can be recognized by a computer (digital circuit). The `photosensitive element` looks like this:\n\n![camera sensor](../../assets/other/sensor.png)\n\n(The square element in the middle is the photosensitive element)\n\n## What are pixels and resolution?\n\nThe photosensitive element is composed of many photosensitive points. For example, there are `640` x `480` points. Each point is a pixel. Collect and organize the pixels of each point to form a picture. Then the picture is The resolution is 640x480:\n\n## What is frame rate\n\nThe frame rate (FPS) is the number of pictures processed per second. If it exceeds 20 frames, the human eye can hardly distinguish the freeze. Of course, if used on a machine, the higher the frame rate, the better.\n\n## What is color\n\nPhysically, colors are electromagnetic waves of different wavelengths.\n\n![sRGB rendering of the spectrum of visible light](../../assets/other/1920px-Linear_visible_spectrum.svg.png)\n\nHowever, according to the visual effect of the human eye, the color of visible light can be described through RGB, CMYK, HSB, LAB color gamut.\n\n## RGB three primary colors\n\nThe principle of the three primary colors is not caused by physical reasons, but by human physiological reasons. There are several color-discriminating cone photoreceptor cells in the human eye, which are the most sensitive to yellow-green, green, and blue-violet (or violet) light (wavelengths are 564, 534, and 420 nanometers, respectively).\n\nSo RGB is often used on monitors to display pictures.\n\n- LAB brightness-contrast\nIn the Lab color space, L brightness; the positive number of a represents red, the negative end represents green; the positive number of b represents yellow, and the negative end represents blue. Unlike the RGB color space, Lab colors are designed to approximate human vision.\n\nTherefore, the L component can adjust the brightness pair, and modify the output color scale of the a and b components for accurate color balance.\n\nNote: In MaixPy's algorithm for finding color patches, this LAB mode is used!\n\n- Selection of light source\n\nIf your machine is in the industry, or a device that runs for a long time 24 hours, maintaining a stable light source is crucial, especially in the color algorithm. When the brightness changes, the value of the entire color will change greatly!\n\n\n## The focal length of the lens\n\nBecause the image is optically refracted by the lens, it hits the photosensitive element. Then the lens determines the size and distance of the entire picture. One of the most important parameters is the focal length.\n\n![focal_distance](../../assets/other/focal_distance.jpg)\n\n**Lens focal length**: refers to the distance from the principal point to the focal point behind the lens optics, which is an important performance index of the lens. The length of the lens focal length determines the size of the image taken, the angle of view, the depth of field and the perspective of the picture. When shooting the same subject at the same distance, the image formed by the long focal length of the lens is large, and the image formed by the short focal length of the lens is small. Note that the longer the focal length, the smaller the viewing angle.\n\n\nAnother point is the distortion of the lens. Because of the optical principle, the distance between the lens and the lens is different at different positions on the photosensitive chip. Simply put, the distance is small, so fisheye effects (barrel distortion) appear at the edges. In order to solve this problem, algorithms can be used in the code to correct the distortion. Note: image.lens_corr(1.8) is used in MaixPy to correct the 2.8mm focal length lens. You can also directly use the distortionless lens. The non-distortion lens adds an additional corrective lens part, and the price will naturally be much higher.\n\n## Lens filter\n\nOn the lens, there is usually a filter.\n\n![camera sensor](../../assets/other/sensor_1.png)\n\nWhat does this filter do?\n\nWe know that different colors of light have different wavelengths. In a normal environment, in addition to visible light, there are a lot of infrared light. In night vision, infrared light is used.\n\nHowever, in normal color applications, infrared light is not needed, because infrared light will also cause the photosensitive element to react, making the entire screen white. So we put a filter on the lens that can only pass through the wavelength of 650nm to filter the infrared light."}, "/soft/maixpy/en/get_started/upgrade_stm32_firmwave.html": {"title": "MaixGo updates the onboard STM32 debugger firmware", "content": "---\ntitle: MaixGo updates the onboard STM32 debugger firmware\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixGo Update onboard STM32 debugger firmware\n---\n\n\nThe MaixGo development board has an STM32-based debugger onboard"}, "/soft/maixpy/en/get_started/env_serial_tools.html": {"title": "Use serial port tools", "content": "---\ntitle: Use serial port tools\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: use serial port tool\n---\n\n\n## Connect the hardware\n\nConnect the Type C cable, one end of the computer and the other end of the development board\n\nCheck whether the device has been correctly identified:\n\nUnder Linux, you can use `ls /dev/ttyUSB*` or `ls /dev/ttyACM*` to check. If not, you can look for it with `ls /dev`. The specific device name is related to the serial port chip and driver. Use `sudo dmesg` to see if there is a device mount record\n\nIn Windows, you can open the Device Manager to view\n\nIf the device is not found, you need to confirm whether the driver is installed and the contact is good\n\n\n## Use serial port tool\n\n### Windows\n\nCommonly used serial terminal software for Windows includes [putty](https://www.putty.org/), [mobaxterm](https://mobaxterm.mobatek.net/), [xshell](https://xshell.en .softonic.com/) and other tools\n\n- Putty\n\nThen select the serial port mode, then set the serial port and baud rate, and open the serial port.\n\n![](../../assets/get_started/putty.png)\n\nThen click the Enter key, you can see the interactive interface of MaixPy\n\n`>>>`\n\nType `help()` to view the help\n\n> Source of the above picture: [laurentopia's tutorial](https://github.com/laurentopia/Learning-AI/wiki/MaixPy)\n\n- Mobaxterm\n\n[MobaXterm](https://mobaxterm.mobatek.net/) is a very easy-to-use multi-function terminal software under Windows (of course it also includes a serial terminal)\n\n![Mobaxterm](../../assets/get_started/mobaxterm_serail_port.png)\n![Mobaxterm](../../assets/get_started/mobaxterm.png)\n\n\n### Linux\n\nUse tools such as `minicom` (recommended) or `screen`\n\n#### minicom\n\n```\nsudo apt update\nsudo apt install minicom\nsudo minicom -s\n# Then follow the prompt to set the serial port number and baud rate 115200, etc., if you don’t understand, you can use the search tool to search\n# Set Backspace to DEL function\n# Set linewrap to Yes\nsudo minicom\n```\n\nNote that saving the default configuration file of minicom requires sudo permission, so use `sudo minicom -s`\n\n![minicom setting](../../assets/get_started/minicom_setting.png)\n\n![minicom setting2](../../assets/get_started/minicom_setting2.png)\n\nPress `A` here to set up the device\n\nPress `E` to set the baud rate, the baud rate needs to be set to `115200`\n\n![minicom setting3](../../assets/get_started/minicom_setting3.png)\n\nPress `A` and `R` here to switch the settings to the same as the settings in the figure. The first is to use the `pye` editor shortcut keys to not conflict with each other, and the second setting of automatic line wrapping is to display the complete output.\n\nSave and exit after setting. You don’t need to set it again next time. Just execute `sudo minicom`. If you don’t want to use `sudo` command every time, execute `sudo usermod -a -G dialout $(whoami)` Just add yourself to the `dialout` user group, you may need to log out or restart to take effect. Note that `sudo minicom -s` still needs `sudo` if you need to modify the default configuration file\n\nAfter entering `minicom`, click the enter key or the reset button of the development board, you can see the interactive interface of MaixPy\n\n![minicom](../../assets/get_started/minicom.png)\n\nType `help()` to view the help\n\nTo exit `minicom`, press `Ctrl+A` `X`, press `Enter` to confirm exit\n\n> In addition, the serial port number may change during the development process. You can specify the serial port number when executing minicom, so you don't need to set it every time the serial port number changes, for example: `minicom -D /dev/ttyUSB1 -b 115200 `"}, "/soft/maixpy/en/get_started/knowledge_git_github.html": {"title": "Introduction to git and github", "content": "---\ntitle: Introduction to git and github\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: introduction to git and github\n---\n\n\nBecause in the process of learning MaixPy, git and github are used in many places, so here is a brief explanation of what they are and what are the differences.\n\n\n## What is git\n\nGit is a code hosting **software**, used to manage the version of the code.\nsuch as:\nI changed the code today, and then I changed the code tomorrow. From now on, I can see the history of these two changes, and what content was changed, which line can be accurate to find problems later;\nOr I find that there is a problem with the code submitted for the second time, and I need to go back to the version after the first submission, which can be achieved with this tool;\nIn addition, it is convenient for multiple people to modify the same code, can manage the code submitted by everyone, and it is not easy to cause confusion.\n\nNo longer have to copy countless folders to back up changes!\n\nGit will create a hidden folder `.git` in the directory, all changes are stored in it, and this folder cannot be deleted.\n\nBut it should be noted that the current git is mainly used to manage text files. It is not suitable to manage binary files, such as picture PDFs, etc., which will make the space occupied by the folder become large.\n\nFor specific tutorials, you can see [here](https://git-scm.com/), and Chinese tutorials can be viewed [here](https://www.liaoxuefeng.com/wiki/896043488029600/896067008724000)\n\n\n## What is github\n\n[github](http://github.com/) is a **website** for sharing code.\n\nYou can register on this website, then create a repository, put the code in this repository for public sharing, so that more people can use it, and even modify and optimize the code together. This is **open source**.\n\nEach warehouse can be managed separately using the software `git`, you can modify the code on your computer, then use `git` to submit, and then use `git` to push to the website of `github`, you can See the new content.\n\nThe source address of MaixPy is: [https://github.com/sipeed/maixpy](https://github.com/sipeed/maixpy), which is a `git repository`.\n\n\n[Help](https://docs.github.com/en/free-pro-team@latest/github), Chinese [Help](https://docs.github.com/cn/free-pro- team@latest/github)\n\n\nIn addition, there are several websites similar to `github` in China, such as [gitee](https://gitee.com/)\n\n\n## The difference between git and github\n\nOne is a software, the other is a website.\nIt's just that this website uses git technology to manage the warehouse.\n\n## Why can't I access github, or the access speed is very slow\n\nGithub is a foreign website. Because of the long distance and line problems, some lines of some operators may be slow or even inaccessible.\nFor example, the domain name `https://raw.githubusercontent.com/` used by github to store source files may not be accessible\n\nSolution:\n* Change the line, that is, change the network. For example, if you use a telecommunications network, you can change to China Mobile or China Unicom, change the mobile phone traffic, or change the location, etc.\n* Use VPN software, not taught here, please pay attention to legal use\n\n\n\n## What is star\n\nOn github, everyone can like and collect every public warehouse, that is, star, in the upper right corner of github ⭐ shaped button\n\n![](../../assets/other/github_star.jpg)\n\nIf you think the project is good, please give it a star. This will encourage developers to spend more time maintaining the warehouse, and also tell first-time visitors that this is a good project and deserves attention.\n\nAfter star, you can find your star warehouse in your profile, so you can find it next time\n\nHaving said that, everyone thinks that [MaixPy](https://github.com/sipeed/maixpy) is good, you can star one~\n\n## What is the master branch\n\nIn each warehouse, there can be many branches, different branches can have different codes, and different branches can be merged with each other, which is convenient to save different versions of the code and facilitate teamwork. The master branch refers to the main branch. That is the most important branch, usually the master branch is displayed by default in the warehouse.\n\n\n## What is submission\n\nSubmit, called `commit` in English, means that every time you change the code of the warehouse, you submit it once and it will be recorded in the submission history. You can see what was submitted this time at any time later, or you can roll back the code here. Commits\n\nEach commit has an independent `commit ID`, such as `d28cb7ac7db5ad61c0738df95d733717deefda1d`, abbreviated as `d28cb7a`\n\n## What is a submodule\n\nSubmodule, called `submodule` in English, means that other warehouses can be referenced in the warehouse, which is equivalent to a soft link. You don't need to put actual code in the warehouse, just put a link.\nThe advantage of this is that multiple warehouses can be managed separately. For example, `Warehouse 1` references `Warehouse 2` as a submodule. If the code of `Warehouse 2` is updated, `Warehouse 1` can choose to continue to use the old version of `Warehouse 2` Code, you can also choose to use the latest code of `Warehouse 2`, just update the submodule link\n\nFor example, `MaixPy` uses `kendryte-standalone-sdk` as a submodule, see [here](https://github.com/sipeed/MaixPy/tree/master/components/kendryte_sdk)\n![submodule](../../assets/get_started/github_submodule.jpg)\n\nYou can see that the icon of the folder here is not the same, it is just a link, click will jump to the corresponding warehouse instead of opening the folder directly\n\nSo **MaixPy uses submodules**\n\n\n\n## What is cloning\n\nIn the repository on `github`, if you need to download it locally, you need to use clone, use\n```\ngit clone address\n```\nJust clone the warehouse locally. The cloned local warehouse is actually a clone on github, which is exactly the same, and keeps historical records, etc.\n\nOf course, you don’t need to clone. The webpage has a download button, but the defect of downloading is that it will not include the history of the submitted code. Choose according to your own situation.\n\nIt should be noted that when cloning a repository that contains submodules, because cloning will only clone the link of the submodule by default, the code of the submodule is not cloned locally, you need to clone like this\n```\ngit clone address --recursive\n```\n\nor\n```\ngit clone address project_name\ncd project_name\ngit submodule update --init --recursive\n```\n\nsuch as:\n```\ngit clone https://github.com/sipeed/MaixPy --recursive\n```\n\n\n\n## What is issue\n\nThat is the meaning of the question. On github, each warehouse has a special place for asking questions, such as [MaixPy's issue](https://github.com/sipeed/MaixPy/issues)\nEveryone asks questions here, similar to forums, they will be recorded for easy reference\n\n## What is fork\n\nOn github, there is a fork button in the upper right corner of the warehouse page\n![](/assets/other/github_star.jpg)\nClick to fork the warehouse to your own warehouse, which is equivalent to a copy. The reason why it is called fork is that after you fork into your own warehouse, you can modify your own warehouse at will, which is regarded as a development branch of the original fork warehouse. Derived from it but not the same as it\n\n\n## What is PR\n\nThat is, the pull request function on github is to participate in the code update of a warehouse. It is to fork into its own warehouse, then modify it, and submit and merge it into the forked source warehouse. The specific method can be learned by yourself"}, "/soft/maixpy/en/get_started/knowledge_prepare.html": {"title": "Essential basic knowledge", "content": "---\ntitle: Essential basic knowledge\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: essential basic knowledge\n---\n\n\n\nTo start using `MaixPy`, we recommend at least the following basic knowledge (if not, you need to learn first):\n\n* Have enough patience and attentiveness, able to calm down to study technology, carefully review documents, and concentrate on writing code\n\n* With `Python` or `Micropython` foundation, will use `Python` basic syntax.\n  * If you don’t know the `Python` syntax, but you have the basis of other programming languages, please use Baidu to search the `Python Tutorial` to learn the basic syntax part;\n  * If you don’t know any programming language, then this document looks very difficult, please learn the basic syntax and usage of `Python`\n\n* There is at least one kind of MCU development foundation, and can understand the basic circuit diagram. At present, there is no tutorial for people with zero foundation in this document.\n> The reason for having MCU development experience is that this document has not taught some basic terms, such as what is `UART`? What is `I2S`? And in the future, most of these basic knowledge will not be elaborated (but in fact, if you are good at using search tools to learn, you can learn even if you don’t understand)\n\n* To understand what Micropython is, check here: [MicroPython language introduction](http://docs.micropython.org/en/latest/reference/index.html)\n\n\n* A general understanding of the difference between Micropython and Python can be found here: [The difference between MicroPython and CPython (Python3)](http://docs.micropython.org/en/latest/genrst/index.html)\n\n\n\nIf the above points are not satisfied at all, it is recommended to make up the missing ones first, otherwise the learning and development process will be extremely difficult! ! ! !"}, "/soft/maixpy/en/get_started/get_started_led_blink.html": {"title": "Turn on the LED", "content": "---\ntitle: Turn on the LED\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: turn on the LED\n---\n\n\n\nThe lighting program is the first program to learn all the development boards, just like learning all programming languages, it has a sacred meaning.\n\n## Circuit\n\nAs we all know, lighting an LED requires a power supply, a resistor, and an LED bulb,\nThere are three LEDs on the Maix Dock development board, the wiring is as follows:\n\n![](../../assets/hardware/maix_dock/LED_sch.png)\n\n\nFor example, we want the red light to light up, that is, the LED connected to `LED_R`. As you can see in the picture, the anode of the LED has been connected to a 3.3V power supply, so we only need to make LED_R a low-level LED to light up.\n\n> Note that here `LED_R` is an alias for this pin, which is actually connected to a pin of the chip, such as `Pin13` or `IO13`\n\n## FPIOA (Field Programmable Input and Output Array)\n\nMaybe you have used some single-chip microcomputers, and the manual stipulates the binding of pins and on-chip peripheral functions (that is, the peripherals integrated in the chip, such as `GPIO`, `I2C`, `SPI`, etc.), or re Mapping. For example, it is stipulated that `I2C` can only use `Pin9` and `Pin10`. After the remapping function is enabled, only `Pin11` and `Pin12` can be used\n\nHowever, the pins (hardware pins) corresponding to the on-chip peripherals of the hardware K210 used by MaixPy can be **arbitrarily mapped**. In contrast, the K210 hardware design and software design have more freedom. For example, `I2C` can use `Pin11` and `Pin12`, and can also be changed to any other pin\n\n> Pay attention to distinguish the difference between `GPIO` and `IO`. `IO` can also be called `Pin`, which is a hardware pin derived from the chip, and `GPIO` is a peripheral device that can control these Peripherals of `Pin/IO`\n\nBecause of this powerful mapping function, when using pins, you need to add a step of mapping:\n```python\nfrom fpioa_manager import fm # import library\nfm.register(28, fm.fpioa.GPIO0)\n```\nHere we map pin `28` to the function of `GPIO0`. After executing this command, pins `28` and `GPIO0` are mapped (bound). If you want to unmap (unbind), then Need to call the `fm.unregister` function, see the `API` documentation for details, not introduced here\n\nIn addition, `Pin` and peripherals can only correspond **unique**, not one-to-many. It is necessary to map the same peripherals or pins repeatedly, otherwise the program may produce errors that are difficult to find (`BUG`)\n\n## Code\n\nWe need to use GPIO to control the LED\n\nThe procedure is as follows:\n\n```python\nfrom fpioa_manager import fm\nfrom Maix import GPIO\n\nio_led_red = 13\nfm.register(io_led_red, fm.fpioa.GPIO0)\n\nled_r=GPIO(GPIO.GPIO0, GPIO.OUT)\nled_r.value(0)\n```\n\nRun the code in the terminal according to the previous method of running the code, and you will find that the LED light is lit!\n\nNext we analyze the code:\n\n* Import the `fm` object from the `fpioa_manager` package, which is mainly used for pin and peripheral mapping\n* Imported the class `GPIO` from package `Maix`, GPIO peripheral related operations\n* Define a variable `io_led_red`, the value is `13`, that is, `Pin13/IO13`, which pin of the chip is connected to the specific LED pin, please see the schematic in the previous development board introduction\n* Use the built-in object `fm` (abbreviation of fpioa manager) to register the correspondence between the peripherals of the chip and the pins, 　here `fm.fpioa.GPIO0` is a GPIO peripheral of K210 (`pay attention to distinguish GPIO (external Set) and the difference between pins (real hardware pins)`), so `fm.fpioa.GPIO0` is registered to pin `IO13`;\n\n* Then define a `GPIO` object `led_r`, see the `GPIO` API documentation for specific parameters, and find it in the left sidebar.\n\n* Use `led_r.value(1)` or `led_r.value(0)` to set the high and low levels, because the low level is set here. According to the above schematic diagram, it can be seen that the low level is on and the LED is on\n\n\nNow you can light up the lights. Now you can try to use the `for` loop to achieve the `LED` flashing or running lights~ to make different transformation effects"}, "/soft/maixpy/en/get_started/install_driver/ft2232.html": {"title": "ft2232 USB Driver Installation", "content": "---\ntitle: ft2232 USB Driver Installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: ft2232 USB driver installation\n---\n\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\n`Windows` users need to install the driver of `FT2232`.\n\n- USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n\nWhen we get the MaixPy development board and connect it to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n<img src=\"../../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Windows 10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install the USB driver manually:\n    ![](../../../assets/get_started/win_device_2.png)\n\n2. Open the link in the previous section to download the driver\n    ![](../../../assets/get_started/win_device_3.png)\n\n3. Click Install\n    ![](../../../assets/get_started/drives.gif)\n\n4. After the installation is complete, you can see in the device manager that two serial devices have been identified (only one serial port is available)\n    ![](../../../assets/get_started/win_device_4.png)"}, "/soft/maixpy/en/get_started/install_driver/bit.html": {"title": "Maix Bit USB Driver Installation", "content": "---\ntitle: Maix Bit USB Driver Installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Bit USB driver installation\n---\n\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\nThe development board is divided into two versions, new and old, and different drivers need to be installed separately\n\n### `Maix Bit` (old version)\n\nWindows download [ch340 ch341 driver](https://api.dl.sipeed.com/shareURL/MAIX/tools/ch340_ch341_driver) and install it, then you can see the serial device in the `Device Manager`\n\n### `Maix Bit` new version with microphone (use `CH552`) development board\n\nThe development board uses the `CH552` chip to realize the `USB` to serial port function. There is no `JTAG` simulation function. `Windows` needs to install the `FT2232` driver.\n\n- USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n\nWhen we get the MaixPy development board and connect it to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n<img src=\"../../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Windows 10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install the USB driver manually:\n    ![](../../../assets/get_started/win_device_2.png)\n\n2. Open the link in the previous section to download the driver\n    ![](../../../assets/get_started/win_device_3.png)\n\n3. Click Install\n    ![](../../../assets/get_started/drives.gif)\n\n4. After the installation is complete, you can see in the device manager that two serial devices have been identified (only one serial port is available)\n    ![](../../../assets/get_started/win_device_4.png)"}, "/soft/maixpy/en/get_started/install_driver/nano.html": {"title": "Maix Nano USB Driver Installation", "content": "---\ntitle: Maix Nano USB Driver Installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Nano USB driver installation\n---\n\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\nThe development board uses the `CH552` chip to realize the `USB` to serial port function, and `Windows` users need to install the `FT2232` driver.\n\n- USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n\nWhen we get the MaixPy development board and connect it to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n<img src=\"../../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Windows 10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install the USB driver manually:\n    ![](../../../assets/get_started/win_device_2.png)\n\n2. Open the link in the previous section to download the driver\n    ![](../../../assets/get_started/win_device_3.png)\n\n3. Click Install\n    ![](../../../assets/get_started/drives.gif)\n\n4. After the installation is complete, you can see in the device manager that two serial devices have been identified (only one serial port is available)\n    ![](../../../assets/get_started/win_device_4.png)"}, "/soft/maixpy/en/get_started/install_driver/go.html": {"title": "Maix Go USB Driver Installation", "content": "---\ntitle: Maix Go USB Driver Installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Go USB driver installation\n---\n\n\nThe firmware of this `STM32` chip is shipped with [open-ec](https://github.com/sipeed/open-ec) firmware by default. If there is no problem, one or two serial ports will appear, such as `Linux There are two serial ports `/dev/ttyUSB0` and `/dev/ttyUSB1` under `. Please use `/dev/ttyUSB1` when downloading and accessing the serial port. Windows is similar.\n\nIf you need to re-burn this firmware, you can download it from [github](https://github.com/sipeed/open-ec/releases) or [download open-ec firmware from the official website](http://dl.sipeed.com/ MAIX/tools/flash-zero.bin), and then use `ST-LINK` to connect the `SW` pins (`GND`, `SWDIO`, `SWCLK`) of `STM32` on the board to burn. (The `STM32` on the current version of the `Go` board does not support serial port programming. You can only use `ST-LINK` for programming. If necessary, please purchase it yourself, or use a board to simulate it with `IO` ( Such as Raspberry Pi))\n\nIn addition to `open-ec`, there is also `CMSIS-DAP` firmware. Compared with `open-ec`, it can simulate `JTAG` to debug the board. Currently, `open-ec` does not support simulation of `JTAG`. Download the firmware from the official website](http://dl.sipeed.com/MAIX/tools/cmsis-dap/), use `ST-LINK` to burn it, there will be `/dev/ttyACM0` under `Linux` equipment\n\n> ST-LINK has complete information on the programming method of `STM32`, please search by yourself\n\n**Please note that updating the firmware of STM32 is not the same as updating the firmware of MaixPy. Generally, there is no need to update the firmware of STM32. The default is enough. STM32 is just a USB-to-serial tool! ! ! Don't be confused. . . **\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\nThe development board uses a `STM32` to realize the analog serial port and the `JTAG` function. `Windows` needs to install the driver of `FT2232`.\n\n-USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n\nWhen we get the MaixPy development board and connect it to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n<img src=\"../../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Windows 10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install the USB driver manually:\n    ![](../../../assets/get_started/win_device_2.png)\n\n2. Open the link in the previous section to download the driver\n    ![](../../../assets/get_started/win_device_3.png)\n\n3. Click Install\n    ![](../../../assets/get_started/drives.gif)\n\n4. After the installation is complete, you can see in the device manager that two serial devices have been identified (only one serial port is available)\n    ![](../../../assets/get_started/win_device_4.png)"}, "/soft/maixpy/en/get_started/install_driver/duino.html": {"title": "Maix Duino USB Driver Installation", "content": "---\ntitle: Maix Duino USB Driver Installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Maix Duino USB driver installation\n---\n\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\nThe development board uses the `CH552` chip to realize the `USB` to serial port function. There is no `JTAG` simulation function. `Windows` needs to install the `FT2232` driver.\n\n- USB driver: **FT2232** ->[[download link here](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)](https://dl.sipeed.com/MAIX/tools/ftdi_vcp_driver)\n\nWhen we get the MaixPy development board and connect it to the computer, we can open the device manager to check whether the serial port driver has been installed. The methods to open the device manager are:\n\n- This computer (right click) -> Properties -> Device Manager\n- Start menu (right click) -> Device Manager\n- Control Panel -> (Search) Device Manager\n\n<img src=\"../../../assets/get_started/win_device_1.png\" height=\"400\">\n\n1. When our system is a Windows 10 system, the system will automatically install the driver for us, and if it is an old version of Win7, win8, we need to install the USB driver manually:\n    ![](../../../assets/get_started/win_device_2.png)\n\n2. Open the link in the previous section to download the driver\n    ![](../../../assets/get_started/win_device_3.png)\n\n3. Click Install\n    ![](../../../assets/get_started/drives.gif)\n\n4. After the installation is complete, you can see in the device manager that two serial devices have been identified (only one serial port is available)\n    ![](../../../assets/get_started/win_device_4.png)"}, "/soft/maixpy/en/get_started/install_driver/dock.html": {"title": "Maix Dock USB driver installation", "content": "---\ntitle: Maix Dock USB driver installation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: Maix Dock USB driver installation\n---\n\n## Linux\n\nLinux does not need to install the driver, the system comes with it, use `ls /dev/ttyUSB*` to see the device number\n\n## Windows\n\n`Maix Dock` uses `CH340` as the driver chip.`Windows` users need to install the driver of `CH340`.\n\nWindows download [ch340 ch341 driver](https://api.dl.sipeed.com/shareURL/MAIX/tools/ch340_ch341_driver) and install it, and then you can see the serial device in the `Device Manager`"}, "/soft/maixpy/en/get_started/upgrade_esp32_firmware.html": {"title": "Update onboard ESP32 firmware", "content": "---\ntitle: Update onboard ESP32 firmware\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: update onboard ESP32 firmware\n---\n\n\n## Introduction:\n\nIn the MaixPy series of development boards, MaixDuino has an ESP32 WIFI SOC onboard. By default, we don’t need to update the onboard ESP32 module, but we find that there are bugs in the use process and fix them, we need to update the repaired firmware.\n\n## Update ESP32 firmware steps\n\n### Preparation\n\n\n- Hardware: MaixDuino, USB Type-C data cable\n- Software: ESPFLASH\n\n- ESP32 firmware update tool: ESP32 **flash_download_tools**\n  -Download link: [**flash_download_tools**](https://www.espressif.com/zh-hans/support/download/other-tools)\n- ESP32 MaixDuino firmware:\n  -Download link: [**flash_download_tools**](https://cn.dl.sipeed.com/MAIX/factory_firmware/)\n\n### Update process:\n\n1. Download **flash_download_tools**,\n\n   ![flash_download_tools](../../assets/hardware/module_esp32/image-20200504164050916.png)\n   ![flash_download_tools](../../assets/hardware/module_esp32/image-20200504164221705.png)\n\n2. Download **MaixDuino ESP32 firmware**\n   ![update esp32](../../assets/hardware/module_esp32/image-20200504164245329.png)\n\n3. Connect MaixDuino, select ESP32 serial port (usually the serial port number is relatively large)\n\n4. Set download options:\n   1. Configure the corresponding options as shown in the figure, and note that the **baud rate must be set to 115200**\n\n   ![b6474ddd5340cc9b7cf6006f75974a7b.png](../../assets/hardware/module_esp32/image-20200504164320888.png)\n   ![acf618a24b4cb8c5f8c2e98acc6cf11b.png](../../assets/hardware/module_esp32/image-20200504164450650.png)\n\n5. Click **Start** to update the firmware and wait for the update to complete\n\n6. Verify that the update is complete\n\n   1. Using XCOM, open the ESP32 serial port, click RST to reset ESP32, the flashing is successful as shown in the figure\n\n   ![96e955badd7450e7b5ba58230ae12c48.png](../../assets/hardware/module_esp32/image-20200504164747839.png)"}, "/soft/maixpy/en/get_started/upgrade_esp8285_firmware.html": {"title": "Update onboard ESP8285 firmware", "content": "---\ntitle: Update onboard ESP8285 firmware\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: update onboard ESP8285 firmware\n---\n\n\n## Introduction:\n\nAt present, MaixPy series adopt M1W module as the core module development boards: MaixDock(M1W), MaixGo\n\nNormally we don’t need to update the firmware of the WIFI SOC ESP8285 inside the module, but if there is a bug in the use process, and a new version of the firmware is released, we can update the firmware\n\n> The ESP8285 in the M1W module used by MaixDock and MaixGo burns AT firmware by default\n\n## Verify that ESP8285 can work normally\n\n- MaixPy verifies whether ESP8285 is working properly\n\n> View the end of text routine\n\n- External USB to serial module test\n\n   Use USB to serial port module, connect according to the following table, and then power on\n\n| M1W | USB Module | Description |\n| --- | --- | --- |\n| M1W GND | GND | Common ground |\n| K210 (IO6)/ESP8285 TX | RX |-|\n| K210 (IO7)/ESP8285 RX | TX |-|\n| k210 RST (ground before power on, pull down RST during the whole process) | GND |\n\n   After power-on, the board will output serial port (here XCOM, baud rate 115200) to verify whether ESP8285 starts normally\n   ![image-20200805175207487](../../assets/hardware/module_esp8285/image-20200805175207487.png)\n\n\n## AT command set\n\nESP8285 and ESP8266 are the same series of products, using the same set of AT commands\nESP8285/ESP8266/ESP32 latest AT command set https://github.com/espressif/esp-at/blob/v2.0.0.0_esp8266/docs/ESP_AT_Commands_Set.md\n\n\n## Update ESP8285 firmware steps\n\nBefore burning ESP8285 firmware, first understand the ESP8285 burning principle:\n\n### ESP8285 firmware burning principle\n\nWhen ESP8285 is powered on, it will determine the state of the boot stapping pin and determine the boot mode, such as:\n\n> ets Jan 8 2013,rst cause:1, boot mode:(3,2)\n\nThe first digit (3) of the printed boot mode represents the current boot mode.\nBoot mode is determined by the 3-bit value of strapping pin [GPIO15, GPIO0, GPIO2]. As shown in the following table\nShow:\n\n| 3-bit value of strapping pin/[GPIO15, GPIO0, GPIO2] | Boot mode |\n| --- | --- |\n| 7 / [1, 1, 1] | SDIO HighSpeed ​​V2 IO |\n| 6 / [1, 1, 0] | SDIO LowSpeed ​​V1 IO |\n| 5 / [1, 0, 1] | SDIO HighSpeed ​​V1 IO |\n| 4 / [1, 0, 0] | SDIO LowSpeed ​​V2 IO |\n| 3 / [0, 1, 1] | Flash Boot |\n| 2 / [0, 1, 0] | Jump Boot |\n| 1 / [0, 0, 1] | UART Boot |\n| 0 / [0, 0, 0] | Remapping |\n\n\nPlease see the following table for the IO level of ESP8285 entering different modes:\n\n| Mode | CH_PD(EN) | RST | GPIO15 | GPIO0 | GPIO2 | TXD0 |\n| :------------- | :-------- | :--- | :----- | :---- | :---- | ---- |\n| UART download mode | High | High | Low | Low | High | High |\n| Flash operating mode | High | High | Low | High | High | High |\n| Chip Test Mode |-|-|-|-|-| Low |\n\nThat is, ESP8285 enters UART download mode, the first bit of the startup information mode should be mode:(1, X), as follows:\n\n> ets Jan 8 2013,rst cause:1, boot mode:(1,1)\n\n\nTaking MaixDock as an example, you can see the schematic diagram of MaixDock as follows:\n\n![](../../assets/hardware/maix_dock/sipeed_maix_dock_sch_wifi.png)\n\n![](../../assets/hardware/maix_dock/sipeed_maix_dock_sch_wifi_spi.png)\n\n### Preparation\n\n> Here is MaixDock(M1W), Windows 10 system as an example\n\n- Hardware: MaixDock, USB Type-C data cable\n- Software:\n\n- ESP firmware update tool: ESP8285 **flash_download_tools**\n  - Espressif's official website download link: [**flash_download_tools**](https://www.espressif.com/zh-hans/support/download/other-tools)\n\n- ESP8285 AT firmware:\n  - Download link: [**ESP8266 AT bin**](https://cn.dl.sipeed.com/MAIX/factory_firmware/)\n - Espressif's official download link: [espressif_esp8266-at](https://www.espressif.com/zh-hans/support/download/at?keys=&field_type_tid%5B%5D=14)\n\n   ![](../../assets/hardware/module_esp8285/image-20210105192007.png)\n\n\n\n### Windows uses flash_download_tools to update ES8285 (here, MaixDock is taken as an example):\n\n1. Follow the configuration below to connect to MaixDock,\n\n    Connect the USB to serial port module and ESP8285, the connection method has been introduced above\n    Before power-on, GPIO0 needs to be pulled down, that is, the contact in the upper left corner next to the antenna is grounded to enter the UART download mode.\n\n![](../../assets/hardware/maix_dock/maix_dock_2.jpg)\n\n\n1. Open **flash_download_tools**\n\n2. Download **MaixDock ESP8285 firmware**\n\n    ![](../../assets/hardware/module_esp8285/flash_download_tool.png)\n\n3. Select ESP8285 serial port (usually the serial port number is relatively large)\n\n4. Set download options:\n\n    Configure the corresponding options as shown in the figure, note that the baud rate must be set to 115200**\n\n    ![](../../assets/hardware/module_esp8285/flash_download_tool_ESP8285.png)\n\n5. Click **Start** to update the firmware and wait for the update to complete\n\n6. Verify that the update is complete\n\n   - Use the XCOM baud rate of 115200, open the ESP8285 serial port, and output `AT\\r\\n`, as shown in the figure, it prompts `OK` to flash in successfully\n    ![esp8285_at.png](../../assets/hardware/maix_dock/esp8285_at.png)\n\n### LINUX uses esp_tool to update ES8285 (here, MaixDock is taken as an example):\n\n\n1. Follow the configuration below to connect to MaixDock,\n\n    ![](../../assets/hardware/maix_dock/sipeed_maix_dock_m1w_2.png)\n\n2. Install esptool\n\n    ```shell\n    pip3 install esptool\n    ```\n\n3. Download **MaixDock ESP8285 firmware**\n\n    ```shell\n    ls /dev/ttyUSB* # View USB serial port\n    esptool --port /dev/ttyUSB0 write_flash 0x0 ESP8285-AT-V1.7.4_8Mbit_40Mhz.bin # Burn the firmware\n    ```\n\n4. Verify that the update is complete\n\n    Use XCOM baud rate 115200, open ESP8285 serial port, output `AT\\r\\n`, as shown in the figure, prompt `OK`, then flashing is successful\n    ![esp8285_at.png](../../assets/hardware/maix_dock/esp8285_at.png)\n\n\n### MaixPy routine test:\n\n\n\n```python\nimport network, time\nfrom machine import UART\nfrom Maix import GPIO\nfrom fpioa_manager import fm\n\n# En SEP8285 rst\n#fm.register(8, fm.fpioa.GPIOHS0, force=True)\n#wifi_en=GPIO(GPIO.GPIOHS0, GPIO.OUT)\n#wifi_en.value(1)\n# En SEP8285 rst\nfm.register(0, fm.fpioa.GPIOHS0, force=True)\nwifi_io15=GPIO(GPIO.GPIOHS0, GPIO.OUT)\nwifi_io15.value(0)\n\nfm.register(8, fm.fpioa.GPIOHS1, force=True)\nwifi_en=GPIO(GPIO.GPIOHS1, GPIO.OUT)\nwifi_en.value(1)\n# for new MaixGO board, if not, remove it\n#fm.register(0, fm.fpioa.GPIOHS1, force=True)\n#wifi_io15_en=GPIO(GPIO.GPIOHS1, GPIO.OUT)\n#wifi_io15_en.value(0)\n\nfm.register(6, fm.fpioa.UART2_RX, force=True)\nfm.register(7, fm.fpioa.UART2_TX, force=True)\n\nuart = UART(UART.UART2,115200,timeout=1000, read_buf_len=4096)\n\ndef wifi_enable(en):\n    global wifi_en\n    wifi_en.value(en)\n\ndef wifi_deal_ap_info(info):\n    res = []\n    for ap_str in info:\n        ap_str = ap_str.split(\",\")\n        info_one = []\n        for node in ap_str:\n            if node.startswith('\"'):\n                info_one.append(node[1:-1])\n            else:\n                info_one.append(int(node))\n        res.append(info_one)\n    return res\n\n\n#wifi_enable(0)\ntime.sleep(2)\nnic = network.ESP8285(uart)\n\nap_info = nic.scan()\nap_info = wifi_deal_ap_info(ap_info)\n\nap_info.sort(key=lambda x:x[2], reverse=True) # sort by rssi\nfor ap in ap_info:\n    print(\"SSID:{:^20}, RSSI:{:>5}, MAC:{:^20}\".format(ap[1], ap[2], ap[3]))\n\n\n```"}, "/soft/maixpy/en/get_started/maixpy_get_started_video.html": {"title": "MaixPy video tutorial", "content": "---\ntitle: MaixPy video tutorial\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: MaixPy video tutorial\n---\n\n\nThe video briefly introduces the basic getting started process. In fact, the document will be more detailed. The video only provides a more intuitive reference for getting started. It will be easier for some people to watch the video to get started. In addition, the document version in this video is the originalVersion, the new document directory structure has been adjusted appropriately, please draw inferences about it:\n\n<iframe width=\"800\" height=\"600\" src=\"//player.bilibili.com/player.html?aid=52613549&cid=92076022&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\"framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\nIt is recommended to enter [Bilibili](https://www.bilibili.com/video/av52613549?zw) to log in to see the high-definition version. If the rhythm is too slow, you can right-click to adjust the speed~"}, "/soft/maixpy/en/get_started/env_maixpyide.html": {"title": "MaixPy IDE installation and use", "content": "---\ntitle: MaixPy IDE installation and use\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: MaixPy IDE installation and use\n---\n\n\n![maixpy_ide_start](../../assets/maixpy/maixpy_ide_start.png)\n\n## About MaixPy IDE\n\n\n![MaixPy IDE](../../assets/maixpy/maixpy_ide.png)\n\nFirst of all, you need to clarify: **MaixPy** uses `Micropython` script syntax, so it does not need to be compiled like `C` language. In fact, it can be used happily without `IDE`: Use the serial terminal tool, which has been installed before\n\nUsing `IDE` will facilitate real-time editing of scripts on the computer and upload to the development board, execute scripts directly on the development board, and view camera images on the computer in real time, save files to the development board, etc.\n\nOf course, the use of `IDE` will consume some resources for compression and transmission, so the performance will be reduced, and if MaixPy is down, there is no serial terminal to find the problem.\n\n\n\n## MaixPy firmware\n\nTo use `MaixPy IDE`, the firmware must be `v0.3.1` or higher, otherwise MaixPyIDE will not be connected. Try to check the firmware version and IDE version before use, and update to the latest version to ensure normal use\n\n## Download the installation package\n\n[dl.sipeed.com](http://dl.sipeed.com/MAIX/MaixPy/ide/)\n\nPlease refer to the `readme.txt` file in the latest version folder for the description of the file list. If the download speed is slow, please use the cdn link to download\n\n## Installation\n\n#### If it is an installer (**recommended**, simple and convenient)\n\n`Windows` directly double-click the `exe` file to run the installer; `Linux` command line to run the permission and then execute\n\n```shell\nchmod +x maixpy-ide-linux-x86_64-0.2.2.run\n./maixpy-ide-linux-x86_64-0.2.2.run\n```\n\n#### If it is a compressed package (`7z`)\n\nUnzip to folder\n\n> If the system does not support `7z`, you need to [download `7z` decompression tool](https://www.7-zip.org/), then use `7z`\n\nYou can also double-click the compressed package to decompress it under `Linux`!\n\nIf you need to use the terminal to decompress, you can refer to the following command:\n\n```bash\nsudo apt install p7zip-full\n7z x maixpy-ide-linux-x86_64-0.2.2-installer-archive.7z -r -omaixpy-ide\n# `-o` is directly followed by the decompressed path, without spaces.\n```\n\n* After decompression, execute\n  * If it is `Windows`: directly double-click `maixpyide` to execute, you can right-click to fix it to the start page or fix it to the taskbar for later use\n  * `Linux`: execute\n\n```\nchmod +x setup.sh\n./setup.sh\n./bin/maipyide.sh\n```\n\n\n\n## Test run\n\nOpen MaixPy IDE, select the model of the development board in the upper toolbar. **Please select Maixduino to connect to amigo and cube development board**.\n\n`Tool-> Select Board` (Tool->Select Board)\n\nClick `connect` to connect to `MaixPy IDE`\n\n![connect-icon.png](../../assets/maixpy/maixpy_connect_icon.png)\n\nAfter the connection is successful, the link button will change from green to red.\n\n![connect-success.png](../../assets/maixpy/maixpy_connect-success.png)\n\nBelow the link button is the run button, which will execute the `py` file in the current editing area.\n\n\n\n![helloworld-run.png](../../assets/maixpy/maixpy_helloworld.png)\n\nClick the run button (red) again to stop running the current code.\n\n## upload files\n\nYou can choose to send files in the **Tool/Tools** menu\n\n\n## Note\n\n* After clicking the connection, do not use it with the terminal tool at the same time, otherwise the serial port will be occupied and cannot be opened\n* If you have been unable to successfully connect successfully, check:\n  * Please check whether the development board model selection is wrong;\n  * Observe whether there is any change on the development board screen, if there is no response, it may be the serial port selection error;\n  * Try to upgrade to the latest [master branch firmware](http://cn.dl.sipeed.com/MAIX/MaixPy/release/master), and the latest MaixPy IDE software\n\n\n## Find the reason according to the error message\n\nWhen the program runs incorrectly, a pop-up box will prompt an error, but the error information may not be complete, please **look for more detailed error information in the terminal output**\n\nIf necessary, please disconnect the IDE, and only use the serial terminal to run the program (maybe you need to save the program to a file first, and then run the file) to check and print to troubleshoot\n\nIf you submit a problem (bbs, group, github issue, etc.), in order to solve the problem quickly, please be sure to bring the complete information described above"}, "/soft/maixpy/en/get_started/env_install_driver.html": {"title": "Install USB driver", "content": "---\ntitle: Install USB driver\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: install USB driver\n---\n\n\nBefore officially using MaixPy, we need to install the serial port driver before proceeding with the next development and use; because the board is connected to the computer through a USB to serial device (K210 has no USB hardware support function).\nInstall the driver according to the board's USB to serial chip model.\n\n> Operate the serial port under `Linux` or `Mac`, if you don’t want to use the `sudo` command every time, execute `sudo usermod -a -G dialout $(whoami)` to add yourself to the `dialout` user group, May need to log off or restart to take effect\n\n\n- Description of the USB to serial port IC on the existing development board\n\n| Development board model | USB to serial port IC | Description |Installation tutorial|\n| --- | --- | --- | --- |\n| Maix Go | STM32 | STM32 USB emulation FT2232 |[Go](install_driver/go.md)|\n| Maix Dock | CH340 | |[Dock](install_driver/dock.md)|\n| Maix Duino | CH552 | CH552 Simulation FT2232 |[Duino](install_driver/duino.md)|\n| Maix Bit | CH552 (new version)/CH340 (old version) | CH552 analog FT2232 |[Bit](install_driver/bit.md)|\n| Maix Cube | GD32(new version)/CH552(old version) | CH552 simulation FT2232 |[Cube](install_driver/ft2232.md)|\n| Maix Amigo | GD32 | GD32 simulation FT2232 |[Amigo](install_driver/ft2232.md)|\n| Maix Nano | CH552 | CH552 Analog FT2232 |[Nano](install_driver/nano.md)|\n| Grove AI HAT | GD32 | GD32 simulation FT2232 |[Amigo](install_driver/ft2232.md)|\n\n\n> Use the CH340 IC board to directly install the CH340 driver, and all others use the FT2232 driver.\n\n## About the troubleshooting of USB serial ports\n\nIf you do not see the serial port, please troubleshoot hardware problems in the following order.\n\n- If there is a ding-dong sound when plugged in to the computer, such as the sound of USB driver loading when the USB flash drive is inserted, it does not indicate that there is a problem with the serial chip on the hardware.\n-Replace the cable and try again, replace the computer's USB port and try again, but still can't be loaded, replace the computer to confirm.\n\nIf there is no way to burn the firmware, please troubleshoot hardware problems in the following order.\n\n- Use serial port tool to check whether there is maixpy ​​firmware in the hardware\n- Set 115200 baud rate to connect to the serial port, press the reset button (RST) to receive the data from the chip, no matter what it is, it means that the serial port chip is working normally, if not, it means the hardware is abnormal.\n- Based on the above, proceed to burn the firmware. Before burning, press the BOOT button of the hardware and then press the reset button, then release the BOOT button. At this time, the burning will proceed normally. If not, the Flash is damaged. You can try to burn to SRAM. If the programming fails, it means the serial port chip is abnormal.\n- If you still can’t solve the problem when you get here, the hardware is indeed defective\n\n### Introduction to K210's programming mechanism\n\nWe often call this a one-key download circuit, which means that it can easily control the BOOT and RST pins through the completion of the RST and DTR of the control serial port to enter the burning mode. As described above, the hardware circuit is expected to be automatically completed by humans. Press RST after BOOT. This is strongly related to the hardware implementation. Based on this, the TX and RX data transmission will be carried out, so we actually need to use the function pins of the UART serial port.\n\nThere are multiple types of triggers in Kflash.\n\nWe can simply divide them into several types, low-speed 115200 and high-speed 1.500000 baud rate. The difference is based on the programming methods that match these two types of baud rates. Point, if you find that the download process fails, you can appropriately reduce the baud rate. This is caused by the unstable operation of the serial port chip, and the selection of the layout in the tool will only affect the triggering of the first stage of the programming mode, and after that The configured baud rate will be used in the programming firmware, usually not exceeding the communication programming speed with the flash, which is usually 50~60 KB/S.\n\nIf you find that you cannot enter the programming mode anyway, either the programming version does not match, or there is a problem with the DTR RST pin of the serial chip (physically)."}, "/soft/maixpy/en/get_started/get_started_fs.html": {"title": "Introduction to Storage System", "content": "---\ntitle: Introduction to Storage System\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: storage system introduction\n---\n\n\nThe MaixPy storage system is roughly as shown in the figure below:\n\n![](../../assets/get_started/memory.png)\n\nAs can be seen from the above figure, the storage medium in MaixPy is mainly composed of `Flash` and `SD` cards, which are divided into three areas, namely MaixPy.bin firmware area, xxx.kmodel model area, and file system area: Flash is [ `spiffs`](https://github.com/pellepl/spiffs) (SPI Flash File System), SD card is Fatfs (FAT file system).\n\n## MaixPy.bin firmware area\n\nIt is used to store MaixPy.bin firmware, starting at 0x000000, because K210 will start to run the program from 0x000000.\n\n## xxx.kmodel model area\n\nIt usually starts at 0x300000. The reason why the model file is not burned in the file system of `Flash` (the file system will be explained later) is due to the following reasons:\n\n1. The memory of the file system in `Flash` is not large enough to fit in a large model, and a larger model can be placed in an SD card.\n2. Reading model files directly is faster than reading through the file system.\n\nThere is no file system management in this area. You need to operate files based on the starting address during programming. For example, the reading method when the model is programmed at 0x500000:\n\n```python\nKpuTask = kpu.load(0x500000)\n```\n\n## File system area\n\nUsually starting from 0xD00000, this area is managed by the file system. We reserve the space `3MiB` at the end of `Flash`, which will be managed by [`spiffs`](https://github.com/pellepl/spiffs), and Also supports `FAT32` (Fatfs) `SD` card. These file systems provide interfaces so that we can read and write files through **file name** instead of using **file start address** as in the model area. At the same time, it can also help us effectively manage storage media. For example, wear leveling (Flash has a wear life, please search for relevant knowledge) can give full play to the life of Flash.\n\n### Use of MaixPy File System\n\nBecause the file systems of `Flash` and `SD` cards are different and the interfaces are inconsistent, different file systems need to call different interfaces. At this time, the virtual file system (VFS) in MaixPy is used to solve this problem, `VFS `You can mount multiple file systems of different types, and provide a unified interface for users to operate these file systems, and users can ignore the differences between different file systems when using these interfaces. These interfaces are implemented in the `os` module. Examples of usage are as follows:\n\n```python\nimport uos\n\nprint(\"files:\", uos.listdir(\"/flash\"))\n\nwith open(\"/flash/test.txt\", \"w\") as f:\n    f.write(\"hello text\")\n\nprint(\"files:\", uos.listdir(\"/flash\"))\n\nwith open(\"/flash/test.txt\", \"r\") as f:\n    content = f.read()\n\nprint(\"read:\", content)\n```\n\nIn the above example, the `spiffs` file system is automatically mounted to the `/flash` directory when booting. The user only needs to pass in the `\"/flash\"` directory name as a parameter when using the `os` interface to access the file system .\n\nInterpretation:\n\n* Import the `uos` module\n* List all files in the `/flash` directory\n* Write a file named `test.txt` to the `/flash` directory with the content of `hello text`,\n* List all files in the `/flash` directory, you will find the existence of `test.txt`\n* Read the content of the file into the `content` variable\n* Print the `content` variable and output `hello text`, which is the content of the file just written\n* This content is powered on after the development board is powered off, the correct content can still be read (the content will not be lost after the Flash is powered off)\n\nOf course, SD card is also supported. If you need to use it, SD card needs to meet the following points:\n\n* Support `SPI` mode, most genuine cards on the market support\n* The partition is `MBR (msdos)`\n* Format as `FAT32`\n* The size tested is the largest `128GiB` available\n\nsAfter inserting the `SD` after power off, the `SD` card will be mounted on `/sd` if it is powered on. If there are multiple partitions, the second partition name is `/sd2`\n\nNote that `/` (root directory) cannot write data, only write data to `/flash` or `/sd`\nIf there is a `SD` card at boot, it will automatically switch the current directory to `/sd`, if not, it will automatically switch to `/flash`"}, "/soft/maixpy/en/get_started/get_started_upload_script.html": {"title": "Upload scripts & modules to the development board", "content": "---\ntitle: Upload scripts & modules to the development board\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: upload scripts & modules to the development board\n---\n\n\n\nEarlier we came into contact with the direct execution of `pye(\"filename.py\")` command to open an editor, which can directly edit files in the file system\n\nBut slowly we will find that this method is only suitable for changing a small amount of code. When the amount of code is huge or we need highlighting support, it is not applicable. We need to write the code on the computer and upload it to the board. Inside the file system\n\nThere are currently the following methods:\n\n### Use MaixPy IDE to upload scripts to the development board\n\nOpen `MaixPy IDE`, connect to the development board\n\nEdit the file, and then in the top `Tool` (tool) menu, click `Save the opened file as boot.py` to save the code to the `boot.py` file of the development board. Next time the development board is powered on This file will be executed automatically\n\nOf course, you can also use the `send file` function in the top `Tool` menu to send a file. It will be saved to the development board and the file name is the same as the file name on the computer. )\n\n![](../../assets/maixpy/maixpy_ide_tools.png)\n\n\n\n## Use the graphical tool uPyLoader to upload and run scripts\n\n[uPyLoader](https://github.com/BetaRavener/uPyLoader) is an open source software, with which you can easily connect to MaixPy and upload, download, execute files, and monitor output at the same time. The functions are relatively complete\n\nDownload the executable file: [release](https://github.com/BetaRavener/uPyLoader/releases)\n\n![uPyLoader](../../assets/other/uPyLoader.png)\n\nSelect the serial port and click the `Connect` button to connect to the board\n\nThe software needs to be initialized the first time to run the software. Click `File->Init transfer files` to complete the initialization. This will create two files on the board, namely `__upload.py` and `__download.py`.\n\nSelect the file to be uploaded on the left and click `Transfer` to upload to the file system of the board.\n\nOn the right is the file in the board, click on `List files` to refresh the file list, select the file name, click on `Execute` to execute the script file\n\nClick on the above `View -> terminal` to open the terminal to view the runtime output or send commands\n\n\n## Use tool rshell\n\nJust like using the `linux` terminal, use the `cp` command of [rshell](https://github.com/dhylands/rshell) to simply copy files to the development board\n\nInstall `rshell` according to the instructions of `rshell` project homepage\n\n```python\nsudo apt-get install python3-pip\nsudo pip3 install rshell\nrshell -p /dev/ttyUSB1 # Here, choose the serial port according to the actual situation\n```\n\n```python\nls /flash\ncp ./test.py /flash/ #Copy the file test.py in the current directory of the computer to the flash root directory of the development board\n```\n\nOf course, there are more functions, please visit its [Project Homepage](https://github.com/dhylands/rshell)\n\n\n## Use the command line tool ampy\n\n[ampy](https://github.com/pycampers/ampy) is a simple and easy-to-use command line tool to upload, download and execute files, and it is open source\n\nNote that this tool is running on the computer, not on the board\n\nUse `ampy --help` to view help information\n\nUse the `ampy run file_in_PC.py` command to run the script directly on the board instead of uploading the script to the board\n\n\n## SD（TF） Direct operation\n\nAfter copying to the SD card, execute `import filename` or `exec()` in the terminal to run the script\n\n## SD card is automatically copied to Flash file system\n\n\nIn order to copy the contents of the SD card to the Flash file system conveniently, only need to rename the file to be copied to the Flash file system to `cover.boot.py` or `cover.main.py`, and then put it in the root of the `SD` card Directory, the development board is powered off and inserted into the `SD` card, and then the development board is powered on, the program will automatically copy these two files to `/flash/boot.py` or `/flash/main.py`, so that even later Take out the `SD` card, the program is already in `/flash/boot.py` or `/flash/main.py`"}, "/soft/maixpy/en/get_started/get_started_boot.html": {"title": "boot script", "content": "---\ntitle: boot script\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: boot script\n---\n\n\nThe system will create the `boot.py` file and `main.py` in the `/flash` or `/sd` (priority) directory, and automatically execute `boot.py` first, and then execute `main.py` (if If the SD card is detected, execute the SD card), edit the contents of these two scripts to achieve self-startup. If you write an infinite loop (While True) program in `boot.py`, it will cause `main.py `Can't run (call `boot.py` first and then `main.py`), and re-send `boot.py` without infinite loop to solve it.\n\n- boot.py is mainly used to configure the hardware and only needs to be configured once.\n- main.py can be used for the main running program.\n\nThe corresponding specific implementation [code here](https://github.com/sipeed/MaixPy/blob/972059491227ece63fbfc2cd0e78fe13ee78427d/components/micropython/port/src/maixpy_main.c#L586-L595), if you have any questions, just look at the source .\n\nnote:\n    * The Micro SD card should be formatted as FAT (FAT32) file system\n    * FAT formatted memory card will be mounted to `/sd`, and SPIFFS in internal Flash will be mounted to `/flash`"}, "/soft/maixpy/en/get_started/get_started_cam_lcd.html": {"title": "", "content": "---\ntitle: First program: Use screen and camera\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: first program: use screen and camera\n---\n\n\nThe development board has a matching camera and screen, please check whether the hardware connection is correct before powering on(**Align according to the No. 1 pin marked on the cable**)\n\nThen power on, open the serial terminal, press the keyboard `Ctrl+E`, and paste the following code:\n\n```python\nimport sensor, lcd\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\nsensor.skip_frames()\n\nlcd.init(freq=15000000)\n\nwhile(True):\n    lcd.display(sensor.snapshot())\n\n```\nPress the keyboard `Ctrl+D` to start running the code\n\nYou will find that the screen is lit, and the picture taken by the camera is displayed\n\nIf it displays `reset fail`, the camera is not connected well, or the camera is damaged, or check whether an unsupported camera is used\n\nThe meaning of the above programs can be found in the API manual, which can be found in the directory on the left, or you can use the search box in the upper left corner to search.\nNow explain the above program:\n\n* `import sensor, lcd`: first import the built-in `sensor` (camera) library and `lcd` (screen) library\n* `sensor.reset()`: Initialize the camera. If it fails, check the hardware\n* `sensor.set_pixformat(sensor.RGB565)`: Set the camera to `RGB565` format, the default is to use `RGB565`\n* `sensor.set_framesize(sensor.QVGA)`: The resolution is `QVGA`, that is, `320x240`\n* `sensor.run(1)`: start to run, it is not necessary to call it in the current version, the camera will automatically start to run after the above settings are completed\n* `sensor.skip_frames()`: The image quality is not stable when the camera is just started, so some images are skipped\n* `lcd.init(freq=15000000)`: Initialize the LCD, here is a parameter called `freq`, frequency, which specifies the clock frequency for driving the LCD, here is `15MHz`, which can be adjusted according to the hardware performance\n* `while(True)`: This is a loop, the code inside the loop will be run continuously\n* `sensor.snapshot()`: fetch a frame of image data from the camera, the return value is an image object\n* `lcd.display()`: display image to LCD\n* `lcd.display(sensor.snapshot())`: here is to execute the image acquisition in brackets first, and the return value is directly displayed as a parameter to the LCD"}, "/soft/maixpy/en/get_started/knowledge_audio.html": {"title": "Audio processing background knowledge", "content": "---\ntitle: Audio processing background knowledge\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: audio processing background knowledge\n---\n\n\n## What is sound (audio)\n\n> People are rational, and the world is emotional.\n\nWhat is audio, audio is vibration.\nThe vibration of light particles forms light waves, namely light;\n\nAnd the vibration of universal objects forms sound waves, that is, sound\n\n## Audio coding basics\n\n- Number of channels (number of channels)\n\nThat is, the number of sound channels. When recording the sound, simultaneously record the audio of different spatial positions, that is, record multi-channel audio;\n\nCommon audio files are divided into mono and stereo, that is, mono records audio at a single location, while stereo has left and right channels to record audio at different spatial locations, and can play different channels of audio through different speakers. In this way, the audio of different spatial positions is restored, and the human ear can feel the different spatial positions through audio (more spatial sense).\n\n- Number of sampling bits\n\nThat is, the sampling value or sampling value (that is, the sampling sample amplitude is quantized). It is a parameter used to measure the fluctuation of sound, and it can also be said to be the resolution of the sound card. The larger its value, the higher the resolution and the stronger the sound power.\n\nThe number of sampling bits in a computer is generally divided into 8 bits and 16 bits, but please note that 8 bits does not mean dividing the ordinate into 8 parts, but divided into 2 to the 8th power, which is 256 parts; the same is true for 16 bits. It divides the ordinate into 2 to the 16th power of 65536.\n\n- Sampling frequency\n\nThat is, the sampling frequency, which refers to the number of times a sound sample is obtained per second. The higher the sampling frequency, the better the sound quality, and the more realistic the sound reproduction, but at the same time it occupies more resources. Due to the limited resolution of the human ear, too high a frequency cannot be distinguished. In the 16-bit sound card, there are 22KHz, 44KHz, etc., of which 22KHz is equivalent to the sound quality of ordinary FM broadcasting, and 44KHz is equivalent to the sound quality of CD. The current common sampling frequency does not exceed 48KHz.\n\n## PCM of audio encoding processing\n\nPCM introduction\n\nAt present, we all need to rely on audio files for audio playback on computers. The generation process of audio files is the process of sampling, quantizing and encoding sound information. The lowest frequency of the sound that human ears can hear is from From 20Hz to the highest frequency 20Khz, so the maximum bandwidth of the audio file format is 20Kzh. According to Nyquist's theory, only when the sampling frequency is higher than twice the highest frequency of the sound signal, can the sound represented by the digital signal be restored to the original sound, so the sampling rate of the audio file is generally 40~50KHZ, such as the most common The CD sound quality sampling rate is 44.1KHZ.\n\nThe process of sampling and quantizing the sound is called Pulse Code Modulation, or PCM for short. From the above three concepts of sampling frequency, number of sampling bits, and number of channels, the three concepts can be derived from the following formula. PCM file in the computer The amount of storage space occupied:\n\nPCM audio data size = (sampling frequency * number of sampling bits * channel * time)//8 (unit: Bytes).\n\nSince PCM data is the most primitive audio data, it is completely lossless to the sampled data. Although PCM data has excellent sound quality, its volume is still too large for computer storage. In order to solve this problem, a series of audio formats have been born. These audio formats use Different methods are used to compress audio data, including lossless compression (ALAC, APE, FLAC) and lossy compression (MP3, AAC, OGG, WMA).\n\n## WAV\n\nWaveform Audio File Format (WAVE, or WAV known by the public because of its extension) is an encoding format developed by Microsoft and IBM to store audio streams on personal computers. The application software on the Windows platform is widely supported. The status is similar to AIFF in Macintosh computers. This format is one of the applications of the Resource Exchange File Format (RIFF), and the audio data modulated by pulse code is usually stored in blocks. It is also one of the designated specifications commonly used among music enthusiasts. Since this audio format is not compressed, there will be no distortion in sound quality, but the volume of the file is larger among many audio formats.\n\nAll WAVs have a file header, which is the encoding parameter of the audio stream. WAV has no hard and fast rules on the encoding of audio streams. In addition to PCM, almost all encodings that support the ACM specification can encode WAV audio streams. WAV can also use a variety of audio encodings to compress its audio stream, but we are usually WAV whose audio stream is encoded by PCM, but this does not mean that WAV can only use PCM encoding. MP3 encoding can also be used in WAV. Like AVI, as long as the corresponding Decode is installed, you can enjoy these WAVs.\n\nUnder the Windows platform, WAV based on PCM encoding is the best supported audio format. All audio software can perfectly support it. Because it can meet the requirements of higher sound quality, WAV is also the preferred format for music editing and creation. Suitable for saving music material. Therefore, WAV based on PCM encoding is used as an intermediary format, which is often used in the mutual conversion of other encodings, such as converting MP3 to WMA.\n\n**In MaixPy, the WAV file format supported by the aduio module is PCM_s16le (signed 16 bits little endian, signed 16 bits little endian)**"}, "/soft/maixpy/en/how_to_read.html": {"title": "How to read this article correctly", "content": "---\ntitle: How to read this article correctly\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: how to read this article correctly\n---\n\n\n**Note: Currently the only official document website: [maixpy.sipeed.com](https://maixpy.sipeed.com)**\n\n\n## First, please read carefully the directory structure on the left sidebar to take a look at the contents of the document\n\n* **Introduction**: MiaxPy's introduction, works display, and development history, etc.\n* **Getting Started**: The introductory tutorial for using MaxiPy, including the basic knowledge, must be read to avoid many problems and save a lot of time for subsequent development\n* **Hand-in-hand tutorial**: Here is a step-by-step teaching of the use of various functions. It is useful for students who are just getting started and don’t know what to do. Read carefully.\n* **API Manual**: API manuals of each functional module, convenient to refer to during programming\n  * **Standard Library**: micropython standard library, many APIs are compatible with python3 APIs\n  * **machine**: machine related, restart control, machine UID, and various peripheral control\n  * **Maix**: Some special modules, such as FPIOA, KPU, FFT, etc.\n  * **Built-in class**: Built-in class written in mpy (short for micropython), which can be found in the source code project\n  * **Machine Vision**: Some machine vision related modules, image sensor lcd is roughly compatible with OpenMV API, but will not be updated with OpenMV in real time later\n  * **Additional Peripheral Modules**: The use of some peripheral modules, such as touch screen, ultrasonic, LED lights, etc.\n  * **Built-in applications**: Built-in applications, such as NES game console (FC gamer), pye (built-in document editor)\n* **Frequently Asked Questions FAQ**: Summary of frequently asked questions\n* **Advanced**: Some advanced gameplay, and how to participate in the modification of the document and the modification of the source code, or the contribution of the routine\n* **Community & Sharing**: Collect some good tutorials, works, open source projects, etc. from the community. You can also share your own works or tutorials according to the contribution instructions\n\n## Important must-read part\n\n**Introduction** and **Getting Started Guide**, be sure to read them completely, and you must read it first if you encounter problems **FAQ**\n\n\n## Start learning\n\n* Just contact, you can read carefully from top to next page according to the table of contents on the left sidebar, just follow along, don’t skip the entry! ! !\n* Learn how to update the firmware and how to write code. It is also very important to learn how to use a serial terminal. It is not recommended to rely too much on the IDE, especially when the program dies, the terminal may get more error messages, which is more conducive to solving the problem. When encountering problems and asking questions in the community, try to give complete information about the terminal operation\n* Each module/library document is accompanied by a simple routine at the end, or here: [MaixPy_script](https://github.com/sipeed/MaixPy_scripts) to find the examples you need, you can try to run it to see the effect\n\n## Learn to search\n\n* Regarding the interface and parameters of the module, please refer to it according to your needs when using it. **There is a search box** in the upper right corner, which can be used well. At the same time, you can also use the browser's page search function, that is, press the keyboard <kbd> Ctrl +F </kbd>, then enter the content to be searched and press the confirm key\n* Please don’t worry if there is anything you can’t find, you can go to the [issue](https://github.com/sipeed/MaixPy/issues) page of github to find (search and search) if anyone has mentioned it , If not, you can create a new issue, or go to [Forum](https://bbs.sipeed.com) to search for the issue, and don’t ask for help anymore, or contact technical support.\n\n## FAQ of this document\n\n* PDF generation is added to the document, but try not to spread the PDF version, because the PDF cannot be updated in time after the content is updated, try to visit this website (`https://maixpy.sipeed.com`) to view the document\n\n* If the web page loads slowly, please try to refresh or wait, or change the line (try using a proxy or changing mobile phone data)\n\n* This document has two domain names: `https://maixpy.sipeed.com` and `https://cn.maixpy.sipeed.com`, you can visit the other if you can’t access one\n\n* The document uses gitbook to automatically generate static pages from markdown. If you encounter some pages that cannot be accessed, please check whether the URL (path) is correct, and you can return to the home page (`maixpy.sipeed.com`) and enter again.\n\nFor example, this URL is caused by a poor network condition and a quick click:\n```\nhttp://localhost:4000/zh/zh/how_to_read.html\n```\nThe correct URL should be:\n```\nhttp://localhost:4000/zh/how_to_read.html\n```\n\n\n\n## MaixPy FAQ\n\n* For frequently asked questions, please see [FAQ](./others/maixpy_faq.html)\n\n\n## Other tutorials\n\n* In addition to the documentation, you can also browse [blog](http://blog.sipeed.com), tutorials written by [BBS](https://bbs.sipeed.com) users, or Baidu search, and various developers’ Blogs, there will be many development tutorials, development diaries, etc., you can refer to\n\n## Questioning skills\n\nAsk questions in various places, whether it’s github or QQ groups, forums, or emails. When asking questions, try to provide complete steps to reproduce the problem. You should use the process you have gone through, how the problem occurred, and what the phenomenon is It must be fully explained. Don't be afraid of too many words. Think about the problem from the perspective of the solver. Can the developer solve the problem? It is convenient for developers to test and solve problems during their busy schedule!\n\nFor more details, please see the next section [How to ask questions elegantly](./how_to_ask.html)"}, "/soft/maixpy/en/firmware/online_compile.html": {"title": "Firmware online compilation", "content": "---\ntitle: Firmware online compilation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: firmware online compilation\n---\n\n\nOnline compilation does not need to build a compilation environment, just select the required modules and click compile, the compilation process will be completed in the cloud, and the firmware will be sent by email\n\nVisit [maixhub](https://www.maixhub.com/compile.html) for firmware customization"}, "/soft/maixpy/en/firmware/compile.html": {"title": "source code compilation", "content": "---\ntitle: source code compilation\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: source code compilation\n---\n\n\nThe pre-compiled firmware may not meet specific usage scenarios. If you need to modify the configuration, please configure and compile the required firmware\n\n## Native environment compilation\n\nFor the compilation method, please refer to the compilation instructions under the source code [build.md](https://github.com/sipeed/MaixPy/blob/master/build.md)\n\n## Use docker environment to compile\n\nDocker can simplify development environment installation\n> If you have never used docker, please learn about docker by yourself,\n> If you haven't studied before, you can think of it as similar to a virtual machine, that is, a virtual machine with a compilation environment has been prepared for you, and you can download and run it directly to compile the source code\n\nThe docker image has already packaged the environment, just pull the image and run it to start compiling, refer to [Use Docker to compile the source code](https://github.com/sipeed/MaixPy/tree/master/tools/docker)"}, "/soft/maixpy/en/firmware/why_customize_firware.html": {"title": "Why need firmware customization", "content": "---\ntitle: Why need firmware customization\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: why need firmware customization\n---\n\n\n\nMainly to save memory.\n\nThe memory of the chip is `6MiB` general purpose memory + `2MiB` AI dedicated memory, which is really very large compared to ordinary single-chip microcomputers. If AI function is not used, we can use the entire `8MiB` memory.\nBut because many times we need to run a model, a model may reach `3MiB` or even larger, and the firmware also needs to take up memory.\nSo in order to run a larger model, we need to compromise and cut some unnecessary functions.\n\nIn the previous chapter of firmware update, many firmware versions were introduced and compiled, including `minimum`, `with_v4_support`, `with_ide_support`, and `with_lvgl`,\nThese firmwares may be used in different situations. such as:\n\n* Cut IDE code, if you don't need to connect MaixPy IDE, you can cut IDE part to save memory.\n\n* Cut the OpenMV function, the firmware is compatible with some functions of OpenMV, if you use the model, these functions may not be needed, you can cut it out.\n\n* Tailoring multithreading support, if you don't need multithreading support, you can trim this part to get more memory space.\n\nTherefore, if you are using a certain function, and you find the prompt `ImportError: no module named'XXX'`, it may be that you are using a firmware that does not include this function. For example, the `minimum` firmware does not include IDE and `image.find_blobs` Function, if this firmware is burned, it will be unable to connect for a long time if you connect to the `IDE` again. Using the function `iamge.find_blobs` will also prompt that the function definition cannot be found."}, "/soft/maixpy/en/SUMMARY.html": {"title": "Summary", "content": "---\ntitle: Summary\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: Summary\n---\n\n\n* [Introduction](README.md)\n* [What can MaixPy do](./what_maix_do.html)\n* [MaixPy Development History](./maixpy_history.html)\n* [Thanks](./thanks.html)\n\n\n## Getting started must see guide\n\n* [How to read this article correctly (important!!!)](./how_to_read.html)\n* [How to ask questions elegantly (important!!!)](./how_to_ask.html)\n* Development board and accessories selection guide\n  -[Development Board Selection Guide (Comparison)](./develop_kit_board/get_hardware.html)\n  -Development board introduction\n    -[Maix Dock](./develop_kit_board/maix_dock.html)\n    -[Maix Bit](./develop_kit_board/maix_bit.html)\n    -[Maix Amigo](./develop_kit_board/maix_amigo.html)\n    -[Maix Duino](./develop_kit_board/maix_duino.html)\n    -[Maix Cube](./develop_kit_board/maix_cube.html)\n    -[Maix Go](./develop_kit_board/maix_go.html)\n    -[Maix Nano](./develop_kit_board/maix_nano.html)\n  -Peripheral modules (accessories)\n    -[SP-MOD](./modules/sp_mod/index.html)\n    -[Grove](./modules/grove/index.html)\n    -[Other](./modules/others/index.html)\n* Basic knowledge\n  -[MaixPy Grammar Basics](./get_started/knowledge_micropython.html)\n  -[git and github](./get_started/knowledge_git_github.html)\n  -[MaixPy image basics](./get_started/knowledge_image.html)\n  -[MaixPy Audio Basic Knowledge](./get_started/knowledge_audio.html)\n* Development environment preparation\n  -[Install Driver](./get_started/env_install_driver.html)\n    -[Maix Dock](./get_started/install_driver/dock.html)\n    -[Maix Bit](get_started/install_driver/bit.md)\n    -[Maix Amigo](get_started/install_driver/amigo.md)\n    -[Maix Cube](get_started/install_driver/cube.md)\n    -[Maix Go](get_started/install_driver/go.md)\n    -[Maix Nano](get_started/install_driver/nano.md)\n  -[Update MaixPy firmware](./get_started/upgrade_maixpy_firmware.html)\n  -[Use serial terminal tool](./get_started/env_serial_tools.html)\n  -[MaixPy IDE Instructions for Use](./get_started/env_maixpyide.html)\n  -Update WIFI module firmware\n    -[Update onboard ESP32 firmware](./get_started/upgrade_esp32_firmware.html)\n    -[Update onboard ESP8285 firmware](./get_started/upgrade_esp8285_firmware.html)\n* Get started\n  -[Power on](/get_started/get_started_power_on.html)\n  -[First program: Use screen and camera](./get_started/get_started_cam_lcd.html)\n  -[Second program: turn on the LED](./get_started/get_started_led_blink.html)\n  -[Storage System Introduction](./get_started/get_started_fs.html)\n  -[Edit and run script](./get_started/get_started_edit_file.html)\n  -[Upload script to development board](./get_started/get_started_upload_script.html)\n  -[Automatically run script at boot](./get_started/get_started_boot.html)\n  -[Development board configuration file](./api_reference/builtin_py/board_info.html)\n  -[Getting started video tutorial](./get_started/maixpy_get_started_video.html)\n* Firmware customization\n  -[Why custom firmware is needed](./firmware/why_customize_firware.html)\n  -[Online Compile](./firmware/online_compile.html)\n  -[Source code compilation](./firmware/compile.html)\n\n\n## MaixPy hands-on tutorial\n\n* [Tutorial Description](./course/index.html)\n* Basic image processing\n  * Image acquisition and display\n    * [Image Acquisition](./course/image/basic/get_images.html)\n    * [Image display](./course/image/basic/display_images.html)\n  * [MaixPy image and common operations](./course/image/basic/vary.html)\n  * [Basic drawing, writing](./course/image/basic/draw.html)\n  * [Hardware accelerated image processing](./course/image/basic/acc_image_deal.html)\n* MaixPy AI\n  * [Basic knowledge of deep neural networks](./course/ai/basic/dnn_basic.html)\n  * [MaixPy AI hardware acceleration basic knowledge](./course/ai/basic/maixpy_hardware_ai_basic.html)\n  * Image Processing\n    * [Face Detection](./course/ai/image/face_detect.html)\n    * [1000 object classification](./course/ai/image/1000_type_classifier.html)\n    * [Face Recognition](./course/ai/image/face_recognization.html)\n    * [Self-learning classification](./course/ai/image/self_learn_classifier.html)\n  * Audio processing\n    * [Speech recognition](./course/speech/recognizer_cnn.html)\n* Model training\n  * Train your own classification and detection model\n    * [MaixHub Cloud Training](./course/ai/train/maixhub.html)\n    * [Local Training](./course/ai/train/local.html)\n* Traditional algorithm\n  * Image Processing\n    -[Find color blocks](./course/image/find_color_blob.html)\n    -[QR code recognition](course/image/find_qrcodes.md)\n  * Audio processing\n    -[FFT](course/speech/fft.md)\n    -[FFT waterfall chart](course/speech/fft_waterfall.md)\n    -[Keyword recognition](./course/speech/recognizer_mfcc.html)\n* Peripherals\n  * On-chip peripherals\n    -[I2C](modules/on_chip/i2c.md)\n    -[PWM](modules/on_chip/pwm.md)\n    -[SPI](modules/on_chip/spi.md)\n    -[Timer](modules/on_chip/timer.md)\n    -[UART](modules/on_chip/uart.md)\n    -[I2S](modules/on_chip/i2s.md)\n    -[WDT](modules/on_chip/wdt.md)\n  * [SP-MOD](./modules/sp_mod/index.html)\n    -[BT Bluetooth transparent transmission](./modules/sp_mod/sp_bt.html)\n    -[LoRa Wireless Communication](./modules/sp_mod/sp_lora.html)\n    -[RFID Radio Frequency Identification](./modules/sp_mod/sp_rfid.html)\n    -[TOF Ranging](./modules/sp_mod/sp_tof.html)\n    -[Eink electronic ink screen](./modules/sp_mod/sp_eink.html)\n    -[Lcd1.14 IPS screen](./modules/sp_mod/sp_lcd1.14.html)\n    -[Weather Weather Module](./modules/sp_mod/sp_weather.html)\n    -[Ethernet wired network port](modules/sp_mod/sp_ethernet.md)\n  * [Grove](./modules/grove/index.html)\n    -[Ultrasonic Ranger](modules/grove/grove_ultrasonic_ranger.md)\n    -[Chainable RGB LED light](modules/grove/grove_chainable_rgb_led.md)\n    -[RGB LED Ring strip](modules/grove/grove_rgb_led_ring.md)\n  * More peripherals\n    -[Sipeed Microphone Array](./develop_kit_board/module_microphone.html)\n    -[Dual camera module](modules/others/binocular_camera.md)\n    -[MLX90640 serial infrared lens](modules/others/mlx90640.md)\n    -[HTPA infrared lens](modules/others/htpa.md)\n    -[Servo](modules/others/servo.md)\n    -[ESP32 ADC](./modules/others/esp32_read_adc.html)\n    -[onwire single bus](modules/others/onewire.md)\n* More features\n  * System\n    -[Main frequency, reset, etc.](./course/others/system.html)\n    -[Memory Configuration and View](./course/others/mem.html)\n  * GUI\n    -[Multi-language support including Chinese](./course/image/image_draw_font/image_draw_font.html)\n    -[Maix UI](./course/others/maixui.html)\n    -[Lvgl](./course/others/lvgl.html)\n    -[Editor pye](./course/others/pye.html)\n  * The internet\n    -[Configure network card](./course/network/network_config.html)\n    -[Use socket communication](./course/network/socket_usage.html)\n  * Multimedia\n    -[audio](./course/media/audio.html)\n    -[video](./course/media/video.html)\n  * Game\n    -[NES game console](./api_reference/media/nes.html)\n\n## API Manual\n\n* [Standard Library](./api_reference/standard/index.html)\n  -[cmath](./api_reference/standard/cmath.html)\n  -[gc](./api_reference/standard/gc.html)\n  -[math](./api_reference/standard/math.html)\n  -[sys](./api_reference/standard/sys.html)\n  -[ubinascii](./api_reference/standard/ubinascii.html)\n  -[ucollections](./api_reference/standard/ucollections.html)\n  -[uctypes](./api_reference/standard/uctypes.html)\n  -[uerrno](./api_reference/standard/uerrno.html)\n  -[uhashlib](./api_reference/standard/uhashlib.html)\n  -[uheapq](./api_reference/standard/uheapq.html)\n  -[ujson](./api_reference/standard/ujson.html)\n  -[uos](./api_reference/standard/uos.html)\n  -[ure](./api_reference/standard/ure.html)\n  -[usocket](./api_reference/standard/usocket.html)\n  -[ustruct](./api_reference/standard/ustruct.html)\n  -[utime](./api_reference/standard/utime.html)\n  -[uzlib](./api_reference/standard/uzlib.html)\n* [machine](./api_reference/machine/index.html)\n  -[I2C](./api_reference/machine/i2c.html)\n  -[PWM](./api_reference/machine/pwm.html)\n  -[SPI](./api_reference/machine/spi.html)\n  -[Timer](./api_reference/machine/timer.html)\n  -[UART](./api_reference/machine/uart.html)\n  -[network](./api_reference/machine/network.html)\n  -[WDT](api_reference/machine/wdt.md)\n* [Maix](./api_reference/Maix/index.html)\n  -[FPIOA](./api_reference/Maix/fpioa.html)\n  -[GPIO](./api_reference/Maix/gpio.html)\n  -[KPU](./api_reference/Maix/kpu.html)\n  -[FFT](./api_reference/Maix/fft.html)\n  -[I2S](./api_reference/Maix/i2s.html)\n  -[freq](./api_reference/Maix/freq.html)\n  -[utils](./api_reference/Maix/utils.html)\n* [helper](./api_reference/builtin_py/index.html)\n  -[fpioa_manager](./api_reference/builtin_py/fm.html)\n  -[board_info](./api_reference/builtin_py/board_info.html)\n  -[Micropython Editor](./api_reference/application/pye.html)\n* [media](./api_reference/machine_vision/index.html)\n  -[lcd](./api_reference/machine_vision/lcd.html)\n  -[sensor](./api_reference/machine_vision/sensor.html)\n  -[image](api_reference/machine_vision/image/image.md)\n  -[video](./api_reference/media/video.html)\n  -[audio](./api_reference/media/audio.html)\n  -[nes](./api_reference/media/nes.html)\n  -[lvgl](./course/others/lvgl.html)\n  -[isolated_word](./api_reference/machine_vision/isolated_word.html)\n  -[maix_asr](./api_reference/machine_vision/maix_asr.html)\n* [extend](./api_reference/extend/index.html)\n  -[touchscreen](./api_reference/extend/touchscreen.html)\n  -[modules.ultrasonic](./api_reference/extend/ultrasonic.html)\n  -[modules.ws2812](./api_reference/extend/ws2812.html)\n  -[modules.htpa](./api_reference/extend/htpa.html)\n  -[modules.onewire](./api_reference/extend/onewire.html)\n\n\n## Frequently Asked Questions FAQ\n\n* [MaixPy Frequently Asked Questions FAQ](./others/maixpy_faq.html)\n* [MaixHub platform FAQ](./others/maixhub_faq.html)\n\n\n## Advanced\n\n* Advanced development\n  -[Source directory structure](./course/advance/project_framework.html)\n  -[How to compile MaixPy project](course/advance/compile.md)\n  -[How to add a MaixPy module with C](./course/advance/add_c_module.html)\n  -[Packing File System](./course/advance/pack_fs.html)\n\n* Participate in contribution\n  -[Participate in document writing (specification)](./contribute/doc_convention.html)\n  -[Code Writing Specification](./contribute/code_convention.html)\n\n\n## Community & Share\n\n-[Featured Articles](./share/recommend_articles.html)\n-[Open source project](./share/open_projects.html)\n-Everyone's experience sharing\n  * [Participation in experience sharing/sharing template](./share/my_share/index.html)"}, "/soft/maixpy/en/course/image/basic/acc_image_deal.html": {"title": "Hardware accelerated image processing", "content": "---\ntitle: Hardware accelerated image processing\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: hardware accelerated image processing\n---\n\n\nUsing hardware to replace certain software parts can make the calculation faster. The methods of acceleration optimization have been done as follows:\n\nThe following code respectively performs `edge search`, `sharpening`, and `embossing` on the image, and uses the convolution calculation to quickly obtain the result.\n\n```python\nimport sensor\nimport image\nimport lcd\nimport time\n\nlcd.init(freq=15000000)\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\norigin = (0,0,0, 0,1,0, 0,0,0)\nedge = (-1,-1,-1,-1,8,-1,-1,-1,-1)\nsharp = (-1,-1,-1,-1,9,-1,-1,-1,-1)\nrelievo = (2,0,0,0,-1,0,0,0,-1)\n\ntim = time.time()\nwhile True:\n    img=sensor.snapshot()\n    img.conv3(edge)\n    lcd.display(img)\n    if time.time() -tim >10:\n        break\ntim = time.time()\nwhile True:\n    img=sensor.snapshot()\n    img.conv3(sharp)\n    lcd.display(img)\n    if time.time() -tim >10:\n        break\ntim = time.time()\nwhile True:\n    img=sensor.snapshot()\n    img.conv3(relievo)\n    lcd.display(img)\n    if time.time() -tim >10:\n        break\n\nlcd.clear()\n```"}, "/soft/maixpy/en/course/image/basic/get_images.html": {"title": "get image", "content": "---\ntitle: get image\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy ​​doc: get image\n---\n\n\nYou can get images from the camera, you can read picture files from the file system, or you can get pictures from the network\n\n## Get from camera\n\n\nThis part has been mentioned in the previous tutorial\n\n```\nimport sensor, lcd\n\nsensor.reset()\nsensor.set_pixformat(sensor.RGB565)\nsensor.set_framesize(sensor.QVGA)\nsensor.run(1)\nsensor.skip_frames()\n\nimg = sensor.snapshot()\nprint(img)\n```\n\n* `import sensor`: first import the built-in `sensor` (camera) library\n* `sensor.reset()`: Initialize the camera. If it fails, check the hardware\n* `sensor.set_pixformat(sensor.RGB565)`: Set the camera to `RGB565` format, the default is to use `RGB565`\n* `sensor.set_framesize(sensor.QVGA)`: The resolution is `QVGA`, that is, `320x240`\n* `sensor.run(1)`: start to run, it is not necessary to call it in the current version, the camera will automatically start to run after the above settings are completed\n* `sensor.skip_frames()`: The image quality is not stable when the camera is just started, so some images are skipped\n* `sensor.snapshot()`: fetch a frame of image data from the camera, the return value is an image object\n\nIn addition to the above functions, you may also need to set the image to mirror (`hmirror`), such as the front camera; or flip up and down (`vflip`), and white balance, etc., see [sensor module API manual](/ api_reference/machine_vision/sensor.html)\n\n\n## Read from file\n\n```python\nimport image\n\nimg = image.Image(\"/sd/test.jpg\")\nprint(img)\n```\n\nOf course you can also save the picture to the file system`\n```python\nimg.save(\"/sd/test2.jpg\", quality=95)\n```\n\n\n## Read from memory (or read from network)\n\nYou can read the file to the memory first, depending on your application where you read it from, such as network, or serial port SPI, etc.\nConstruct a `bytes` object\n\n```python\nimport image\n\njpeg_buff = b'\\xFF' # jpeg buffer\nimg = image.Image(jpeg_buff, from_bytes = True)\nprint(img)\n```\n\n## Create a blank image directly\n\n```python\nimport image\n\nimg = image.Image(size=(320, 240))\n```\n\nThis picture is a black blank image"}, "/soft/maixpy/en/course/image/basic/display_images.html": {"title": "Show picture", "content": "---\ntitle: Show picture\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: show picture\n---\n\n\n\nDisplaying the picture is very simple. You can use the `lcd` module directly and call the function to display it, as follows:\n\n```python\nimport lcd, image\n\nlcd.init()\n\nimg = image.Image(\"/sd/test.jpg\")\nlcd.display(img)\n```\n\nBut different screen initialization sequence may be different. There are many optional parameters in `lcd.init`. See the description of API document for details. Common ones are as follows\n\nFor IPS screens, you need to reverse the color:\n```python\nlcd.init(type=2)\n```\n\nFor the screen is not very good, you need to lower the frequency, or if you are good, you need to overclock:\n```python\nlcd.init(freq = 15000000)\n```\n\nIn addition, you can also set the rotation direction of the screen:\n```python\nlcd.rotation(2)\n```\nThe parameters are `0～3`, which respectively represent clockwise rotation `0 degrees` `90 degrees` `180 degrees` `270 degrees`\n\nFor more methods, please refer to [lcd document](/api_reference/machine_vision/lcd.html)"}, "/soft/maixpy/en/course/image/basic/draw.html": {"title": "drawing and writing", "content": "---\ntitle: drawing and writing\nkeywords: maixpy, k210, AIOT, edge computing\ndesc: maixpy doc: drawing, writing\n---\n\n\n\nThere are two ways, the second is recommended\n\n## First, use the `lcd` module to draw directly on the screen\n\n```python\nimport image, lcd\n\nlcd.init()\n\nlcd.draw_string(0, 0, \"hello\")\n```\n\nFor more functions and parameters, please refer to [lcd API Manual](/api_reference/machine_vision/lcd.html)\n\n## Second, use the `image` module to draw in the memory, and use the `lcd.display` function to display the entire picture on the screen after drawing\n\n```python\nimport image, lcd\n\nlcd.init()\n\nimg = image.Image(size=(320, 240))\nimg.draw_string(0,0, \"hello\")\nlcd.display(img)\n\n```\n\nFor more functions and parameters, please see [image API manual](/api_reference/machine_vision/image/image.html), search for `image.draw` on the page to find all drawing functions\nFor Chinese (multi-language) support, please see [How to display Chinese](/course/image/image_draw_font/image_draw_font.html), or search for \"font\"."}, "/soft/maixpy/en/no_translate.html": {"title": "no translation", "content": "---\ntitle: no translation\nclass: md_page\n---\n\n\n<div id=\"visit_from\"></div>\n<div id=\"no_translate_hint\">This page not translated yet</div>\n<div>\n    <span id=\"visit_hint\">Please visit</span>\n    <a id=\"translate_src\"></a>\n</div>\n\n<div>\n    <script>\n        function getQueryVariable(variable)\n        {\n            var query = window.location.search.substring(1);\n            var vars = query.split(\"&\");\n            for (var i=0;i<vars.length;i++) {\n                    var pair = vars[i].split(\"=\");\n                    if(pair[0] == variable){return pair[1];}\n            }\n            return(false);\n        }\n        var ref = getQueryVariable(\"ref\");\n        var from = getQueryVariable(\"from\");\n        var link = document.getElementById(\"translate_src\");\n        var fromDis = document.getElementById(\"visit_from\");\n        link.href = ref;\n        link.text = ref;\n        fromDis.innerHTML = from;\n    </script>\n</div>"}}